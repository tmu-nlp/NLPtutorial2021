2
<s> Natural	0.005380476556495004
Natural language	0.6923076923076923
language processing	0.22297297297297297
processing -LRB-	0.07407407407407407
-LRB- NLP	0.008130081300813009
NLP -RRB-	0.0851063829787234
-RRB- is	0.02981029810298103
is a	0.10975609756097561
a field	0.0036809815950920245
field of	0.4444444444444444
of computer	0.0035650623885918
computer science	0.09090909090909091
science ,	0.4
, artificial	0.0011229646266142617
artificial intelligence	0.6363636363636364
intelligence -LRB-	0.125
-LRB- also	0.01084010840108401
also called	0.043478260869565216
called machine	0.05555555555555555
machine learning	0.24050632911392406
learning -RRB-	0.023255813953488372
-RRB- ,	0.21138211382113822
, and	0.10612015721504772
and linguistics	0.002890173410404624
linguistics concerned	0.05
concerned with	0.8
with the	0.15300546448087432
the interactions	0.0006920415224913495
interactions between	1.0
between computers	0.02564102564102564
computers and	0.1111111111111111
and human	0.001445086705202312
human -LRB-	0.043478260869565216
-LRB- natural	0.0027100271002710027
natural -RRB-	0.013333333333333334
-RRB- languages	0.0027100271002710027
languages .	0.16
. <\s>	0.9875195007800313
Natural	0.00036270297416438817
language	0.00412923385971765
processing	0.0015066123542213047
-LRB-	0.010295184420512249
NLP	0.0013113107527481726
-RRB-	0.010295184420512249
is	0.013726912560682997
a	0.02273868645722895
field	0.0007533061771106523
of	0.03130405669326489
computer	0.0012276100664025446
science	0.00027900228781876013
,	0.04969030746052117
artificial	0.00030690251660063614
intelligence	0.0002232018302550081
also	0.0019251157859494449
called	0.0005022041180737682
machine	0.002204118073768205
learning	0.0011997098376206685
and	0.019306958317058198
linguistics	0.0005580045756375203
concerned	0.00013950114390938006
with	0.00510574186708331
the	0.040315830589810836
interactions	2.7900228781876013e-05
between	0.0010881089224931645
computers	0.0002511020590368841
human	0.0012834105239662966
natural	0.0020925171586407007
languages	0.0013950114390938006
.	0.03576809329836505
<\s>	0.036298197645220694
<s> Specifically	0.0007686395080707148
Specifically ,	1.0
, it	0.01347557551937114
it is	0.20512820512820512
is the	0.09146341463414634
the process	0.007612456747404845
process of	0.3333333333333333
of a	0.08199643493761141
a computer	0.018404907975460124
computer extracting	0.022727272727272728
extracting meaningful	0.2
meaningful information	0.125
information from	0.06521739130434782
from natural	0.009615384615384616
natural language	0.76
language input	0.02027027027027027
input and\/or	0.024390243902439025
and\/or producing	0.3333333333333333
producing natural	0.3333333333333333
language output	0.006756756756756757
output .	0.15384615384615385
Specifically	2.7900228781876013e-05
it	0.0032643267674794933
process	0.0010044082361475365
extracting	0.00013950114390938006
meaningful	0.0002232018302550081
information	0.0012834105239662966
from	0.0029016237933151053
input	0.0011439093800569165
and\/or	8.370068634562804e-05
producing	8.370068634562804e-05
output	0.0007254059483287763
<s> In	0.07455803228285934
In theory	0.01904761904761905
theory ,	0.3076923076923077
, natural	0.0005614823133071309
processing is	0.037037037037037035
a very	0.013496932515337423
very attractive	0.024390243902439025
attractive method	0.3333333333333333
method of	0.125
of human	0.004456327985739751
human --	0.021739130434782608
-- computer	0.04
computer interaction	0.022727272727272728
interaction .	0.25
In	0.002929524022096981
theory	0.00036270297416438817
very	0.0011439093800569165
attractive	8.370068634562804e-05
method	0.0004464036605100162
--	0.0006975057195469003
interaction	0.0002232018302550081
language understanding	0.0945945945945946
understanding is	0.06060606060606061
is sometimes	0.006097560975609756
sometimes referred	0.23076923076923078
referred to	1.0
to as	0.005312084993359893
as an	0.04529616724738676
an AI-complete	0.007575757575757576
AI-complete problem	0.3333333333333333
problem because	0.022727272727272728
because it	0.1
it seems	0.008547008547008548
seems to	1.0
to require	0.0013280212483399733
require extensive	0.09090909090909091
extensive knowledge	0.3333333333333333
knowledge about	0.1111111111111111
about the	0.2
the outside	0.0006920415224913495
outside world	0.5
world and	0.06666666666666667
and the	0.059248554913294796
the ability	0.001384083044982699
ability to	0.75
to manipulate	0.0026560424966799467
manipulate it	0.3333333333333333
it .	0.042735042735042736
understanding	0.0009207075498019084
sometimes	0.00036270297416438817
referred	0.0002232018302550081
to	0.021008872272752638
as	0.008007365660398415
an	0.0036828301992076337
AI-complete	8.370068634562804e-05
problem	0.0012276100664025446
because	0.0008370068634562804
seems	5.5800457563752025e-05
require	0.0006138050332012723
extensive	8.370068634562804e-05
knowledge	0.0007533061771106523
about	0.0011160091512750405
outside	5.5800457563752025e-05
world	0.0004185034317281402
ability	0.00011160091512750405
manipulate	8.370068634562804e-05
<s> Whether	0.0015372790161414297
Whether NLP	0.5
NLP is	0.02127659574468085
is distinct	0.0020325203252032522
distinct from	0.42857142857142855
from ,	0.009615384615384616
, or	0.018528916339135316
or identical	0.0045045045045045045
identical to	1.0
to ,	0.0026560424966799467
, the	0.058394160583941604
the field	0.011764705882352941
of computational	0.00267379679144385
computational linguistics	0.6
linguistics is	0.15
a matter	0.001226993865030675
matter of	0.3333333333333333
of perspective	0.00089126559714795
perspective .	0.25
Whether	5.5800457563752025e-05
distinct	0.0001953016014731321
or	0.006193850789576474
identical	5.5800457563752025e-05
computational	0.00027900228781876013
matter	8.370068634562804e-05
perspective	0.00011160091512750405
<s> The	0.11222136817832437
The Association	0.005208333333333333
Association for	1.0
for Computational	0.0036101083032490976
Computational Linguistics	1.0
Linguistics defines	0.3333333333333333
defines the	0.5
the latter	0.0006920415224913495
latter as	1.0
as focusing	0.003484320557491289
focusing on	1.0
on the	0.30660377358490565
the theoretical	0.0006920415224913495
theoretical aspects	0.3333333333333333
aspects of	0.8571428571428571
of NLP	0.004456327985739751
NLP .	0.10638297872340426
The	0.0053568439261201944
Association	2.7900228781876013e-05
for	0.007728363372579655
Computational	8.370068634562804e-05
Linguistics	8.370068634562804e-05
defines	5.5800457563752025e-05
latter	2.7900228781876013e-05
focusing	2.7900228781876013e-05
on	0.005914848501757715
theoretical	8.370068634562804e-05
aspects	0.0001953016014731321
<s> On	0.003843197540353574
On the	0.3333333333333333
the other	0.005536332179930796
other hand	0.07142857142857142
hand ,	0.5
the open-access	0.0006920415224913495
open-access journal	1.0
journal ``	0.3333333333333333
`` Computational	0.005291005291005291
Linguistics ''	0.3333333333333333
'' ,	0.15463917525773196
, styles	0.0005614823133071309
styles itself	1.0
itself as	0.2
as ``	0.04878048780487805
`` the	0.026455026455026454
the longest	0.0006920415224913495
longest running	1.0
running publication	0.3333333333333333
publication devoted	0.3333333333333333
devoted exclusively	0.2
exclusively to	1.0
to the	0.10225763612217796
the design	0.001384083044982699
design and	0.25
and analysis	0.001445086705202312
analysis of	0.18461538461538463
of natural	0.0196078431372549
processing systems	0.05555555555555555
systems ''	0.008928571428571428
'' -LRB-	0.04639175257731959
-LRB- Computational	0.0027100271002710027
Linguistics -LRB-	0.3333333333333333
-LRB- Journal	0.0027100271002710027
Journal -RRB-	0.3333333333333333
-RRB- -RRB-	0.005420054200542005
-RRB- Modern	0.0027100271002710027
Modern NLP	0.3333333333333333
NLP algorithms	0.0425531914893617
algorithms are	0.05714285714285714
are grounded	0.008298755186721992
grounded in	1.0
in machine	0.009363295880149813
learning ,	0.09302325581395349
, especially	0.0050533408197641775
especially statistical	0.06666666666666667
statistical machine	0.09090909090909091
learning .	0.09302325581395349
On	0.00016740137269125608
other	0.0019530160147313209
hand	0.0003906032029462642
open-access	2.7900228781876013e-05
journal	8.370068634562804e-05
``	0.005273143239774566
''	0.005412644383683946
styles	2.7900228781876013e-05
itself	0.00013950114390938006
longest	2.7900228781876013e-05
running	8.370068634562804e-05
publication	8.370068634562804e-05
devoted	0.00013950114390938006
exclusively	2.7900228781876013e-05
design	0.00011160091512750405
analysis	0.0018135148708219408
systems	0.0031248256235701134
Journal	8.370068634562804e-05
Modern	8.370068634562804e-05
algorithms	0.0009765080073656604
are	0.006723955136432118
grounded	8.370068634562804e-05
in	0.01489872216952179
especially	0.0004185034317281402
statistical	0.0009207075498019084
<s> Research	0.0015372790161414297
Research into	0.125
into modern	0.01282051282051282
modern statistical	0.2
statistical NLP	0.06060606060606061
algorithms requires	0.02857142857142857
requires an	0.0625
an understanding	0.015151515151515152
understanding of	0.15151515151515152
a number	0.024539877300613498
number of	0.8372093023255814
of disparate	0.00089126559714795
disparate fields	1.0
fields ,	0.3333333333333333
, including	0.004491858506457047
including linguistics	0.14285714285714285
linguistics ,	0.4
, computer	0.0011229646266142617
and statistics	0.002890173410404624
statistics .	0.375
Research	0.0002232018302550081
into	0.002176217844986329
modern	0.00013950114390938006
requires	0.0004464036605100162
number	0.0011997098376206685
disparate	2.7900228781876013e-05
fields	0.00016740137269125608
including	0.0003906032029462642
statistics	0.0002232018302550081
<s> For	0.043812451960030745
For a	0.03278688524590164
a discussion	0.001226993865030675
discussion of	0.5
of the	0.17379679144385027
the types	0.001384083044982699
types of	0.8571428571428571
of algorithms	0.00089126559714795
algorithms currently	0.02857142857142857
currently used	0.14285714285714285
used in	0.20353982300884957
in NLP	0.0149812734082397
NLP ,	0.02127659574468085
, see	0.0011229646266142617
see the	0.1
the article	0.0006920415224913495
article on	0.034482758620689655
on pattern	0.0047169811320754715
pattern recognition	0.6666666666666666
recognition .	0.05785123966942149
For	0.0017019139556944368
discussion	5.5800457563752025e-05
types	0.0003906032029462642
currently	0.0001953016014731321
used	0.0031527258523519892
see	0.0005580045756375203
article	0.0008091066346744044
pattern	0.00016740137269125608
recognition	0.0033759276826069973
<s> An	0.008455034588777863
An automated	0.0625
automated online	0.14285714285714285
online assistant	0.125
assistant providing	1.0
providing customer	0.5
customer service	1.0
service on	0.2
on a	0.10849056603773585
a web	0.001226993865030675
web page	0.125
page ,	0.42857142857142855
, an	0.005614823133071308
an example	0.03787878787878788
example of	0.08641975308641975
of an	0.011586452762923352
an application	0.015151515151515152
application where	0.07142857142857142
where natural	0.02857142857142857
a major	0.006134969325153374
major component	0.08333333333333333
component .	0.2
An	0.0004464036605100162
automated	0.0001953016014731321
online	0.0002232018302550081
assistant	2.7900228781876013e-05
providing	5.5800457563752025e-05
customer	2.7900228781876013e-05
service	0.00013950114390938006
web	0.0002232018302550081
page	0.0001953016014731321
example	0.002259918531331957
application	0.0003906032029462642
where	0.0009765080073656604
major	0.00033480274538251215
component	0.00013950114390938006
In 1950	0.01904761904761905
1950 ,	1.0
, Alan	0.0005614823133071309
Alan Turing	1.0
Turing published	0.5
published his	0.14285714285714285
his famous	0.08333333333333333
famous article	0.3333333333333333
article ``	0.034482758620689655
`` Computing	0.005291005291005291
Computing Machinery	0.5
Machinery and	1.0
and Intelligence	0.001445086705202312
Intelligence ''	0.3333333333333333
'' which	0.005154639175257732
which proposed	0.007246376811594203
proposed what	0.1111111111111111
what is	0.09375
is now	0.006097560975609756
now called	0.07692307692307693
called the	0.1111111111111111
the Turing	0.0006920415224913495
Turing test	0.5
test as	0.1
as a	0.11846689895470383
a criterion	0.001226993865030675
criterion of	0.5
of intelligence	0.00089126559714795
intelligence .	0.125
1950	5.5800457563752025e-05
Alan	2.7900228781876013e-05
Turing	5.5800457563752025e-05
published	0.0001953016014731321
his	0.00033480274538251215
famous	8.370068634562804e-05
Computing	5.5800457563752025e-05
Machinery	2.7900228781876013e-05
Intelligence	8.370068634562804e-05
which	0.0038502315718988898
proposed	0.0002511020590368841
what	0.0008928073210200324
now	0.00036270297416438817
test	0.00027900228781876013
criterion	5.5800457563752025e-05
<s> This	0.03996925441967717
This criterion	0.015873015873015872
criterion depends	0.5
depends on	0.875
ability of	0.25
computer program	0.11363636363636363
program to	0.09090909090909091
to impersonate	0.0013280212483399733
impersonate a	1.0
a human	0.013496932515337423
human in	0.021739130434782608
in a	0.09363295880149813
a real-time	0.001226993865030675
real-time written	0.5
written conversation	0.038461538461538464
conversation with	0.5
with a	0.1092896174863388
human judge	0.021739130434782608
judge ,	0.25
, sufficiently	0.0005614823133071309
sufficiently well	1.0
well that	0.03571428571428571
that the	0.08156028368794327
the judge	0.0006920415224913495
judge is	0.25
is unable	0.0020325203252032522
unable to	1.0
to distinguish	0.006640106241699867
distinguish reliably	0.2
reliably --	1.0
-- on	0.04
the basis	0.002768166089965398
basis of	0.6666666666666666
the conversational	0.0006920415224913495
conversational content	1.0
content alone	0.08333333333333333
alone --	0.25
-- between	0.04
between the	0.1794871794871795
the program	0.0020761245674740486
program and	0.045454545454545456
and a	0.023121387283236993
a real	0.00245398773006135
real human	0.1111111111111111
human .	0.06521739130434782
This	0.0017577144132581888
depends	0.0002232018302550081
program	0.0006138050332012723
impersonate	2.7900228781876013e-05
real-time	5.5800457563752025e-05
written	0.0007254059483287763
conversation	0.00011160091512750405
judge	0.00011160091512750405
sufficiently	2.7900228781876013e-05
well	0.0007812064058925284
that	0.007867864516489036
unable	5.5800457563752025e-05
distinguish	0.00013950114390938006
reliably	2.7900228781876013e-05
basis	0.00016740137269125608
conversational	2.7900228781876013e-05
content	0.00033480274538251215
alone	0.00011160091512750405
real	0.0002511020590368841
The Georgetown	0.015625
Georgetown experiment	1.0
experiment in	0.2
in 1954	0.003745318352059925
1954 involved	0.3333333333333333
involved fully	0.3333333333333333
fully automatic	0.5
automatic translation	0.08695652173913043
translation of	0.14864864864864866
of more	0.0035650623885918
more than	0.042105263157894736
than sixty	0.022222222222222223
sixty Russian	1.0
Russian sentences	1.0
sentences into	0.039473684210526314
into English	0.02564102564102564
English .	0.13513513513513514
Georgetown	8.370068634562804e-05
experiment	0.00013950114390938006
1954	8.370068634562804e-05
involved	0.00016740137269125608
fully	0.00016740137269125608
automatic	0.0006417052619831483
translation	0.002064616929858825
more	0.002650521734278221
than	0.0012555102951844206
sixty	5.5800457563752025e-05
Russian	5.5800457563752025e-05
sentences	0.002120417387422577
English	0.0010323084649294125
The authors	0.015625
authors claimed	0.4
claimed that	1.0
that within	0.0070921985815602835
within three	0.1111111111111111
three or	0.3333333333333333
or five	0.0045045045045045045
five years	0.4
years ,	0.23809523809523808
, machine	0.0016844469399213925
machine translation	0.4936708860759494
translation would	0.02702702702702703
would be	0.16981132075471697
be a	0.05485232067510549
a solved	0.00245398773006135
solved problem	0.4
problem .	0.22727272727272727
authors	0.00013950114390938006
claimed	5.5800457563752025e-05
within	0.0005022041180737682
three	8.370068634562804e-05
five	0.00013950114390938006
years	0.0005859048044193963
would	0.0014787121254394287
be	0.006612354221304614
solved	0.00013950114390938006
<s> However	0.02843966179861645
However ,	0.8648648648648649
, real	0.0005614823133071309
real progress	0.1111111111111111
progress was	0.2857142857142857
was much	0.025974025974025976
much slower	0.09090909090909091
slower ,	1.0
and after	0.004335260115606936
after the	0.16666666666666666
the ALPAC	0.001384083044982699
ALPAC report	1.0
report in	0.25
in 1966	0.0018726591760299626
1966 ,	0.3333333333333333
, which	0.031443009545199324
which found	0.014492753623188406
found that	0.35714285714285715
that ten	0.0035460992907801418
ten years	1.0
years long	0.047619047619047616
long research	0.5
research had	0.047619047619047616
had failed	0.14285714285714285
failed to	1.0
to fulfill	0.0026560424966799467
fulfill the	0.5
the expectations	0.0006920415224913495
expectations ,	1.0
, funding	0.0016844469399213925
funding for	0.25
for machine	0.010830324909747292
translation was	0.02702702702702703
was dramatically	0.012987012987012988
dramatically reduced	1.0
reduced .	0.5
However	0.0010323084649294125
progress	0.0001953016014731321
was	0.0021483176162044528
much	0.0006138050332012723
slower	5.5800457563752025e-05
after	0.00033480274538251215
ALPAC	5.5800457563752025e-05
report	0.00011160091512750405
1966	8.370068634562804e-05
found	0.0003906032029462642
ten	2.7900228781876013e-05
long	5.5800457563752025e-05
research	0.0011718096088387925
had	0.0003906032029462642
failed	5.5800457563752025e-05
fulfill	5.5800457563752025e-05
expectations	5.5800457563752025e-05
funding	0.0002232018302550081
dramatically	2.7900228781876013e-05
reduced	0.00011160091512750405
<s> Little	0.0007686395080707148
Little further	1.0
further research	0.125
research in	0.14285714285714285
was conducted	0.025974025974025976
conducted until	0.2
until the	0.5
the late	0.005536332179930796
late 1980s	0.4444444444444444
1980s ,	0.5555555555555556
, when	0.003368893879842785
when the	0.11428571428571428
the first	0.010380622837370242
first statistical	0.06060606060606061
translation systems	0.02702702702702703
systems were	0.05357142857142857
were developed	0.12195121951219512
developed .	0.07692307692307693
Little	2.7900228781876013e-05
further	0.0002232018302550081
conducted	0.00013950114390938006
until	5.5800457563752025e-05
late	0.0002511020590368841
1980s	0.0002511020590368841
when	0.0009765080073656604
first	0.0009207075498019084
were	0.0011439093800569165
developed	0.0007254059483287763
<s> Some	0.012298232129131437
Some notably	0.047619047619047616
notably successful	0.3333333333333333
successful NLP	0.1111111111111111
NLP systems	0.06382978723404255
systems developed	0.017857142857142856
developed in	0.23076923076923078
in the	0.2602996254681648
the 1960s	0.001384083044982699
1960s were	0.3333333333333333
were SHRDLU	0.024390243902439025
SHRDLU ,	0.16666666666666666
, a	0.02695115103874228
a natural	0.006134969325153374
language system	0.006756756756756757
system working	0.010752688172043012
working in	0.2857142857142857
in restricted	0.0018726591760299626
restricted ``	0.25
`` blocks	0.010582010582010581
blocks worlds	0.25
worlds ''	1.0
'' with	0.020618556701030927
with restricted	0.00546448087431694
restricted vocabularies	0.25
vocabularies ,	1.0
and ELIZA	0.002890173410404624
ELIZA ,	0.3333333333333333
a simulation	0.001226993865030675
simulation of	0.3333333333333333
a Rogerian	0.001226993865030675
Rogerian psychotherapist	1.0
psychotherapist ,	1.0
, written	0.0005614823133071309
written by	0.23076923076923078
by Joseph	0.005714285714285714
Joseph Weizenbaum	1.0
Weizenbaum between	0.3333333333333333
between 1964	0.02564102564102564
1964 to	1.0
to 1966	0.0013280212483399733
1966 .	0.3333333333333333
Some	0.0005859048044193963
notably	8.370068634562804e-05
successful	0.0002511020590368841
1960s	8.370068634562804e-05
SHRDLU	0.00016740137269125608
system	0.002594721276714469
working	0.0001953016014731321
restricted	0.00011160091512750405
blocks	0.00011160091512750405
worlds	2.7900228781876013e-05
vocabularies	5.5800457563752025e-05
ELIZA	0.0002511020590368841
simulation	8.370068634562804e-05
Rogerian	2.7900228781876013e-05
psychotherapist	2.7900228781876013e-05
by	0.004882540036828302
Joseph	5.5800457563752025e-05
Weizenbaum	8.370068634562804e-05
1964	2.7900228781876013e-05
<s> Using	0.0015372790161414297
Using almost	0.5
almost no	1.0
no information	0.07692307692307693
information about	0.043478260869565216
about human	0.025
human thought	0.021739130434782608
thought or	0.3333333333333333
or emotion	0.0045045045045045045
emotion ,	1.0
, ELIZA	0.0011229646266142617
ELIZA sometimes	0.1111111111111111
sometimes provided	0.07692307692307693
provided a	0.2
a startlingly	0.001226993865030675
startlingly human-like	1.0
human-like interaction	1.0
Using	5.5800457563752025e-05
almost	2.7900228781876013e-05
no	0.00036270297416438817
thought	8.370068634562804e-05
emotion	2.7900228781876013e-05
provided	0.00013950114390938006
startlingly	2.7900228781876013e-05
human-like	2.7900228781876013e-05
<s> When	0.004611837048424289
When the	0.14285714285714285
the ``	0.0034602076124567475
`` patient	0.005291005291005291
patient ''	1.0
'' exceeded	0.005154639175257732
exceeded the	1.0
the very	0.0006920415224913495
very small	0.04878048780487805
small knowledge	0.1111111111111111
knowledge base	0.14814814814814814
base ,	0.5
ELIZA might	0.1111111111111111
might provide	0.038461538461538464
provide a	0.3333333333333333
a generic	0.001226993865030675
generic response	0.3333333333333333
response ,	0.5
, for	0.012352610892756879
for example	0.06498194945848375
example ,	0.6666666666666666
, responding	0.0005614823133071309
responding to	1.0
to ``	0.005312084993359893
`` My	0.005291005291005291
My head	1.0
head hurts	1.0
hurts ''	0.5
with ``	0.01639344262295082
`` Why	0.015873015873015872
Why do	0.14285714285714285
do you	0.038461538461538464
you say	0.07692307692307693
say your	0.14285714285714285
your head	0.5
hurts ?	0.5
? ''	0.375
'' .	0.06701030927835051
When	0.0001953016014731321
patient	2.7900228781876013e-05
exceeded	2.7900228781876013e-05
small	0.0002511020590368841
base	0.00011160091512750405
might	0.0007254059483287763
provide	0.00016740137269125608
generic	8.370068634562804e-05
response	5.5800457563752025e-05
responding	2.7900228781876013e-05
My	2.7900228781876013e-05
head	5.5800457563752025e-05
hurts	5.5800457563752025e-05
Why	0.0001953016014731321
do	0.0007254059483287763
you	0.00036270297416438817
say	0.0001953016014731321
your	5.5800457563752025e-05
?	0.0006696054907650243
<s> During	0.0030745580322828594
During the	0.5
the 70	0.0006920415224913495
70 's	0.25
's many	0.0196078431372549
many programmers	0.019230769230769232
programmers began	1.0
began to	0.5714285714285714
to write	0.0013280212483399733
write `	1.0
` conceptual	0.0625
conceptual ontologies	0.5
ontologies '	0.16666666666666666
' ,	0.3157894736842105
which structured	0.007246376811594203
structured real-world	0.16666666666666666
real-world information	0.16666666666666666
information into	0.043478260869565216
into computer-understandable	0.01282051282051282
computer-understandable data	1.0
data .	0.22077922077922077
During	0.00011160091512750405
70	0.00011160091512750405
's	0.0014229116678756766
many	0.0014508118966575527
programmers	2.7900228781876013e-05
began	0.0001953016014731321
write	2.7900228781876013e-05
`	0.0004464036605100162
conceptual	5.5800457563752025e-05
ontologies	0.00016740137269125608
'	0.0005301043468556442
structured	0.00016740137269125608
real-world	0.00016740137269125608
computer-understandable	2.7900228781876013e-05
data	0.0021483176162044528
<s> Examples	0.0023059185242121443
Examples are	0.6666666666666666
are MARGIE	0.004149377593360996
MARGIE -LRB-	1.0
-LRB- Schank	0.0027100271002710027
Schank ,	0.2
, 1975	0.0005614823133071309
1975 -RRB-	1.0
, SAM	0.0005614823133071309
SAM -LRB-	1.0
-LRB- Cullingford	0.0027100271002710027
Cullingford ,	1.0
, 1978	0.0011229646266142617
1978 -RRB-	0.6666666666666666
, PAM	0.0005614823133071309
PAM -LRB-	1.0
-LRB- Wilensky	0.0027100271002710027
Wilensky ,	1.0
, TaleSpin	0.0005614823133071309
TaleSpin -LRB-	1.0
-LRB- Meehan	0.0027100271002710027
Meehan ,	1.0
, 1976	0.0011229646266142617
1976 -RRB-	0.5
, QUALM	0.0005614823133071309
QUALM -LRB-	1.0
-LRB- Lehnert	0.005420054200542005
Lehnert ,	0.6666666666666666
, 1977	0.0005614823133071309
1977 -RRB-	1.0
, Politics	0.0005614823133071309
Politics -LRB-	1.0
-LRB- Carbonell	0.0027100271002710027
Carbonell ,	1.0
, 1979	0.0005614823133071309
1979 -RRB-	1.0
and Plot	0.001445086705202312
Plot Units	1.0
Units -LRB-	1.0
Lehnert 1981	0.3333333333333333
1981 -RRB-	1.0
-RRB- .	0.27371273712737126
Examples	8.370068634562804e-05
MARGIE	2.7900228781876013e-05
Schank	0.00013950114390938006
1975	2.7900228781876013e-05
SAM	2.7900228781876013e-05
Cullingford	2.7900228781876013e-05
1978	8.370068634562804e-05
PAM	2.7900228781876013e-05
Wilensky	5.5800457563752025e-05
TaleSpin	2.7900228781876013e-05
Meehan	2.7900228781876013e-05
1976	5.5800457563752025e-05
QUALM	2.7900228781876013e-05
Lehnert	8.370068634562804e-05
1977	2.7900228781876013e-05
Politics	2.7900228781876013e-05
Carbonell	2.7900228781876013e-05
1979	2.7900228781876013e-05
Plot	2.7900228781876013e-05
Units	2.7900228781876013e-05
1981	2.7900228781876013e-05
During this	0.5
this time	0.03296703296703297
time ,	0.3333333333333333
, many	0.0039303761931499155
many chatterbots	0.019230769230769232
chatterbots were	0.5
were written	0.024390243902439025
written including	0.038461538461538464
including PARRY	0.07142857142857142
PARRY ,	1.0
, Racter	0.0005614823133071309
Racter ,	1.0
and Jabberwacky	0.001445086705202312
Jabberwacky .	1.0
this	0.002538920819150717
time	0.0009207075498019084
chatterbots	5.5800457563752025e-05
PARRY	2.7900228781876013e-05
Racter	2.7900228781876013e-05
Jabberwacky	2.7900228781876013e-05
<s> Up	0.0007686395080707148
Up to	1.0
the 1980s	0.001384083044982699
, most	0.004491858506457047
most NLP	0.017241379310344827
were based	0.024390243902439025
based on	0.8333333333333334
on complex	0.0047169811320754715
complex sets	0.041666666666666664
sets of	0.36363636363636365
of hand-written	0.00267379679144385
hand-written rules	0.8571428571428571
rules .	0.13953488372093023
Up	2.7900228781876013e-05
most	0.0016182132693488087
based	0.0015066123542213047
complex	0.0006696054907650243
sets	0.00030690251660063614
hand-written	0.0001953016014731321
rules	0.0011997098376206685
<s> Starting	0.0007686395080707148
Starting in	1.0
, however	0.006176305446378439
however ,	0.9230769230769231
, there	0.006176305446378439
there was	0.075
was a	0.03896103896103896
a revolution	0.001226993865030675
revolution in	1.0
NLP with	0.02127659574468085
the introduction	0.0006920415224913495
introduction of	1.0
of machine	0.0071301247771836
learning algorithms	0.11627906976744186
algorithms for	0.11428571428571428
for language	0.0036101083032490976
processing .	0.12962962962962962
Starting	2.7900228781876013e-05
however	0.00036270297416438817
there	0.0011160091512750405
revolution	2.7900228781876013e-05
introduction	2.7900228781876013e-05
This was	0.015873015873015872
was due	0.012987012987012988
due both	0.4
both to	0.12903225806451613
the steady	0.001384083044982699
steady increase	0.5
increase in	0.75
in computational	0.003745318352059925
computational power	0.2
power resulting	0.25
resulting from	0.25
from Moore	0.009615384615384616
Moore 's	1.0
's Law	0.0196078431372549
Law and	1.0
the gradual	0.0006920415224913495
gradual lessening	1.0
lessening of	1.0
the dominance	0.0006920415224913495
dominance of	1.0
of Chomskyan	0.00089126559714795
Chomskyan theories	1.0
theories of	0.6
of linguistics	0.00089126559714795
linguistics -LRB-	0.05
-LRB- e.g.	0.10298102981029811
e.g. transformational	0.017857142857142856
transformational grammar	1.0
grammar -RRB-	0.08108108108108109
, whose	0.0011229646266142617
whose theoretical	0.3333333333333333
theoretical underpinnings	0.3333333333333333
underpinnings discouraged	1.0
discouraged the	1.0
the sort	0.0006920415224913495
sort of	0.6666666666666666
of corpus	0.00089126559714795
corpus linguistics	0.0967741935483871
linguistics that	0.1
that underlies	0.0035460992907801418
underlies the	1.0
the machine-learning	0.0006920415224913495
machine-learning approach	0.25
approach to	0.17142857142857143
to language	0.0013280212483399733
due	0.00013950114390938006
both	0.0008649070922381564
steady	5.5800457563752025e-05
increase	0.00011160091512750405
power	0.00011160091512750405
resulting	0.00011160091512750405
Moore	2.7900228781876013e-05
Law	2.7900228781876013e-05
gradual	2.7900228781876013e-05
lessening	2.7900228781876013e-05
dominance	2.7900228781876013e-05
Chomskyan	2.7900228781876013e-05
theories	0.00013950114390938006
e.g.	0.0015624128117850567
transformational	5.5800457563752025e-05
grammar	0.0010323084649294125
whose	8.370068634562804e-05
underpinnings	2.7900228781876013e-05
discouraged	2.7900228781876013e-05
sort	8.370068634562804e-05
corpus	0.0008649070922381564
underlies	2.7900228781876013e-05
machine-learning	0.00011160091512750405
approach	0.0009765080073656604
Some of	0.19047619047619047
the earliest-used	0.001384083044982699
earliest-used machine	0.5
algorithms ,	0.14285714285714285
, such	0.019651880965749578
such as	0.7317073170731707
as decision	0.010452961672473868
decision trees	1.0
trees ,	0.5
, produced	0.0016844469399213925
produced systems	0.2222222222222222
systems of	0.05357142857142857
of hard	0.0017825311942959
hard if-then	0.3333333333333333
if-then rules	1.0
rules similar	0.046511627906976744
similar to	0.5555555555555556
to existing	0.0013280212483399733
existing hand-written	0.2
earliest-used	5.5800457563752025e-05
such	0.0034317281401707493
decision	0.00011160091512750405
trees	0.00016740137269125608
produced	0.0002511020590368841
hard	0.00016740137269125608
if-then	5.5800457563752025e-05
similar	0.0007533061771106523
existing	0.00013950114390938006
<s> Increasingly	0.0015372790161414297
Increasingly ,	1.0
, research	0.0011229646266142617
research has	0.14285714285714285
has focused	0.047619047619047616
focused on	0.9090909090909091
on statistical	0.009433962264150943
statistical models	0.21212121212121213
models ,	0.07692307692307693
which make	0.014492753623188406
make soft	0.2
soft ,	0.5
, probabilistic	0.0016844469399213925
probabilistic decisions	0.2857142857142857
decisions based	0.2
on attaching	0.009433962264150943
attaching real-valued	1.0
real-valued weights	0.6666666666666666
weights to	0.4
the features	0.0034602076124567475
features making	0.038461538461538464
making up	0.14285714285714285
up the	0.045454545454545456
the input	0.005536332179930796
input data	0.14634146341463414
Increasingly	5.5800457563752025e-05
has	0.002343619217677585
focused	0.00030690251660063614
models	0.0007254059483287763
make	0.0005580045756375203
soft	0.00011160091512750405
probabilistic	0.0001953016014731321
decisions	0.00027900228781876013
attaching	5.5800457563752025e-05
real-valued	8.370068634562804e-05
weights	0.00013950114390938006
features	0.0007254059483287763
making	0.0001953016014731321
up	0.0006138050332012723
The cache	0.005208333333333333
cache language	1.0
language models	0.013513513513513514
models upon	0.038461538461538464
upon which	1.0
which many	0.007246376811594203
many speech	0.019230769230769232
speech recognition	0.42105263157894735
recognition systems	0.08264462809917356
systems now	0.008928571428571428
now rely	0.07692307692307693
rely are	0.14285714285714285
are examples	0.012448132780082987
examples of	0.20833333333333334
of such	0.004456327985739751
such statistical	0.008130081300813009
models .	0.11538461538461539
cache	2.7900228781876013e-05
upon	2.7900228781876013e-05
speech	0.004240834774845154
rely	0.0001953016014731321
examples	0.0006696054907650243
<s> Such	0.006149116064565719
Such models	0.25
models are	0.038461538461538464
are generally	0.016597510373443983
generally more	0.18181818181818182
more robust	0.021052631578947368
robust when	0.5
when given	0.05714285714285714
given unfamiliar	0.08333333333333333
unfamiliar input	1.0
input ,	0.07317073170731707
especially input	0.13333333333333333
input that	0.04878048780487805
that contains	0.010638297872340425
contains errors	0.2
errors -LRB-	0.4
-LRB- as	0.018970189701897018
as is	0.013937282229965157
is very	0.012195121951219513
very common	0.04878048780487805
common for	0.08
for real-world	0.007220216606498195
real-world data	0.3333333333333333
data -RRB-	0.03896103896103896
and produce	0.002890173410404624
produce more	0.09090909090909091
more reliable	0.031578947368421054
reliable results	0.5
results when	0.09523809523809523
when integrated	0.02857142857142857
integrated into	0.3333333333333333
into a	0.21794871794871795
a larger	0.0049079754601227
larger system	0.125
system comprising	0.010752688172043012
comprising multiple	0.5
multiple subtasks	0.07692307692307693
subtasks .	0.5
Such	0.0002232018302550081
generally	0.00030690251660063614
robust	0.00011160091512750405
given	0.0006696054907650243
unfamiliar	8.370068634562804e-05
contains	0.00027900228781876013
errors	0.00013950114390938006
common	0.0006975057195469003
produce	0.0006138050332012723
reliable	0.00011160091512750405
results	0.0005859048044193963
integrated	8.370068634562804e-05
larger	0.0004464036605100162
comprising	5.5800457563752025e-05
multiple	0.00036270297416438817
subtasks	5.5800457563752025e-05
<s> Many	0.008455034588777863
Many of	0.16666666666666666
the notable	0.0006920415224913495
notable early	1.0
early successes	0.1
successes occurred	1.0
occurred in	1.0
translation ,	0.10810810810810811
, due	0.0005614823133071309
due especially	0.2
especially to	0.06666666666666667
to work	0.0026560424966799467
work at	0.041666666666666664
at IBM	0.014705882352941176
IBM Research	0.3333333333333333
Research ,	0.125
, where	0.008422234699606962
where successively	0.02857142857142857
successively more	1.0
more complicated	0.010526315789473684
complicated statistical	0.3333333333333333
models were	0.038461538461538464
Many	0.00033480274538251215
notable	2.7900228781876013e-05
early	0.00027900228781876013
successes	2.7900228781876013e-05
occurred	2.7900228781876013e-05
work	0.0006696054907650243
at	0.0018972155571675689
IBM	8.370068634562804e-05
successively	2.7900228781876013e-05
complicated	8.370068634562804e-05
<s> These	0.012298232129131437
These systems	0.23529411764705882
were able	0.024390243902439025
able to	1.0
to take	0.006640106241699867
take advantage	0.4
advantage of	0.8
of existing	0.0017825311942959
existing multilingual	0.2
multilingual textual	0.3333333333333333
textual corpora	0.2
corpora that	0.09090909090909091
that had	0.0035460992907801418
had been	0.07142857142857142
been produced	0.014705882352941176
produced by	0.3333333333333333
by the	0.15428571428571428
the Parliament	0.0006920415224913495
Parliament of	0.5
of Canada	0.0017825311942959
Canada and	0.16666666666666666
the European	0.001384083044982699
European Union	0.3333333333333333
Union as	1.0
a result	0.0036809815950920245
result of	0.2727272727272727
of laws	0.00089126559714795
laws calling	1.0
calling for	1.0
for the	0.11191335740072202
the translation	0.004152249134948097
of all	0.0035650623885918
all governmental	0.023255813953488372
governmental proceedings	1.0
proceedings into	1.0
into all	0.01282051282051282
all official	0.023255813953488372
official languages	1.0
languages of	0.02
the corresponding	0.001384083044982699
corresponding systems	0.16666666666666666
of government	0.0017825311942959
government .	0.3333333333333333
These	0.0004743038892918922
able	0.0004464036605100162
take	0.00027900228781876013
advantage	0.00013950114390938006
multilingual	8.370068634562804e-05
textual	0.00013950114390938006
corpora	0.00030690251660063614
been	0.0018972155571675689
Parliament	5.5800457563752025e-05
Canada	0.00016740137269125608
European	8.370068634562804e-05
Union	2.7900228781876013e-05
result	0.00030690251660063614
laws	2.7900228781876013e-05
calling	2.7900228781876013e-05
all	0.0011997098376206685
governmental	2.7900228781876013e-05
proceedings	2.7900228781876013e-05
official	2.7900228781876013e-05
corresponding	0.00016740137269125608
government	8.370068634562804e-05
most other	0.017241379310344827
other systems	0.02857142857142857
systems depended	0.008928571428571428
depended on	1.0
on corpora	0.0047169811320754715
corpora specifically	0.09090909090909091
specifically developed	0.5
developed for	0.038461538461538464
the tasks	0.0006920415224913495
tasks implemented	0.03125
implemented by	0.2
by these	0.005714285714285714
these systems	0.11904761904761904
systems ,	0.05357142857142857
which was	0.036231884057971016
was -LRB-	0.012987012987012988
-LRB- and	0.013550135501355014
and often	0.004335260115606936
often continues	0.022727272727272728
continues to	1.0
to be	0.057104913678618856
be -RRB-	0.004219409282700422
-RRB- a	0.005420054200542005
major limitation	0.08333333333333333
limitation in	1.0
the success	0.001384083044982699
success of	0.6
of these	0.00980392156862745
systems .	0.08928571428571429
depended	2.7900228781876013e-05
specifically	5.5800457563752025e-05
tasks	0.0008928073210200324
implemented	0.00013950114390938006
these	0.0011718096088387925
often	0.0012276100664025446
continues	2.7900228781876013e-05
limitation	2.7900228781876013e-05
success	0.00013950114390938006
<s> As	0.010760953112990008
As a	0.1111111111111111
result ,	0.2727272727272727
a great	0.00245398773006135
great deal	0.3333333333333333
deal of	0.25
of research	0.0071301247771836
has gone	0.011904761904761904
gone into	1.0
into methods	0.01282051282051282
methods of	0.045454545454545456
more effectively	0.010526315789473684
effectively learning	0.3333333333333333
learning from	0.046511627906976744
from limited	0.009615384615384616
limited amounts	0.1
amounts of	1.0
of data	0.006238859180035651
As	0.0005022041180737682
great	8.370068634562804e-05
deal	0.00011160091512750405
gone	2.7900228781876013e-05
methods	0.0012276100664025446
effectively	8.370068634562804e-05
limited	0.00027900228781876013
amounts	5.5800457563752025e-05
<s> Recent	0.0023059185242121443
Recent research	0.6666666666666666
has increasingly	0.011904761904761904
increasingly focused	0.3333333333333333
on unsupervised	0.0047169811320754715
unsupervised and	0.125
and semi-supervised	0.001445086705202312
semi-supervised learning	0.5
algorithms .	0.11428571428571428
Recent	8.370068634562804e-05
increasingly	8.370068634562804e-05
unsupervised	0.0002232018302550081
semi-supervised	5.5800457563752025e-05
Such algorithms	0.125
are able	0.012448132780082987
to learn	0.00796812749003984
learn from	0.07692307692307693
from data	0.019230769230769232
data that	0.025974025974025976
that has	0.02127659574468085
has not	0.023809523809523808
not been	0.017857142857142856
been hand-annotated	0.029411764705882353
hand-annotated with	1.0
the desired	0.002768166089965398
desired answers	0.2
answers ,	0.08333333333333333
or using	0.009009009009009009
using a	0.1694915254237288
a combination	0.00245398773006135
combination of	0.2
of annotated	0.00089126559714795
annotated and	0.5
and non-annotated	0.001445086705202312
non-annotated data	1.0
learn	0.00036270297416438817
not	0.0031248256235701134
hand-annotated	5.5800457563752025e-05
desired	0.00013950114390938006
answers	0.00033480274538251215
using	0.0016461134981306848
combination	0.00013950114390938006
annotated	5.5800457563752025e-05
non-annotated	5.5800457563752025e-05
<s> Generally	0.003843197540353574
Generally ,	0.6
, this	0.003368893879842785
this task	0.04395604395604396
task is	0.14285714285714285
is much	0.0040650406504065045
much more	0.18181818181818182
more difficult	0.07368421052631578
difficult than	0.10714285714285714
than supervised	0.022222222222222223
supervised learning	0.3125
and typically	0.002890173410404624
typically produces	0.05555555555555555
produces less	0.25
less accurate	0.08333333333333333
accurate results	0.14285714285714285
results for	0.047619047619047616
for a	0.10469314079422383
a given	0.014723926380368098
given amount	0.041666666666666664
amount of	1.0
of input	0.00267379679144385
Generally	0.00013950114390938006
task	0.0011718096088387925
difficult	0.0007812064058925284
supervised	0.0004464036605100162
typically	0.0005022041180737682
produces	0.00011160091512750405
less	0.00033480274538251215
accurate	0.0001953016014731321
amount	0.00013950114390938006
there is	0.35
is an	0.02032520325203252
an enormous	0.007575757575757576
enormous amount	1.0
of non-annotated	0.00089126559714795
data available	0.03896103896103896
available -LRB-	0.058823529411764705
-LRB- including	0.0027100271002710027
including ,	0.07142857142857142
, among	0.0005614823133071309
among other	0.375
other things	0.04285714285714286
things ,	0.3333333333333333
the entire	0.0006920415224913495
entire content	0.3333333333333333
content of	0.08333333333333333
the World	0.0034602076124567475
World Wide	0.5714285714285714
Wide Web	1.0
Web -RRB-	0.1111111111111111
which can	0.036231884057971016
can often	0.0055248618784530384
often make	0.022727272727272728
make up	0.1
up for	0.09090909090909091
the inferior	0.0006920415224913495
inferior results	1.0
results .	0.09523809523809523
enormous	2.7900228781876013e-05
available	0.0004743038892918922
among	0.0002232018302550081
things	8.370068634562804e-05
entire	8.370068634562804e-05
World	0.0001953016014731321
Wide	0.00011160091512750405
Web	0.0002511020590368841
can	0.005049941409519558
inferior	2.7900228781876013e-05
<s> NLP	0.0007686395080707148
NLP using	0.02127659574468085
using machine	0.01694915254237288
learning As	0.023255813953488372
As described	0.05555555555555555
described above	0.5
above ,	0.3076923076923077
, modern	0.0005614823133071309
modern approaches	0.2
approaches to	0.17857142857142858
to natural	0.0013280212483399733
-RRB- are	0.008130081300813009
described	0.00016740137269125608
above	0.00036270297416438817
approaches	0.0007812064058925284
The paradigm	0.005208333333333333
paradigm of	0.3333333333333333
learning is	0.023255813953488372
is different	0.0020325203252032522
different from	0.12244897959183673
from that	0.009615384615384616
that of	0.028368794326241134
of most	0.00089126559714795
most prior	0.017241379310344827
prior attempts	0.3333333333333333
attempts at	0.3333333333333333
at language	0.014705882352941176
paradigm	8.370068634562804e-05
different	0.0013671112103119246
prior	8.370068634562804e-05
attempts	0.00016740137269125608
<s> Prior	0.0007686395080707148
Prior implementations	1.0
implementations of	1.0
of language-processing	0.00089126559714795
language-processing tasks	1.0
tasks typically	0.03125
typically involved	0.05555555555555555
involved the	0.16666666666666666
the direct	0.0006920415224913495
direct hand	0.16666666666666666
hand coding	0.07142857142857142
coding of	1.0
of large	0.0035650623885918
large sets	0.08695652173913043
of rules	0.00267379679144385
Prior	2.7900228781876013e-05
implementations	5.5800457563752025e-05
language-processing	2.7900228781876013e-05
direct	0.00016740137269125608
coding	2.7900228781876013e-05
large	0.0006417052619831483
The machine-learning	0.005208333333333333
machine-learning paradigm	0.25
paradigm calls	0.3333333333333333
calls instead	1.0
instead for	0.14285714285714285
for using	0.0036101083032490976
using general	0.01694915254237288
general learning	0.045454545454545456
algorithms --	0.02857142857142857
-- often	0.04
often ,	0.022727272727272728
, although	0.0022459292532285235
although not	0.16666666666666666
not always	0.008928571428571428
always ,	0.3333333333333333
, grounded	0.0005614823133071309
in statistical	0.003745318352059925
statistical inference	0.06060606060606061
inference --	0.25
-- to	0.04
to automatically	0.00796812749003984
automatically learn	0.09523809523809523
learn such	0.07692307692307693
such rules	0.008130081300813009
rules through	0.023255813953488372
through the	0.5
the analysis	0.002768166089965398
large corpora	0.043478260869565216
corpora of	0.09090909090909091
of typical	0.00089126559714795
typical real-world	0.1111111111111111
real-world examples	0.16666666666666666
examples .	0.16666666666666666
calls	2.7900228781876013e-05
instead	0.0001953016014731321
general	0.0006138050332012723
although	0.00016740137269125608
always	8.370068634562804e-05
inference	0.00011160091512750405
automatically	0.0005859048044193963
through	0.0002232018302550081
typical	0.0002511020590368841
<s> A	0.033820138355111454
A corpus	0.02
corpus -LRB-	0.03225806451612903
-LRB- plural	0.0027100271002710027
plural ,	0.4
, ``	0.01403705783267827
`` corpora	0.005291005291005291
corpora ''	0.09090909090909091
'' -RRB-	0.09278350515463918
a set	0.01717791411042945
set of	0.717948717948718
of documents	0.004456327985739751
documents -LRB-	0.13157894736842105
-LRB- or	0.02710027100271003
or sometimes	0.0045045045045045045
sometimes ,	0.07692307692307693
, individual	0.0005614823133071309
individual sentences	0.08333333333333333
sentences -RRB-	0.02631578947368421
-RRB- that	0.005420054200542005
that have	0.02127659574468085
have been	0.25
the correct	0.004152249134948097
correct values	0.06666666666666667
values to	0.125
be learned	0.004219409282700422
learned .	0.2
A	0.0013950114390938006
plural	0.00013950114390938006
set	0.0010881089224931645
documents	0.0010602086937112885
individual	0.00033480274538251215
have	0.0029016237933151053
correct	0.0004185034317281402
values	0.0002232018302550081
learned	0.00013950114390938006
<s> Consider	0.0015372790161414297
Consider the	1.0
the task	0.004844290657439446
task of	0.21428571428571427
of part	0.00089126559714795
part of	0.8148148148148148
of speech	0.040998217468805706
speech tagging	0.013157894736842105
tagging ,	0.08
, i.e.	0.0039303761931499155
i.e. determining	0.05263157894736842
determining the	0.6666666666666666
correct part	0.2
speech of	0.006578947368421052
of each	0.006238859180035651
each word	0.1111111111111111
word in	0.06666666666666667
given sentence	0.08333333333333333
sentence ,	0.125
, typically	0.0016844469399213925
typically one	0.05555555555555555
one that	0.015384615384615385
has never	0.023809523809523808
never been	0.4
been seen	0.04411764705882353
seen before	0.2
before .	0.16666666666666666
Consider	5.5800457563752025e-05
part	0.0007533061771106523
tagging	0.0006975057195469003
i.e.	0.0005301043468556442
determining	0.00016740137269125608
each	0.0012555102951844206
word	0.0016740137269125608
sentence	0.0013392109815300486
one	0.0018135148708219408
never	0.00013950114390938006
seen	0.00027900228781876013
before	0.00016740137269125608
A typical	0.04
typical machine-learning-based	0.1111111111111111
machine-learning-based implementation	1.0
implementation of	1.0
a part	0.00245398773006135
speech tagger	0.006578947368421052
tagger proceeds	0.1111111111111111
proceeds in	1.0
in two	0.0018726591760299626
two steps	0.034482758620689655
steps ,	0.5
a training	0.001226993865030675
training step	0.07142857142857142
step and	0.06666666666666667
and an	0.004335260115606936
an evaluation	0.007575757575757576
evaluation step	0.037037037037037035
step .	0.13333333333333333
machine-learning-based	2.7900228781876013e-05
implementation	5.5800457563752025e-05
tagger	0.0002511020590368841
proceeds	2.7900228781876013e-05
two	0.0008091066346744044
steps	5.5800457563752025e-05
training	0.0007812064058925284
step	0.0004185034317281402
evaluation	0.0015066123542213047
The first	0.036458333333333336
first step	0.06060606060606061
step --	0.13333333333333333
-- the	0.12
the training	0.002768166089965398
-- makes	0.04
makes use	0.125
use of	0.2916666666666667
a corpus	0.0036809815950920245
corpus of	0.22580645161290322
of training	0.0035650623885918
training data	0.35714285714285715
data ,	0.12987012987012986
which consists	0.007246376811594203
consists of	1.0
a large	0.0098159509202454
large number	0.08695652173913043
of sentences	0.006238859180035651
sentences ,	0.10526315789473684
, each	0.003368893879842785
each of	0.1111111111111111
of which	0.008912655971479501
which has	0.050724637681159424
has the	0.023809523809523808
speech attached	0.006578947368421052
attached to	0.5
to each	0.006640106241699867
word .	0.13333333333333333
makes	0.0002232018302550081
use	0.002008816472295073
consists	5.5800457563752025e-05
attached	5.5800457563752025e-05
<s> -LRB-	0.014604150653343582
-LRB- An	0.005420054200542005
An example	0.1875
such a	0.04878048780487805
corpus in	0.06451612903225806
in common	0.003745318352059925
common use	0.08
use is	0.013888888888888888
the Penn	0.005536332179930796
Penn Treebank	0.6666666666666666
Treebank .	0.3333333333333333
Penn	0.0002511020590368841
Treebank	0.00016740137269125608
This includes	0.015873015873015872
includes -LRB-	0.14285714285714285
-LRB- among	0.005420054200542005
things -RRB-	0.3333333333333333
of 500	0.0017825311942959
500 texts	0.5
texts from	0.058823529411764705
from the	0.21153846153846154
the Brown	0.005536332179930796
Brown Corpus	0.8571428571428571
Corpus ,	0.0625
, containing	0.0011229646266142617
containing examples	0.125
of various	0.00089126559714795
various genres	0.05555555555555555
genres of	1.0
of text	0.0213903743315508
text ,	0.18867924528301888
and 2500	0.001445086705202312
2500 articles	1.0
articles from	0.125
the Wall	0.001384083044982699
Wall Street	1.0
Street Journal	0.6666666666666666
Journal .	0.3333333333333333
. -RRB-	0.0062402496099844
-RRB- <\s>	0.037940379403794036
includes	0.0001953016014731321
500	5.5800457563752025e-05
texts	0.0004743038892918922
Brown	0.0003906032029462642
Corpus	0.0004464036605100162
containing	0.0002232018302550081
various	0.0005022041180737682
genres	2.7900228781876013e-05
text	0.004436136376318286
2500	2.7900228781876013e-05
articles	0.0002232018302550081
Wall	5.5800457563752025e-05
Street	8.370068634562804e-05
This corpus	0.031746031746031744
corpus is	0.03225806451612903
is analyzed	0.006097560975609756
analyzed and	0.2
a learning	0.00245398773006135
learning model	0.023255813953488372
model is	0.1
is generated	0.006097560975609756
generated from	0.13333333333333333
from it	0.009615384615384616
it ,	0.017094017094017096
, consisting	0.0005614823133071309
consisting of	1.0
of automatically	0.0017825311942959
automatically created	0.047619047619047616
created rules	0.14285714285714285
rules for	0.046511627906976744
for determining	0.007220216606498195
the part	0.001384083044982699
speech for	0.02631578947368421
a word	0.013496932515337423
a sentence	0.01717791411042945
typically based	0.05555555555555555
the nature	0.0034602076124567475
nature of	1.0
the word	0.005536332179930796
in question	0.003745318352059925
question ,	0.2619047619047619
of surrounding	0.00089126559714795
surrounding words	0.4
words ,	0.13761467889908258
the most	0.01314878892733564
most likely	0.05172413793103448
likely part	0.0625
for those	0.007220216606498195
those surrounding	0.045454545454545456
words .	0.14678899082568808
analyzed	0.00013950114390938006
model	0.0008370068634562804
generated	0.0004185034317281402
consisting	5.5800457563752025e-05
created	0.0001953016014731321
nature	0.00016740137269125608
question	0.0011718096088387925
surrounding	0.00013950114390938006
words	0.003041124937224485
likely	0.0004464036605100162
those	0.0006138050332012723
The model	0.005208333333333333
model that	0.13333333333333333
that is	0.05673758865248227
generated is	0.06666666666666667
is typically	0.006097560975609756
typically the	0.05555555555555555
the best	0.008996539792387544
best model	0.05555555555555555
that can	0.04609929078014184
can be	0.5027624309392266
be found	0.012658227848101266
that simultaneously	0.0035460992907801418
simultaneously meets	0.5
meets two	0.5
two conflicting	0.034482758620689655
conflicting objectives	1.0
objectives :	0.5
: To	0.00980392156862745
To perform	0.1111111111111111
perform as	0.09090909090909091
as well	0.04878048780487805
well as	0.4642857142857143
as possible	0.017421602787456445
possible on	0.041666666666666664
and to	0.015895953757225433
be as	0.012658227848101266
as simple	0.006968641114982578
simple as	0.07692307692307693
possible -LRB-	0.041666666666666664
-LRB- so	0.005420054200542005
so that	0.2
the model	0.0020761245674740486
model avoids	0.03333333333333333
avoids overfitting	1.0
overfitting the	0.5
i.e. so	0.05263157894736842
that it	0.010638297872340425
it generalizes	0.008547008547008548
generalizes as	1.0
possible to	0.125
to new	0.005312084993359893
new data	0.041666666666666664
data rather	0.012987012987012988
rather than	0.875
than only	0.044444444444444446
only succeeding	0.02631578947368421
succeeding on	1.0
on sentences	0.0047169811320754715
sentences that	0.06578947368421052
have already	0.009615384615384616
already been	0.4
seen -RRB-	0.1
best	0.0005022041180737682
simultaneously	5.5800457563752025e-05
meets	5.5800457563752025e-05
conflicting	2.7900228781876013e-05
objectives	5.5800457563752025e-05
:	0.0028458233357513533
To	0.0002511020590368841
perform	0.00030690251660063614
possible	0.0006696054907650243
simple	0.0007254059483287763
so	0.0008370068634562804
avoids	2.7900228781876013e-05
overfitting	5.5800457563752025e-05
generalizes	2.7900228781876013e-05
new	0.0006696054907650243
rather	0.0004464036605100162
only	0.0010602086937112885
succeeding	2.7900228781876013e-05
already	0.00013950114390938006
In the	0.13333333333333333
the second	0.001384083044982699
second step	0.2
step -LRB-	0.06666666666666667
-LRB- the	0.02168021680216802
the evaluation	0.0034602076124567475
step -RRB-	0.06666666666666667
has been	0.3333333333333333
been learned	0.029411764705882353
learned is	0.2
is used	0.026422764227642278
used to	0.19469026548672566
to process	0.00398406374501992
process new	0.027777777777777776
new sentences	0.041666666666666664
sentences .	0.10526315789473684
second	0.00027900228781876013
An important	0.125
important part	0.0625
the development	0.0034602076124567475
development of	0.5833333333333334
of any	0.00267379679144385
any learning	0.03225806451612903
learning algorithm	0.11627906976744186
algorithm is	0.17857142857142858
is testing	0.0020325203252032522
testing the	0.2
learned on	0.2
on new	0.0047169811320754715
new ,	0.041666666666666664
, previously	0.0005614823133071309
previously unseen	0.5
unseen data	1.0
important	0.0004464036605100162
development	0.00033480274538251215
any	0.0008649070922381564
algorithm	0.0007812064058925284
testing	0.00013950114390938006
previously	5.5800457563752025e-05
unseen	2.7900228781876013e-05
<s> It	0.026133743274404306
It is	0.6052631578947368
is critical	0.0020325203252032522
critical that	0.25
the data	0.002768166089965398
data used	0.025974025974025976
used for	0.13274336283185842
for testing	0.0036101083032490976
testing is	0.2
is not	0.03861788617886179
not the	0.044642857142857144
the same	0.01522491349480969
same as	0.08
as the	0.09407665505226481
for training	0.010830324909747292
training ;	0.03571428571428571
; otherwise	0.02127659574468085
otherwise ,	0.5
the testing	0.0006920415224913495
testing accuracy	0.2
accuracy will	0.03225806451612903
will be	0.2571428571428571
be unrealistically	0.004219409282700422
unrealistically high	1.0
high .	0.05555555555555555
It	0.0010602086937112885
critical	0.00011160091512750405
same	0.0006975057195469003
;	0.0013113107527481726
otherwise	5.5800457563752025e-05
accuracy	0.0008649070922381564
will	0.0009765080073656604
unrealistically	2.7900228781876013e-05
high	0.0005022041180737682
Many different	0.16666666666666666
different classes	0.02040816326530612
classes of	0.4
algorithms have	0.08571428571428572
been applied	0.08823529411764706
applied to	0.7333333333333333
to NLP	0.0013280212483399733
NLP tasks	0.0425531914893617
tasks .	0.125
classes	0.00013950114390938006
applied	0.0004185034317281402
In common	0.009523809523809525
common to	0.04
to all	0.00398406374501992
all of	0.09302325581395349
these algorithms	0.023809523809523808
algorithms is	0.02857142857142857
is that	0.024390243902439025
that they	0.024822695035460994
they take	0.025
take as	0.1
as input	0.006968641114982578
input a	0.024390243902439025
large set	0.043478260869565216
of ``	0.0071301247771836
`` features	0.005291005291005291
features ''	0.038461538461538464
'' that	0.020618556701030927
that are	0.05319148936170213
are generated	0.004149377593360996
they	0.0011160091512750405
As an	0.1111111111111111
a part-of-speech	0.001226993865030675
part-of-speech tagger	0.06666666666666667
tagger ,	0.4444444444444444
, typical	0.0005614823133071309
typical features	0.1111111111111111
features might	0.038461538461538464
might be	0.23076923076923078
be the	0.012658227848101266
the identity	0.002768166089965398
identity of	1.0
word being	0.03333333333333333
being processed	0.05555555555555555
processed ,	0.16666666666666666
the words	0.004152249134948097
words immediately	0.009174311926605505
immediately to	1.0
the left	0.001384083044982699
left and	0.3333333333333333
and right	0.002890173410404624
right ,	0.1
the part-of-speech	0.0006920415224913495
part-of-speech tag	0.06666666666666667
tag of	0.0625
word to	0.016666666666666666
left ,	0.16666666666666666
and whether	0.001445086705202312
whether the	0.15384615384615385
being considered	0.1111111111111111
considered or	0.1111111111111111
or its	0.0045045045045045045
its immediate	0.02857142857142857
immediate neighbors	1.0
neighbors are	0.3333333333333333
are content	0.004149377593360996
content words	0.08333333333333333
words or	0.06422018348623854
or function	0.0045045045045045045
function words	0.125
part-of-speech	0.0004185034317281402
identity	0.00011160091512750405
being	0.0005022041180737682
processed	0.00016740137269125608
immediately	2.7900228781876013e-05
left	0.00016740137269125608
right	0.00027900228781876013
tag	0.0004464036605100162
whether	0.00036270297416438817
considered	0.0002511020590368841
its	0.0009765080073656604
immediate	2.7900228781876013e-05
neighbors	8.370068634562804e-05
function	0.0002232018302550081
The algorithms	0.010416666666666666
algorithms differ	0.02857142857142857
differ ,	0.3333333333333333
, in	0.01909039865244245
the rules	0.0034602076124567475
rules generated	0.023255813953488372
generated .	0.2
differ	8.370068634562804e-05
earliest-used algorithms	0.5
the systems	0.0020761245674740486
rules that	0.09302325581395349
that were	0.014184397163120567
were then	0.024390243902439025
then common	0.02857142857142857
common .	0.08
then	0.0009765080073656604
each input	0.022222222222222223
input feature	0.024390243902439025
feature .	0.15384615384615385
feature	0.00036270297416438817
models have	0.038461538461538464
have the	0.009615384615384616
the advantage	0.0006920415224913495
advantage that	0.2
they can	0.15
can express	0.022099447513812154
express the	0.4
the relative	0.0006920415224913495
relative certainty	0.3333333333333333
certainty of	1.0
of many	0.0017825311942959
many different	0.07692307692307693
different possible	0.02040816326530612
possible answers	0.041666666666666664
answers rather	0.08333333333333333
only one	0.02631578947368421
one ,	0.06153846153846154
, producing	0.0005614823133071309
producing more	0.3333333333333333
when such	0.05714285714285714
a model	0.001226993865030675
is included	0.0020325203252032522
included as	0.125
a component	0.00245398773006135
component of	0.6
system .	0.11827956989247312
express	0.00013950114390938006
relative	8.370068634562804e-05
certainty	2.7900228781876013e-05
included	0.0002232018302550081
In addition	0.02857142857142857
addition ,	0.3333333333333333
, models	0.0005614823133071309
models that	0.11538461538461539
that make	0.010638297872340425
soft decisions	0.5
decisions are	0.1
addition	0.00016740137269125608
<s> Systems	0.006149116064565719
Systems based	0.25
on machine-learning	0.0047169811320754715
machine-learning algorithms	0.25
have many	0.04807692307692308
many advantages	0.019230769230769232
advantages over	1.0
over hand-produced	0.08333333333333333
hand-produced rules	1.0
rules :	0.046511627906976744
: The	0.0392156862745098
The learning	0.005208333333333333
learning procedures	0.046511627906976744
procedures used	0.25
used during	0.008849557522123894
during machine	0.1
learning automatically	0.023255813953488372
automatically focus	0.047619047619047616
focus on	0.5714285714285714
most common	0.10344827586206896
common cases	0.04
cases ,	0.3888888888888889
, whereas	0.0011229646266142617
whereas when	0.3333333333333333
when writing	0.05714285714285714
writing rules	0.1111111111111111
rules by	0.023255813953488372
by hand	0.03428571428571429
hand it	0.07142857142857142
is often	0.022357723577235773
often not	0.045454545454545456
not obvious	0.008928571428571428
obvious at	1.0
at all	0.07352941176470588
all where	0.023255813953488372
where the	0.37142857142857144
the effort	0.0006920415224913495
effort should	0.25
should be	0.47368421052631576
be directed	0.004219409282700422
directed .	1.0
Systems	0.00033480274538251215
advantages	2.7900228781876013e-05
over	0.00033480274538251215
hand-produced	2.7900228781876013e-05
procedures	0.00011160091512750405
during	0.00027900228781876013
focus	0.0001953016014731321
cases	0.0005022041180737682
whereas	8.370068634562804e-05
writing	0.0002511020590368841
obvious	2.7900228781876013e-05
effort	0.00011160091512750405
should	0.0005301043468556442
directed	2.7900228781876013e-05
<s> Automatic	0.005380476556495004
Automatic learning	0.1111111111111111
procedures can	0.5
can make	0.016574585635359115
make use	0.05
of statistical	0.0017825311942959
inference algorithms	0.25
algorithms to	0.08571428571428572
to produce	0.013280212483399735
produce models	0.045454545454545456
are robust	0.004149377593360996
robust to	0.25
to unfamiliar	0.0013280212483399733
input -LRB-	0.04878048780487805
e.g. containing	0.017857142857142856
containing words	0.125
or structures	0.0045045045045045045
structures that	0.4
have not	0.019230769230769232
before -RRB-	0.3333333333333333
-RRB- and	0.05420054200542006
to erroneous	0.0013280212483399733
erroneous input	1.0
e.g. with	0.017857142857142856
with misspelled	0.00546448087431694
misspelled words	1.0
or words	0.0045045045045045045
words accidentally	0.009174311926605505
accidentally omitted	1.0
omitted -RRB-	1.0
Automatic	0.0002511020590368841
structures	0.00013950114390938006
erroneous	2.7900228781876013e-05
misspelled	2.7900228781876013e-05
accidentally	2.7900228781876013e-05
omitted	2.7900228781876013e-05
, handling	0.0011229646266142617
handling such	0.5
such input	0.008130081300813009
input gracefully	0.024390243902439025
gracefully with	1.0
with hand-written	0.00546448087431694
rules --	0.023255813953488372
-- or	0.04
or more	0.018018018018018018
more generally	0.010526315789473684
generally ,	0.09090909090909091
, creating	0.0011229646266142617
creating systems	0.14285714285714285
decisions --	0.1
-- is	0.04
is extremely	0.0040650406504065045
extremely difficult	0.75
difficult ,	0.03571428571428571
, error-prone	0.0005614823133071309
error-prone and	1.0
and time-consuming	0.001445086705202312
time-consuming .	0.3333333333333333
handling	5.5800457563752025e-05
gracefully	2.7900228781876013e-05
creating	0.0001953016014731321
extremely	0.00011160091512750405
error-prone	2.7900228781876013e-05
time-consuming	8.370068634562804e-05
on automatically	0.0047169811320754715
automatically learning	0.047619047619047616
learning the	0.023255813953488372
rules can	0.06976744186046512
be made	0.016877637130801686
made more	0.125
more accurate	0.031578947368421054
accurate simply	0.14285714285714285
simply by	0.08333333333333333
by supplying	0.005714285714285714
supplying more	1.0
more input	0.010526315789473684
made	0.0004464036605100162
simply	0.00033480274538251215
supplying	2.7900228781876013e-05
, systems	0.0011229646266142617
systems based	0.017857142857142856
on hand-written	0.0047169811320754715
can only	0.011049723756906077
only be	0.02631578947368421
accurate by	0.14285714285714285
by increasing	0.005714285714285714
increasing the	0.3333333333333333
the complexity	0.005536332179930796
complexity of	0.6666666666666666
rules ,	0.11627906976744186
which is	0.09420289855072464
a much	0.0036809815950920245
difficult task	0.03571428571428571
task .	0.23809523809523808
increasing	8.370068634562804e-05
complexity	0.00033480274538251215
In particular	0.02857142857142857
particular ,	0.23076923076923078
a limit	0.001226993865030675
limit to	0.25
of systems	0.0017825311942959
on hand-crafted	0.0047169811320754715
hand-crafted rules	0.5
, beyond	0.0005614823133071309
beyond which	0.16666666666666666
which the	0.057971014492753624
systems become	0.008928571428571428
become more	0.25
more and	0.021052631578947368
and more	0.0072254335260115606
more unmanageable	0.010526315789473684
unmanageable .	1.0
particular	0.00036270297416438817
limit	0.00011160091512750405
hand-crafted	5.5800457563752025e-05
beyond	0.00016740137269125608
become	0.00011160091512750405
unmanageable	2.7900228781876013e-05
creating more	0.14285714285714285
more data	0.021052631578947368
data to	0.012987012987012988
to input	0.0026560424966799467
input to	0.07317073170731707
to machine-learning	0.0013280212483399733
machine-learning systems	0.25
systems simply	0.008928571428571428
simply requires	0.08333333333333333
requires a	0.0625
a corresponding	0.001226993865030675
corresponding increase	0.16666666666666666
the number	0.004844290657439446
of man-hours	0.00089126559714795
man-hours worked	1.0
worked ,	0.2
, generally	0.0005614823133071309
generally without	0.09090909090909091
without significant	0.07692307692307693
significant increases	0.1111111111111111
increases in	1.0
the annotation	0.0006920415224913495
annotation process	0.25
process .	0.1388888888888889
man-hours	2.7900228781876013e-05
worked	0.00013950114390938006
without	0.00036270297416438817
significant	0.0002511020590368841
increases	5.5800457563752025e-05
annotation	0.00011160091512750405
<s> Major	0.0015372790161414297
Major tasks	0.5
tasks in	0.09375
NLP The	0.0425531914893617
The following	0.020833333333333332
following is	0.06666666666666667
a list	0.008588957055214725
list of	0.7272727272727273
of some	0.004456327985739751
some of	0.1566265060240964
most commonly	0.017241379310344827
commonly researched	0.125
researched tasks	1.0
Major	5.5800457563752025e-05
following	0.0004185034317281402
list	0.00030690251660063614
some	0.002315718988895709
commonly	0.0002232018302550081
researched	2.7900228781876013e-05
<s> Note	0.006917755572636433
Note that	0.7777777777777778
that some	0.014184397163120567
these tasks	0.047619047619047616
tasks have	0.03125
have direct	0.009615384615384616
direct real-world	0.16666666666666666
real-world applications	0.16666666666666666
applications ,	0.16
, while	0.007860752386299831
while others	0.2
others more	0.08333333333333333
more commonly	0.021052631578947368
commonly serve	0.125
serve as	0.8
as subtasks	0.003484320557491289
subtasks that	0.5
are used	0.03319502074688797
to aid	0.0013280212483399733
aid in	0.75
in solving	0.0018726591760299626
solving larger	1.0
larger tasks	0.0625
Note	0.0002511020590368841
applications	0.0006975057195469003
while	0.0005580045756375203
others	0.00033480274538251215
serve	0.00013950114390938006
aid	0.00011160091512750405
solving	2.7900228781876013e-05
<s> What	0.0030745580322828594
What distinguishes	0.09090909090909091
distinguishes these	0.5
tasks from	0.03125
from other	0.009615384615384616
other potential	0.014285714285714285
potential and	0.14285714285714285
and actual	0.001445086705202312
actual NLP	0.2
tasks is	0.03125
not only	0.0625
only the	0.10526315789473684
the volume	0.0006920415224913495
volume of	0.5
research devoted	0.023809523809523808
devoted to	0.6
to them	0.0026560424966799467
them but	0.05263157894736842
but the	0.04411764705882353
the fact	0.002768166089965398
fact that	0.45454545454545453
that for	0.0035460992907801418
for each	0.02527075812274368
each one	0.044444444444444446
one there	0.015384615384615385
typically a	0.05555555555555555
a well-defined	0.001226993865030675
well-defined problem	1.0
problem setting	0.022727272727272728
setting ,	0.4
a standard	0.00245398773006135
standard metric	0.07142857142857142
metric for	0.3333333333333333
for evaluating	0.010830324909747292
evaluating the	0.2
task ,	0.09523809523809523
, standard	0.0011229646266142617
standard corpora	0.07142857142857142
corpora on	0.09090909090909091
on which	0.014150943396226415
task can	0.023809523809523808
be evaluated	0.008438818565400843
evaluated ,	0.14285714285714285
and competitions	0.001445086705202312
competitions devoted	1.0
the specific	0.0020761245674740486
specific task	0.047619047619047616
What	0.00030690251660063614
distinguishes	5.5800457563752025e-05
potential	0.0001953016014731321
actual	0.00013950114390938006
volume	0.00011160091512750405
them	0.0005301043468556442
but	0.0018972155571675689
fact	0.00030690251660063614
well-defined	2.7900228781876013e-05
setting	0.00013950114390938006
standard	0.0003906032029462642
metric	8.370068634562804e-05
evaluating	0.00013950114390938006
evaluated	0.0001953016014731321
competitions	2.7900228781876013e-05
specific	0.0005859048044193963
Automatic summarization	0.2222222222222222
summarization :	0.02
: Produce	0.00980392156862745
Produce a	1.0
a readable	0.001226993865030675
readable summary	0.3333333333333333
summary of	0.07142857142857142
a chunk	0.007361963190184049
chunk of	1.0
text .	0.16981132075471697
summarization	0.0013950114390938006
Produce	2.7900228781876013e-05
readable	8.370068634562804e-05
summary	0.0011718096088387925
chunk	0.0001953016014731321
<s> Often	0.0023059185242121443
Often used	0.3333333333333333
to provide	0.005312084993359893
provide summaries	0.16666666666666666
summaries of	0.09302325581395349
text of	0.006289308176100629
a known	0.00245398773006135
known type	0.038461538461538464
type ,	0.07142857142857142
as articles	0.003484320557491289
articles in	0.25
the financial	0.0006920415224913495
financial section	0.25
section of	0.16666666666666666
a newspaper	0.001226993865030675
newspaper .	0.3333333333333333
Often	8.370068634562804e-05
summaries	0.0011997098376206685
known	0.0007254059483287763
type	0.0003906032029462642
financial	0.00011160091512750405
section	0.00016740137269125608
newspaper	8.370068634562804e-05
<s> Coreference	0.0007686395080707148
Coreference resolution	1.0
resolution :	0.25
: Given	0.09803921568627451
Given a	0.7142857142857143
sentence or	0.041666666666666664
or larger	0.0045045045045045045
larger chunk	0.0625
, determine	0.003368893879842785
determine which	0.08695652173913043
which words	0.014492753623188406
words -LRB-	0.027522935779816515
-LRB- ``	0.02168021680216802
`` mentions	0.005291005291005291
mentions ''	0.3333333333333333
-RRB- refer	0.0027100271002710027
refer to	1.0
same objects	0.04
objects -LRB-	0.2
`` entities	0.005291005291005291
entities ''	0.14285714285714285
Coreference	2.7900228781876013e-05
resolution	0.00011160091512750405
Given	0.0003906032029462642
determine	0.0006417052619831483
mentions	8.370068634562804e-05
refer	0.00016740137269125608
objects	0.00013950114390938006
entities	0.0001953016014731321
<s> Anaphora	0.0007686395080707148
Anaphora resolution	1.0
resolution is	0.25
a specific	0.006134969325153374
specific example	0.047619047619047616
of this	0.00980392156862745
and is	0.008670520231213872
is specifically	0.0020325203252032522
specifically concerned	0.5
with matching	0.00546448087431694
matching up	0.2
up pronouns	0.045454545454545456
pronouns with	0.5
the nouns	0.0006920415224913495
nouns or	0.1111111111111111
or names	0.0045045045045045045
names that	0.2857142857142857
they refer	0.05
to .	0.00398406374501992
Anaphora	2.7900228781876013e-05
matching	0.00013950114390938006
pronouns	5.5800457563752025e-05
nouns	0.0002511020590368841
names	0.0001953016014731321
For example	0.6229508196721312
sentence such	0.020833333333333332
`` He	0.005291005291005291
He entered	0.125
entered John	0.5
John 's	0.25
's house	0.0392156862745098
house through	0.5
the front	0.0020761245674740486
front door	1.0
door ''	0.5
'' is	0.04639175257731959
a referring	0.001226993865030675
referring expression	0.5
expression and	0.2
the bridging	0.0006920415224913495
bridging relationship	1.0
relationship to	0.16666666666666666
be identified	0.008438818565400843
identified is	0.2
the door	0.0006920415224913495
door being	0.25
being referred	0.05555555555555555
to is	0.0013280212483399733
door of	0.25
of John	0.00089126559714795
house -LRB-	0.5
-LRB- rather	0.0027100271002710027
than of	0.022222222222222223
some other	0.08433734939759036
other structure	0.014285714285714285
structure that	0.08333333333333333
that might	0.0070921985815602835
might also	0.038461538461538464
also be	0.10144927536231885
be referred	0.004219409282700422
to -RRB-	0.0013280212483399733
He	0.0002232018302550081
entered	5.5800457563752025e-05
John	0.0002232018302550081
house	5.5800457563752025e-05
front	8.370068634562804e-05
door	0.00011160091512750405
referring	5.5800457563752025e-05
expression	0.00027900228781876013
bridging	2.7900228781876013e-05
relationship	0.00016740137269125608
identified	0.00013950114390938006
structure	0.00033480274538251215
<s> Discourse	0.0023059185242121443
Discourse analysis	1.0
analysis :	0.06153846153846154
: This	0.0392156862745098
This rubric	0.015873015873015872
rubric includes	1.0
includes a	0.14285714285714285
of related	0.00267379679144385
related tasks	0.2
Discourse	8.370068634562804e-05
rubric	2.7900228781876013e-05
related	0.0004185034317281402
<s> One	0.009223674096848577
One task	0.07692307692307693
is identifying	0.0020325203252032522
identifying the	0.6666666666666666
the discourse	0.0020761245674740486
discourse structure	0.027777777777777776
structure of	0.3333333333333333
of connected	0.00089126559714795
connected text	0.2
i.e. the	0.2631578947368421
discourse relationships	0.027777777777777776
relationships between	0.16666666666666666
between sentences	0.05128205128205128
sentences -LRB-	0.02631578947368421
e.g. elaboration	0.017857142857142856
elaboration ,	1.0
, explanation	0.0005614823133071309
explanation ,	1.0
, contrast	0.0005614823133071309
contrast -RRB-	0.125
One	0.00036270297416438817
identifying	0.00016740137269125608
discourse	0.0010044082361475365
connected	0.00013950114390938006
relationships	0.00016740137269125608
elaboration	2.7900228781876013e-05
explanation	2.7900228781876013e-05
contrast	0.0002232018302550081
<s> Another	0.009992313604919293
Another possible	0.07692307692307693
possible task	0.041666666666666664
is recognizing	0.0020325203252032522
recognizing and	0.2
and classifying	0.001445086705202312
classifying the	0.2
the speech	0.006920415224913495
speech acts	0.019736842105263157
acts in	0.3333333333333333
text -LRB-	0.03773584905660377
e.g. yes-no	0.017857142857142856
yes-no question	1.0
, content	0.0005614823133071309
content question	0.08333333333333333
, statement	0.0005614823133071309
statement ,	1.0
, assertion	0.0005614823133071309
assertion ,	1.0
, etc.	0.011229646266142616
etc. -RRB-	0.4090909090909091
Another	0.00036270297416438817
recognizing	0.00013950114390938006
classifying	0.00013950114390938006
acts	8.370068634562804e-05
yes-no	2.7900228781876013e-05
statement	2.7900228781876013e-05
assertion	2.7900228781876013e-05
etc.	0.0006138050332012723
<s> Machine	0.0023059185242121443
Machine translation	0.5555555555555556
translation :	0.02702702702702703
: Automatically	0.00980392156862745
Automatically translate	1.0
translate text	0.3333333333333333
text from	0.012578616352201259
from one	0.028846153846153848
one human	0.015384615384615385
human language	0.06521739130434782
language to	0.02702702702702703
to another	0.00398406374501992
another .	0.23076923076923078
Machine	0.0002511020590368841
Automatically	2.7900228781876013e-05
translate	0.00016740137269125608
another	0.00036270297416438817
This is	0.2698412698412698
is one	0.012195121951219513
one of	0.2153846153846154
most difficult	0.017241379310344827
difficult problems	0.10714285714285714
problems ,	0.35294117647058826
a member	0.001226993865030675
member of	1.0
a class	0.001226993865030675
class of	0.75
of problems	0.0017825311942959
problems colloquially	0.11764705882352941
colloquially termed	1.0
termed ``	0.5
`` AI-complete	0.010582010582010581
AI-complete ''	0.6666666666666666
i.e. requiring	0.05263157894736842
requiring all	0.5
the different	0.0006920415224913495
different types	0.04081632653061224
of knowledge	0.0017825311942959
knowledge that	0.037037037037037035
that humans	0.0070921985815602835
humans possess	0.08333333333333333
possess -LRB-	1.0
-LRB- grammar	0.0027100271002710027
grammar ,	0.10810810810810811
, semantics	0.0016844469399213925
semantics ,	0.2857142857142857
, facts	0.0005614823133071309
facts about	1.0
the real	0.0020761245674740486
real world	0.3333333333333333
world ,	0.06666666666666667
-RRB- in	0.01084010840108401
in order	0.013108614232209739
order to	0.5714285714285714
to solve	0.005312084993359893
solve properly	0.25
properly .	0.5
problems	0.0004743038892918922
member	2.7900228781876013e-05
class	0.00011160091512750405
colloquially	5.5800457563752025e-05
termed	0.00011160091512750405
requiring	5.5800457563752025e-05
humans	0.00033480274538251215
possess	2.7900228781876013e-05
semantics	0.0003906032029462642
facts	2.7900228781876013e-05
order	0.0003906032029462642
solve	0.00011160091512750405
properly	5.5800457563752025e-05
<s> Morphological	0.0007686395080707148
Morphological segmentation	1.0
segmentation :	0.09090909090909091
: Separate	0.0196078431372549
Separate words	0.5
words into	0.03669724770642202
into individual	0.01282051282051282
individual morphemes	0.08333333333333333
morphemes and	0.3333333333333333
and identify	0.002890173410404624
identify the	0.5
the class	0.0006920415224913495
the morphemes	0.0006920415224913495
morphemes .	0.3333333333333333
Morphological	2.7900228781876013e-05
segmentation	0.0009207075498019084
Separate	5.5800457563752025e-05
morphemes	8.370068634562804e-05
identify	0.00033480274538251215
The difficulty	0.015625
difficulty of	0.42857142857142855
task depends	0.023809523809523808
depends greatly	0.125
greatly on	0.14285714285714285
the morphology	0.0006920415224913495
morphology -LRB-	0.14285714285714285
-LRB- i.e.	0.02981029810298103
the structure	0.0020761245674740486
of words	0.013368983957219251
words -RRB-	0.027522935779816515
-RRB- of	0.018970189701897018
the language	0.005536332179930796
language being	0.013513513513513514
considered .	0.1111111111111111
difficulty	0.0001953016014731321
greatly	0.0001953016014731321
morphology	0.0001953016014731321
<s> English	0.0007686395080707148
English has	0.05405405405405406
has fairly	0.011904761904761904
fairly simple	0.25
simple morphology	0.038461538461538464
morphology ,	0.7142857142857143
especially inflectional	0.06666666666666667
inflectional morphology	1.0
and thus	0.004335260115606936
thus it	0.1
often possible	0.022727272727272728
to ignore	0.0013280212483399733
ignore this	1.0
task entirely	0.023809523809523808
entirely and	0.5
and simply	0.001445086705202312
simply model	0.08333333333333333
model all	0.03333333333333333
all possible	0.06976744186046512
possible forms	0.041666666666666664
forms of	0.3333333333333333
word -LRB-	0.016666666666666666
e.g. ``	0.017857142857142856
`` open	0.005291005291005291
open ,	0.25
, opens	0.0005614823133071309
opens ,	1.0
, opened	0.0005614823133071309
opened ,	1.0
, opening	0.0005614823133071309
opening ''	1.0
-RRB- as	0.008130081300813009
as separate	0.003484320557491289
separate words	0.3
fairly	0.00011160091512750405
inflectional	5.5800457563752025e-05
thus	0.00027900228781876013
ignore	2.7900228781876013e-05
entirely	5.5800457563752025e-05
forms	0.00016740137269125608
open	0.00011160091512750405
opens	2.7900228781876013e-05
opened	2.7900228781876013e-05
opening	2.7900228781876013e-05
separate	0.00027900228781876013
In languages	0.009523809523809525
languages such	0.1
as Turkish	0.003484320557491289
Turkish ,	1.0
such an	0.016260162601626018
an approach	0.030303030303030304
approach is	0.14285714285714285
not possible	0.008928571428571428
possible ,	0.125
, as	0.01291409320606401
as each	0.003484320557491289
each dictionary	0.022222222222222223
dictionary entry	0.14285714285714285
entry has	0.25
has thousands	0.011904761904761904
thousands of	0.6666666666666666
of possible	0.00267379679144385
possible word	0.041666666666666664
word forms	0.016666666666666666
forms .	0.16666666666666666
Turkish	2.7900228781876013e-05
dictionary	0.0001953016014731321
entry	0.00011160091512750405
thousands	8.370068634562804e-05
<s> Named	0.0007686395080707148
Named entity	1.0
entity recognition	0.4
recognition -LRB-	0.049586776859504134
-LRB- NER	0.0027100271002710027
NER -RRB-	1.0
-RRB- :	0.024390243902439025
a stream	0.001226993865030675
stream of	0.5
which items	0.007246376811594203
items in	0.5
the text	0.017993079584775088
text map	0.006289308176100629
map to	0.5
to proper	0.0013280212483399733
proper names	0.14285714285714285
names ,	0.2857142857142857
as people	0.003484320557491289
people or	0.0625
or places	0.0045045045045045045
places ,	0.5
and what	0.001445086705202312
what the	0.125
the type	0.002768166089965398
type of	0.5714285714285714
each such	0.022222222222222223
such name	0.008130081300813009
name is	0.2
is -LRB-	0.0040650406504065045
e.g. person	0.017857142857142856
person ,	0.21052631578947367
, location	0.0005614823133071309
location ,	1.0
, organization	0.0011229646266142617
organization -RRB-	0.2
Named	2.7900228781876013e-05
entity	0.00013950114390938006
NER	2.7900228781876013e-05
stream	5.5800457563752025e-05
items	5.5800457563752025e-05
map	5.5800457563752025e-05
proper	0.0001953016014731321
people	0.0004464036605100162
places	5.5800457563752025e-05
name	0.00013950114390938006
person	0.0005301043468556442
location	2.7900228781876013e-05
organization	0.00013950114390938006
that ,	0.0035460992907801418
although capitalization	0.16666666666666666
capitalization can	0.3333333333333333
can aid	0.0055248618784530384
in recognizing	0.003745318352059925
recognizing named	0.2
named entities	0.42857142857142855
entities in	0.14285714285714285
in languages	0.0018726591760299626
as English	0.010452961672473868
English ,	0.16216216216216217
this information	0.01098901098901099
information can	0.021739130434782608
can not	0.08287292817679558
not aid	0.008928571428571428
in determining	0.0018726591760299626
of named	0.00089126559714795
named entity	0.2857142857142857
entity ,	0.4
and in	0.010115606936416185
in any	0.0018726591760299626
any case	0.0967741935483871
case is	0.058823529411764705
often inaccurate	0.022727272727272728
inaccurate or	1.0
or insufficient	0.0045045045045045045
insufficient .	1.0
capitalization	8.370068634562804e-05
named	0.0001953016014731321
case	0.0004743038892918922
inaccurate	2.7900228781876013e-05
insufficient	5.5800457563752025e-05
first word	0.030303030303030304
word of	0.016666666666666666
sentence is	0.041666666666666664
is also	0.02032520325203252
also capitalized	0.014492753623188406
capitalized ,	0.6666666666666666
and named	0.001445086705202312
entities often	0.14285714285714285
often span	0.022727272727272728
span several	1.0
several words	0.045454545454545456
, only	0.0011229646266142617
only some	0.05263157894736842
which are	0.08695652173913043
are capitalized	0.004149377593360996
capitalized .	0.3333333333333333
capitalized	8.370068634562804e-05
span	2.7900228781876013e-05
several	0.0006138050332012723
<s> Furthermore	0.004611837048424289
Furthermore ,	1.0
many other	0.09615384615384616
other languages	0.07142857142857142
languages in	0.02
in non-Western	0.0018726591760299626
non-Western scripts	1.0
scripts -LRB-	0.6666666666666666
e.g. Chinese	0.017857142857142856
Chinese or	0.14285714285714285
or Arabic	0.0045045045045045045
Arabic -RRB-	0.25
-RRB- do	0.0027100271002710027
do not	0.5
not have	0.017857142857142856
have any	0.009615384615384616
any capitalization	0.03225806451612903
capitalization at	0.3333333333333333
all ,	0.06976744186046512
and even	0.008670520231213872
even languages	0.037037037037037035
languages with	0.02
with capitalization	0.00546448087431694
capitalization may	0.3333333333333333
may not	0.09615384615384616
not consistently	0.017857142857142856
consistently use	0.3333333333333333
use it	0.027777777777777776
it to	0.042735042735042736
distinguish names	0.2
names .	0.2857142857142857
Furthermore	0.00016740137269125608
non-Western	2.7900228781876013e-05
scripts	8.370068634562804e-05
Chinese	0.0001953016014731321
Arabic	0.00011160091512750405
even	0.0007533061771106523
may	0.0014508118966575527
consistently	8.370068634562804e-05
, German	0.0011229646266142617
German capitalizes	0.25
capitalizes all	1.0
all nouns	0.023255813953488372
nouns ,	0.6666666666666666
, regardless	0.0016844469399213925
regardless of	1.0
of whether	0.00089126559714795
whether they	0.07692307692307693
to names	0.0013280212483399733
and French	0.001445086705202312
French and	0.25
and Spanish	0.001445086705202312
Spanish do	0.5
not capitalize	0.008928571428571428
capitalize names	1.0
that serve	0.0035460992907801418
as adjectives	0.003484320557491289
adjectives .	0.3333333333333333
German	0.00011160091512750405
capitalizes	2.7900228781876013e-05
regardless	8.370068634562804e-05
French	0.0002232018302550081
Spanish	5.5800457563752025e-05
capitalize	2.7900228781876013e-05
adjectives	8.370068634562804e-05
language generation	0.033783783783783786
generation :	0.2222222222222222
: Convert	0.0196078431372549
Convert information	0.5
from computer	0.009615384615384616
computer databases	0.022727272727272728
databases into	0.125
into readable	0.01282051282051282
readable human	0.3333333333333333
language .	0.07432432432432433
generation	0.0002511020590368841
Convert	5.5800457563752025e-05
databases	0.0002232018302550081
understanding :	0.030303030303030304
Convert chunks	0.5
chunks of	1.0
text into	0.0440251572327044
into more	0.02564102564102564
more formal	0.010526315789473684
formal representations	0.2222222222222222
representations such	0.25
as first-order	0.003484320557491289
first-order logic	1.0
logic structures	0.25
are easier	0.004149377593360996
easier for	0.125
for computer	0.010830324909747292
computer programs	0.045454545454545456
programs to	0.09090909090909091
manipulate .	0.3333333333333333
chunks	2.7900228781876013e-05
formal	0.0002511020590368841
representations	0.00011160091512750405
first-order	2.7900228781876013e-05
logic	0.00011160091512750405
easier	0.0002232018302550081
programs	0.00030690251660063614
understanding involves	0.030303030303030304
involves the	0.2
the identification	0.001384083044982699
identification of	0.4
the intended	0.001384083044982699
intended semantic	0.2
semantic from	0.047619047619047616
the multiple	0.0006920415224913495
multiple possible	0.15384615384615385
possible semantics	0.041666666666666664
semantics which	0.14285714285714285
be derived	0.008438818565400843
derived from	0.5
from a	0.11538461538461539
language expression	0.006756756756756757
expression which	0.1
which usually	0.007246376811594203
usually takes	0.03125
takes the	0.3333333333333333
the form	0.0006920415224913495
form of	0.35
of organized	0.00089126559714795
organized notations	1.0
notations of	0.5
natural languages	0.12
languages concepts	0.02
concepts .	0.4
involves	0.00027900228781876013
identification	0.00013950114390938006
intended	0.00013950114390938006
semantic	0.0005859048044193963
derived	0.00016740137269125608
usually	0.0008928073210200324
takes	8.370068634562804e-05
form	0.0005580045756375203
organized	2.7900228781876013e-05
notations	5.5800457563752025e-05
concepts	0.00013950114390938006
<s> Introduction	0.0007686395080707148
Introduction and	1.0
and creation	0.001445086705202312
creation of	1.0
of language	0.004456327985739751
language metamodel	0.006756756756756757
metamodel and	1.0
and ontology	0.001445086705202312
ontology are	0.5
are efficient	0.004149377593360996
efficient however	0.3333333333333333
however empirical	0.07692307692307693
empirical solutions	1.0
solutions .	0.5
Introduction	2.7900228781876013e-05
creation	5.5800457563752025e-05
metamodel	2.7900228781876013e-05
ontology	5.5800457563752025e-05
efficient	8.370068634562804e-05
empirical	2.7900228781876013e-05
solutions	5.5800457563752025e-05
An explicit	0.0625
explicit formalization	0.2
formalization of	0.5
languages semantics	0.02
semantics without	0.07142857142857142
without confusions	0.07692307692307693
confusions with	1.0
with implicit	0.00546448087431694
implicit assumptions	1.0
assumptions such	0.2
as closed	0.003484320557491289
closed world	1.0
world assumption	0.13333333333333333
assumption -LRB-	0.5
-LRB- CWA	0.0027100271002710027
CWA -RRB-	1.0
-RRB- vs.	0.0027100271002710027
vs. open	0.08333333333333333
open world	0.25
assumption ,	0.5
or subjective	0.009009009009009009
subjective Yes\/No	0.16666666666666666
Yes\/No vs.	1.0
vs. objective	0.08333333333333333
objective True\/False	0.2
True\/False is	1.0
is expected	0.0020325203252032522
expected for	0.14285714285714285
the construction	0.0006920415224913495
construction of	0.6666666666666666
a basis	0.00245398773006135
of semantics	0.00089126559714795
semantics formalization	0.07142857142857142
formalization .	0.5
explicit	0.00013950114390938006
formalization	5.5800457563752025e-05
confusions	2.7900228781876013e-05
implicit	2.7900228781876013e-05
assumptions	0.00013950114390938006
closed	2.7900228781876013e-05
assumption	5.5800457563752025e-05
CWA	2.7900228781876013e-05
vs.	0.00033480274538251215
subjective	0.00016740137269125608
Yes\/No	2.7900228781876013e-05
objective	0.00013950114390938006
True\/False	2.7900228781876013e-05
expected	0.0001953016014731321
construction	8.370068634562804e-05
<s> Optical	0.0015372790161414297
Optical character	0.6666666666666666
character recognition	0.5
-LRB- OCR	0.0027100271002710027
OCR -RRB-	0.02040816326530612
Given an	0.07142857142857142
an image	0.007575757575757576
image representing	0.3333333333333333
representing printed	0.5
printed text	0.25
determine the	0.391304347826087
corresponding text	0.16666666666666666
Optical	8.370068634562804e-05
character	0.0006138050332012723
OCR	0.0013671112103119246
image	8.370068634562804e-05
representing	5.5800457563752025e-05
printed	0.00033480274538251215
<s> Part-of-speech	0.0007686395080707148
Part-of-speech tagging	0.5
tagging :	0.04
Part-of-speech	5.5800457563752025e-05
Many words	0.16666666666666666
especially common	0.13333333333333333
common ones	0.04
ones ,	0.3
, can	0.003368893879842785
can serve	0.011049723756906077
as multiple	0.003484320557491289
multiple parts	0.07692307692307693
parts of	1.0
speech .	0.06578947368421052
ones	0.00027900228781876013
parts	0.0004464036605100162
`` book	0.005291005291005291
book ''	0.125
'' can	0.02577319587628866
a noun	0.007361963190184049
noun -LRB-	0.07142857142857142
the book	0.001384083044982699
book on	0.125
the table	0.001384083044982699
table ''	0.14285714285714285
-RRB- or	0.01084010840108401
or verb	0.0045045045045045045
verb -LRB-	0.15384615384615385
`` to	0.010582010582010581
to book	0.0013280212483399733
book a	0.125
a flight	0.001226993865030675
flight ''	0.5
-RRB- ;	0.02168021680216802
; ``	0.02127659574468085
`` set	0.005291005291005291
set ''	0.05128205128205128
noun ,	0.42857142857142855
, verb	0.0011229646266142617
verb or	0.23076923076923078
or adjective	0.0045045045045045045
adjective ;	0.14285714285714285
; and	0.0851063829787234
and ``	0.028901734104046242
`` out	0.005291005291005291
out ''	0.07142857142857142
be any	0.004219409282700422
any of	0.06451612903225806
of at	0.00089126559714795
at least	0.07352941176470588
least five	0.2
five different	0.2
different parts	0.04081632653061224
book	0.0002232018302550081
noun	0.0003906032029462642
table	0.0001953016014731321
verb	0.00036270297416438817
flight	5.5800457563752025e-05
adjective	0.0001953016014731321
out	0.0003906032029462642
least	0.00013950114390938006
some languages	0.024096385542168676
languages have	0.04
have more	0.028846153846153848
more such	0.010526315789473684
such ambiguity	0.024390243902439025
ambiguity than	0.125
than others	0.044444444444444446
others .	0.25
ambiguity	0.0002232018302550081
<s> Languages	0.0023059185242121443
Languages with	0.3333333333333333
with little	0.00546448087431694
little inflectional	0.3333333333333333
English are	0.02702702702702703
are particularly	0.004149377593360996
particularly prone	0.2
prone to	1.0
to such	0.0026560424966799467
ambiguity .	0.125
Languages	8.370068634562804e-05
little	8.370068634562804e-05
particularly	0.00013950114390938006
prone	5.5800457563752025e-05
<s> Chinese	0.0007686395080707148
Chinese is	0.14285714285714285
is prone	0.0020325203252032522
ambiguity because	0.125
a tonal	0.001226993865030675
tonal language	1.0
language during	0.006756756756756757
during verbalization	0.1
verbalization .	1.0
tonal	2.7900228781876013e-05
verbalization	2.7900228781876013e-05
Such inflection	0.125
inflection is	1.0
not readily	0.008928571428571428
readily conveyed	0.3333333333333333
conveyed via	1.0
via the	1.0
the entities	0.0006920415224913495
entities employed	0.14285714285714285
employed within	1.0
within the	0.16666666666666666
the orthography	0.0006920415224913495
orthography to	0.5
to convey	0.00398406374501992
convey intended	0.3333333333333333
intended meaning	0.2
meaning .	0.08695652173913043
inflection	2.7900228781876013e-05
readily	8.370068634562804e-05
conveyed	2.7900228781876013e-05
via	2.7900228781876013e-05
employed	2.7900228781876013e-05
orthography	5.5800457563752025e-05
convey	8.370068634562804e-05
meaning	0.0006417052619831483
<s> Parsing	0.0030745580322828594
Parsing :	0.2
: Determine	0.00980392156862745
Determine the	1.0
the parse	0.0006920415224913495
parse tree	0.1111111111111111
tree -LRB-	1.0
-LRB- grammatical	0.0027100271002710027
grammatical analysis	0.09090909090909091
analysis -RRB-	0.03076923076923077
sentence .	0.14583333333333334
Parsing	0.00013950114390938006
Determine	2.7900228781876013e-05
parse	0.0002511020590368841
tree	2.7900228781876013e-05
grammatical	0.00030690251660063614
The grammar	0.010416666666666666
grammar for	0.02702702702702703
for natural	0.01444043321299639
languages is	0.02
is ambiguous	0.0020325203252032522
ambiguous and	0.16666666666666666
and typical	0.001445086705202312
typical sentences	0.1111111111111111
sentences have	0.02631578947368421
have multiple	0.009615384615384616
possible analyses	0.08333333333333333
analyses .	0.4
ambiguous	0.00033480274538251215
analyses	0.00013950114390938006
In fact	0.0380952380952381
fact ,	0.45454545454545453
, perhaps	0.0016844469399213925
perhaps surprisingly	0.16666666666666666
surprisingly ,	0.3333333333333333
a typical	0.00245398773006135
typical sentence	0.1111111111111111
sentence there	0.020833333333333332
there may	0.025
may be	0.40384615384615385
be thousands	0.004219409282700422
of potential	0.0017825311942959
potential parses	0.14285714285714285
parses -LRB-	0.5
-LRB- most	0.01084010840108401
most of	0.08620689655172414
which will	0.021739130434782608
will seem	0.02857142857142857
seem completely	0.5
completely nonsensical	1.0
nonsensical to	1.0
to a	0.03718459495351926
human -RRB-	0.043478260869565216
perhaps	0.00016740137269125608
surprisingly	8.370068634562804e-05
parses	5.5800457563752025e-05
seem	5.5800457563752025e-05
completely	2.7900228781876013e-05
nonsensical	2.7900228781876013e-05
<s> Question	0.003843197540353574
Question answering	0.2857142857142857
answering :	0.08333333333333333
a human-language	0.001226993865030675
human-language question	1.0
determine its	0.08695652173913043
its answer	0.02857142857142857
answer .	0.23333333333333334
Question	0.0001953016014731321
answering	0.00033480274538251215
human-language	2.7900228781876013e-05
answer	0.0008370068634562804
<s> Typical	0.0015372790161414297
Typical questions	0.5
questions have	0.038461538461538464
have a	0.125
specific right	0.047619047619047616
right answer	0.1
answer -LRB-	0.03333333333333333
-LRB- such	0.02168021680216802
`` What	0.015873015873015872
What is	0.2727272727272727
the capital	0.001384083044982699
capital of	0.6666666666666666
Canada ?	0.16666666666666666
Typical	5.5800457563752025e-05
questions	0.0007254059483287763
capital	8.370068634562804e-05
<s> ,	0.0007686395080707148
, but	0.02695115103874228
but sometimes	0.014705882352941176
sometimes open-ended	0.07692307692307693
open-ended questions	1.0
questions are	0.07692307692307693
are also	0.03319502074688797
also considered	0.014492753623188406
considered -LRB-	0.1111111111111111
the meaning	0.006920415224913495
meaning of	0.30434782608695654
of life	0.00089126559714795
life ?	0.25
open-ended	2.7900228781876013e-05
life	0.00011160091512750405
<s> Relationship	0.0007686395080707148
Relationship extraction	1.0
extraction :	0.06451612903225806
, identify	0.0011229646266142617
the relationships	0.0006920415224913495
relationships among	0.16666666666666666
among named	0.125
entities -LRB-	0.14285714285714285
e.g. who	0.017857142857142856
who is	0.2
the wife	0.0006920415224913495
wife of	1.0
of whom	0.00089126559714795
whom -RRB-	0.5
Relationship	2.7900228781876013e-05
extraction	0.0008649070922381564
who	0.00027900228781876013
wife	2.7900228781876013e-05
whom	5.5800457563752025e-05
<s> Sentence	0.0023059185242121443
Sentence breaking	0.2
breaking -LRB-	0.5
also known	0.08695652173913043
known as	0.38461538461538464
as sentence	0.006968641114982578
sentence boundary	0.0625
boundary disambiguation	0.3333333333333333
disambiguation -RRB-	0.2
, find	0.0011229646266142617
find the	0.3076923076923077
the sentence	0.004152249134948097
sentence boundaries	0.08333333333333333
boundaries .	0.36363636363636365
Sentence	0.00013950114390938006
breaking	5.5800457563752025e-05
boundary	0.00016740137269125608
disambiguation	0.00027900228781876013
find	0.00036270297416438817
boundaries	0.00030690251660063614
Sentence boundaries	0.2
boundaries are	0.09090909090909091
are often	0.016597510373443983
often marked	0.022727272727272728
marked by	0.3333333333333333
by periods	0.005714285714285714
periods or	0.3333333333333333
or other	0.009009009009009009
other punctuation	0.014285714285714285
punctuation marks	0.2857142857142857
marks ,	0.25
but these	0.014705882352941176
these same	0.023809523809523808
same characters	0.04
characters can	0.1875
serve other	0.2
other purposes	0.014285714285714285
purposes -LRB-	0.25
e.g. marking	0.017857142857142856
marking abbreviations	0.5
abbreviations -RRB-	0.2
marked	8.370068634562804e-05
periods	8.370068634562804e-05
punctuation	0.0001953016014731321
marks	0.00011160091512750405
characters	0.0004464036605100162
purposes	0.00011160091512750405
marking	5.5800457563752025e-05
abbreviations	0.00013950114390938006
<s> Sentiment	0.003843197540353574
Sentiment analysis	0.8333333333333334
: Extract	0.00980392156862745
Extract subjective	1.0
subjective information	0.3333333333333333
information usually	0.021739130434782608
usually from	0.03125
documents ,	0.23684210526315788
, often	0.0016844469399213925
often using	0.022727272727272728
using online	0.01694915254237288
online reviews	0.25
reviews to	0.16666666666666666
to determine	0.014608233731739707
determine ``	0.043478260869565216
`` polarity	0.005291005291005291
polarity ''	0.25
'' about	0.005154639175257732
about specific	0.025
specific objects	0.047619047619047616
objects .	0.2
Sentiment	0.00016740137269125608
Extract	2.7900228781876013e-05
reviews	0.00016740137269125608
polarity	0.0002232018302550081
is especially	0.0040650406504065045
especially useful	0.06666666666666667
useful for	0.21428571428571427
for identifying	0.0036101083032490976
identifying trends	0.16666666666666666
trends of	1.0
of public	0.00089126559714795
public opinion	1.0
opinion in	0.4
the social	0.0020761245674740486
social media	0.2857142857142857
media ,	0.5
the purpose	0.001384083044982699
purpose of	0.2
of marketing	0.00089126559714795
marketing .	1.0
useful	0.0003906032029462642
trends	2.7900228781876013e-05
public	2.7900228781876013e-05
opinion	0.00013950114390938006
social	0.0003906032029462642
media	0.00016740137269125608
purpose	0.00013950114390938006
marketing	2.7900228781876013e-05
<s> Speech	0.011529592621060722
Speech recognition	0.2903225806451613
recognition :	0.01652892561983471
a sound	0.008588957055214725
sound clip	0.1
clip of	1.0
a person	0.013496932515337423
person or	0.10526315789473684
or people	0.009009009009009009
people speaking	0.125
speaking ,	0.625
the textual	0.0006920415224913495
textual representation	0.2
representation of	0.10526315789473684
Speech	0.0008649070922381564
sound	0.0005580045756375203
clip	5.5800457563752025e-05
speaking	0.0002232018302550081
representation	0.0005301043468556442
the opposite	0.001384083044982699
opposite of	1.0
text to	0.0440251572327044
to speech	0.00398406374501992
speech and	0.013157894736842105
the extremely	0.0006920415224913495
-LRB- see	0.032520325203252036
see above	0.05
above -RRB-	0.07692307692307693
opposite	5.5800457563752025e-05
In natural	0.009523809523809525
natural speech	0.02666666666666667
speech there	0.006578947368421052
there are	0.375
are hardly	0.004149377593360996
hardly any	1.0
any pauses	0.03225806451612903
pauses between	0.5
between successive	0.02564102564102564
successive words	0.5
thus speech	0.1
speech segmentation	0.03289473684210526
segmentation is	0.2727272727272727
a necessary	0.001226993865030675
necessary subtask	0.1
subtask of	1.0
see below	0.05
below -RRB-	0.4
hardly	2.7900228781876013e-05
pauses	0.00011160091512750405
successive	5.5800457563752025e-05
necessary	0.00027900228781876013
subtask	5.5800457563752025e-05
below	0.00013950114390938006
Note also	0.1111111111111111
also that	0.014492753623188406
that in	0.0070921985815602835
in most	0.00749063670411985
most spoken	0.034482758620689655
spoken languages	0.14285714285714285
languages ,	0.22
the sounds	0.001384083044982699
sounds representing	0.06666666666666667
representing successive	0.5
successive letters	0.5
letters blend	0.1
blend into	0.3333333333333333
into each	0.01282051282051282
each other	0.13333333333333333
other in	0.014285714285714285
a process	0.0049079754601227
process termed	0.027777777777777776
termed coarticulation	0.25
coarticulation ,	1.0
, so	0.00673778775968557
so the	0.23333333333333334
the conversion	0.0006920415224913495
conversion of	0.6666666666666666
the analog	0.0006920415224913495
analog signal	0.5
signal to	0.16666666666666666
to discrete	0.0013280212483399733
discrete characters	0.3333333333333333
very difficult	0.04878048780487805
difficult process	0.03571428571428571
spoken	0.0003906032029462642
sounds	0.0004185034317281402
letters	0.00027900228781876013
blend	8.370068634562804e-05
coarticulation	2.7900228781876013e-05
conversion	8.370068634562804e-05
analog	5.5800457563752025e-05
signal	0.00016740137269125608
discrete	8.370068634562804e-05
Speech segmentation	0.0967741935483871
, separate	0.0011229646266142617
separate it	0.2
it into	0.042735042735042736
into words	0.038461538461538464
A subtask	0.02
recognition and	0.05785123966942149
typically grouped	0.05555555555555555
grouped with	0.5
with it	0.01092896174863388
grouped	5.5800457563752025e-05
<s> Topic	0.0007686395080707148
Topic segmentation	1.0
segmentation and	0.06060606060606061
and recognition	0.001445086705202312
into segments	0.02564102564102564
segments each	0.2
is devoted	0.0020325203252032522
a topic	0.001226993865030675
topic ,	0.25
the topic	0.001384083044982699
topic of	0.125
the segment	0.0006920415224913495
segment .	0.1111111111111111
Topic	2.7900228781876013e-05
segments	0.00013950114390938006
topic	0.0002232018302550081
segment	0.0002511020590368841
<s> Word	0.003843197540353574
Word segmentation	0.14285714285714285
Separate a	0.5
of continuous	0.0017825311942959
continuous text	0.16666666666666666
into separate	0.02564102564102564
Word	0.0001953016014731321
continuous	0.00016740137269125608
a language	0.007361963190184049
language like	0.006756756756756757
like English	0.07142857142857142
this is	0.0989010989010989
is fairly	0.0020325203252032522
fairly trivial	0.25
trivial ,	0.25
, since	0.002807411566535654
since words	0.1
words are	0.09174311926605505
are usually	0.012448132780082987
usually separated	0.03125
separated by	0.6666666666666666
by spaces	0.005714285714285714
spaces .	0.2
like	0.0007812064058925284
trivial	0.00011160091512750405
since	0.00027900228781876013
separated	8.370068634562804e-05
spaces	0.00013950114390938006
, some	0.0050533408197641775
some written	0.024096385542168676
written languages	0.19230769230769232
languages like	0.02
like Chinese	0.07142857142857142
Chinese ,	0.2857142857142857
, Japanese	0.0011229646266142617
Japanese and	0.25
and Thai	0.001445086705202312
Thai do	0.5
not mark	0.008928571428571428
mark word	0.3333333333333333
word boundaries	0.016666666666666666
boundaries in	0.09090909090909091
in such	0.0056179775280898875
a fashion	0.001226993865030675
fashion ,	1.0
in those	0.0018726591760299626
those languages	0.09090909090909091
languages text	0.02
text segmentation	0.0440251572327044
a significant	0.001226993865030675
significant task	0.1111111111111111
task requiring	0.023809523809523808
requiring knowledge	0.5
knowledge of	0.14814814814814814
the vocabulary	0.0006920415224913495
vocabulary and	0.25
and morphology	0.001445086705202312
morphology of	0.14285714285714285
words in	0.09174311926605505
Japanese	0.0002232018302550081
Thai	5.5800457563752025e-05
mark	8.370068634562804e-05
fashion	2.7900228781876013e-05
vocabulary	0.0002232018302550081
Word sense	0.2857142857142857
sense disambiguation	0.25
disambiguation :	0.1
: Many	0.00980392156862745
words have	0.009174311926605505
than one	0.06666666666666667
one meaning	0.03076923076923077
meaning ;	0.043478260869565216
; we	0.02127659574468085
we have	0.06666666666666667
have to	0.019230769230769232
to select	0.005312084993359893
select the	0.3333333333333333
meaning which	0.043478260869565216
which makes	0.021739130434782608
makes the	0.25
most sense	0.017241379310344827
sense in	0.125
in context	0.00749063670411985
context .	0.21212121212121213
sense	0.0002232018302550081
we	0.0012555102951844206
select	0.00016740137269125608
context	0.0009207075498019084
For this	0.04918032786885246
this problem	0.07692307692307693
problem ,	0.09090909090909091
, we	0.009545199326221224
we are	0.044444444444444446
are typically	0.012448132780082987
typically given	0.05555555555555555
given a	0.16666666666666666
words and	0.06422018348623854
and associated	0.001445086705202312
associated word	0.25
word senses	0.016666666666666666
senses ,	0.5
, e.g.	0.005614823133071308
e.g. from	0.017857142857142856
a dictionary	0.0036809815950920245
dictionary or	0.14285714285714285
or from	0.0045045045045045045
from an	0.009615384615384616
an online	0.007575757575757576
online resource	0.125
resource such	0.2
as WordNet	0.003484320557491289
WordNet .	0.5
associated	0.00011160091512750405
senses	5.5800457563752025e-05
resource	0.00013950114390938006
WordNet	5.5800457563752025e-05
In some	0.0380952380952381
some cases	0.04819277108433735
, sets	0.0005614823133071309
tasks are	0.125
are grouped	0.004149377593360996
grouped into	0.5
into subfields	0.01282051282051282
subfields of	1.0
NLP that	0.02127659574468085
often considered	0.022727272727272728
considered separately	0.1111111111111111
separately from	1.0
from NLP	0.009615384615384616
NLP as	0.02127659574468085
a whole	0.00245398773006135
whole .	0.1111111111111111
subfields	2.7900228781876013e-05
separately	2.7900228781876013e-05
whole	0.0002511020590368841
Examples include	0.3333333333333333
include :	0.1111111111111111
: Information	0.00980392156862745
Information retrieval	0.2
retrieval -LRB-	0.14285714285714285
-LRB- IR	0.0027100271002710027
IR -RRB-	0.3333333333333333
is concerned	0.0040650406504065045
with storing	0.00546448087431694
storing ,	1.0
, searching	0.0005614823133071309
searching and	0.3333333333333333
and retrieving	0.001445086705202312
retrieving information	1.0
information .	0.08695652173913043
include	0.0007533061771106523
Information	0.00013950114390938006
retrieval	0.0001953016014731321
IR	8.370068634562804e-05
storing	2.7900228781876013e-05
searching	8.370068634562804e-05
retrieving	2.7900228781876013e-05
a separate	0.00245398773006135
separate field	0.1
field within	0.037037037037037035
within computer	0.05555555555555555
science -LRB-	0.1
-LRB- closer	0.0027100271002710027
closer to	1.0
to databases	0.0013280212483399733
databases -RRB-	0.125
but IR	0.014705882352941176
IR relies	0.3333333333333333
relies on	1.0
on some	0.04245283018867924
some NLP	0.012048192771084338
NLP methods	0.02127659574468085
methods -LRB-	0.045454545454545456
-LRB- for	0.018970189701897018
, stemming	0.0005614823133071309
stemming -RRB-	0.5
closer	5.5800457563752025e-05
relies	2.7900228781876013e-05
stemming	5.5800457563752025e-05
Some current	0.09523809523809523
current research	0.14285714285714285
research and	0.11904761904761904
and applications	0.001445086705202312
applications seek	0.04
seek to	1.0
to bridge	0.0013280212483399733
bridge the	1.0
the gap	0.0006920415224913495
gap between	1.0
between IR	0.02564102564102564
IR and	0.3333333333333333
and NLP	0.002890173410404624
current	0.0001953016014731321
seek	2.7900228781876013e-05
bridge	2.7900228781876013e-05
gap	2.7900228781876013e-05
<s> Information	0.0007686395080707148
Information extraction	0.2
extraction -LRB-	0.06451612903225806
-LRB- IE	0.005420054200542005
IE -RRB-	0.6666666666666666
concerned in	0.2
in general	0.009363295880149813
general with	0.045454545454545456
the extraction	0.002768166089965398
extraction of	0.0967741935483871
of semantic	0.004456327985739751
semantic information	0.09523809523809523
from text	0.019230769230769232
IE	8.370068634562804e-05
This covers	0.031746031746031744
covers tasks	0.25
tasks such	0.0625
as named	0.003484320557491289
recognition ,	0.11570247933884298
, coreference	0.0005614823133071309
coreference resolution	1.0
resolution ,	0.25
, relationship	0.0005614823133071309
relationship extraction	0.3333333333333333
extraction ,	0.1935483870967742
etc. .	0.4090909090909091
covers	0.00011160091512750405
coreference	2.7900228781876013e-05
Speech processing	0.03225806451612903
processing :	0.018518518518518517
covers speech	0.25
, text-to-speech	0.0011229646266142617
text-to-speech and	0.5
and related	0.004335260115606936
text-to-speech	0.00011160091512750405
<s> Other	0.005380476556495004
Other tasks	0.14285714285714285
tasks include	0.03125
: Stemming	0.00980392156862745
Stemming Text	1.0
Text simplification	0.16666666666666666
simplification Text-to-speech	1.0
Text-to-speech Text-proofing	1.0
Text-proofing Natural	1.0
language search	0.006756756756756757
search Query	0.09090909090909091
Query expansion	1.0
expansion Automated	0.3333333333333333
Automated essay	0.5
essay scoring	1.0
scoring Truecasing	0.5
Truecasing Statistical	1.0
Statistical NLP	0.2222222222222222
NLP Main	0.02127659574468085
Main article	1.0
article :	0.4482758620689655
: statistical	0.00980392156862745
statistical natural	0.030303030303030304
processing Statistical	0.018518518518518517
Statistical natural-language	0.1111111111111111
natural-language processing	1.0
processing uses	0.018518518518518517
uses stochastic	0.07142857142857142
stochastic ,	0.25
probabilistic and	0.14285714285714285
and statistical	0.004335260115606936
statistical methods	0.12121212121212122
methods to	0.09090909090909091
to resolve	0.00398406374501992
resolve some	0.25
the difficulties	0.0006920415224913495
difficulties discussed	0.5
discussed above	0.14285714285714285
especially those	0.2
those which	0.045454545454545456
which arise	0.007246376811594203
arise because	1.0
because longer	0.03333333333333333
longer sentences	1.0
sentences are	0.09210526315789473
are highly	0.004149377593360996
highly ambiguous	0.1111111111111111
ambiguous when	0.08333333333333333
when processed	0.02857142857142857
processed with	0.3333333333333333
with realistic	0.00546448087431694
realistic grammars	1.0
grammars ,	0.14285714285714285
, yielding	0.0005614823133071309
yielding thousands	1.0
thousands or	0.3333333333333333
or millions	0.0045045045045045045
millions of	1.0
Other	0.0001953016014731321
Stemming	2.7900228781876013e-05
Text	0.00016740137269125608
simplification	2.7900228781876013e-05
Text-to-speech	2.7900228781876013e-05
Text-proofing	2.7900228781876013e-05
search	0.00030690251660063614
Query	2.7900228781876013e-05
expansion	8.370068634562804e-05
Automated	5.5800457563752025e-05
essay	2.7900228781876013e-05
scoring	5.5800457563752025e-05
Truecasing	2.7900228781876013e-05
Statistical	0.0002511020590368841
Main	0.00033480274538251215
natural-language	2.7900228781876013e-05
uses	0.0003906032029462642
stochastic	0.0002232018302550081
resolve	0.00011160091512750405
difficulties	5.5800457563752025e-05
discussed	0.0001953016014731321
arise	2.7900228781876013e-05
longer	2.7900228781876013e-05
highly	0.0002511020590368841
realistic	2.7900228781876013e-05
grammars	0.0003906032029462642
yielding	2.7900228781876013e-05
millions	5.5800457563752025e-05
<s> Methods	0.0023059185242121443
Methods for	0.5
for disambiguation	0.0036101083032490976
disambiguation often	0.1
often involve	0.022727272727272728
involve the	0.16666666666666666
the use	0.010380622837370242
of corpora	0.00089126559714795
corpora and	0.09090909090909091
and Markov	0.001445086705202312
Markov models	0.3333333333333333
Methods	0.00011160091512750405
involve	0.00016740137269125608
Markov	0.0005022041180737682
<s> Statistical	0.0023059185242121443
NLP comprises	0.02127659574468085
comprises all	1.0
all quantitative	0.023255813953488372
quantitative approaches	0.25
to automated	0.0013280212483399733
automated language	0.14285714285714285
processing ,	0.16666666666666666
including probabilistic	0.07142857142857142
probabilistic modeling	0.14285714285714285
modeling ,	0.14285714285714285
, information	0.0011229646266142617
information theory	0.021739130434782608
and linear	0.001445086705202312
linear algebra	0.14285714285714285
algebra .	0.5
comprises	2.7900228781876013e-05
quantitative	0.00011160091512750405
modeling	0.0001953016014731321
linear	0.0001953016014731321
algebra	5.5800457563752025e-05
The technology	0.005208333333333333
technology for	0.09090909090909091
for statistical	0.007220216606498195
NLP comes	0.02127659574468085
comes mainly	0.2
mainly from	0.16666666666666666
from machine	0.019230769230769232
learning and	0.023255813953488372
and data	0.005780346820809248
data mining	0.025974025974025976
mining ,	0.2
, both	0.0016844469399213925
both of	0.06451612903225806
are fields	0.004149377593360996
fields of	0.3333333333333333
of artificial	0.00089126559714795
intelligence that	0.25
that involve	0.0035460992907801418
involve learning	0.16666666666666666
technology	0.0006138050332012723
comes	0.00013950114390938006
mainly	0.00016740137269125608
mining	0.00013950114390938006
<s> Evaluation	0.003843197540353574
Evaluation of	0.1111111111111111
processing Objectives	0.018518518518518517
Objectives The	1.0
The goal	0.005208333333333333
goal of	0.2857142857142857
NLP evaluation	0.06382978723404255
evaluation is	0.07407407407407407
is to	0.03861788617886179
to measure	0.005312084993359893
measure one	0.09090909090909091
one or	0.03076923076923077
more qualities	0.010526315789473684
qualities of	0.5
an algorithm	0.022727272727272728
algorithm or	0.03571428571428571
or a	0.08558558558558559
a system	0.012269938650306749
system ,	0.10752688172043011
determine whether	0.043478260869565216
whether -LRB-	0.07692307692307693
or to	0.009009009009009009
to what	0.005312084993359893
what extent	0.03125
extent -RRB-	0.25
-RRB- the	0.0027100271002710027
the system	0.01384083044982699
system answers	0.010752688172043012
answers the	0.08333333333333333
the goals	0.0006920415224913495
goals of	1.0
of its	0.0071301247771836
its designers	0.02857142857142857
designers ,	1.0
or meets	0.0045045045045045045
meets the	0.5
the needs	0.0006920415224913495
needs of	0.1
its users	0.02857142857142857
users .	0.2222222222222222
Evaluation	0.0002511020590368841
Objectives	2.7900228781876013e-05
goal	0.0001953016014731321
measure	0.00030690251660063614
qualities	5.5800457563752025e-05
extent	0.00011160091512750405
goals	2.7900228781876013e-05
designers	2.7900228781876013e-05
needs	0.00027900228781876013
users	0.0002511020590368841
Research in	0.125
evaluation has	0.018518518518518517
has received	0.011904761904761904
received considerable	0.5
considerable attention	0.2
attention ,	0.5
, because	0.004491858506457047
because the	0.13333333333333333
the definition	0.0020761245674740486
definition of	0.6
of proper	0.00089126559714795
proper evaluation	0.14285714285714285
evaluation criteria	0.037037037037037035
criteria is	0.25
one way	0.015384615384615385
way to	0.4166666666666667
to specify	0.0013280212483399733
specify precisely	1.0
precisely an	1.0
an NLP	0.022727272727272728
NLP problem	0.0425531914893617
, going	0.0005614823133071309
going thus	0.25
thus beyond	0.1
beyond the	0.5
the vagueness	0.0006920415224913495
vagueness of	1.0
of tasks	0.00089126559714795
tasks defined	0.03125
defined only	0.16666666666666666
only as	0.02631578947368421
as language	0.003484320557491289
understanding or	0.030303030303030304
or language	0.0045045045045045045
generation .	0.2222222222222222
received	5.5800457563752025e-05
considerable	0.00013950114390938006
attention	5.5800457563752025e-05
definition	0.00013950114390938006
criteria	0.00011160091512750405
way	0.0006696054907650243
specify	2.7900228781876013e-05
precisely	2.7900228781876013e-05
going	0.00011160091512750405
vagueness	2.7900228781876013e-05
defined	0.00016740137269125608
A precise	0.02
precise set	0.3333333333333333
of evaluation	0.004456327985739751
criteria ,	0.25
which includes	0.014492753623188406
includes mainly	0.14285714285714285
mainly evaluation	0.16666666666666666
evaluation data	0.018518518518518517
data and	0.025974025974025976
and evaluation	0.004335260115606936
evaluation metrics	0.018518518518518517
metrics ,	0.1111111111111111
, enables	0.0005614823133071309
enables several	1.0
several teams	0.045454545454545456
teams to	0.5
to compare	0.005312084993359893
compare their	0.14285714285714285
their solutions	0.029411764705882353
solutions to	0.5
given NLP	0.041666666666666664
precise	8.370068634562804e-05
metrics	0.0002511020590368841
enables	2.7900228781876013e-05
teams	5.5800457563752025e-05
compare	0.0001953016014731321
their	0.0009486077785837844
<s> Short	0.0007686395080707148
Short history	1.0
history of	0.5
evaluation in	0.05555555555555555
first evaluation	0.030303030303030304
evaluation campaign	0.018518518518518517
campaign on	0.2
on written	0.0047169811320754715
written texts	0.07692307692307693
texts seems	0.058823529411764705
a campaign	0.001226993865030675
campaign dedicated	0.2
dedicated to	0.6666666666666666
to message	0.0013280212483399733
message understanding	0.5
understanding in	0.030303030303030304
in 1987	0.003745318352059925
1987 -LRB-	0.3333333333333333
-LRB- Pallet	0.0027100271002710027
Pallet 1998	0.5
1998 -RRB-	0.5
Short	2.7900228781876013e-05
history	0.00011160091512750405
campaign	0.00013950114390938006
dedicated	8.370068634562804e-05
message	5.5800457563752025e-05
1987	8.370068634562804e-05
Pallet	5.5800457563752025e-05
1998	0.00011160091512750405
<s> Then	0.003843197540353574
Then ,	0.4
the Parseval\/GEIG	0.0006920415224913495
Parseval\/GEIG project	1.0
project compared	0.15384615384615385
compared phrase-structure	0.14285714285714285
phrase-structure grammars	1.0
grammars -LRB-	0.07142857142857142
-LRB- Black	0.0027100271002710027
Black 1991	0.5
1991 -RRB-	0.6666666666666666
Then	0.00013950114390938006
Parseval\/GEIG	2.7900228781876013e-05
project	0.00036270297416438817
compared	0.0001953016014731321
phrase-structure	2.7900228781876013e-05
Black	5.5800457563752025e-05
1991	8.370068634562804e-05
A series	0.02
series of	0.875
of campaigns	0.00089126559714795
campaigns within	0.5
within Tipster	0.05555555555555555
Tipster project	1.0
project were	0.07692307692307693
were realized	0.024390243902439025
realized on	1.0
on tasks	0.009433962264150943
tasks like	0.0625
like summarization	0.03571428571428571
summarization ,	0.08
, translation	0.0011229646266142617
translation and	0.04054054054054054
and searching	0.001445086705202312
searching -LRB-	0.3333333333333333
-LRB- Hirschman	0.0027100271002710027
Hirschman 1998	0.5
series	0.0002232018302550081
campaigns	5.5800457563752025e-05
Tipster	2.7900228781876013e-05
realized	2.7900228781876013e-05
Hirschman	5.5800457563752025e-05
In 1994	0.009523809523809525
1994 ,	1.0
in Germany	0.003745318352059925
Germany ,	0.5
the Morpholympics	0.0006920415224913495
Morpholympics compared	1.0
compared German	0.14285714285714285
German taggers	0.25
taggers .	0.14285714285714285
1994	2.7900228781876013e-05
Germany	5.5800457563752025e-05
Morpholympics	2.7900228781876013e-05
taggers	0.0001953016014731321
the Senseval	0.0006920415224913495
Senseval and	1.0
and Romanseval	0.001445086705202312
Romanseval campaigns	1.0
campaigns were	0.5
were conducted	0.024390243902439025
conducted with	0.2
the objectives	0.0006920415224913495
objectives of	0.5
semantic disambiguation	0.047619047619047616
disambiguation .	0.1
Senseval	2.7900228781876013e-05
Romanseval	2.7900228781876013e-05
In 1996	0.009523809523809525
1996 ,	1.0
the Sparkle	0.0006920415224913495
Sparkle campaign	1.0
campaign compared	0.2
compared syntactic	0.14285714285714285
syntactic parsers	0.07692307692307693
parsers in	0.07692307692307693
in four	0.003745318352059925
four different	0.2857142857142857
different languages	0.02040816326530612
languages -LRB-	0.04
-LRB- English	0.0027100271002710027
, French	0.0005614823133071309
French ,	0.125
German and	0.25
and Italian	0.001445086705202312
Italian -RRB-	0.5
1996	2.7900228781876013e-05
Sparkle	2.7900228781876013e-05
syntactic	0.00036270297416438817
parsers	0.00036270297416438817
four	0.0001953016014731321
Italian	5.5800457563752025e-05
In France	0.01904761904761905
France ,	0.5
the Grace	0.0006920415224913495
Grace project	1.0
compared a	0.14285714285714285
of 21	0.00089126559714795
21 taggers	1.0
taggers for	0.14285714285714285
for French	0.010830324909747292
French in	0.125
in 1997	0.003745318352059925
1997 -LRB-	0.5
-LRB- Adda	0.0027100271002710027
Adda 1999	0.5
1999 -RRB-	0.5
France	0.00011160091512750405
Grace	2.7900228781876013e-05
21	2.7900228781876013e-05
1997	5.5800457563752025e-05
Adda	5.5800457563752025e-05
1999	5.5800457563752025e-05
In 2004	0.009523809523809525
2004 ,	0.3333333333333333
, during	0.0005614823133071309
during the	0.4
the Technolangue\/Easy	0.0006920415224913495
Technolangue\/Easy project	0.5
project ,	0.38461538461538464
, 13	0.0005614823133071309
13 parsers	0.5
parsers for	0.15384615384615385
French were	0.25
were compared	0.04878048780487805
compared .	0.2857142857142857
2004	8.370068634562804e-05
Technolangue\/Easy	5.5800457563752025e-05
13	5.5800457563752025e-05
<s> Large-scale	0.0007686395080707148
Large-scale evaluation	1.0
evaluation of	0.07407407407407407
of dependency	0.00089126559714795
dependency parsers	0.2
parsers were	0.07692307692307693
were performed	0.024390243902439025
performed in	0.2
the context	0.004152249134948097
context of	0.15151515151515152
the CoNLL	0.0006920415224913495
CoNLL shared	1.0
shared tasks	0.5
in 2006	0.0018726591760299626
2006 and	0.3333333333333333
and 2007	0.001445086705202312
2007 .	0.4
Large-scale	2.7900228781876013e-05
dependency	0.00013950114390938006
performed	0.00027900228781876013
CoNLL	2.7900228781876013e-05
shared	5.5800457563752025e-05
2006	8.370068634562804e-05
2007	0.00013950114390938006
In Italy	0.009523809523809525
Italy ,	1.0
the EVALITA	0.0006920415224913495
EVALITA campaign	0.5
campaign was	0.2
conducted in	0.4
in 2007	0.0018726591760299626
2007 and	0.2
and 2009	0.001445086705202312
2009 to	0.3333333333333333
compare various	0.14285714285714285
various NLP	0.05555555555555555
NLP and	0.02127659574468085
and speech	0.001445086705202312
speech tools	0.006578947368421052
tools for	0.16666666666666666
for Italian	0.0036101083032490976
Italian ;	0.5
; the	0.0851063829787234
the 2011	0.0006920415224913495
2011 campaign	0.5
campaign is	0.2
is in	0.006097560975609756
in full	0.0018726591760299626
full progress	0.2
progress -	0.14285714285714285
- EVALITA	0.0625
EVALITA web	0.5
web site	0.25
site .	1.0
Italy	5.5800457563752025e-05
EVALITA	5.5800457563752025e-05
2009	8.370068634562804e-05
tools	0.00016740137269125608
2011	5.5800457563752025e-05
full	0.00013950114390938006
-	0.0004464036605100162
site	5.5800457563752025e-05
, within	0.0005614823133071309
the ANR-Passage	0.0006920415224913495
ANR-Passage project	1.0
project -LRB-	0.07692307692307693
-LRB- end	0.0027100271002710027
end of	0.25
of 2007	0.0017825311942959
2007 -RRB-	0.2
, 10	0.0011229646266142617
10 parsers	0.125
compared -	0.14285714285714285
- passage	0.0625
passage web	1.0
ANR-Passage	2.7900228781876013e-05
end	0.0002232018302550081
10	0.0002232018302550081
passage	2.7900228781876013e-05
<s> Adda	0.0007686395080707148
Adda G.	0.5
G. ,	0.5
, Mariani	0.0005614823133071309
Mariani J.	1.0
J. ,	0.6666666666666666
, Paroubek	0.0005614823133071309
Paroubek P.	1.0
P. ,	1.0
, Rajman	0.0005614823133071309
Rajman M.	1.0
M. 1999	0.25
1999 L'action	0.5
L'action GRACE	1.0
GRACE d'valuation	1.0
d'valuation de	1.0
de l'assignation	0.5
l'assignation des	1.0
des parties	1.0
parties du	1.0
du discors	1.0
discors pour	1.0
pour le	1.0
le franais	1.0
franais .	1.0
G.	5.5800457563752025e-05
Mariani	2.7900228781876013e-05
J.	8.370068634562804e-05
Paroubek	2.7900228781876013e-05
P.	5.5800457563752025e-05
Rajman	2.7900228781876013e-05
M.	0.00011160091512750405
L'action	2.7900228781876013e-05
GRACE	2.7900228781876013e-05
d'valuation	2.7900228781876013e-05
de	5.5800457563752025e-05
l'assignation	2.7900228781876013e-05
des	2.7900228781876013e-05
parties	2.7900228781876013e-05
du	2.7900228781876013e-05
discors	2.7900228781876013e-05
pour	2.7900228781876013e-05
le	2.7900228781876013e-05
franais	2.7900228781876013e-05
<s> Langues	0.0007686395080707148
Langues vol-2	1.0
vol-2 Black	1.0
Black E.	0.5
E. ,	0.25
, Abney	0.0005614823133071309
Abney S.	1.0
S. ,	1.0
, Flickinger	0.0005614823133071309
Flickinger D.	1.0
D. ,	0.4
, Gdaniec	0.0005614823133071309
Gdaniec C.	1.0
C. ,	1.0
, Grishman	0.0005614823133071309
Grishman R.	1.0
R. ,	0.3333333333333333
, Harrison	0.0005614823133071309
Harrison P.	1.0
, Hindle	0.0005614823133071309
Hindle D.	1.0
, Ingria	0.0005614823133071309
Ingria R.	1.0
, Jelinek	0.0005614823133071309
Jelinek F.	0.5
F. ,	1.0
, Klavans	0.0005614823133071309
Klavans J.	1.0
, Liberman	0.0005614823133071309
Liberman M.	1.0
M. ,	0.5
, Marcus	0.0005614823133071309
Marcus M.	1.0
, Reukos	0.0005614823133071309
Reukos S.	1.0
, Santoni	0.0005614823133071309
Santoni B.	1.0
B. ,	1.0
, Strzalkowski	0.0005614823133071309
Strzalkowski T.	1.0
T. 1991	1.0
1991 A	0.3333333333333333
A procedure	0.02
procedure for	0.3333333333333333
for quantitatively	0.0036101083032490976
quantitatively comparing	1.0
comparing the	0.5
the syntactic	0.0006920415224913495
syntactic coverage	0.07692307692307693
coverage of	0.3333333333333333
of English	0.00267379679144385
English grammars	0.02702702702702703
grammars .	0.14285714285714285
Langues	2.7900228781876013e-05
vol-2	2.7900228781876013e-05
E.	0.00011160091512750405
Abney	2.7900228781876013e-05
S.	5.5800457563752025e-05
Flickinger	2.7900228781876013e-05
D.	0.00013950114390938006
Gdaniec	2.7900228781876013e-05
C.	2.7900228781876013e-05
Grishman	2.7900228781876013e-05
R.	0.00016740137269125608
Harrison	2.7900228781876013e-05
Hindle	2.7900228781876013e-05
Ingria	2.7900228781876013e-05
Jelinek	5.5800457563752025e-05
F.	2.7900228781876013e-05
Klavans	2.7900228781876013e-05
Liberman	2.7900228781876013e-05
Marcus	2.7900228781876013e-05
Reukos	2.7900228781876013e-05
Santoni	2.7900228781876013e-05
B.	2.7900228781876013e-05
Strzalkowski	2.7900228781876013e-05
T.	2.7900228781876013e-05
procedure	8.370068634562804e-05
quantitatively	2.7900228781876013e-05
comparing	5.5800457563752025e-05
coverage	8.370068634562804e-05
<s> DARPA	0.0007686395080707148
DARPA Speech	0.25
Speech and	0.16129032258064516
and Natural	0.001445086705202312
Natural Language	0.23076923076923078
Language Workshop	0.08333333333333333
Workshop Hirschman	1.0
Hirschman L.	0.5
L. 1998	1.0
1998 Language	0.25
Language understanding	0.08333333333333333
understanding evaluation	0.030303030303030304
evaluation :	0.037037037037037035
: lessons	0.00980392156862745
lessons learned	1.0
learned from	0.2
from MUC	0.009615384615384616
MUC and	1.0
and ATIS	0.001445086705202312
ATIS .	1.0
DARPA	0.00011160091512750405
Language	0.00033480274538251215
Workshop	2.7900228781876013e-05
L.	2.7900228781876013e-05
lessons	2.7900228781876013e-05
MUC	2.7900228781876013e-05
ATIS	2.7900228781876013e-05
<s> LREC	0.0015372790161414297
LREC Granada	1.0
Granada Pallet	0.5
Pallet D.S.	0.5
D.S. 1998	1.0
1998 The	0.25
The NIST	0.005208333333333333
NIST role	0.5
role in	0.25
in automatic	0.003745318352059925
automatic speech	0.13043478260869565
recognition benchmark	0.008264462809917356
benchmark tests	1.0
tests .	0.25
LREC	5.5800457563752025e-05
Granada	5.5800457563752025e-05
D.S.	2.7900228781876013e-05
NIST	5.5800457563752025e-05
role	0.00011160091512750405
benchmark	2.7900228781876013e-05
tests	0.00011160091512750405
Granada Different	0.5
Different types	1.0
evaluation Depending	0.018518518518518517
Depending on	1.0
evaluation procedures	0.018518518518518517
procedures ,	0.25
of distinctions	0.00089126559714795
distinctions are	0.5
are traditionally	0.008298755186721992
traditionally made	0.5
made in	0.125
evaluation .	0.05555555555555555
Different	5.5800457563752025e-05
Depending	2.7900228781876013e-05
distinctions	5.5800457563752025e-05
traditionally	5.5800457563752025e-05
<s> Intrinsic	0.0015372790161414297
Intrinsic vs.	0.3333333333333333
vs. extrinsic	0.08333333333333333
extrinsic evaluation	0.5
evaluation Intrinsic	0.018518518518518517
Intrinsic evaluation	0.3333333333333333
evaluation considers	0.018518518518518517
considers an	0.5
an isolated	0.007575757575757576
isolated NLP	0.2
NLP system	0.0851063829787234
system and	0.03225806451612903
and characterizes	0.001445086705202312
characterizes its	1.0
its performance	0.02857142857142857
performance mainly	0.05555555555555555
mainly with	0.16666666666666666
with respect	0.03825136612021858
respect to	1.0
a gold	0.00245398773006135
gold standard	0.8333333333333334
standard result	0.07142857142857142
, pre-defined	0.0005614823133071309
pre-defined by	0.5
the evaluators	0.0006920415224913495
evaluators .	1.0
Intrinsic	8.370068634562804e-05
extrinsic	0.00016740137269125608
considers	5.5800457563752025e-05
isolated	0.00013950114390938006
characterizes	2.7900228781876013e-05
performance	0.0005022041180737682
respect	0.0001953016014731321
gold	0.00016740137269125608
pre-defined	5.5800457563752025e-05
evaluators	2.7900228781876013e-05
<s> Extrinsic	0.0015372790161414297
Extrinsic evaluation	0.5
evaluation ,	0.05555555555555555
, also	0.002807411566535654
called evaluation	0.1111111111111111
in use	0.003745318352059925
use considers	0.013888888888888888
considers the	0.5
the NLP	0.0006920415224913495
system in	0.021505376344086023
a more	0.0049079754601227
more complex	0.08421052631578947
complex setting	0.041666666666666664
, either	0.0011229646266142617
either as	0.3
an embedded	0.007575757575757576
embedded system	0.25
system or	0.021505376344086023
or serving	0.0045045045045045045
serving a	1.0
a precise	0.001226993865030675
precise function	0.3333333333333333
function for	0.125
human user	0.043478260869565216
user .	0.21428571428571427
Extrinsic	5.5800457563752025e-05
either	0.00027900228781876013
embedded	0.00011160091512750405
serving	2.7900228781876013e-05
user	0.0003906032029462642
The extrinsic	0.005208333333333333
extrinsic performance	0.16666666666666666
performance of	0.1111111111111111
system is	0.0967741935483871
is then	0.01016260162601626
then characterized	0.02857142857142857
characterized in	0.25
in terms	0.011235955056179775
terms of	0.5384615384615384
its utility	0.02857142857142857
utility with	0.5
the overall	0.0020761245674740486
overall task	0.16666666666666666
the complex	0.0006920415224913495
complex system	0.08333333333333333
or the	0.04054054054054054
the human	0.0020761245674740486
characterized	0.00011160091512750405
terms	0.00036270297416438817
utility	5.5800457563752025e-05
overall	0.00016740137269125608
, consider	0.0005614823133071309
consider a	0.25
a syntactic	0.001226993865030675
syntactic parser	0.07692307692307693
parser that	0.0625
is based	0.008130081300813009
the output	0.0020761245674740486
output of	0.15384615384615385
some new	0.012048192771084338
new part	0.041666666666666664
speech -LRB-	0.02631578947368421
-LRB- POS	0.005420054200542005
POS -RRB-	0.07692307692307693
-RRB- tagger	0.0027100271002710027
tagger .	0.1111111111111111
consider	0.00011160091512750405
parser	0.0004464036605100162
POS	0.00036270297416438817
An intrinsic	0.125
intrinsic evaluation	0.5
evaluation would	0.05555555555555555
would run	0.03773584905660377
run the	0.4
the POS	0.0020761245674740486
POS tagger	0.3076923076923077
tagger on	0.1111111111111111
some labeled	0.012048192771084338
labeled data	0.3333333333333333
and compare	0.002890173410404624
compare the	0.2857142857142857
system output	0.010752688172043012
tagger to	0.1111111111111111
the gold	0.0020761245674740486
standard -LRB-	0.14285714285714285
-LRB- correct	0.0027100271002710027
correct -RRB-	0.06666666666666667
-RRB- output	0.0027100271002710027
intrinsic	0.00011160091512750405
run	0.00013950114390938006
labeled	8.370068634562804e-05
An extrinsic	0.0625
the parser	0.002768166089965398
parser with	0.0625
with some	0.02185792349726776
other POS	0.014285714285714285
and then	0.010115606936416185
then with	0.02857142857142857
the new	0.0006920415224913495
new POS	0.041666666666666664
the parsing	0.001384083044982699
parsing accuracy	0.03571428571428571
accuracy .	0.22580645161290322
parsing	0.0007812064058925284
<s> Black-box	0.0007686395080707148
Black-box vs.	0.5
vs. glass-box	0.08333333333333333
glass-box evaluation	1.0
evaluation Black-box	0.018518518518518517
Black-box evaluation	0.5
evaluation requires	0.018518518518518517
requires one	0.0625
one to	0.03076923076923077
to run	0.0013280212483399733
run an	0.2
system on	0.010752688172043012
given data	0.041666666666666664
data set	0.012987012987012988
set and	0.02564102564102564
measure a	0.09090909090909091
of parameters	0.00089126559714795
parameters related	0.25
related to	0.26666666666666666
the quality	0.0034602076124567475
quality of	0.5
process -LRB-	0.027777777777777776
-LRB- speed	0.0027100271002710027
speed ,	0.2857142857142857
, reliability	0.0005614823133071309
reliability ,	0.5
, resource	0.0005614823133071309
resource consumption	0.2
consumption -RRB-	1.0
and ,	0.004335260115606936
most importantly	0.017241379310344827
importantly ,	1.0
, to	0.0072992700729927005
the result	0.002768166089965398
result -LRB-	0.09090909090909091
e.g. the	0.05357142857142857
the accuracy	0.0006920415224913495
accuracy of	0.12903225806451613
data annotation	0.012987012987012988
annotation or	0.25
the fidelity	0.0006920415224913495
fidelity of	1.0
a translation	0.00245398773006135
translation -RRB-	0.02702702702702703
Black-box	5.5800457563752025e-05
glass-box	5.5800457563752025e-05
parameters	0.00011160091512750405
quality	0.00027900228781876013
speed	0.0001953016014731321
reliability	5.5800457563752025e-05
consumption	2.7900228781876013e-05
importantly	2.7900228781876013e-05
fidelity	2.7900228781876013e-05
<s> Glass-box	0.0007686395080707148
Glass-box evaluation	1.0
evaluation looks	0.018518518518518517
looks at	0.25
at the	0.22058823529411764
design of	0.25
the algorithms	0.001384083044982699
algorithms that	0.05714285714285714
are implemented	0.004149377593360996
implemented ,	0.2
the linguistic	0.0006920415224913495
linguistic resources	0.0625
resources it	0.16666666666666666
it uses	0.017094017094017096
uses -LRB-	0.07142857142857142
e.g. vocabulary	0.017857142857142856
vocabulary size	0.125
size -RRB-	0.16666666666666666
Glass-box	2.7900228781876013e-05
looks	0.00011160091512750405
linguistic	0.0004464036605100162
resources	0.00016740137269125608
size	0.00016740137269125608
<s> Given	0.0023059185242121443
Given the	0.07142857142857142
NLP problems	0.0425531914893617
often difficult	0.022727272727272728
difficult to	0.39285714285714285
to predict	0.0026560424966799467
predict performance	0.16666666666666666
performance only	0.05555555555555555
only on	0.05263157894736842
of glass-box	0.00089126559714795
but this	0.058823529411764705
this type	0.03296703296703297
is more	0.006097560975609756
more informative	0.010526315789473684
informative with	0.5
to error	0.0013280212483399733
error analysis	0.08333333333333333
analysis or	0.046153846153846156
or future	0.0045045045045045045
future developments	0.3333333333333333
developments of	0.3333333333333333
predict	0.00016740137269125608
informative	5.5800457563752025e-05
error	0.00033480274538251215
future	8.370068634562804e-05
developments	8.370068634562804e-05
Automatic vs.	0.1111111111111111
vs. manual	0.08333333333333333
manual evaluation	0.5
evaluation In	0.018518518518518517
In many	0.01904761904761905
many cases	0.038461538461538464
, automatic	0.0016844469399213925
automatic procedures	0.043478260869565216
be defined	0.004219409282700422
defined to	0.16666666666666666
to evaluate	0.005312084993359893
evaluate an	0.25
system by	0.010752688172043012
by comparing	0.005714285714285714
comparing its	0.5
its output	0.08571428571428572
output with	0.038461538461538464
or desired	0.0045045045045045045
desired -RRB-	0.2
-RRB- one	0.0027100271002710027
one .	0.03076923076923077
manual	5.5800457563752025e-05
evaluate	0.00011160091512750405
<s> Although	0.005380476556495004
Although the	0.375
the cost	0.0006920415224913495
cost of	0.5
of producing	0.00089126559714795
producing the	0.3333333333333333
standard can	0.07142857142857142
be quite	0.004219409282700422
quite high	0.125
high ,	0.05555555555555555
automatic evaluation	0.13043478260869565
evaluation can	0.037037037037037035
be repeated	0.004219409282700422
repeated as	0.5
as often	0.003484320557491289
often as	0.045454545454545456
as needed	0.003484320557491289
needed without	0.047619047619047616
without much	0.07692307692307693
much additional	0.045454545454545456
additional costs	0.16666666666666666
costs -LRB-	1.0
-LRB- on	0.005420054200542005
same input	0.08
Although	0.0002232018302550081
cost	5.5800457563752025e-05
quite	0.0002232018302550081
repeated	5.5800457563752025e-05
needed	0.0005859048044193963
additional	0.00016740137269125608
costs	2.7900228781876013e-05
for many	0.007220216606498195
many NLP	0.019230769230769232
standard is	0.07142857142857142
a complex	0.006134969325153374
complex task	0.041666666666666664
and can	0.011560693641618497
can prove	0.0055248618784530384
prove impossible	1.0
impossible when	0.5
when inter-annotator	0.02857142857142857
inter-annotator agreement	1.0
agreement is	0.3333333333333333
is insufficient	0.0020325203252032522
prove	2.7900228781876013e-05
impossible	5.5800457563752025e-05
inter-annotator	2.7900228781876013e-05
agreement	8.370068634562804e-05
<s> Manual	0.0015372790161414297
Manual evaluation	0.6666666666666666
is performed	0.0040650406504065045
performed by	0.2
by human	0.017142857142857144
human judges	0.043478260869565216
judges ,	0.5
are instructed	0.004149377593360996
instructed to	1.0
to estimate	0.00398406374501992
estimate the	0.5
or most	0.0045045045045045045
most often	0.017241379310344827
often of	0.022727272727272728
a sample	0.001226993865030675
sample of	0.3333333333333333
output ,	0.038461538461538464
, based	0.0011229646266142617
of criteria	0.00089126559714795
criteria .	0.25
Manual	8.370068634562804e-05
judges	5.5800457563752025e-05
instructed	2.7900228781876013e-05
estimate	0.00011160091512750405
sample	8.370068634562804e-05
Although ,	0.125
, thanks	0.0005614823133071309
thanks to	1.0
to their	0.0026560424966799467
their linguistic	0.029411764705882353
linguistic competence	0.0625
competence ,	1.0
, human	0.003368893879842785
judges can	0.5
be considered	0.008438818565400843
considered as	0.1111111111111111
the reference	0.0006920415224913495
reference for	0.125
processing tasks	0.018518518518518517
tasks ,	0.125
also considerable	0.014492753623188406
considerable variation	0.2
variation across	1.0
across their	0.2
their ratings	0.029411764705882353
ratings .	0.1111111111111111
thanks	2.7900228781876013e-05
competence	2.7900228781876013e-05
reference	0.0002232018302550081
variation	2.7900228781876013e-05
across	0.00013950114390938006
ratings	0.0002511020590368841
is why	0.0020325203252032522
why automatic	0.14285714285714285
as objective	0.003484320557491289
objective evaluation	0.2
while the	0.05
human kind	0.021739130434782608
kind appears	0.09090909090909091
appears to	0.2
be more	0.02109704641350211
more subjective	0.010526315789473684
subjective .	0.3333333333333333
why	0.0001953016014731321
kind	0.00030690251660063614
appears	0.00013950114390938006
<s> Shared	0.0007686395080707148
Shared tasks	1.0
tasks -LRB-	0.03125
-LRB- Campaigns	0.0027100271002710027
Campaigns -RRB-	1.0
-RRB- BioCreative	0.0027100271002710027
BioCreative Message	1.0
Message Understanding	1.0
Understanding Conference	0.5
Conference Technolangue\/Easy	0.5
Technolangue\/Easy Text	0.5
Text Retrieval	0.16666666666666666
Retrieval Conference	1.0
Conference Evaluation	0.5
Evaluation exercises	0.1111111111111111
exercises on	1.0
on Semantic	0.0047169811320754715
Semantic Evaluation	0.3333333333333333
Evaluation -LRB-	0.1111111111111111
-LRB- SemEval	0.0027100271002710027
SemEval -RRB-	1.0
-RRB- MorphoChallenge	0.0027100271002710027
MorphoChallenge Semi-supervised	1.0
Semi-supervised and	1.0
and Unsupervised	0.001445086705202312
Unsupervised Morpheme	0.16666666666666666
Morpheme Analysis	1.0
Analysis Standardization	0.2
Standardization in	1.0
NLP An	0.02127659574468085
An ISO	0.0625
ISO sub-committee	0.5
sub-committee is	1.0
is working	0.0040650406504065045
to ease	0.0013280212483399733
ease interoperability	1.0
interoperability between	1.0
between lexical	0.05128205128205128
lexical resources	0.07692307692307693
resources and	0.16666666666666666
NLP programs	0.02127659574468085
programs .	0.2727272727272727
Shared	2.7900228781876013e-05
Campaigns	2.7900228781876013e-05
BioCreative	2.7900228781876013e-05
Message	2.7900228781876013e-05
Understanding	5.5800457563752025e-05
Conference	5.5800457563752025e-05
Retrieval	2.7900228781876013e-05
exercises	2.7900228781876013e-05
Semantic	8.370068634562804e-05
SemEval	2.7900228781876013e-05
MorphoChallenge	2.7900228781876013e-05
Semi-supervised	2.7900228781876013e-05
Unsupervised	0.00016740137269125608
Morpheme	2.7900228781876013e-05
Analysis	0.00013950114390938006
Standardization	2.7900228781876013e-05
ISO	5.5800457563752025e-05
sub-committee	5.5800457563752025e-05
ease	2.7900228781876013e-05
interoperability	2.7900228781876013e-05
lexical	0.00036270297416438817
The sub-committee	0.005208333333333333
is part	0.0020325203252032522
of ISO\/TC37	0.00089126559714795
ISO\/TC37 and	1.0
is called	0.012195121951219513
called ISO\/TC37\/SC4	0.05555555555555555
ISO\/TC37\/SC4 .	1.0
ISO\/TC37	2.7900228781876013e-05
ISO\/TC37\/SC4	2.7900228781876013e-05
Some ISO	0.047619047619047616
ISO standards	0.5
standards are	0.2
are already	0.004149377593360996
already published	0.2
published but	0.14285714285714285
but most	0.029411764705882353
of them	0.0017825311942959
them are	0.10526315789473684
are under	0.004149377593360996
under construction	0.2
construction ,	0.3333333333333333
, mainly	0.0005614823133071309
mainly on	0.16666666666666666
on lexicon	0.0047169811320754715
lexicon representation	0.1111111111111111
representation -LRB-	0.10526315789473684
see LMF	0.05
LMF -RRB-	1.0
, annotation	0.0005614823133071309
annotation and	0.25
data category	0.012987012987012988
category registry	0.5
registry .	1.0
standards	0.00013950114390938006
under	0.00013950114390938006
lexicon	0.0002511020590368841
LMF	2.7900228781876013e-05
category	5.5800457563752025e-05
registry	2.7900228781876013e-05
summarization is	0.12
the creation	0.0006920415224913495
a shortened	0.001226993865030675
shortened version	1.0
version of	0.6666666666666666
a text	0.01717791411042945
text by	0.006289308176100629
by a	0.10285714285714286
program .	0.13636363636363635
shortened	2.7900228781876013e-05
version	8.370068634562804e-05
The product	0.010416666666666666
product of	0.14285714285714285
this procedure	0.01098901098901099
procedure still	0.3333333333333333
still contains	0.06666666666666667
contains the	0.2
most important	0.034482758620689655
important points	0.0625
points of	0.5
the original	0.006920415224913495
original text	0.46153846153846156
product	0.0001953016014731321
still	0.0004185034317281402
points	5.5800457563752025e-05
original	0.00036270297416438817
analysis -LRB-	0.06153846153846154
-LRB- DA	0.005420054200542005
DA -RRB-	0.6666666666666666
or discourse	0.009009009009009009
discourse studies	0.027777777777777776
studies ,	0.5
, is	0.0072992700729927005
a general	0.0036809815950920245
general term	0.045454545454545456
term for	0.16666666666666666
of approaches	0.00089126559714795
to analyzing	0.0013280212483399733
analyzing written	0.2
written ,	0.038461538461538464
, spoken	0.0005614823133071309
spoken ,	0.14285714285714285
, signed	0.0005614823133071309
signed language	1.0
language use	0.02702702702702703
use or	0.027777777777777776
or any	0.013513513513513514
any significant	0.03225806451612903
significant semiotic	0.1111111111111111
semiotic event	1.0
event .	0.3333333333333333
DA	8.370068634562804e-05
studies	0.00011160091512750405
term	0.0005022041180737682
analyzing	0.00013950114390938006
signed	2.7900228781876013e-05
semiotic	2.7900228781876013e-05
event	8.370068634562804e-05
, sometimes	0.0005614823133071309
to by	0.0026560424966799467
the abbreviation	0.0006920415224913495
abbreviation MT	0.5
MT -LRB-	0.2
-LRB- not	0.0027100271002710027
not to	0.008928571428571428
be confused	0.004219409282700422
confused with	1.0
with computer-aided	0.00546448087431694
computer-aided translation	0.3333333333333333
, machine-aided	0.0005614823133071309
machine-aided human	1.0
human translation	0.043478260869565216
translation MAHT	0.013513513513513514
MAHT and	1.0
and interactive	0.001445086705202312
interactive translation	0.25
a sub-field	0.001226993865030675
sub-field of	1.0
that investigates	0.0035460992907801418
investigates the	1.0
of software	0.00089126559714795
software to	0.07407407407407407
to translate	0.00398406374501992
text or	0.018867924528301886
or speech	0.0045045045045045045
speech from	0.006578947368421052
one natural	0.03076923076923077
abbreviation	5.5800457563752025e-05
MT	0.00013950114390938006
confused	5.5800457563752025e-05
computer-aided	8.370068634562804e-05
machine-aided	2.7900228781876013e-05
MAHT	2.7900228781876013e-05
interactive	0.00011160091512750405
sub-field	2.7900228781876013e-05
investigates	2.7900228781876013e-05
software	0.0007533061771106523
On a	0.16666666666666666
a basic	0.00245398773006135
basic level	0.07692307692307693
level ,	0.2
, MT	0.0011229646266142617
MT performs	0.2
performs simple	1.0
simple substitution	0.038461538461538464
substitution of	1.0
in one	0.00749063670411985
language for	0.02027027027027027
for words	0.0036101083032490976
in another	0.00749063670411985
another ,	0.07692307692307693
but that	0.04411764705882353
that alone	0.0035460992907801418
alone usually	0.25
usually can	0.03125
not produce	0.008928571428571428
produce a	0.13636363636363635
a good	0.0049079754601227
good translation	0.07692307692307693
because recognition	0.03333333333333333
recognition of	0.0743801652892562
of whole	0.0017825311942959
whole phrases	0.1111111111111111
phrases and	0.1875
and their	0.008670520231213872
their closest	0.029411764705882353
closest counterparts	0.5
counterparts in	1.0
the target	0.006228373702422145
target language	0.7272727272727273
language is	0.033783783783783786
is needed	0.0020325203252032522
needed .	0.09523809523809523
basic	0.00036270297416438817
level	0.0005580045756375203
performs	2.7900228781876013e-05
substitution	5.5800457563752025e-05
good	0.00036270297416438817
phrases	0.0004464036605100162
closest	5.5800457563752025e-05
counterparts	2.7900228781876013e-05
target	0.00030690251660063614
<s> Solving	0.0007686395080707148
Solving this	0.5
problem with	0.022727272727272728
with corpus	0.00546448087431694
corpus and	0.03225806451612903
statistical techniques	0.06060606060606061
techniques is	0.043478260869565216
a rapidly	0.001226993865030675
rapidly growing	0.5
growing field	0.5
field that	0.07407407407407407
is leading	0.0020325203252032522
leading to	1.0
to better	0.00398406374501992
better translations	0.1111111111111111
translations ,	0.5
handling differences	0.5
differences in	0.3333333333333333
in linguistic	0.003745318352059925
linguistic typology	0.0625
typology ,	1.0
of idioms	0.00089126559714795
idioms ,	1.0
the isolation	0.0006920415224913495
isolation of	0.5
of anomalies	0.00089126559714795
anomalies .	1.0
Solving	5.5800457563752025e-05
techniques	0.0006417052619831483
rapidly	5.5800457563752025e-05
growing	0.00011160091512750405
leading	5.5800457563752025e-05
better	0.0002511020590368841
translations	5.5800457563752025e-05
differences	8.370068634562804e-05
typology	2.7900228781876013e-05
idioms	5.5800457563752025e-05
isolation	5.5800457563752025e-05
anomalies	2.7900228781876013e-05
-LRB- citation	0.03523035230352303
citation needed	1.0
needed -RRB-	0.6190476190476191
-RRB- Current	0.0027100271002710027
Current machine	0.2
translation software	0.04054054054054054
software often	0.037037037037037035
often allows	0.022727272727272728
allows for	0.125
for customisation	0.0036101083032490976
customisation by	1.0
by domain	0.005714285714285714
domain or	0.05
or profession	0.0045045045045045045
profession -LRB-	1.0
as weather	0.003484320557491289
weather reports	0.2857142857142857
reports -RRB-	0.4
, improving	0.0005614823133071309
improving output	1.0
output by	0.038461538461538464
by limiting	0.005714285714285714
limiting the	1.0
the scope	0.001384083044982699
scope of	1.0
of allowable	0.00089126559714795
allowable substitutions	0.5
substitutions .	1.0
citation	0.00036270297416438817
Current	0.00013950114390938006
allows	0.0002232018302550081
customisation	2.7900228781876013e-05
domain	0.0005580045756375203
profession	2.7900228781876013e-05
weather	0.0001953016014731321
reports	0.00013950114390938006
improving	2.7900228781876013e-05
limiting	2.7900228781876013e-05
scope	5.5800457563752025e-05
allowable	5.5800457563752025e-05
substitutions	2.7900228781876013e-05
This technique	0.015873015873015872
technique is	0.14285714285714285
is particularly	0.0040650406504065045
particularly effective	0.2
effective in	0.3333333333333333
in domains	0.0018726591760299626
domains where	0.125
where formal	0.02857142857142857
formal or	0.1111111111111111
or formulaic	0.0045045045045045045
formulaic language	1.0
used .	0.04424778761061947
technique	0.0001953016014731321
effective	0.00016740137269125608
domains	0.0002232018302550081
formulaic	2.7900228781876013e-05
It follows	0.02631578947368421
follows that	0.5
that machine	0.010638297872340425
government and	0.3333333333333333
and legal	0.001445086705202312
legal documents	0.3333333333333333
documents more	0.02631578947368421
more readily	0.010526315789473684
readily produces	0.3333333333333333
produces usable	0.25
usable output	1.0
output than	0.038461538461538464
than conversation	0.022222222222222223
conversation or	0.25
or less	0.018018018018018018
less standardised	0.08333333333333333
standardised text	1.0
follows	5.5800457563752025e-05
legal	8.370068634562804e-05
usable	2.7900228781876013e-05
standardised	2.7900228781876013e-05
<s> Improved	0.0007686395080707148
Improved output	1.0
output quality	0.038461538461538464
quality can	0.1
can also	0.04419889502762431
be achieved	0.02109704641350211
achieved by	0.2
human intervention	0.021739130434782608
intervention :	1.0
: for	0.00980392156862745
some systems	0.024096385542168676
systems are	0.11607142857142858
translate more	0.16666666666666666
more accurately	0.010526315789473684
accurately if	0.5
if the	0.35714285714285715
the user	0.0034602076124567475
user has	0.07142857142857142
has unambiguously	0.011904761904761904
unambiguously identified	1.0
identified which	0.2
text are	0.006289308176100629
are names	0.004149377593360996
Improved	2.7900228781876013e-05
achieved	0.00027900228781876013
intervention	2.7900228781876013e-05
accurately	5.5800457563752025e-05
if	0.0007812064058925284
unambiguously	2.7900228781876013e-05
<s> With	0.003843197540353574
With the	0.2857142857142857
the assistance	0.0006920415224913495
assistance of	1.0
these techniques	0.023809523809523808
techniques ,	0.08695652173913043
MT has	0.2
has proven	0.011904761904761904
proven useful	1.0
useful as	0.07142857142857142
a tool	0.00245398773006135
tool to	0.5
to assist	0.0013280212483399733
assist human	1.0
human translators	0.021739130434782608
translators and	1.0
very limited	0.04878048780487805
limited number	0.2
of cases	0.00089126559714795
can even	0.0055248618784530384
even produce	0.037037037037037035
produce output	0.09090909090909091
output that	0.07692307692307693
be used	0.08016877637130802
used as	0.04424778761061947
e.g. ,	0.4642857142857143
, weather	0.0005614823133071309
With	0.0001953016014731321
assistance	2.7900228781876013e-05
proven	2.7900228781876013e-05
tool	5.5800457563752025e-05
assist	2.7900228781876013e-05
translators	2.7900228781876013e-05
The progress	0.005208333333333333
progress and	0.14285714285714285
and potential	0.001445086705202312
potential of	0.2857142857142857
translation has	0.02702702702702703
been debated	0.014705882352941176
debated much	1.0
much through	0.045454545454545456
through its	0.125
its history	0.02857142857142857
history .	0.25
debated	2.7900228781876013e-05
<s> Since	0.0030745580322828594
Since the	0.2
the 1950s	0.0020761245674740486
1950s ,	0.5
of scholars	0.00089126559714795
scholars have	0.5
have questioned	0.009615384615384616
questioned the	1.0
the possibility	0.002768166089965398
possibility of	0.75
of achieving	0.0017825311942959
achieving fully	0.5
automatic machine	0.043478260869565216
of high	0.00089126559714795
high quality	0.05555555555555555
quality .	0.1
Since	0.00013950114390938006
1950s	0.00011160091512750405
scholars	5.5800457563752025e-05
questioned	2.7900228781876013e-05
possibility	0.00011160091512750405
achieving	5.5800457563752025e-05
Some critics	0.047619047619047616
critics claim	1.0
claim that	1.0
that there	0.0070921985815602835
are in-principle	0.004149377593360996
in-principle obstacles	1.0
obstacles to	1.0
to automatizing	0.0013280212483399733
automatizing the	1.0
translation process	0.02702702702702703
critics	2.7900228781876013e-05
claim	2.7900228781876013e-05
in-principle	2.7900228781876013e-05
obstacles	2.7900228781876013e-05
automatizing	2.7900228781876013e-05
In 1629	0.009523809523809525
1629 ,	1.0
, Ren	0.0005614823133071309
Ren Descartes	1.0
Descartes proposed	1.0
proposed a	0.2222222222222222
a universal	0.001226993865030675
universal language	0.3333333333333333
language ,	0.04054054054054054
, with	0.004491858506457047
with equivalent	0.01092896174863388
equivalent ideas	0.2
ideas in	0.5
in different	0.0056179775280898875
different tongues	0.02040816326530612
tongues sharing	1.0
sharing one	1.0
one symbol	0.015384615384615385
symbol .	0.5
1629	2.7900228781876013e-05
Ren	2.7900228781876013e-05
Descartes	2.7900228781876013e-05
universal	8.370068634562804e-05
equivalent	0.00013950114390938006
ideas	0.00011160091512750405
tongues	2.7900228781876013e-05
sharing	2.7900228781876013e-05
symbol	0.00011160091512750405
, The	0.0005614823133071309
experiment -LRB-	0.2
-LRB- 1954	0.0027100271002710027
1954 -RRB-	0.3333333333333333
-RRB- involved	0.0027100271002710027
of over	0.00089126559714795
over sixty	0.08333333333333333
The experiment	0.005208333333333333
experiment was	0.4
great success	0.3333333333333333
success and	0.2
and ushered	0.001445086705202312
ushered in	1.0
in an	0.0149812734082397
an era	0.007575757575757576
era of	1.0
of substantial	0.00089126559714795
substantial funding	0.2
for machine-translation	0.0036101083032490976
machine-translation research	0.5
research .	0.09523809523809523
ushered	2.7900228781876013e-05
era	2.7900228781876013e-05
substantial	0.00013950114390938006
machine-translation	5.5800457563752025e-05
three to	0.3333333333333333
to five	0.0013280212483399733
<s> Real	0.0015372790161414297
Real progress	0.5
report -LRB-	0.25
-LRB- 1966	0.0027100271002710027
1966 -RRB-	0.3333333333333333
the ten-year-long	0.0006920415224913495
ten-year-long research	1.0
fulfill expectations	0.5
funding was	0.125
was greatly	0.012987012987012988
greatly reduced	0.14285714285714285
Real	5.5800457563752025e-05
ten-year-long	2.7900228781876013e-05
<s> Beginning	0.0007686395080707148
Beginning in	0.5
as computational	0.003484320557491289
power increased	0.25
increased and	0.2
and became	0.001445086705202312
became less	0.2
less expensive	0.08333333333333333
expensive ,	0.42857142857142855
, more	0.0022459292532285235
more interest	0.010526315789473684
interest was	0.09090909090909091
was shown	0.025974025974025976
shown in	0.4
models for	0.23076923076923078
translation .	0.05405405405405406
Beginning	5.5800457563752025e-05
increased	0.00013950114390938006
became	0.00013950114390938006
expensive	0.0001953016014731321
interest	0.00030690251660063614
shown	0.00013950114390938006
The idea	0.010416666666666666
idea of	0.2857142857142857
of using	0.00089126559714795
using digital	0.01694915254237288
digital computers	0.14285714285714285
computers for	0.1111111111111111
for translation	0.0036101083032490976
languages was	0.02
was proposed	0.025974025974025976
proposed as	0.1111111111111111
as early	0.003484320557491289
early as	0.1
as 1946	0.003484320557491289
1946 by	1.0
by A.	0.005714285714285714
A. D.	0.2
D. Booth	0.2
Booth and	1.0
and possibly	0.001445086705202312
possibly others	0.5
idea	0.0001953016014731321
digital	0.0001953016014731321
1946	2.7900228781876013e-05
A.	0.00013950114390938006
Booth	2.7900228781876013e-05
possibly	5.5800457563752025e-05
<s> Warren	0.0007686395080707148
Warren Weaver	1.0
Weaver wrote	1.0
wrote an	0.3333333333333333
an important	0.015151515151515152
important memorandum	0.0625
memorandum ``	1.0
`` Translation	0.005291005291005291
Translation ''	0.3333333333333333
'' in	0.03608247422680412
in 1949	0.0018726591760299626
1949 .	0.5
Warren	2.7900228781876013e-05
Weaver	2.7900228781876013e-05
wrote	0.00016740137269125608
memorandum	2.7900228781876013e-05
Translation	8.370068634562804e-05
1949	5.5800457563752025e-05
was by	0.025974025974025976
by no	0.005714285714285714
no means	0.07692307692307693
means the	0.16666666666666666
first such	0.030303030303030304
such application	0.008130081300813009
application ,	0.14285714285714285
a demonstration	0.0036809815950920245
demonstration was	0.2
was made	0.012987012987012988
1954 on	0.3333333333333333
the APEXC	0.0006920415224913495
APEXC machine	1.0
machine at	0.012658227848101266
at Birkbeck	0.029411764705882353
Birkbeck College	1.0
College -LRB-	0.5
-LRB- University	0.0027100271002710027
University of	0.3333333333333333
of London	0.00089126559714795
London -RRB-	1.0
a rudimentary	0.001226993865030675
rudimentary translation	0.5
English into	0.02702702702702703
into French	0.02564102564102564
French .	0.25
means	0.00016740137269125608
demonstration	0.00013950114390938006
APEXC	2.7900228781876013e-05
Birkbeck	5.5800457563752025e-05
College	5.5800457563752025e-05
University	0.0002511020590368841
London	2.7900228781876013e-05
rudimentary	5.5800457563752025e-05
<s> Several	0.0023059185242121443
Several papers	0.3333333333333333
papers on	0.6666666666666666
topic were	0.125
were published	0.024390243902439025
published at	0.14285714285714285
the time	0.004152249134948097
even articles	0.037037037037037035
in popular	0.0018726591760299626
popular journals	0.1111111111111111
journals -LRB-	0.5
see for	0.05
example Wireless	0.012345679012345678
Wireless World	1.0
World ,	0.14285714285714285
, Sept.	0.0005614823133071309
Sept. 1955	1.0
1955 ,	1.0
, Cleave	0.0005614823133071309
Cleave and	1.0
and Zacharov	0.001445086705202312
Zacharov -RRB-	1.0
Several	8.370068634562804e-05
papers	8.370068634562804e-05
popular	0.0002511020590368841
journals	5.5800457563752025e-05
Wireless	2.7900228781876013e-05
Sept.	2.7900228781876013e-05
1955	5.5800457563752025e-05
Cleave	2.7900228781876013e-05
Zacharov	2.7900228781876013e-05
A similar	0.02
similar application	0.037037037037037035
also pioneered	0.014492753623188406
pioneered at	0.3333333333333333
College at	0.5
, was	0.0022459292532285235
was reading	0.012987012987012988
reading and	0.25
and composing	0.001445086705202312
composing Braille	1.0
Braille texts	1.0
texts by	0.058823529411764705
by computer	0.017142857142857144
computer .	0.06818181818181818
pioneered	8.370068634562804e-05
reading	0.0002232018302550081
composing	2.7900228781876013e-05
Braille	2.7900228781876013e-05
<s> Translation	0.0007686395080707148
Translation process	0.6666666666666666
process Main	0.027777777777777776
: Translation	0.00980392156862745
process The	0.027777777777777776
The human	0.005208333333333333
process may	0.027777777777777776
be described	0.004219409282700422
described as	0.3333333333333333
as :	0.003484320557491289
: Decoding	0.00980392156862745
Decoding the	0.5
the source	0.008304498269896194
source text	0.20833333333333334
text ;	0.006289308176100629
and Re-encoding	0.001445086705202312
Re-encoding this	1.0
this meaning	0.01098901098901099
meaning in	0.08695652173913043
Decoding	5.5800457563752025e-05
source	0.0006696054907650243
Re-encoding	2.7900228781876013e-05
<s> Behind	0.0007686395080707148
Behind this	1.0
this ostensibly	0.01098901098901099
ostensibly simple	1.0
simple procedure	0.038461538461538464
procedure lies	0.3333333333333333
lies a	0.5
complex cognitive	0.041666666666666664
cognitive operation	0.5
operation .	0.5
Behind	2.7900228781876013e-05
ostensibly	2.7900228781876013e-05
lies	5.5800457563752025e-05
cognitive	5.5800457563752025e-05
operation	5.5800457563752025e-05
<s> To	0.006149116064565719
To decode	0.1111111111111111
decode the	1.0
text in	0.050314465408805034
in its	0.003745318352059925
its entirety	0.02857142857142857
entirety ,	1.0
the translator	0.0006920415224913495
translator must	0.14285714285714285
must interpret	0.07142857142857142
interpret and	1.0
and analyze	0.001445086705202312
analyze all	0.25
all the	0.13953488372093023
features of	0.15384615384615385
process that	0.05555555555555555
that requires	0.0070921985815602835
requires in-depth	0.0625
in-depth knowledge	0.6666666666666666
the grammar	0.006228373702422145
, syntax	0.0011229646266142617
syntax ,	0.45454545454545453
, idioms	0.0005614823133071309
etc. ,	0.045454545454545456
, of	0.0022459292532285235
source language	0.125
the culture	0.0006920415224913495
culture of	1.0
its speakers	0.02857142857142857
speakers .	0.25
decode	2.7900228781876013e-05
entirety	2.7900228781876013e-05
translator	0.0001953016014731321
must	0.0003906032029462642
interpret	2.7900228781876013e-05
analyze	0.00011160091512750405
in-depth	8.370068634562804e-05
syntax	0.00030690251660063614
culture	2.7900228781876013e-05
speakers	0.00011160091512750405
The translator	0.005208333333333333
translator needs	0.14285714285714285
needs the	0.1
same in-depth	0.04
knowledge to	0.037037037037037035
to re-encode	0.0013280212483399733
re-encode the	1.0
re-encode	2.7900228781876013e-05
<s> Therein	0.0007686395080707148
Therein lies	1.0
lies the	0.5
the challenge	0.0006920415224913495
challenge in	1.0
: how	0.00980392156862745
how to	0.10344827586206896
to program	0.0013280212483399733
program a	0.09090909090909091
computer that	0.022727272727272728
that will	0.0070921985815602835
will ``	0.05714285714285714
`` understand	0.005291005291005291
understand ''	0.14285714285714285
'' a	0.015463917525773196
text as	0.006289308176100629
person does	0.05263157894736842
does ,	0.1
and that	0.002890173410404624
`` create	0.005291005291005291
create ''	0.058823529411764705
a new	0.007361963190184049
new text	0.08333333333333333
language that	0.006756756756756757
that ``	0.02127659574468085
`` sounds	0.005291005291005291
sounds ''	0.06666666666666667
'' as	0.02577319587628866
as if	0.003484320557491289
if it	0.07142857142857142
it has	0.03418803418803419
been written	0.014705882352941176
person .	0.05263157894736842
Therein	2.7900228781876013e-05
challenge	2.7900228781876013e-05
how	0.0008091066346744044
understand	0.0001953016014731321
does	0.00027900228781876013
create	0.0004743038892918922
This problem	0.06349206349206349
problem may	0.022727272727272728
be approached	0.004219409282700422
approached in	0.5
of ways	0.0017825311942959
ways .	0.125
approached	5.5800457563752025e-05
ways	0.0002232018302550081
<s> Approaches	0.0023059185242121443
Approaches Bernard	0.3333333333333333
Bernard Vauquois	1.0
Vauquois '	1.0
' pyramid	0.05263157894736842
pyramid showing	1.0
showing comparative	0.5
comparative depths	1.0
depths of	1.0
of intermediary	0.00089126559714795
intermediary representation	0.6666666666666666
representation ,	0.15789473684210525
, interlingual	0.0011229646266142617
interlingual machine	0.75
translation at	0.013513513513513514
the peak	0.0006920415224913495
peak ,	1.0
, followed	0.0005614823133071309
followed by	0.5
by transfer-based	0.005714285714285714
transfer-based ,	0.3333333333333333
, then	0.006176305446378439
then direct	0.02857142857142857
direct translation	0.16666666666666666
Approaches	8.370068634562804e-05
Bernard	2.7900228781876013e-05
Vauquois	2.7900228781876013e-05
pyramid	2.7900228781876013e-05
showing	5.5800457563752025e-05
comparative	2.7900228781876013e-05
depths	2.7900228781876013e-05
intermediary	8.370068634562804e-05
interlingual	0.00011160091512750405
peak	2.7900228781876013e-05
followed	0.00011160091512750405
transfer-based	8.370068634562804e-05
translation can	0.02702702702702703
can use	0.016574585635359115
use a	0.05555555555555555
a method	0.0049079754601227
method based	0.125
on linguistic	0.0047169811320754715
linguistic rules	0.0625
which means	0.028985507246376812
means that	0.6666666666666666
that words	0.0070921985815602835
words will	0.01834862385321101
be translated	0.012658227848101266
translated in	0.25
a linguistic	0.00245398773006135
linguistic way	0.0625
way --	0.041666666666666664
most suitable	0.017241379310344827
suitable -LRB-	0.25
-LRB- orally	0.0027100271002710027
orally speaking	1.0
speaking -RRB-	0.125
-RRB- words	0.0027100271002710027
words of	0.027522935779816515
language will	0.006756756756756757
will replace	0.02857142857142857
replace the	1.0
the ones	0.001384083044982699
ones in	0.1
translated	0.00011160091512750405
suitable	0.00011160091512750405
orally	2.7900228781876013e-05
replace	2.7900228781876013e-05
often argued	0.022727272727272728
argued that	1.0
translation requires	0.013513513513513514
requires the	0.1875
the problem	0.006228373702422145
problem of	0.18181818181818182
understanding to	0.06060606060606061
be solved	0.004219409282700422
solved first	0.2
first .	0.030303030303030304
argued	2.7900228781876013e-05
, rule-based	0.0005614823133071309
rule-based methods	0.14285714285714285
methods parse	0.022727272727272728
parse a	0.1111111111111111
, usually	0.002807411566535654
usually creating	0.03125
creating an	0.2857142857142857
an intermediary	0.007575757575757576
intermediary ,	0.3333333333333333
, symbolic	0.0005614823133071309
symbolic representation	1.0
, from	0.0005614823133071309
from which	0.028846153846153848
rule-based	0.0001953016014731321
symbolic	2.7900228781876013e-05
<s> According	0.0007686395080707148
According to	1.0
the intermediary	0.0006920415224913495
is described	0.0020325203252032522
as interlingual	0.003484320557491289
translation or	0.013513513513513514
or transfer-based	0.0045045045045045045
transfer-based machine	0.6666666666666666
According	2.7900228781876013e-05
These methods	0.17647058823529413
methods require	0.022727272727272728
extensive lexicons	0.3333333333333333
lexicons with	0.5
with morphological	0.00546448087431694
morphological ,	0.3333333333333333
, syntactic	0.0016844469399213925
syntactic ,	0.07692307692307693
and semantic	0.004335260115606936
information ,	0.043478260869565216
and large	0.001445086705202312
lexicons	5.5800457563752025e-05
morphological	8.370068634562804e-05
Given enough	0.07142857142857142
enough data	0.4
translation programs	0.013513513513513514
programs often	0.09090909090909091
often work	0.022727272727272728
work well	0.041666666666666664
well enough	0.03571428571428571
enough for	0.2
a native	0.00245398773006135
native speaker	1.0
speaker of	0.1111111111111111
of one	0.0035650623885918
one language	0.03076923076923077
to get	0.005312084993359893
get the	0.2857142857142857
the approximate	0.0006920415224913495
approximate meaning	0.5
of what	0.0035650623885918
is written	0.0020325203252032522
other native	0.014285714285714285
speaker .	0.16666666666666666
enough	0.00013950114390938006
native	0.00011160091512750405
speaker	0.0005022041180737682
get	0.0001953016014731321
approximate	5.5800457563752025e-05
difficulty is	0.14285714285714285
is getting	0.0040650406504065045
getting enough	0.25
data of	0.012987012987012988
the right	0.0020761245674740486
right kind	0.1
kind to	0.09090909090909091
to support	0.0026560424966799467
support the	0.25
the particular	0.001384083044982699
particular method	0.07692307692307693
method .	0.125
getting	0.00011160091512750405
support	0.00011160091512750405
the large	0.0006920415224913495
large multilingual	0.043478260869565216
multilingual corpus	0.3333333333333333
data needed	0.012987012987012988
needed for	0.09523809523809523
work is	0.125
not necessary	0.008928571428571428
necessary for	0.3
the grammar-based	0.0006920415224913495
grammar-based methods	1.0
methods .	0.022727272727272728
grammar-based	2.7900228781876013e-05
<s> But	0.004611837048424289
But then	0.16666666666666666
then ,	0.08571428571428572
grammar methods	0.02702702702702703
methods need	0.045454545454545456
need a	0.19047619047619047
a skilled	0.001226993865030675
skilled linguist	1.0
linguist to	0.5
to carefully	0.0013280212483399733
carefully design	1.0
design the	0.25
grammar that	0.02702702702702703
they use	0.025
use .	0.041666666666666664
But	0.00016740137269125608
need	0.0005859048044193963
skilled	2.7900228781876013e-05
linguist	5.5800457563752025e-05
carefully	2.7900228781876013e-05
To translate	0.1111111111111111
translate between	0.16666666666666666
between closely	0.02564102564102564
closely related	0.4
related languages	0.06666666666666667
a technique	0.001226993865030675
technique referred	0.14285714285714285
as shallow-transfer	0.003484320557491289
shallow-transfer machine	1.0
translation may	0.013513513513513514
closely	0.00013950114390938006
shallow-transfer	2.7900228781876013e-05
<s> Rule-based	0.0007686395080707148
Rule-based The	0.5
The rule-based	0.005208333333333333
rule-based machine	0.14285714285714285
translation paradigm	0.013513513513513514
paradigm includes	0.3333333333333333
includes transfer-based	0.14285714285714285
and dictionary-based	0.001445086705202312
dictionary-based machine	1.0
translation paradigms	0.013513513513513514
paradigms .	1.0
Rule-based	5.5800457563752025e-05
dictionary-based	2.7900228781876013e-05
paradigms	2.7900228781876013e-05
<s> Main	0.0007686395080707148
: Rule-based	0.00980392156862745
Rule-based machine	0.5
translation Transfer-based	0.013513513513513514
Transfer-based machine	1.0
translation Main	0.013513513513513514
: Transfer-based	0.00980392156862745
translation Interlingual	0.02702702702702703
Interlingual Main	0.3333333333333333
: Interlingual	0.00980392156862745
Interlingual machine	0.6666666666666666
translation is	0.013513513513513514
one instance	0.015384615384615385
instance of	0.14285714285714285
of rule-based	0.00089126559714795
rule-based machine-translation	0.14285714285714285
machine-translation approaches	0.5
approaches .	0.10714285714285714
Transfer-based	5.5800457563752025e-05
Interlingual	8.370068634562804e-05
instance	0.0003906032029462642
In this	0.047619047619047616
this approach	0.02197802197802198
approach ,	0.05714285714285714
translated ,	0.25
is transformed	0.0020325203252032522
transformed into	1.0
into an	0.02564102564102564
an interlingual	0.007575757575757576
interlingual ,	0.25
i.e. source	0.05263157894736842
source -	0.041666666666666664
- \/	0.0625
\/ target-language-independent	0.3333333333333333
target-language-independent representation	1.0
representation .	0.21052631578947367
transformed	2.7900228781876013e-05
\/	8.370068634562804e-05
target-language-independent	2.7900228781876013e-05
The target	0.005208333333333333
then generated	0.02857142857142857
generated out	0.06666666666666667
out of	0.07142857142857142
the interlingua	0.0006920415224913495
interlingua .	1.0
interlingua	2.7900228781876013e-05
<s> Dictionary-based	0.0007686395080707148
Dictionary-based Main	0.5
: Dictionary-based	0.00980392156862745
Dictionary-based machine	0.5
translation Machine	0.013513513513513514
on dictionary	0.0047169811320754715
dictionary entries	0.14285714285714285
entries ,	0.5
translated as	0.25
as they	0.010452961672473868
they are	0.175
are by	0.004149377593360996
dictionary .	0.14285714285714285
Dictionary-based	5.5800457563752025e-05
entries	5.5800457563752025e-05
Statistical Main	0.1111111111111111
: Statistical	0.00980392156862745
Statistical machine	0.2222222222222222
translation Statistical	0.013513513513513514
translation tries	0.013513513513513514
tries to	1.0
to generate	0.00796812749003984
generate translations	0.05555555555555555
translations using	0.5
using statistical	0.03389830508474576
methods based	0.022727272727272728
on bilingual	0.0047169811320754715
bilingual text	0.5
text corpora	0.006289308176100629
corpora ,	0.09090909090909091
the Canadian	0.001384083044982699
Canadian Hansard	0.5
Hansard corpus	1.0
corpus ,	0.06451612903225806
the English-French	0.0006920415224913495
English-French record	1.0
record of	1.0
Canadian parliament	0.5
parliament and	1.0
and EUROPARL	0.001445086705202312
EUROPARL ,	1.0
the record	0.0006920415224913495
European Parliament	0.3333333333333333
Parliament .	0.5
tries	2.7900228781876013e-05
generate	0.0005022041180737682
bilingual	5.5800457563752025e-05
Canadian	5.5800457563752025e-05
Hansard	2.7900228781876013e-05
English-French	2.7900228781876013e-05
record	5.5800457563752025e-05
parliament	2.7900228781876013e-05
EUROPARL	2.7900228781876013e-05
<s> Where	0.0007686395080707148
Where such	1.0
such corpora	0.016260162601626018
corpora are	0.18181818181818182
are available	0.008298755186721992
available ,	0.23529411764705882
, impressive	0.0005614823133071309
impressive results	0.5
results can	0.047619047619047616
achieved translating	0.1
translating texts	0.25
texts of	0.11764705882352941
a similar	0.001226993865030675
similar kind	0.037037037037037035
kind ,	0.09090909090909091
but such	0.014705882352941176
are still	0.016597510373443983
still very	0.06666666666666667
very rare	0.024390243902439025
rare .	0.5
Where	2.7900228781876013e-05
impressive	5.5800457563752025e-05
translating	0.00011160091512750405
rare	0.00011160091512750405
software was	0.037037037037037035
was CANDIDE	0.012987012987012988
CANDIDE from	1.0
from IBM	0.009615384615384616
IBM .	0.3333333333333333
CANDIDE	2.7900228781876013e-05
<s> Google	0.0007686395080707148
Google used	0.25
used SYSTRAN	0.008849557522123894
SYSTRAN for	1.0
for several	0.007220216606498195
several years	0.09090909090909091
but switched	0.014705882352941176
switched to	1.0
a statistical	0.0036809815950920245
statistical translation	0.030303030303030304
translation method	0.013513513513513514
method in	0.0625
in October	0.0018726591760299626
October 2007	1.0
Google	0.00011160091512750405
SYSTRAN	2.7900228781876013e-05
switched	2.7900228781876013e-05
October	2.7900228781876013e-05
<s> Recently	0.0007686395080707148
Recently ,	1.0
, they	0.004491858506457047
they improved	0.025
improved their	0.25
their translation	0.029411764705882353
translation capabilities	0.013513513513513514
capabilities by	0.2
by inputting	0.005714285714285714
inputting approximately	1.0
approximately 200	0.5
200 billion	0.5
billion words	1.0
words from	0.01834862385321101
from United	0.009615384615384616
United Nations	0.2222222222222222
Nations materials	0.5
materials to	0.5
to train	0.0013280212483399733
train their	1.0
their system	0.029411764705882353
Recently	2.7900228781876013e-05
improved	0.00011160091512750405
capabilities	0.00013950114390938006
inputting	2.7900228781876013e-05
approximately	5.5800457563752025e-05
200	5.5800457563752025e-05
billion	2.7900228781876013e-05
United	0.0002511020590368841
Nations	5.5800457563752025e-05
materials	5.5800457563752025e-05
train	2.7900228781876013e-05
<s> Accuracy	0.003843197540353574
Accuracy of	0.42857142857142855
has improved	0.011904761904761904
improved .	0.25
Accuracy	0.0001953016014731321
<s> Example-based	0.0007686395080707148
Example-based Main	0.3333333333333333
: Example-based	0.00980392156862745
Example-based machine	0.6666666666666666
translation Example-based	0.013513513513513514
translation -LRB-	0.02702702702702703
-LRB- EBMT	0.0027100271002710027
EBMT -RRB-	1.0
-RRB- approach	0.0027100271002710027
approach was	0.02857142857142857
proposed by	0.1111111111111111
by Makoto	0.005714285714285714
Makoto Nagao	1.0
Nagao in	1.0
in 1984	0.0018726591760299626
1984 .	1.0
Example-based	8.370068634562804e-05
EBMT	2.7900228781876013e-05
Makoto	2.7900228781876013e-05
Nagao	2.7900228781876013e-05
1984	2.7900228781876013e-05
often characterised	0.022727272727272728
characterised by	1.0
by its	0.005714285714285714
its use	0.02857142857142857
a bilingual	0.001226993865030675
bilingual corpus	0.5
corpus as	0.03225806451612903
as its	0.010452961672473868
its main	0.02857142857142857
main knowledge	0.125
, at	0.0016844469399213925
at run-time	0.014705882352941176
run-time .	1.0
characterised	2.7900228781876013e-05
main	0.0002232018302550081
run-time	2.7900228781876013e-05
is essentially	0.006097560975609756
essentially a	0.25
translation by	0.013513513513513514
by analogy	0.005714285714285714
analogy and	1.0
be viewed	0.016877637130801686
viewed as	1.0
an implementation	0.007575757575757576
of case-based	0.00089126559714795
case-based reasoning	1.0
reasoning approach	0.14285714285714285
approach of	0.02857142857142857
essentially	0.0002232018302550081
analogy	2.7900228781876013e-05
viewed	0.00011160091512750405
case-based	2.7900228781876013e-05
reasoning	0.0001953016014731321
<s> Hybrid	0.0007686395080707148
Hybrid MT	0.5
MT Hybrid	0.2
Hybrid machine	0.5
-LRB- HMT	0.0027100271002710027
HMT -RRB-	1.0
-RRB- leverages	0.0027100271002710027
leverages the	1.0
the strengths	0.0006920415224913495
strengths of	0.5
statistical and	0.030303030303030304
and rule-based	0.001445086705202312
rule-based translation	0.14285714285714285
translation methodologies	0.013513513513513514
methodologies .	1.0
Hybrid	5.5800457563752025e-05
HMT	2.7900228781876013e-05
leverages	2.7900228781876013e-05
strengths	5.5800457563752025e-05
methodologies	5.5800457563752025e-05
Several MT	0.3333333333333333
MT companies	0.2
companies -LRB-	0.5
-LRB- Asia	0.0027100271002710027
Asia Online	1.0
Online ,	0.5
, LinguaSys	0.0005614823133071309
LinguaSys ,	1.0
, Systran	0.0005614823133071309
Systran ,	1.0
, PangeaMT	0.0005614823133071309
PangeaMT ,	1.0
, UPV	0.0005614823133071309
UPV -RRB-	1.0
are claiming	0.004149377593360996
claiming to	1.0
to have	0.013280212483399735
a hybrid	0.00245398773006135
hybrid approach	0.5
approach using	0.02857142857142857
using both	0.01694915254237288
both rules	0.03225806451612903
rules and	0.023255813953488372
companies	5.5800457563752025e-05
Asia	2.7900228781876013e-05
Online	5.5800457563752025e-05
LinguaSys	2.7900228781876013e-05
Systran	2.7900228781876013e-05
PangeaMT	2.7900228781876013e-05
UPV	2.7900228781876013e-05
claiming	2.7900228781876013e-05
hybrid	5.5800457563752025e-05
The approaches	0.005208333333333333
approaches differ	0.03571428571428571
differ in	0.3333333333333333
ways :	0.25
: Rules	0.0196078431372549
Rules post-processed	0.3333333333333333
post-processed by	1.0
by statistics	0.005714285714285714
statistics :	0.125
: Translations	0.00980392156862745
Translations are	1.0
are performed	0.004149377593360996
performed using	0.1
a rules	0.001226993865030675
rules based	0.023255813953488372
based engine	0.018518518518518517
engine .	0.6666666666666666
Rules	8.370068634562804e-05
post-processed	2.7900228781876013e-05
Translations	2.7900228781876013e-05
engine	0.00016740137269125608
<s> Statistics	0.0023059185242121443
Statistics are	0.3333333333333333
are then	0.004149377593360996
then used	0.02857142857142857
an attempt	0.022727272727272728
attempt to	1.0
to adjust\/correct	0.0013280212483399733
adjust\/correct the	1.0
output from	0.038461538461538464
rules engine	0.023255813953488372
Statistics	8.370068634562804e-05
attempt	0.00016740137269125608
adjust\/correct	2.7900228781876013e-05
Statistics guided	0.3333333333333333
guided by	1.0
by rules	0.005714285714285714
Rules are	0.6666666666666666
to pre-process	0.0013280212483399733
pre-process data	1.0
data in	0.025974025974025976
better guide	0.1111111111111111
guide the	1.0
the statistical	0.001384083044982699
statistical engine	0.030303030303030304
guided	2.7900228781876013e-05
pre-process	2.7900228781876013e-05
guide	5.5800457563752025e-05
<s> Rules	0.0007686395080707148
also used	0.028985507246376812
to post-process	0.0013280212483399733
post-process the	1.0
statistical output	0.030303030303030304
output to	0.038461538461538464
to perform	0.005312084993359893
perform functions	0.09090909090909091
functions such	0.5
as normalization	0.003484320557491289
normalization .	0.3333333333333333
post-process	2.7900228781876013e-05
functions	5.5800457563752025e-05
normalization	0.00016740137269125608
This approach	0.031746031746031744
approach has	0.02857142857142857
has a	0.047619047619047616
a lot	0.0036809815950920245
lot more	0.3333333333333333
more power	0.010526315789473684
power ,	0.25
, flexibility	0.0005614823133071309
flexibility and	1.0
and control	0.004335260115606936
control when	0.2
when translating	0.02857142857142857
translating .	0.25
lot	8.370068634562804e-05
flexibility	2.7900228781876013e-05
control	0.00013950114390938006
Major issues	0.5
issues Disambiguation	0.2
Disambiguation Main	1.0
: Word	0.00980392156862745
disambiguation Word-sense	0.1
Word-sense disambiguation	1.0
disambiguation concerns	0.1
concerns finding	0.5
finding a	0.4
a suitable	0.0036809815950920245
suitable translation	0.25
translation when	0.013513513513513514
when a	0.11428571428571428
word can	0.03333333333333333
can have	0.011049723756906077
issues	0.00013950114390938006
Disambiguation	2.7900228781876013e-05
Word-sense	2.7900228781876013e-05
concerns	5.5800457563752025e-05
finding	0.00013950114390938006
The problem	0.015625
problem was	0.022727272727272728
was first	0.012987012987012988
first raised	0.030303030303030304
raised in	1.0
1950s by	0.25
by Yehoshua	0.005714285714285714
Yehoshua Bar-Hillel	1.0
Bar-Hillel .	1.0
raised	2.7900228781876013e-05
Yehoshua	2.7900228781876013e-05
Bar-Hillel	2.7900228781876013e-05
<s> He	0.005380476556495004
He pointed	0.125
pointed out	1.0
out that	0.07142857142857142
that without	0.0035460992907801418
without a	0.07692307692307693
a ``	0.007361963190184049
`` universal	0.010582010582010581
universal encyclopedia	0.3333333333333333
encyclopedia ''	1.0
a machine	0.008588957055214725
machine would	0.02531645569620253
would never	0.018867924528301886
never be	0.4
be able	0.02109704641350211
distinguish between	0.4
the two	0.0034602076124567475
two meanings	0.034482758620689655
meanings of	0.25
pointed	2.7900228781876013e-05
encyclopedia	2.7900228781876013e-05
meanings	0.00011160091512750405
<s> Today	0.0007686395080707148
Today there	1.0
are numerous	0.004149377593360996
numerous approaches	1.0
approaches designed	0.03571428571428571
designed to	0.7142857142857143
to overcome	0.0013280212483399733
overcome this	0.5
Today	2.7900228781876013e-05
numerous	2.7900228781876013e-05
designed	0.0001953016014731321
overcome	5.5800457563752025e-05
<s> They	0.0023059185242121443
They can	0.3333333333333333
be approximately	0.004219409282700422
approximately divided	0.5
divided into	0.6666666666666666
into ``	0.01282051282051282
`` shallow	0.005291005291005291
shallow ''	0.16666666666666666
'' approaches	0.010309278350515464
approaches and	0.03571428571428571
`` deep	0.005291005291005291
deep ''	0.14285714285714285
They	8.370068634562804e-05
divided	8.370068634562804e-05
shallow	0.00016740137269125608
deep	0.0001953016014731321
<s> Shallow	0.0015372790161414297
Shallow approaches	0.5
approaches assume	0.03571428571428571
assume no	0.5
no knowledge	0.07692307692307693
Shallow	5.5800457563752025e-05
assume	5.5800457563752025e-05
They simply	0.3333333333333333
simply apply	0.08333333333333333
apply statistical	0.2
words surrounding	0.009174311926605505
surrounding the	0.2
the ambiguous	0.001384083044982699
ambiguous word	0.08333333333333333
apply	0.00013950114390938006
<s> Deep	0.0007686395080707148
Deep approaches	1.0
approaches presume	0.03571428571428571
presume a	1.0
a comprehensive	0.0036809815950920245
comprehensive knowledge	0.2
Deep	2.7900228781876013e-05
presume	2.7900228781876013e-05
comprehensive	0.00013950114390938006
<s> So	0.0023059185242121443
So far	0.3333333333333333
far ,	0.125
, shallow	0.0005614823133071309
shallow approaches	0.16666666666666666
approaches have	0.07142857142857142
been more	0.029411764705882353
more successful	0.031578947368421054
successful .	0.1111111111111111
So	8.370068634562804e-05
far	0.0002232018302550081
-RRB- The	0.005420054200542005
The late	0.005208333333333333
late Claude	0.1111111111111111
Claude Piron	1.0
Piron ,	0.3333333333333333
a long-time	0.001226993865030675
long-time translator	1.0
translator for	0.14285714285714285
the United	0.004844290657439446
Nations and	0.5
World Health	0.14285714285714285
Health Organization	0.5
Organization ,	1.0
, wrote	0.0005614823133071309
wrote that	0.16666666666666666
at its	0.014705882352941176
its best	0.02857142857142857
best ,	0.05555555555555555
, automates	0.0005614823133071309
automates the	1.0
the easier	0.0006920415224913495
easier part	0.125
a translator	0.0036809815950920245
translator 's	0.2857142857142857
's job	0.0392156862745098
job ;	0.5
the harder	0.0020761245674740486
harder and	0.14285714285714285
more time-consuming	0.010526315789473684
time-consuming part	0.3333333333333333
part usually	0.037037037037037035
usually involves	0.03125
involves doing	0.1
doing extensive	0.5
extensive research	0.3333333333333333
research to	0.023809523809523808
resolve ambiguities	0.5
ambiguities in	0.25
the grammatical	0.0020761245674740486
grammatical and	0.09090909090909091
and lexical	0.001445086705202312
lexical exigencies	0.07692307692307693
exigencies of	1.0
language require	0.006756756756756757
require to	0.045454545454545456
be resolved	0.004219409282700422
resolved :	1.0
: Why	0.00980392156862745
Why does	0.2857142857142857
does a	0.2
translator need	0.14285714285714285
whole workday	0.1111111111111111
workday to	1.0
translate five	0.16666666666666666
five pages	0.2
pages ,	0.42857142857142855
and not	0.011560693641618497
not an	0.008928571428571428
an hour	0.007575757575757576
hour or	1.0
or two	0.009009009009009009
two ?	0.034482758620689655
? <\s>	0.5
Claude	2.7900228781876013e-05
Piron	8.370068634562804e-05
long-time	2.7900228781876013e-05
Health	5.5800457563752025e-05
Organization	2.7900228781876013e-05
automates	2.7900228781876013e-05
job	5.5800457563752025e-05
harder	0.0001953016014731321
doing	5.5800457563752025e-05
ambiguities	0.00011160091512750405
exigencies	2.7900228781876013e-05
resolved	2.7900228781876013e-05
workday	2.7900228781876013e-05
pages	0.0001953016014731321
hour	2.7900228781876013e-05
<s> ...	0.0007686395080707148
... About	0.5
About 90	0.5
90 %	1.0
% of	0.20512820512820512
an average	0.007575757575757576
average text	0.5
text corresponds	0.006289308176100629
corresponds to	1.0
to these	0.0026560424966799467
these simple	0.023809523809523808
simple conditions	0.038461538461538464
conditions .	0.2
...	5.5800457563752025e-05
About	5.5800457563752025e-05
90	0.00011160091512750405
%	0.0010881089224931645
average	5.5800457563752025e-05
corresponds	2.7900228781876013e-05
conditions	0.00013950114390938006
But unfortunately	0.16666666666666666
unfortunately ,	1.0
there 's	0.025
's the	0.0196078431372549
other 10	0.014285714285714285
10 %	0.25
% .	0.23076923076923078
unfortunately	2.7900228781876013e-05
It 's	0.05263157894736842
's that	0.0196078431372549
that part	0.0035460992907801418
part that	0.037037037037037035
requires six	0.0625
six -LRB-	0.5
-LRB- more	0.005420054200542005
more -RRB-	0.010526315789473684
-RRB- hours	0.0027100271002710027
hours of	0.5
of work	0.00089126559714795
work .	0.08333333333333333
six	5.5800457563752025e-05
hours	5.5800457563752025e-05
<s> There	0.006917755572636433
There are	0.5454545454545454
are ambiguities	0.004149377593360996
ambiguities one	0.25
one has	0.015384615384615385
has to	0.05952380952380952
resolve .	0.25
There	0.00030690251660063614
For instance	0.11475409836065574
instance ,	0.6428571428571429
the author	0.0020761245674740486
author of	0.3333333333333333
an Australian	0.007575757575757576
Australian physician	0.5
physician ,	1.0
, cited	0.0005614823133071309
cited the	1.0
the example	0.0020761245674740486
an epidemic	0.007575757575757576
epidemic which	1.0
was declared	0.012987012987012988
declared during	0.5
during World	0.1
World War	0.14285714285714285
War II	1.0
II in	0.5
`` Japanese	0.005291005291005291
Japanese prisoner	0.125
prisoner of	1.0
of war	0.00089126559714795
war camp	1.0
camp ''	0.25
author	8.370068634562804e-05
Australian	5.5800457563752025e-05
physician	2.7900228781876013e-05
cited	2.7900228781876013e-05
epidemic	2.7900228781876013e-05
declared	5.5800457563752025e-05
War	2.7900228781876013e-05
II	5.5800457563752025e-05
prisoner	2.7900228781876013e-05
war	2.7900228781876013e-05
camp	0.00011160091512750405
<s> Was	0.0007686395080707148
Was he	1.0
he talking	0.14285714285714285
talking about	1.0
about an	0.025
an American	0.007575757575757576
American camp	0.2
camp with	0.5
with Japanese	0.00546448087431694
Japanese prisoners	0.125
prisoners or	0.5
a Japanese	0.001226993865030675
Japanese camp	0.125
with American	0.00546448087431694
American prisoners	0.2
prisoners ?	0.5
Was	2.7900228781876013e-05
he	0.0001953016014731321
talking	2.7900228781876013e-05
American	0.00013950114390938006
prisoners	5.5800457563752025e-05
The English	0.005208333333333333
has two	0.011904761904761904
two senses	0.034482758620689655
senses .	0.5
's necessary	0.0196078431372549
necessary therefore	0.1
therefore to	0.2
to do	0.00398406374501992
do research	0.038461538461538464
research ,	0.07142857142857142
, maybe	0.0005614823133071309
maybe to	1.0
the extent	0.001384083044982699
extent of	0.25
a phone	0.001226993865030675
phone call	0.25
call to	0.3333333333333333
to Australia	0.0013280212483399733
Australia .	1.0
therefore	0.00013950114390938006
maybe	2.7900228781876013e-05
phone	0.00011160091512750405
call	8.370068634562804e-05
Australia	2.7900228781876013e-05
The ideal	0.005208333333333333
ideal deep	1.0
deep approach	0.14285714285714285
approach would	0.02857142857142857
would require	0.05660377358490566
require the	0.18181818181818182
do all	0.038461538461538464
the research	0.0020761245674740486
research necessary	0.023809523809523808
for this	0.018050541516245487
this kind	0.01098901098901099
kind of	0.7272727272727273
of disambiguation	0.00089126559714795
disambiguation on	0.1
on its	0.009433962264150943
its own	0.14285714285714285
own ;	0.16666666666666666
; but	0.0425531914893617
this would	0.01098901098901099
require a	0.22727272727272727
a higher	0.00245398773006135
higher degree	0.14285714285714285
degree of	0.5
of AI	0.00089126559714795
AI than	0.3333333333333333
than has	0.022222222222222223
has yet	0.011904761904761904
yet been	0.5
been attained	0.014705882352941176
attained .	1.0
ideal	2.7900228781876013e-05
own	0.00016740137269125608
higher	0.0001953016014731321
degree	0.00016740137269125608
AI	8.370068634562804e-05
yet	5.5800457563752025e-05
attained	2.7900228781876013e-05
A shallow	0.04
shallow approach	0.3333333333333333
approach which	0.05714285714285714
which simply	0.007246376811594203
simply guessed	0.08333333333333333
guessed at	1.0
the sense	0.0006920415224913495
sense of	0.125
ambiguous English	0.08333333333333333
English phrase	0.02702702702702703
phrase that	0.1
that Piron	0.0035460992907801418
Piron mentions	0.3333333333333333
mentions -LRB-	0.3333333333333333
-LRB- based	0.005420054200542005
based ,	0.037037037037037035
perhaps ,	0.16666666666666666
, on	0.0039303761931499155
which kind	0.007246376811594203
of prisoner-of-war	0.00089126559714795
prisoner-of-war camp	1.0
camp is	0.25
more often	0.010526315789473684
often mentioned	0.022727272727272728
mentioned in	0.16666666666666666
given corpus	0.041666666666666664
corpus -RRB-	0.12903225806451613
-RRB- would	0.005420054200542005
would have	0.05660377358490566
a reasonable	0.00245398773006135
reasonable chance	0.5
chance of	1.0
of guessing	0.00089126559714795
guessing wrong	1.0
wrong fairly	1.0
fairly often	0.25
often .	0.022727272727272728
guessed	2.7900228781876013e-05
phrase	0.00027900228781876013
prisoner-of-war	2.7900228781876013e-05
mentioned	0.00016740137269125608
reasonable	5.5800457563752025e-05
chance	2.7900228781876013e-05
guessing	2.7900228781876013e-05
wrong	2.7900228781876013e-05
approach that	0.05714285714285714
that involves	0.0035460992907801418
involves ``	0.1
`` ask	0.005291005291005291
ask the	0.5
user about	0.07142857142857142
about each	0.025
each ambiguity	0.022222222222222223
ambiguity ''	0.125
'' would	0.010309278350515464
would ,	0.018867924528301886
, by	0.002807411566535654
by Piron	0.005714285714285714
Piron 's	0.3333333333333333
's estimate	0.0196078431372549
estimate ,	0.25
only automate	0.02631578947368421
automate about	0.3333333333333333
about 25	0.025
25 %	1.0
a professional	0.001226993865030675
professional translator	1.0
job ,	0.5
, leaving	0.0005614823133071309
leaving the	1.0
harder 75	0.14285714285714285
75 %	1.0
% still	0.02564102564102564
still to	0.06666666666666667
be done	0.02109704641350211
done by	0.18181818181818182
ask	0.00011160091512750405
automate	8.370068634562804e-05
25	2.7900228781876013e-05
professional	2.7900228781876013e-05
leaving	2.7900228781876013e-05
75	2.7900228781876013e-05
done	0.00030690251660063614
The objects	0.005208333333333333
objects of	0.2
of discourse	0.00980392156862745
discourse analysis	0.2222222222222222
analysis --	0.015384615384615385
-- discourse	0.04
discourse ,	0.08333333333333333
, writing	0.0011229646266142617
writing ,	0.2222222222222222
, conversation	0.0005614823133071309
conversation ,	0.25
, communicative	0.0005614823133071309
communicative event	0.3333333333333333
event ,	0.6666666666666666
etc. --	0.045454545454545456
-- are	0.08
are variously	0.004149377593360996
variously defined	1.0
defined in	0.16666666666666666
of coherent	0.00089126559714795
coherent sequences	0.2
sequences of	0.3333333333333333
, propositions	0.0011229646266142617
propositions ,	1.0
, speech	0.004491858506457047
acts or	0.3333333333333333
or turns-at-talk	0.0045045045045045045
turns-at-talk .	1.0
communicative	8.370068634562804e-05
variously	2.7900228781876013e-05
coherent	0.00013950114390938006
sequences	0.0002511020590368841
propositions	5.5800457563752025e-05
turns-at-talk	2.7900228781876013e-05
<s> Contrary	0.0015372790161414297
Contrary to	1.0
to much	0.0013280212483399733
much of	0.09090909090909091
of traditional	0.00089126559714795
traditional linguistics	1.0
, discourse	0.0005614823133071309
discourse analysts	0.05555555555555555
analysts not	0.5
only study	0.02631578947368421
study language	0.25
use `	0.013888888888888888
` beyond	0.0625
boundary '	0.16666666666666666
but also	0.07352941176470588
also prefer	0.014492753623188406
prefer to	0.5
to analyze	0.0013280212483399733
analyze `	0.25
` naturally	0.0625
naturally occurring	0.5
occurring '	1.0
' language	0.05263157894736842
use ,	0.05555555555555555
not invented	0.008928571428571428
invented examples	0.5
Contrary	5.5800457563752025e-05
traditional	2.7900228781876013e-05
analysts	5.5800457563752025e-05
study	0.00011160091512750405
prefer	5.5800457563752025e-05
naturally	5.5800457563752025e-05
occurring	2.7900228781876013e-05
invented	5.5800457563752025e-05
<s> Text	0.0015372790161414297
Text linguistics	0.16666666666666666
is related	0.0020325203252032522
related .	0.06666666666666667
The essential	0.005208333333333333
essential difference	1.0
difference between	0.25
between discourse	0.1282051282051282
analysis and	0.03076923076923077
and text	0.005780346820809248
text linguistics	0.006289308176100629
it aims	0.008547008547008548
aims at	0.3333333333333333
at revealing	0.014705882352941176
revealing socio-psychological	1.0
socio-psychological characteristics	1.0
characteristics of	0.5
a person\/persons	0.001226993865030675
person\/persons rather	1.0
than text	0.022222222222222223
text structure	0.006289308176100629
structure .	0.16666666666666666
essential	2.7900228781876013e-05
difference	0.00011160091512750405
aims	8.370068634562804e-05
revealing	2.7900228781876013e-05
socio-psychological	2.7900228781876013e-05
characteristics	5.5800457563752025e-05
person\/persons	2.7900228781876013e-05
analysis has	0.015384615384615385
been taken	0.014705882352941176
taken up	0.3333333333333333
up in	0.09090909090909091
a variety	0.008588957055214725
variety of	1.0
of social	0.0017825311942959
social science	0.07142857142857142
science disciplines	0.1
disciplines ,	1.0
, sociology	0.0005614823133071309
sociology ,	1.0
, anthropology	0.0005614823133071309
anthropology ,	1.0
, social	0.0011229646266142617
social work	0.07142857142857142
work ,	0.125
, cognitive	0.0005614823133071309
cognitive psychology	0.5
psychology ,	0.75
social psychology	0.07142857142857142
, international	0.0005614823133071309
international relations	0.5
relations ,	0.16666666666666666
human geography	0.021739130434782608
geography ,	1.0
, communication	0.0005614823133071309
communication studies	0.2
studies and	0.25
and translation	0.004335260115606936
translation studies	0.013513513513513514
is subject	0.0020325203252032522
subject to	0.125
to its	0.0013280212483399733
own assumptions	0.16666666666666666
assumptions ,	0.2
, dimensions	0.0005614823133071309
dimensions of	0.6666666666666666
of analysis	0.00089126559714795
analysis ,	0.1076923076923077
and methodologies	0.001445086705202312
taken	8.370068634562804e-05
variety	0.0002232018302550081
disciplines	5.5800457563752025e-05
sociology	2.7900228781876013e-05
anthropology	2.7900228781876013e-05
psychology	0.00011160091512750405
international	5.5800457563752025e-05
relations	0.00033480274538251215
geography	2.7900228781876013e-05
communication	0.00013950114390938006
subject	0.0002232018302550081
dimensions	8.370068634562804e-05
The examples	0.005208333333333333
examples and	0.16666666666666666
and perspective	0.001445086705202312
perspective in	0.25
in this	0.018726591760299626
this article	0.04395604395604396
article deal	0.034482758620689655
deal primarily	0.25
primarily with	0.5
United States	0.7777777777777778
States and	0.14285714285714285
and do	0.001445086705202312
not represent	0.008928571428571428
represent a	0.2222222222222222
a worldwide	0.001226993865030675
worldwide view	1.0
view of	0.3333333333333333
the subject	0.0034602076124567475
subject .	0.25
primarily	5.5800457563752025e-05
States	0.0001953016014731321
represent	0.0002511020590368841
worldwide	2.7900228781876013e-05
view	8.370068634562804e-05
<s> Please	0.0023059185242121443
Please improve	0.3333333333333333
improve this	0.15384615384615385
article and	0.06896551724137931
and discuss	0.001445086705202312
discuss the	1.0
the issue	0.002768166089965398
issue on	0.125
the talk	0.0006920415224913495
talk page	1.0
page .	0.14285714285714285
Please	8.370068634562804e-05
improve	0.00036270297416438817
discuss	2.7900228781876013e-05
issue	0.0002232018302550081
talk	2.7900228781876013e-05
-LRB- December	0.0027100271002710027
December 2010	1.0
2010 -RRB-	0.3333333333333333
-RRB- Some	0.0027100271002710027
Some scholars	0.047619047619047616
scholars -LRB-	0.5
-LRB- which	0.008130081300813009
which ?	0.007246376811594203
? -RRB-	0.125
December	2.7900228781876013e-05
2010	8.370068634562804e-05
<s> consider	0.0007686395080707148
consider the	0.5
the Austrian	0.0006920415224913495
Austrian emigre	1.0
emigre Leo	1.0
Leo Spitzer	1.0
Spitzer 's	1.0
's Stilstudien	0.0196078431372549
Stilstudien -LRB-	1.0
-LRB- Style	0.0027100271002710027
Style Studies	1.0
Studies -RRB-	1.0
of 1928	0.00089126559714795
1928 the	1.0
the earliest	0.0006920415224913495
earliest example	0.5
; Michel	0.02127659574468085
Michel Foucault	1.0
Foucault himself	0.3333333333333333
himself translated	0.5
translated it	0.25
Austrian	2.7900228781876013e-05
emigre	2.7900228781876013e-05
Leo	2.7900228781876013e-05
Spitzer	2.7900228781876013e-05
Stilstudien	2.7900228781876013e-05
Style	2.7900228781876013e-05
Studies	2.7900228781876013e-05
1928	2.7900228781876013e-05
earliest	5.5800457563752025e-05
Michel	8.370068634562804e-05
Foucault	8.370068634562804e-05
himself	5.5800457563752025e-05
But the	0.16666666666666666
the term	0.0034602076124567475
term first	0.05555555555555555
first came	0.030303030303030304
came into	0.5
into general	0.01282051282051282
general use	0.045454545454545456
use following	0.013888888888888888
following the	0.06666666666666667
the publication	0.001384083044982699
publication of	0.6666666666666666
a series	0.007361963190184049
of papers	0.00089126559714795
papers by	0.3333333333333333
by Zellig	0.005714285714285714
Zellig Harris	1.0
Harris beginning	0.1111111111111111
beginning in	0.5
in 1952	0.0018726591760299626
1952 and	0.5
and reporting	0.001445086705202312
reporting on	0.3333333333333333
on work	0.0047169811320754715
work from	0.041666666666666664
which he	0.007246376811594203
he developed	0.14285714285714285
developed transformational	0.038461538461538464
grammar in	0.02702702702702703
late 1930s	0.1111111111111111
1930s .	1.0
came	5.5800457563752025e-05
Zellig	8.370068634562804e-05
Harris	0.0002511020590368841
beginning	5.5800457563752025e-05
1952	5.5800457563752025e-05
reporting	8.370068634562804e-05
1930s	2.7900228781876013e-05
<s> Formal	0.0007686395080707148
Formal equivalence	1.0
equivalence relations	0.5
relations among	0.16666666666666666
among the	0.125
the sentences	0.005536332179930796
sentences of	0.02631578947368421
a coherent	0.00245398773006135
coherent discourse	0.2
discourse are	0.027777777777777776
are made	0.012448132780082987
made explicit	0.0625
explicit by	0.2
by using	0.017142857142857144
using sentence	0.01694915254237288
sentence transformations	0.020833333333333332
transformations to	0.5
to put	0.0026560424966799467
put the	0.25
a canonical	0.001226993865030675
canonical form	1.0
form .	0.1
Formal	2.7900228781876013e-05
equivalence	5.5800457563752025e-05
transformations	5.5800457563752025e-05
put	0.00011160091512750405
canonical	2.7900228781876013e-05
<s> Words	0.0015372790161414297
Words and	0.25
and sentences	0.002890173410404624
sentences with	0.013157894736842105
equivalent information	0.2
information then	0.021739130434782608
then appear	0.02857142857142857
appear in	0.4375
same column	0.04
column of	1.0
an array	0.007575757575757576
array .	1.0
Words	0.00011160091512750405
appear	0.0004464036605100162
column	2.7900228781876013e-05
array	2.7900228781876013e-05
This work	0.031746031746031744
work progressed	0.041666666666666664
progressed over	1.0
over the	0.25
the next	0.004152249134948097
next four	0.14285714285714285
four decades	0.14285714285714285
decades -LRB-	1.0
see references	0.05
references -RRB-	0.5
-RRB- into	0.005420054200542005
a science	0.00245398773006135
science of	0.1
of sublanguage	0.0017825311942959
sublanguage analysis	0.3333333333333333
-LRB- Kittredge	0.0027100271002710027
Kittredge &	0.5
& Lehrberger	0.125
Lehrberger 1982	1.0
1982 -RRB-	0.3333333333333333
, culminating	0.0005614823133071309
culminating in	1.0
demonstration of	0.4
the informational	0.0006920415224913495
informational structures	0.5
structures in	0.2
in texts	0.0018726591760299626
a sublanguage	0.001226993865030675
sublanguage of	0.3333333333333333
of science	0.00089126559714795
, that	0.0022459292532285235
of immunology	0.00089126559714795
immunology ,	1.0
, -LRB-	0.0016844469399213925
-LRB- Harris	0.005420054200542005
Harris et	0.1111111111111111
et al.	1.0
al. 1989	1.0
1989 -RRB-	0.5
a fully	0.001226993865030675
fully articulated	0.16666666666666666
articulated theory	1.0
theory of	0.07692307692307693
of linguistic	0.0017825311942959
linguistic informational	0.0625
informational content	0.5
content -LRB-	0.08333333333333333
Harris 1991	0.1111111111111111
progressed	2.7900228781876013e-05
next	0.0001953016014731321
decades	2.7900228781876013e-05
references	0.00011160091512750405
sublanguage	8.370068634562804e-05
Kittredge	5.5800457563752025e-05
&	0.0002232018302550081
Lehrberger	2.7900228781876013e-05
1982	8.370068634562804e-05
culminating	2.7900228781876013e-05
informational	5.5800457563752025e-05
immunology	2.7900228781876013e-05
et	2.7900228781876013e-05
al.	2.7900228781876013e-05
1989	5.5800457563752025e-05
articulated	2.7900228781876013e-05
most linguists	0.017241379310344827
linguists decided	0.3333333333333333
decided a	0.3333333333333333
a succession	0.001226993865030675
succession of	1.0
of elaborate	0.00089126559714795
elaborate theories	1.0
of sentence-level	0.00089126559714795
sentence-level syntax	1.0
syntax and	0.09090909090909091
and semantics	0.004335260115606936
semantics .	0.07142857142857142
linguists	8.370068634562804e-05
decided	8.370068634562804e-05
succession	2.7900228781876013e-05
elaborate	2.7900228781876013e-05
sentence-level	2.7900228781876013e-05
Although Harris	0.125
Harris had	0.1111111111111111
had mentioned	0.07142857142857142
mentioned the	0.16666666666666666
whole discourses	0.1111111111111111
discourses ,	0.5
, he	0.0011229646266142617
he had	0.14285714285714285
had not	0.07142857142857142
not worked	0.008928571428571428
worked out	0.2
out a	0.07142857142857142
comprehensive model	0.2
model ,	0.1
as of	0.006968641114982578
of January	0.00089126559714795
January ,	0.25
, 1952	0.0005614823133071309
1952 .	0.5
discourses	5.5800457563752025e-05
January	0.00011160091512750405
A linguist	0.02
linguist working	0.5
working for	0.14285714285714285
the American	0.001384083044982699
American Bible	0.2
Bible Society	1.0
Society ,	1.0
, James	0.0022459292532285235
James A.	0.5
A. Lauriault\/Loriot	0.4
Lauriault\/Loriot ,	1.0
, needed	0.0005614823133071309
needed to	0.09523809523809523
to find	0.010624169986719787
find answers	0.07692307692307693
answers to	0.08333333333333333
to some	0.006640106241699867
some fundamental	0.012048192771084338
fundamental errors	0.5
errors in	0.2
in translating	0.0018726591760299626
translating Quechua	0.25
Quechua ,	1.0
the Cuzco	0.0006920415224913495
Cuzco area	1.0
area of	0.45454545454545453
of Peru	0.00089126559714795
Peru .	0.5
Bible	2.7900228781876013e-05
Society	2.7900228781876013e-05
James	0.00011160091512750405
Lauriault\/Loriot	5.5800457563752025e-05
fundamental	5.5800457563752025e-05
Quechua	5.5800457563752025e-05
Cuzco	2.7900228781876013e-05
area	0.00030690251660063614
Peru	5.5800457563752025e-05
He took	0.125
took Harris	1.0
Harris 's	0.2222222222222222
's idea	0.0196078431372549
idea ,	0.14285714285714285
, recorded	0.0005614823133071309
recorded all	0.5
the legends	0.0006920415224913495
legends and	1.0
, after	0.0005614823133071309
after going	0.08333333333333333
going over	0.25
meaning and	0.043478260869565216
and placement	0.001445086705202312
placement of	1.0
word with	0.016666666666666666
of Quechua	0.00089126559714795
was able	0.05194805194805195
to form	0.005312084993359893
form logical	0.05
logical ,	0.16666666666666666
, mathematical	0.0005614823133071309
mathematical rules	0.5
that transcended	0.0035460992907801418
transcended the	1.0
the simple	0.0006920415224913495
simple sentence	0.038461538461538464
sentence structure	0.020833333333333332
took	2.7900228781876013e-05
recorded	5.5800457563752025e-05
legends	2.7900228781876013e-05
placement	2.7900228781876013e-05
logical	0.00016740137269125608
mathematical	5.5800457563752025e-05
transcended	2.7900228781876013e-05
He then	0.125
then applied	0.05714285714285714
applied the	0.06666666666666667
process to	0.1111111111111111
another language	0.23076923076923078
language of	0.006756756756756757
of Eastern	0.00089126559714795
Eastern Peru	1.0
Peru ,	0.5
, Shipibo	0.0005614823133071309
Shipibo .	0.5
Eastern	2.7900228781876013e-05
Shipibo	5.5800457563752025e-05
He taught	0.125
taught the	0.6666666666666666
the theory	0.0020761245674740486
theory in	0.07692307692307693
in Norman	0.0018726591760299626
Norman ,	0.5
, Oklahoma	0.0005614823133071309
Oklahoma ,	1.0
the summers	0.0006920415224913495
summers of	1.0
of 1956	0.00089126559714795
1956 and	1.0
and 1957	0.001445086705202312
1957 and	1.0
and entered	0.001445086705202312
entered the	0.5
the University	0.0006920415224913495
of Pennsylvania	0.00089126559714795
Pennsylvania in	1.0
the interim	0.0006920415224913495
interim year	1.0
year .	0.5
taught	8.370068634562804e-05
Norman	5.5800457563752025e-05
Oklahoma	2.7900228781876013e-05
summers	2.7900228781876013e-05
1956	2.7900228781876013e-05
1957	2.7900228781876013e-05
Pennsylvania	2.7900228781876013e-05
interim	2.7900228781876013e-05
year	0.00016740137269125608
He tried	0.125
tried to	0.3333333333333333
to publish	0.0013280212483399733
publish a	1.0
a paper	0.001226993865030675
paper Shipibo	0.09090909090909091
Shipibo Paragraph	0.5
Paragraph Structure	1.0
Structure ,	1.0
but it	0.058823529411764705
it was	0.02564102564102564
was delayed	0.012987012987012988
delayed until	1.0
until 1970	0.5
1970 -LRB-	0.3333333333333333
-LRB- Loriot	0.0027100271002710027
Loriot &	1.0
& Hollenbach	0.125
Hollenbach 1970	1.0
1970 -RRB-	0.3333333333333333
tried	8.370068634562804e-05
publish	2.7900228781876013e-05
paper	0.00030690251660063614
Paragraph	2.7900228781876013e-05
Structure	2.7900228781876013e-05
delayed	2.7900228781876013e-05
1970	8.370068634562804e-05
Loriot	2.7900228781876013e-05
Hollenbach	2.7900228781876013e-05
the meantime	0.0006920415224913495
meantime ,	1.0
, Dr.	0.0005614823133071309
Dr. Kenneth	1.0
Kenneth Lee	1.0
Lee Pike	1.0
Pike ,	1.0
a professor	0.001226993865030675
professor at	1.0
at University	0.014705882352941176
of Michigan	0.00089126559714795
Michigan ,	1.0
, Ann	0.0005614823133071309
Ann Arbor	1.0
Arbor ,	1.0
, taught	0.0005614823133071309
and one	0.001445086705202312
of his	0.00267379679144385
his students	0.16666666666666666
students ,	0.3333333333333333
, Robert	0.0016844469399213925
Robert E.	0.5
E. Longacre	0.5
Longacre ,	1.0
to disseminate	0.0013280212483399733
disseminate it	1.0
it in	0.008547008547008548
a dissertation	0.001226993865030675
dissertation .	0.3333333333333333
meantime	2.7900228781876013e-05
Dr.	2.7900228781876013e-05
Kenneth	2.7900228781876013e-05
Lee	2.7900228781876013e-05
Pike	2.7900228781876013e-05
professor	2.7900228781876013e-05
Michigan	2.7900228781876013e-05
Ann	2.7900228781876013e-05
Arbor	2.7900228781876013e-05
students	8.370068634562804e-05
Robert	0.00011160091512750405
Longacre	5.5800457563752025e-05
disseminate	2.7900228781876013e-05
dissertation	8.370068634562804e-05
<s> Harris	0.0007686395080707148
's methodology	0.0196078431372549
methodology was	0.5
was developed	0.012987012987012988
developed into	0.038461538461538464
system for	0.021505376344086023
the computer-aided	0.0006920415224913495
computer-aided analysis	0.3333333333333333
language by	0.006756756756756757
a team	0.001226993865030675
team led	1.0
led by	0.3333333333333333
by Naomi	0.005714285714285714
Naomi Sager	1.0
Sager at	0.5
at NYU	0.014705882352941176
NYU ,	1.0
sublanguage domains	0.3333333333333333
domains ,	0.125
most notably	0.017241379310344827
notably to	0.3333333333333333
to medical	0.0013280212483399733
medical informatics	0.16666666666666666
informatics .	1.0
methodology	5.5800457563752025e-05
team	2.7900228781876013e-05
led	8.370068634562804e-05
Naomi	5.5800457563752025e-05
Sager	5.5800457563752025e-05
NYU	2.7900228781876013e-05
medical	0.00016740137269125608
informatics	2.7900228781876013e-05
The software	0.005208333333333333
software for	0.037037037037037035
the Medical	0.0006920415224913495
Medical Language	0.5
Language Processor	0.08333333333333333
Processor is	1.0
is publicly	0.0020325203252032522
publicly available	1.0
available on	0.058823529411764705
on SourceForge	0.0047169811320754715
SourceForge .	1.0
Medical	5.5800457563752025e-05
Processor	2.7900228781876013e-05
publicly	2.7900228781876013e-05
SourceForge	2.7900228781876013e-05
late 1960s	0.1111111111111111
1960s and	0.3333333333333333
and 1970s	0.001445086705202312
1970s ,	0.3333333333333333
and without	0.002890173410404624
without reference	0.07692307692307693
reference to	0.25
to this	0.00796812749003984
this prior	0.01098901098901099
prior work	0.3333333333333333
of other	0.0035650623885918
other approaches	0.014285714285714285
new cross-discipline	0.041666666666666664
cross-discipline of	1.0
of DA	0.00089126559714795
DA began	0.3333333333333333
to develop	0.006640106241699867
develop in	0.2
the humanities	0.0006920415224913495
humanities and	1.0
and social	0.004335260115606936
social sciences	0.14285714285714285
sciences concurrently	0.5
concurrently with	1.0
with ,	0.00546448087431694
, other	0.0005614823133071309
other disciplines	0.014285714285714285
as semiotics	0.003484320557491289
semiotics ,	1.0
, psycholinguistics	0.0005614823133071309
psycholinguistics ,	0.5
, sociolinguistics	0.0005614823133071309
sociolinguistics ,	0.5
and pragmatics	0.001445086705202312
pragmatics .	0.3333333333333333
1970s	8.370068634562804e-05
cross-discipline	2.7900228781876013e-05
develop	0.00013950114390938006
humanities	2.7900228781876013e-05
sciences	5.5800457563752025e-05
concurrently	2.7900228781876013e-05
semiotics	2.7900228781876013e-05
psycholinguistics	5.5800457563752025e-05
sociolinguistics	5.5800457563752025e-05
pragmatics	8.370068634562804e-05
these approaches	0.047619047619047616
approaches ,	0.03571428571428571
those influenced	0.045454545454545456
influenced by	1.0
sciences ,	0.5
, favor	0.0005614823133071309
favor a	0.5
more dynamic	0.010526315789473684
dynamic study	0.2
study of	0.25
of oral	0.00089126559714795
oral talk-in-interaction	1.0
talk-in-interaction .	1.0
influenced	8.370068634562804e-05
favor	5.5800457563752025e-05
dynamic	0.00013950114390938006
oral	2.7900228781876013e-05
talk-in-interaction	2.7900228781876013e-05
<s> Mention	0.0007686395080707148
Mention must	1.0
must also	0.07142857142857142
made of	0.1875
term ``	0.1111111111111111
`` Conversational	0.005291005291005291
Conversational analysis	1.0
analysis ''	0.015384615384615385
was influenced	0.012987012987012988
the Sociologist	0.0006920415224913495
Sociologist Harold	1.0
Harold Garfinkel	1.0
Garfinkel who	1.0
the founder	0.0006920415224913495
founder of	1.0
of Ethnomethodology	0.00089126559714795
Ethnomethodology .	1.0
Mention	2.7900228781876013e-05
Conversational	2.7900228781876013e-05
Sociologist	2.7900228781876013e-05
Harold	2.7900228781876013e-05
Garfinkel	2.7900228781876013e-05
founder	2.7900228781876013e-05
Ethnomethodology	2.7900228781876013e-05
In Europe	0.01904761904761905
Europe ,	0.6
, Michel	0.0011229646266142617
Foucault became	0.3333333333333333
became one	0.2
the key	0.0006920415224913495
key theorists	0.16666666666666666
theorists of	1.0
subject ,	0.25
especially of	0.06666666666666667
and wrote	0.001445086705202312
wrote The	0.16666666666666666
The Archaeology	0.005208333333333333
Archaeology of	1.0
of Knowledge	0.00089126559714795
Knowledge on	0.5
Europe	0.00013950114390938006
key	0.00016740137269125608
theorists	2.7900228781876013e-05
Archaeology	2.7900228781876013e-05
Knowledge	5.5800457563752025e-05
<s> Topics	0.0007686395080707148
Topics of	1.0
of interest	0.00267379679144385
interest Topics	0.09090909090909091
analysis include	0.015384615384615385
The various	0.005208333333333333
various levels	0.05555555555555555
levels or	0.045454545454545456
or dimensions	0.0045045045045045045
as sounds	0.003484320557491289
sounds -LRB-	0.13333333333333333
-LRB- intonation	0.0027100271002710027
intonation ,	1.0
, gestures	0.0005614823133071309
gestures ,	0.5
the lexicon	0.0006920415224913495
lexicon ,	0.1111111111111111
, style	0.0005614823133071309
style ,	0.5
, rhetoric	0.0005614823133071309
rhetoric ,	1.0
, meanings	0.0005614823133071309
meanings ,	0.25
acts ,	0.3333333333333333
, moves	0.0005614823133071309
moves ,	1.0
, strategies	0.0005614823133071309
strategies ,	0.5
, turns	0.0005614823133071309
turns and	0.3333333333333333
and other	0.01300578034682081
other aspects	0.014285714285714285
of interaction	0.00089126559714795
interaction Genres	0.125
Genres of	1.0
discourse -LRB-	0.05555555555555555
-LRB- various	0.0027100271002710027
various types	0.1111111111111111
discourse in	0.05555555555555555
in politics	0.0018726591760299626
politics ,	1.0
the media	0.0006920415224913495
, education	0.0005614823133071309
education ,	1.0
, science	0.0005614823133071309
, business	0.0005614823133071309
business ,	0.25
The relations	0.026041666666666668
relations between	0.4166666666666667
discourse and	0.1111111111111111
the emergence	0.0006920415224913495
emergence of	1.0
of syntactic	0.0017825311942959
syntactic structure	0.07692307692307693
structure The	0.08333333333333333
between text	0.02564102564102564
-LRB- discourse	0.0027100271002710027
discourse -RRB-	0.027777777777777776
and context	0.004335260115606936
context The	0.06060606060606061
and power	0.001445086705202312
power The	0.25
and interaction	0.001445086705202312
interaction The	0.125
and cognition	0.001445086705202312
cognition and	1.0
and memory	0.001445086705202312
memory Political	0.5
Political discourse	1.0
discourse Political	0.027777777777777776
analysis is	0.015384615384615385
analysis which	0.015384615384615385
which focuses	0.007246376811594203
focuses on	1.0
on discourse	0.0047169811320754715
in political	0.0018726591760299626
political forums	0.3333333333333333
forums -LRB-	1.0
as debates	0.003484320557491289
debates ,	1.0
, speeches	0.0005614823133071309
speeches ,	1.0
and hearings	0.001445086705202312
hearings -RRB-	1.0
the phenomenon	0.001384083044982699
phenomenon of	0.6
interest .	0.09090909090909091
Topics	5.5800457563752025e-05
levels	0.0006138050332012723
intonation	2.7900228781876013e-05
gestures	5.5800457563752025e-05
style	5.5800457563752025e-05
rhetoric	2.7900228781876013e-05
moves	2.7900228781876013e-05
strategies	5.5800457563752025e-05
turns	8.370068634562804e-05
Genres	2.7900228781876013e-05
politics	2.7900228781876013e-05
education	2.7900228781876013e-05
business	0.00011160091512750405
emergence	2.7900228781876013e-05
cognition	2.7900228781876013e-05
memory	5.5800457563752025e-05
Political	8.370068634562804e-05
focuses	5.5800457563752025e-05
political	8.370068634562804e-05
forums	2.7900228781876013e-05
debates	5.5800457563752025e-05
speeches	2.7900228781876013e-05
hearings	2.7900228781876013e-05
phenomenon	0.00013950114390938006
<s> Political	0.0007686395080707148
discourse is	0.08333333333333333
the informal	0.0006920415224913495
informal exchange	0.5
exchange of	1.0
of reasoned	0.00089126559714795
reasoned views	1.0
views as	1.0
as to	0.013937282229965157
to which	0.006640106241699867
which of	0.007246376811594203
of several	0.00267379679144385
several alternative	0.045454545454545456
alternative courses	0.3333333333333333
courses of	1.0
of action	0.00089126559714795
action should	0.2
be taken	0.004219409282700422
taken to	0.3333333333333333
solve a	0.25
a societal	0.001226993865030675
societal problem	1.0
informal	5.5800457563752025e-05
exchange	2.7900228781876013e-05
reasoned	2.7900228781876013e-05
views	2.7900228781876013e-05
alternative	8.370068634562804e-05
courses	2.7900228781876013e-05
action	0.00013950114390938006
societal	2.7900228781876013e-05
science that	0.1
been used	0.07352941176470588
used through	0.008849557522123894
the history	0.0006920415224913495
States .	0.2857142857142857
the essence	0.001384083044982699
essence of	1.0
of democracy	0.00089126559714795
democracy .	1.0
essence	5.5800457563752025e-05
democracy	2.7900228781876013e-05
<s> Full	0.0007686395080707148
Full of	1.0
problems and	0.11764705882352941
and persuasion	0.001445086705202312
persuasion ,	1.0
, political	0.0005614823133071309
political discourse	0.3333333333333333
in many	0.0149812734082397
many debates	0.019230769230769232
, candidacies	0.0005614823133071309
candidacies and	1.0
in our	0.0018726591760299626
our everyday	0.2
everyday life	1.0
life .	0.25
Full	2.7900228781876013e-05
persuasion	2.7900228781876013e-05
candidacies	2.7900228781876013e-05
our	0.00013950114390938006
everyday	2.7900228781876013e-05
<s> Perspectives	0.0007686395080707148
Perspectives The	1.0
following are	0.06666666666666667
are some	0.004149377593360996
specific theoretical	0.047619047619047616
theoretical perspectives	0.3333333333333333
perspectives and	1.0
and analytical	0.001445086705202312
analytical approaches	0.5
approaches used	0.03571428571428571
linguistic discourse	0.0625
: Emergent	0.00980392156862745
Emergent grammar	1.0
grammar Text	0.02702702702702703
Text grammar	0.16666666666666666
grammar -LRB-	0.02702702702702703
or `	0.0045045045045045045
` discourse	0.0625
discourse grammar	0.027777777777777776
grammar '	0.02702702702702703
' -RRB-	0.05263157894736842
-RRB- Cohesion	0.0027100271002710027
Cohesion and	1.0
and relevance	0.001445086705202312
relevance theory	0.3333333333333333
theory Functional	0.07692307692307693
Functional grammar	1.0
grammar Rhetoric	0.02702702702702703
Rhetoric Stylistics	1.0
Stylistics -LRB-	1.0
-LRB- linguistics	0.005420054200542005
linguistics -RRB-	0.1
-RRB- Interactional	0.0027100271002710027
Interactional sociolinguistics	1.0
sociolinguistics Ethnography	0.5
Ethnography of	1.0
of communication	0.0017825311942959
communication Pragmatics	0.2
Pragmatics ,	1.0
, particularly	0.0011229646266142617
particularly speech	0.2
speech act	0.006578947368421052
act theory	0.25
theory Conversation	0.07692307692307693
Conversation analysis	1.0
analysis Variation	0.015384615384615385
Variation analysis	1.0
analysis Applied	0.015384615384615385
Applied linguistics	0.5
linguistics Cognitive	0.05
Cognitive psychology	0.3333333333333333
often under	0.022727272727272728
under the	0.2
the label	0.0006920415224913495
label discourse	1.0
discourse processing	0.027777777777777776
, studying	0.0005614823133071309
studying the	1.0
the production	0.0006920415224913495
production and	0.3333333333333333
and comprehension	0.001445086705202312
comprehension of	0.2857142857142857
discourse .	0.027777777777777776
Perspectives	2.7900228781876013e-05
perspectives	2.7900228781876013e-05
analytical	5.5800457563752025e-05
Emergent	2.7900228781876013e-05
Cohesion	2.7900228781876013e-05
relevance	8.370068634562804e-05
Functional	2.7900228781876013e-05
Rhetoric	2.7900228781876013e-05
Stylistics	2.7900228781876013e-05
Interactional	2.7900228781876013e-05
Ethnography	2.7900228781876013e-05
Pragmatics	2.7900228781876013e-05
act	0.00011160091512750405
Conversation	2.7900228781876013e-05
Variation	2.7900228781876013e-05
Applied	5.5800457563752025e-05
Cognitive	8.370068634562804e-05
label	2.7900228781876013e-05
studying	2.7900228781876013e-05
production	8.370068634562804e-05
comprehension	0.0001953016014731321
<s> Discursive	0.0007686395080707148
Discursive psychology	1.0
psychology Response	0.25
Response based	1.0
based therapy	0.018518518518518517
therapy -LRB-	1.0
-LRB- counselling	0.0027100271002710027
counselling -RRB-	1.0
-RRB- Critical	0.0027100271002710027
Critical discourse	0.5
analysis Sublanguage	0.015384615384615385
Sublanguage analysis	1.0
analysis Genre	0.015384615384615385
Genre Analysis	1.0
Analysis &	0.2
& Critical	0.125
Critical Genre	0.5
Analysis Although	0.2
Although these	0.125
approaches emphasize	0.03571428571428571
emphasize different	1.0
different aspects	0.02040816326530612
they all	0.05
all view	0.023255813953488372
view language	0.3333333333333333
language as	0.006756756756756757
as social	0.003484320557491289
social interaction	0.07142857142857142
interaction ,	0.125
and are	0.0072254335260115606
are concerned	0.004149377593360996
social contexts	0.07142857142857142
contexts in	0.14285714285714285
in which	0.0149812734082397
which discourse	0.007246376811594203
is embedded	0.0020325203252032522
embedded .	0.25
Discursive	2.7900228781876013e-05
Response	2.7900228781876013e-05
therapy	2.7900228781876013e-05
counselling	2.7900228781876013e-05
Critical	5.5800457563752025e-05
Sublanguage	2.7900228781876013e-05
Genre	5.5800457563752025e-05
emphasize	2.7900228781876013e-05
contexts	0.0001953016014731321
Often a	0.3333333333333333
a distinction	0.001226993865030675
distinction is	0.4
is made	0.0040650406504065045
made between	0.0625
between `	0.02564102564102564
` local	0.0625
local '	0.3333333333333333
' structures	0.10526315789473684
structures of	0.2
as relations	0.003484320557491289
among sentences	0.125
and turns	0.001445086705202312
turns -RRB-	0.3333333333333333
and `	0.001445086705202312
` global	0.0625
global '	0.3333333333333333
structures ,	0.2
as overall	0.003484320557491289
overall topics	0.16666666666666666
topics and	0.14285714285714285
the schematic	0.0006920415224913495
schematic organization	1.0
organization of	0.4
of discourses	0.00089126559714795
discourses and	0.5
and conversations	0.001445086705202312
conversations .	0.3333333333333333
distinction	0.00013950114390938006
local	8.370068634562804e-05
global	8.370068634562804e-05
topics	0.0001953016014731321
schematic	2.7900228781876013e-05
conversations	8.370068634562804e-05
many types	0.019230769230769232
discourse begin	0.027777777777777776
begin with	0.6666666666666666
some kind	0.04819277108433735
of global	0.00089126559714795
global `	0.3333333333333333
` summary	0.0625
summary '	0.023809523809523808
in titles	0.0018726591760299626
titles ,	0.5
, headlines	0.0005614823133071309
headlines ,	1.0
, leads	0.0005614823133071309
leads ,	1.0
, abstracts	0.0005614823133071309
abstracts ,	0.5
and so	0.008670520231213872
so on	0.16666666666666666
on .	0.018867924528301886
begin	8.370068634562804e-05
titles	5.5800457563752025e-05
headlines	2.7900228781876013e-05
leads	2.7900228781876013e-05
abstracts	5.5800457563752025e-05
A problem	0.02
problem for	0.022727272727272728
discourse analyst	0.027777777777777776
analyst is	1.0
to decide	0.0026560424966799467
decide when	0.25
a particular	0.0049079754601227
particular feature	0.07692307692307693
feature is	0.07692307692307693
is relevant	0.0020325203252032522
relevant to	0.14285714285714285
the specification	0.001384083044982699
specification is	0.5
is required	0.0040650406504065045
required .	0.14285714285714285
analyst	2.7900228781876013e-05
decide	0.00011160091512750405
relevant	0.0001953016014731321
specification	5.5800457563752025e-05
required	0.0001953016014731321
<s> Are	0.0007686395080707148
Are there	1.0
there general	0.025
general principles	0.045454545454545456
principles which	1.0
will determine	0.02857142857142857
the relevance	0.0006920415224913495
relevance or	0.3333333333333333
or nature	0.0045045045045045045
specification .	0.5
Are	2.7900228781876013e-05
principles	2.7900228781876013e-05
<s> Prominent	0.0007686395080707148
Prominent discourse	1.0
analysts This	0.5
This article	0.015873015873015872
article contains	0.034482758620689655
contains embedded	0.1
embedded lists	0.25
lists that	1.0
that may	0.0070921985815602835
be poorly	0.004219409282700422
poorly defined	1.0
defined ,	0.16666666666666666
, unverified	0.0005614823133071309
unverified or	1.0
or indiscriminate	0.0045045045045045045
indiscriminate .	1.0
Prominent	2.7900228781876013e-05
lists	2.7900228781876013e-05
poorly	2.7900228781876013e-05
unverified	2.7900228781876013e-05
indiscriminate	2.7900228781876013e-05
Please help	0.6666666666666666
help to	0.1111111111111111
to clean	0.0013280212483399733
clean it	0.5
it up	0.008547008547008548
up to	0.22727272727272727
to meet	0.005312084993359893
meet Wikipedia	0.25
Wikipedia 's	0.5
's quality	0.0196078431372549
quality standards	0.1
standards .	0.4
help	0.0002511020590368841
clean	5.5800457563752025e-05
meet	0.00011160091512750405
Wikipedia	5.5800457563752025e-05
-LRB- May	0.005420054200542005
May 2012	0.5
2012 -RRB-	1.0
-RRB- Marc	0.0027100271002710027
Marc Angenot	1.0
Angenot ,	1.0
Robert de	0.25
de Beaugrande	0.5
Beaugrande ,	1.0
, Jan	0.0005614823133071309
Jan Blommaert	1.0
Blommaert ,	1.0
, Adriana	0.0005614823133071309
Adriana Bolivar	1.0
Bolivar ,	1.0
, Carmen	0.0005614823133071309
Carmen Rosa	1.0
Rosa Caldas-Coulthard	1.0
Caldas-Coulthard ,	1.0
, Robyn	0.0005614823133071309
Robyn Carston	1.0
Carston ,	1.0
, Wallace	0.0005614823133071309
Wallace Chafe	1.0
Chafe ,	1.0
, Paul	0.0016844469399213925
Paul Chilton	0.2
Chilton ,	1.0
, Guy	0.0005614823133071309
Guy Cook	1.0
Cook ,	1.0
, Malcolm	0.0005614823133071309
Malcolm Coulthard	1.0
Coulthard ,	1.0
James Deese	0.25
Deese ,	1.0
Paul Drew	0.2
Drew ,	1.0
, John	0.002807411566535654
John Du	0.125
Du Bois	1.0
Bois ,	1.0
, Alessandro	0.0005614823133071309
Alessandro Duranti	1.0
Duranti ,	1.0
, Brenton	0.0005614823133071309
Brenton D.	1.0
D. Faber	0.2
Faber ,	1.0
, Norman	0.0005614823133071309
Norman Fairclough	0.5
Fairclough ,	1.0
Foucault ,	0.3333333333333333
, Roger	0.0005614823133071309
Roger Fowler	0.25
Fowler ,	1.0
James Paul	0.25
Paul Gee	0.2
Gee ,	1.0
, Talmy	0.0005614823133071309
Talmy Givn	1.0
Givn ,	1.0
, Charles	0.0005614823133071309
Charles Goodwin	1.0
Goodwin ,	1.0
, Art	0.0005614823133071309
Art Graesser	1.0
Graesser ,	1.0
, Michael	0.0022459292532285235
Michael Halliday	0.25
Halliday ,	1.0
, Zellig	0.0011229646266142617
Harris ,	0.1111111111111111
John Heritage	0.125
Heritage ,	1.0
, Janet	0.0005614823133071309
Janet Holmes	0.5
Holmes ,	1.0
, David	0.0016844469399213925
David R.	0.25
R. Howarth	0.16666666666666666
Howarth ,	1.0
Paul Hopper	0.2
Hopper ,	1.0
, Gail	0.0005614823133071309
Gail Jefferson	1.0
Jefferson ,	1.0
, Barbara	0.0005614823133071309
Barbara Johnstone	1.0
Johnstone ,	1.0
, Walter	0.0005614823133071309
Walter Kintsch	1.0
Kintsch ,	1.0
, Richard	0.0005614823133071309
Richard Kittredge	1.0
Kittredge ,	0.5
, Adam	0.0005614823133071309
Adam Jaworski	1.0
Jaworski ,	1.0
, William	0.0011229646266142617
William Labov	0.5
Labov ,	1.0
, George	0.0005614823133071309
George Lakoff	1.0
Lakoff ,	1.0
, Jay	0.0005614823133071309
Jay Lemke	1.0
Lemke ,	1.0
, Stephen	0.0005614823133071309
Stephen H.	1.0
H. Levinsohn	0.5
Levinsohn ,	1.0
, Jim	0.0005614823133071309
Jim Martin	1.0
Martin ,	0.5
, Aletta	0.0005614823133071309
Aletta Norval	1.0
Norval ,	1.0
David Nunan	0.25
Nunan ,	1.0
, Elinor	0.0005614823133071309
Elinor Ochs	1.0
Ochs ,	1.0
, Gina	0.0005614823133071309
Gina Poncini	1.0
Poncini ,	1.0
, Jonathan	0.0005614823133071309
Jonathan Potter	1.0
Potter ,	1.0
, Edward	0.0005614823133071309
Edward Robinson	1.0
Robinson ,	1.0
, Nikolas	0.0005614823133071309
Nikolas Rose	1.0
Rose ,	1.0
, Harvey	0.0005614823133071309
Harvey Sacks	1.0
Sacks ,	1.0
, Svenka	0.0005614823133071309
Svenka Savic	1.0
Savic Naomi	1.0
Sager ,	0.5
, Emanuel	0.0011229646266142617
Emanuel Schegloff	0.5
Schegloff ,	1.0
, Deborah	0.0011229646266142617
Deborah Schiffrin	0.5
Schiffrin ,	1.0
Michael Schober	0.25
Schober ,	1.0
, Stef	0.0005614823133071309
Stef Slembrouck	1.0
Slembrouck ,	1.0
Michael Stubbs	0.25
Stubbs ,	1.0
John Swales	0.25
Swales ,	1.0
Deborah Tannen	0.5
Tannen ,	1.0
, Sandra	0.0005614823133071309
Sandra Thompson	1.0
Thompson ,	1.0
, Teun	0.0005614823133071309
Teun A.	1.0
A. van	0.2
van Dijk	0.5
Dijk ,	1.0
, Theo	0.0005614823133071309
Theo van	1.0
van Leeuwen	0.5
Leeuwen ,	1.0
, Jef	0.0005614823133071309
Jef Verschueren	1.0
Verschueren ,	1.0
, Henry	0.0005614823133071309
Henry Widdowson	0.5
Widdowson ,	1.0
, Carla	0.0005614823133071309
Carla Willig	1.0
Willig ,	1.0
, Deirdre	0.0005614823133071309
Deirdre Wilson	1.0
Wilson ,	1.0
, Ruth	0.0005614823133071309
Ruth Wodak	1.0
Wodak ,	1.0
, Margaret	0.0005614823133071309
Margaret Wetherell	1.0
Wetherell ,	1.0
, Ernesto	0.0005614823133071309
Ernesto Laclau	1.0
Laclau ,	1.0
, Chantal	0.0005614823133071309
Chantal Mouffe	1.0
Mouffe ,	1.0
, Judith	0.0005614823133071309
Judith M.	1.0
M. De	0.25
De Guzman	1.0
Guzman ,	1.0
, Cynthia	0.0005614823133071309
Cynthia Hardy	1.0
Hardy ,	1.0
, Louise	0.0005614823133071309
Louise J.	1.0
J. Phillips	0.3333333333333333
Phillips .	1.0
May	5.5800457563752025e-05
2012	2.7900228781876013e-05
Marc	2.7900228781876013e-05
Angenot	2.7900228781876013e-05
Beaugrande	2.7900228781876013e-05
Jan	2.7900228781876013e-05
Blommaert	2.7900228781876013e-05
Adriana	2.7900228781876013e-05
Bolivar	2.7900228781876013e-05
Carmen	2.7900228781876013e-05
Rosa	2.7900228781876013e-05
Caldas-Coulthard	2.7900228781876013e-05
Robyn	2.7900228781876013e-05
Carston	2.7900228781876013e-05
Wallace	2.7900228781876013e-05
Chafe	2.7900228781876013e-05
Paul	0.00013950114390938006
Chilton	2.7900228781876013e-05
Guy	2.7900228781876013e-05
Cook	2.7900228781876013e-05
Malcolm	2.7900228781876013e-05
Coulthard	2.7900228781876013e-05
Deese	2.7900228781876013e-05
Drew	2.7900228781876013e-05
Du	2.7900228781876013e-05
Bois	2.7900228781876013e-05
Alessandro	2.7900228781876013e-05
Duranti	2.7900228781876013e-05
Brenton	2.7900228781876013e-05
Faber	2.7900228781876013e-05
Fairclough	2.7900228781876013e-05
Roger	0.00011160091512750405
Fowler	2.7900228781876013e-05
Gee	2.7900228781876013e-05
Talmy	2.7900228781876013e-05
Givn	2.7900228781876013e-05
Charles	2.7900228781876013e-05
Goodwin	2.7900228781876013e-05
Art	2.7900228781876013e-05
Graesser	2.7900228781876013e-05
Michael	0.00011160091512750405
Halliday	2.7900228781876013e-05
Heritage	2.7900228781876013e-05
Janet	5.5800457563752025e-05
Holmes	2.7900228781876013e-05
David	0.00011160091512750405
Howarth	2.7900228781876013e-05
Hopper	2.7900228781876013e-05
Gail	2.7900228781876013e-05
Jefferson	2.7900228781876013e-05
Barbara	2.7900228781876013e-05
Johnstone	2.7900228781876013e-05
Walter	2.7900228781876013e-05
Kintsch	2.7900228781876013e-05
Richard	2.7900228781876013e-05
Adam	2.7900228781876013e-05
Jaworski	2.7900228781876013e-05
William	5.5800457563752025e-05
Labov	2.7900228781876013e-05
George	2.7900228781876013e-05
Lakoff	2.7900228781876013e-05
Jay	2.7900228781876013e-05
Lemke	2.7900228781876013e-05
Stephen	2.7900228781876013e-05
H.	5.5800457563752025e-05
Levinsohn	2.7900228781876013e-05
Jim	2.7900228781876013e-05
Martin	5.5800457563752025e-05
Aletta	2.7900228781876013e-05
Norval	2.7900228781876013e-05
Nunan	2.7900228781876013e-05
Elinor	2.7900228781876013e-05
Ochs	2.7900228781876013e-05
Gina	2.7900228781876013e-05
Poncini	2.7900228781876013e-05
Jonathan	2.7900228781876013e-05
Potter	2.7900228781876013e-05
Edward	2.7900228781876013e-05
Robinson	2.7900228781876013e-05
Nikolas	2.7900228781876013e-05
Rose	2.7900228781876013e-05
Harvey	2.7900228781876013e-05
Sacks	2.7900228781876013e-05
Svenka	2.7900228781876013e-05
Savic	2.7900228781876013e-05
Emanuel	5.5800457563752025e-05
Schegloff	2.7900228781876013e-05
Deborah	5.5800457563752025e-05
Schiffrin	2.7900228781876013e-05
Schober	2.7900228781876013e-05
Stef	2.7900228781876013e-05
Slembrouck	2.7900228781876013e-05
Stubbs	2.7900228781876013e-05
Swales	5.5800457563752025e-05
Tannen	2.7900228781876013e-05
Sandra	2.7900228781876013e-05
Thompson	2.7900228781876013e-05
Teun	2.7900228781876013e-05
van	5.5800457563752025e-05
Dijk	2.7900228781876013e-05
Theo	2.7900228781876013e-05
Leeuwen	2.7900228781876013e-05
Jef	2.7900228781876013e-05
Verschueren	2.7900228781876013e-05
Henry	5.5800457563752025e-05
Widdowson	2.7900228781876013e-05
Carla	2.7900228781876013e-05
Willig	2.7900228781876013e-05
Deirdre	2.7900228781876013e-05
Wilson	2.7900228781876013e-05
Ruth	2.7900228781876013e-05
Wodak	2.7900228781876013e-05
Margaret	2.7900228781876013e-05
Wetherell	2.7900228781876013e-05
Ernesto	2.7900228781876013e-05
Laclau	2.7900228781876013e-05
Chantal	2.7900228781876013e-05
Mouffe	2.7900228781876013e-05
Judith	2.7900228781876013e-05
De	2.7900228781876013e-05
Guzman	2.7900228781876013e-05
Cynthia	2.7900228781876013e-05
Hardy	2.7900228781876013e-05
Louise	2.7900228781876013e-05
Phillips	2.7900228781876013e-05
-RRB- Bhatia	0.0027100271002710027
Bhatia ,	1.0
, V.J.	0.0005614823133071309
V.J. ,	1.0
Harris The	0.1111111111111111
The phenomenon	0.005208333333333333
of information	0.004456327985739751
information overload	0.021739130434782608
overload has	1.0
has meant	0.011904761904761904
meant that	0.5
that access	0.0035460992907801418
access to	1.0
to coherent	0.0013280212483399733
coherent and	0.2
and correctly-developed	0.001445086705202312
correctly-developed summaries	1.0
summaries is	0.06976744186046512
is vital	0.0020325203252032522
vital .	1.0
Bhatia	2.7900228781876013e-05
V.J.	2.7900228781876013e-05
overload	2.7900228781876013e-05
meant	5.5800457563752025e-05
access	8.370068634562804e-05
correctly-developed	2.7900228781876013e-05
vital	2.7900228781876013e-05
As access	0.05555555555555555
to data	0.0026560424966799467
data has	0.012987012987012988
has increased	0.011904761904761904
increased so	0.2
so has	0.03333333333333333
has interest	0.011904761904761904
interest in	0.6363636363636364
automatic summarization	0.08695652173913043
summarization .	0.12
of summarization	0.0071301247771836
summarization technology	0.02
technology is	0.13636363636363635
is search	0.0020325203252032522
search engines	0.18181818181818182
engines such	0.3333333333333333
as Google	0.003484320557491289
Google .	0.5
engines	8.370068634562804e-05
<s> Technologies	0.0007686395080707148
Technologies that	1.0
make a	0.2
coherent summary	0.2
summary ,	0.14285714285714285
any kind	0.03225806451612903
, need	0.0005614823133071309
need to	0.47619047619047616
take into	0.3
into account	0.038461538461538464
account several	0.3333333333333333
several variables	0.045454545454545456
variables such	1.0
as length	0.003484320557491289
length ,	0.25
writing style	0.1111111111111111
style and	0.5
and syntax	0.001445086705202312
syntax to	0.18181818181818182
to make	0.005312084993359893
a useful	0.001226993865030675
useful summary	0.07142857142857142
summary .	0.2619047619047619
Technologies	2.7900228781876013e-05
account	8.370068634562804e-05
variables	2.7900228781876013e-05
length	0.0002232018302550081
<s> Extractive	0.0007686395080707148
Extractive methods	1.0
methods work	0.045454545454545456
work by	0.08333333333333333
by selecting	0.011428571428571429
selecting a	0.4
a subset	0.0036809815950920245
subset of	1.0
existing words	0.2
, phrases	0.0005614823133071309
phrases ,	0.125
or sentences	0.0045045045045045045
sentences in	0.10526315789473684
form the	0.05
the summary	0.005536332179930796
Extractive	2.7900228781876013e-05
selecting	0.00013950114390938006
subset	8.370068634562804e-05
In contrast	0.047619047619047616
contrast ,	0.625
, abstractive	0.0005614823133071309
abstractive methods	0.3333333333333333
methods build	0.022727272727272728
build an	0.6666666666666666
an internal	0.022727272727272728
internal semantic	0.2
semantic representation	0.047619047619047616
representation and	0.10526315789473684
then use	0.02857142857142857
use natural	0.013888888888888888
generation techniques	0.1111111111111111
techniques to	0.17391304347826086
to create	0.01195219123505976
create a	0.4117647058823529
a summary	0.0098159509202454
summary that	0.047619047619047616
is closer	0.0020325203252032522
what a	0.09375
human might	0.021739130434782608
might generate	0.038461538461538464
generate .	0.05555555555555555
abstractive	0.00016740137269125608
build	8.370068634562804e-05
internal	0.00013950114390938006
Such a	0.125
summary might	0.023809523809523808
might contain	0.038461538461538464
contain words	0.08333333333333333
words not	0.009174311926605505
not explicitly	0.008928571428571428
explicitly present	0.25
present in	0.8333333333333334
original .	0.07692307692307693
contain	0.00033480274538251215
explicitly	0.00011160091512750405
present	0.00016740137269125608
The state-of-the-art	0.005208333333333333
state-of-the-art abstractive	0.5
methods are	0.045454545454545456
still quite	0.06666666666666667
quite weak	0.125
weak ,	1.0
so most	0.03333333333333333
most research	0.017241379310344827
on extractive	0.0047169811320754715
extractive methods	0.14285714285714285
methods ,	0.09090909090909091
and this	0.001445086705202312
is what	0.0040650406504065045
what we	0.09375
we will	0.08888888888888889
will cover	0.02857142857142857
cover .	1.0
state-of-the-art	5.5800457563752025e-05
weak	2.7900228781876013e-05
extractive	0.0001953016014731321
cover	2.7900228781876013e-05
<s> Two	0.005380476556495004
Two particular	0.14285714285714285
particular types	0.07692307692307693
summarization often	0.02
often addressed	0.022727272727272728
addressed in	0.5
the literature	0.0006920415224913495
literature are	1.0
are keyphrase	0.004149377593360996
keyphrase extraction	0.631578947368421
the goal	0.002768166089965398
goal is	0.42857142857142855
select individual	0.16666666666666666
individual words	0.08333333333333333
or phrases	0.009009009009009009
phrases to	0.0625
`` tag	0.010582010582010581
tag ''	0.0625
a document	0.008588957055214725
document ,	0.1388888888888889
and document	0.002890173410404624
document summarization	0.1388888888888889
select whole	0.16666666666666666
whole sentences	0.2222222222222222
sentences to	0.07894736842105263
a short	0.006134969325153374
short paragraph	0.125
paragraph summary	0.3333333333333333
Two	0.0001953016014731321
addressed	5.5800457563752025e-05
literature	2.7900228781876013e-05
keyphrase	0.0005301043468556442
document	0.0010044082361475365
short	0.0002232018302550081
paragraph	8.370068634562804e-05
<s> Extraction	0.0015372790161414297
Extraction and	0.3333333333333333
and abstraction	0.002890173410404624
abstraction Broadly	0.25
Broadly ,	1.0
, one	0.003368893879842785
one distinguishes	0.015384615384615385
distinguishes two	0.5
two approaches	0.034482758620689655
approaches :	0.14285714285714285
: extraction	0.00980392156862745
extraction and	0.06451612903225806
abstraction .	0.25
Extraction	8.370068634562804e-05
abstraction	0.00011160091512750405
Broadly	2.7900228781876013e-05
Extraction techniques	0.3333333333333333
techniques merely	0.043478260869565216
merely copy	0.5
copy the	1.0
the information	0.0034602076124567475
information deemed	0.021739130434782608
deemed most	0.5
important by	0.0625
system to	0.053763440860215055
summary -LRB-	0.023809523809523808
, key	0.0005614823133071309
key clauses	0.16666666666666666
clauses ,	1.0
, sentences	0.0011229646266142617
sentences or	0.013157894736842105
or paragraphs	0.009009009009009009
paragraphs -RRB-	0.25
while abstraction	0.05
abstraction involves	0.25
involves paraphrasing	0.1
paraphrasing sections	1.0
sections of	1.0
source document	0.08333333333333333
document .	0.1388888888888889
merely	5.5800457563752025e-05
copy	2.7900228781876013e-05
deemed	5.5800457563752025e-05
clauses	2.7900228781876013e-05
paragraphs	0.00011160091512750405
paraphrasing	2.7900228781876013e-05
sections	5.5800457563752025e-05
In general	0.02857142857142857
general ,	0.2727272727272727
, abstraction	0.0005614823133071309
abstraction can	0.25
can condense	0.0055248618784530384
condense a	1.0
text more	0.006289308176100629
more strongly	0.010526315789473684
strongly than	0.5
than extraction	0.022222222222222223
the programs	0.0006920415224913495
programs that	0.09090909090909091
can do	0.011049723756906077
do this	0.07692307692307693
this are	0.02197802197802198
are harder	0.004149377593360996
harder to	0.2857142857142857
develop as	0.2
they require	0.05
generation technology	0.1111111111111111
technology ,	0.13636363636363635
which itself	0.007246376811594203
itself is	0.2
a growing	0.001226993865030675
field .	0.14814814814814814
condense	2.7900228781876013e-05
strongly	5.5800457563752025e-05
<s> Types	0.0015372790161414297
Types of	1.0
of summaries	0.0035650623885918
summaries There	0.023255813953488372
are different	0.004149377593360996
summaries depending	0.046511627906976744
depending what	0.25
the summarization	0.0020761245674740486
summarization program	0.02
program focuses	0.045454545454545456
on to	0.009433962264150943
make the	0.05
example generic	0.012345679012345678
generic summaries	0.3333333333333333
summaries or	0.023255813953488372
or query	0.0045045045045045045
query relevant	0.6666666666666666
relevant summaries	0.14285714285714285
summaries -LRB-	0.046511627906976744
-LRB- sometimes	0.0027100271002710027
sometimes called	0.07692307692307693
called query-biased	0.05555555555555555
query-biased summaries	1.0
summaries -RRB-	0.023255813953488372
Types	5.5800457563752025e-05
depending	0.00011160091512750405
query	8.370068634562804e-05
query-biased	2.7900228781876013e-05
<s> Summarization	0.0015372790161414297
Summarization systems	0.25
create both	0.058823529411764705
both query	0.03225806451612903
relevant text	0.14285714285714285
text summaries	0.006289308176100629
summaries and	0.046511627906976744
and generic	0.001445086705202312
generic machine-generated	0.3333333333333333
machine-generated summaries	1.0
depending on	0.75
on what	0.009433962264150943
user needs	0.07142857142857142
needs .	0.1
Summarization	0.00011160091512750405
machine-generated	2.7900228781876013e-05
Summarization of	0.25
of multimedia	0.00089126559714795
multimedia documents	0.5
e.g. pictures	0.017857142857142856
pictures or	1.0
or movies	0.0045045045045045045
movies ,	1.0
also possible	0.043478260869565216
possible .	0.125
multimedia	5.5800457563752025e-05
pictures	2.7900228781876013e-05
movies	2.7900228781876013e-05
Some systems	0.09523809523809523
systems will	0.008928571428571428
will generate	0.08571428571428572
generate a	0.3333333333333333
summary based	0.023809523809523808
a single	0.011042944785276074
single source	0.14285714285714285
others can	0.08333333333333333
use multiple	0.013888888888888888
multiple source	0.07692307692307693
source documents	0.125
a cluster	0.00245398773006135
cluster of	1.0
of news	0.0017825311942959
news stories	0.07692307692307693
stories on	1.0
same topic	0.04
topic -RRB-	0.125
single	0.0003906032029462642
cluster	5.5800457563752025e-05
news	0.00036270297416438817
stories	2.7900228781876013e-05
are known	0.012448132780082987
as multi-document	0.003484320557491289
multi-document summarization	0.75
summarization systems	0.1
multi-document	0.00011160091512750405
<s> Keyphrase	0.0023059185242121443
Keyphrase extraction	0.5
extraction Task	0.03225806451612903
Task description	0.3333333333333333
description and	1.0
and example	0.001445086705202312
example The	0.012345679012345678
The task	0.020833333333333332
the following	0.004844290657439446
following .	0.13333333333333333
Keyphrase	0.00011160091512750405
Task	8.370068634562804e-05
description	2.7900228781876013e-05
<s> You	0.0007686395080707148
You are	1.0
are given	0.012448132780082987
a piece	0.00245398773006135
piece of	1.0
a journal	0.001226993865030675
journal article	0.3333333333333333
article ,	0.10344827586206896
and you	0.004335260115606936
you must	0.07692307692307693
must produce	0.07142857142857142
of keywords	0.00089126559714795
keywords or	0.5
or keyphrases	0.0045045045045045045
keyphrases that	0.08571428571428572
that capture	0.0035460992907801418
capture the	0.5
the primary	0.001384083044982699
primary topics	0.5
topics discussed	0.14285714285714285
discussed in	0.14285714285714285
You	2.7900228781876013e-05
piece	8.370068634562804e-05
keywords	5.5800457563752025e-05
keyphrases	0.0009765080073656604
capture	5.5800457563752025e-05
primary	5.5800457563752025e-05
the case	0.005536332179930796
case of	0.35294117647058826
research articles	0.023809523809523808
articles ,	0.125
many authors	0.019230769230769232
authors provide	0.2
provide manually	0.16666666666666666
manually assigned	0.25
assigned keywords	0.5
keywords ,	0.5
most text	0.017241379310344827
text lacks	0.006289308176100629
lacks pre-existing	1.0
pre-existing keyphrases	0.5
keyphrases .	0.3142857142857143
manually	0.00011160091512750405
assigned	5.5800457563752025e-05
lacks	2.7900228781876013e-05
pre-existing	5.5800457563752025e-05
, news	0.0005614823133071309
news articles	0.23076923076923078
articles rarely	0.125
rarely have	0.3333333333333333
have keyphrases	0.019230769230769232
keyphrases attached	0.02857142857142857
attached ,	0.5
it would	0.03418803418803419
be useful	0.012658227848101266
useful to	0.14285714285714285
automatically do	0.047619047619047616
do so	0.038461538461538464
so for	0.03333333333333333
of applications	0.00267379679144385
applications discussed	0.04
discussed below	0.42857142857142855
below .	0.4
rarely	8.370068634562804e-05
example text	0.012345679012345678
a recent	0.001226993865030675
recent news	0.125
news article	0.15384615384615385
: ``	0.0196078431372549
`` The	0.015873015873015872
The Army	0.005208333333333333
Army Corps	0.5
Corps of	1.0
of Engineers	0.0017825311942959
Engineers ,	0.5
, rushing	0.0005614823133071309
rushing to	1.0
meet President	0.25
President Bush	0.5
Bush 's	0.5
's promise	0.0196078431372549
promise to	1.0
to protect	0.0013280212483399733
protect New	1.0
New Orleans	1.0
Orleans by	0.5
the start	0.002768166089965398
start of	0.2857142857142857
the 2006	0.0006920415224913495
2006 hurricane	0.3333333333333333
hurricane season	1.0
season ,	1.0
, installed	0.0005614823133071309
installed defective	0.3333333333333333
defective flood-control	1.0
flood-control pumps	1.0
pumps last	0.5
last year	0.2
year despite	0.16666666666666666
despite warnings	0.3333333333333333
warnings from	1.0
from its	0.009615384615384616
own expert	0.16666666666666666
expert that	1.0
the equipment	0.0006920415224913495
equipment would	0.3333333333333333
would fail	0.018867924528301886
fail during	0.3333333333333333
during a	0.2
a storm	0.001226993865030675
storm ,	1.0
, according	0.0005614823133071309
according to	1.0
to documents	0.0013280212483399733
documents obtained	0.02631578947368421
obtained by	0.5714285714285714
by The	0.005714285714285714
The Associated	0.005208333333333333
Associated Press	1.0
Press ''	1.0
recent	0.0002232018302550081
Army	0.00011160091512750405
Corps	5.5800457563752025e-05
Engineers	5.5800457563752025e-05
rushing	2.7900228781876013e-05
President	0.00011160091512750405
Bush	5.5800457563752025e-05
promise	2.7900228781876013e-05
protect	2.7900228781876013e-05
New	5.5800457563752025e-05
Orleans	5.5800457563752025e-05
start	0.0001953016014731321
hurricane	2.7900228781876013e-05
season	2.7900228781876013e-05
installed	8.370068634562804e-05
defective	5.5800457563752025e-05
flood-control	5.5800457563752025e-05
pumps	5.5800457563752025e-05
last	0.00013950114390938006
despite	8.370068634562804e-05
warnings	2.7900228781876013e-05
expert	2.7900228781876013e-05
equipment	8.370068634562804e-05
fail	8.370068634562804e-05
storm	2.7900228781876013e-05
according	0.00013950114390938006
obtained	0.0001953016014731321
Associated	2.7900228781876013e-05
Press	2.7900228781876013e-05
An extractive	0.0625
extractive keyphrase	0.14285714285714285
keyphrase extractor	0.05263157894736842
extractor might	0.5
might select	0.038461538461538464
select ``	0.16666666666666666
`` Army	0.005291005291005291
Engineers ''	0.5
`` President	0.005291005291005291
Bush ''	0.5
`` New	0.005291005291005291
Orleans ''	0.5
`` defective	0.005291005291005291
pumps ''	0.5
as keyphrases	0.003484320557491289
extractor	5.5800457563752025e-05
These are	0.11764705882352941
are pulled	0.004149377593360996
pulled directly	1.0
directly from	0.2
pulled	2.7900228781876013e-05
directly	0.00013950114390938006
an abstractive	0.015151515151515152
abstractive keyphrase	0.16666666666666666
keyphrase system	0.05263157894736842
system would	0.021505376344086023
would somehow	0.018867924528301886
somehow internalize	1.0
internalize the	1.0
the content	0.0020761245674740486
content and	0.16666666666666666
and generate	0.001445086705202312
generate keyphrases	0.05555555555555555
more descriptive	0.010526315789473684
descriptive and	0.3333333333333333
more like	0.010526315789473684
like what	0.03571428571428571
human would	0.021739130434782608
would produce	0.03773584905660377
produce ,	0.045454545454545456
`` political	0.005291005291005291
political negligence	0.3333333333333333
negligence ''	1.0
'' or	0.02577319587628866
or ``	0.018018018018018018
`` inadequate	0.005291005291005291
inadequate protection	1.0
protection from	1.0
from floods	0.009615384615384616
floods ''	1.0
somehow	2.7900228781876013e-05
internalize	2.7900228781876013e-05
descriptive	8.370068634562804e-05
negligence	2.7900228781876013e-05
inadequate	2.7900228781876013e-05
protection	2.7900228781876013e-05
floods	2.7900228781876013e-05
that these	0.010638297872340425
these terms	0.023809523809523808
terms do	0.07692307692307693
not appear	0.008928571428571428
text and	0.018867924528301886
and require	0.004335260115606936
a deep	0.001226993865030675
deep understanding	0.2857142857142857
understanding ,	0.09090909090909091
makes it	0.25
it difficult	0.017094017094017096
difficult for	0.03571428571428571
computer to	0.045454545454545456
produce such	0.045454545454545456
such keyphrases	0.008130081300813009
<s> Keyphrases	0.0007686395080707148
Keyphrases have	1.0
many applications	0.038461538461538464
to improve	0.01195219123505976
improve document	0.07692307692307693
document browsing	0.027777777777777776
browsing by	1.0
by providing	0.005714285714285714
providing a	0.5
short summary	0.125
Keyphrases	2.7900228781876013e-05
browsing	2.7900228781876013e-05
<s> Also	0.0023059185242121443
Also ,	1.0
, keyphrases	0.0005614823133071309
keyphrases can	0.05714285714285714
can improve	0.0055248618784530384
improve information	0.07692307692307693
information retrieval	0.10869565217391304
retrieval --	0.14285714285714285
-- if	0.08
if documents	0.03571428571428571
documents have	0.02631578947368421
keyphrases assigned	0.02857142857142857
assigned ,	0.5
a user	0.00245398773006135
user could	0.07142857142857142
could search	0.0625
search by	0.09090909090909091
by keyphrase	0.005714285714285714
keyphrase to	0.05263157894736842
reliable hits	0.25
hits than	1.0
than a	0.1111111111111111
a full-text	0.001226993865030675
full-text search	1.0
search .	0.09090909090909091
Also	8.370068634562804e-05
could	0.0004464036605100162
hits	2.7900228781876013e-05
full-text	2.7900228781876013e-05
automatic keyphrase	0.043478260869565216
extraction can	0.03225806451612903
useful in	0.14285714285714285
in generating	0.0018726591760299626
generating index	0.2
index entries	1.0
entries for	0.5
large text	0.043478260869565216
text corpus	0.012578616352201259
corpus .	0.03225806451612903
generating	0.00013950114390938006
index	2.7900228781876013e-05
extraction as	0.06451612903225806
as supervised	0.003484320557491289
learning Beginning	0.023255813953488372
Beginning with	0.5
the Turney	0.0006920415224913495
Turney paper	0.2222222222222222
paper ,	0.09090909090909091
many researchers	0.019230769230769232
researchers have	0.3
have approached	0.009615384615384616
approached keyphrase	0.5
a supervised	0.00245398773006135
supervised machine	0.0625
learning problem	0.023255813953488372
Turney	0.0002511020590368841
researchers	0.00027900228781876013
we construct	0.022222222222222223
construct an	0.3333333333333333
example for	0.024691358024691357
each unigram	0.044444444444444446
unigram ,	0.6
, bigram	0.0016844469399213925
bigram ,	1.0
and trigram	0.001445086705202312
trigram found	0.3333333333333333
found in	0.21428571428571427
-LRB- though	0.0027100271002710027
though other	0.1
other text	0.02857142857142857
text units	0.018867924528301886
units are	0.2857142857142857
as discussed	0.003484320557491289
construct	8.370068634562804e-05
unigram	0.00013950114390938006
bigram	8.370068634562804e-05
trigram	8.370068634562804e-05
though	0.00027900228781876013
units	0.0001953016014731321
<s> We	0.005380476556495004
We then	0.14285714285714285
then compute	0.02857142857142857
compute various	0.5
various features	0.05555555555555555
features describing	0.038461538461538464
describing each	0.25
each example	0.044444444444444446
example -LRB-	0.012345679012345678
, does	0.0011229646266142617
does the	0.1
the phrase	0.002768166089965398
phrase begin	0.1
with an	0.0273224043715847
an upper-case	0.007575757575757576
upper-case letter	1.0
letter ?	0.16666666666666666
We	0.0001953016014731321
compute	5.5800457563752025e-05
describing	0.00011160091512750405
upper-case	2.7900228781876013e-05
letter	0.00016740137269125608
We assume	0.14285714285714285
assume there	0.5
known keyphrases	0.15384615384615385
keyphrases available	0.02857142857142857
available for	0.11764705882352941
training documents	0.10714285714285714
documents .	0.13157894736842105
Using the	0.5
the known	0.0034602076124567475
keyphrases ,	0.05714285714285714
we can	0.06666666666666667
can assign	0.0055248618784530384
assign positive	0.2
positive or	0.2857142857142857
or negative	0.009009009009009009
negative labels	0.125
labels to	1.0
the examples	0.0020761245674740486
assign	0.00013950114390938006
positive	0.0001953016014731321
negative	0.0002232018302550081
labels	5.5800457563752025e-05
Then we	0.2
we learn	0.022222222222222223
learn a	0.23076923076923078
a classifier	0.001226993865030675
classifier that	0.14285714285714285
can discriminate	0.0055248618784530384
discriminate between	0.3333333333333333
between positive	0.02564102564102564
positive and	0.2857142857142857
and negative	0.002890173410404624
negative examples	0.125
examples as	0.041666666666666664
a function	0.001226993865030675
function of	0.125
features .	0.07692307692307693
classifier	0.0001953016014731321
discriminate	8.370068634562804e-05
Some classifiers	0.047619047619047616
classifiers make	0.5
a binary	0.00245398773006135
binary classification	0.5
classification for	0.11764705882352941
a test	0.0036809815950920245
test example	0.1
others assign	0.08333333333333333
assign a	0.4
a probability	0.001226993865030675
probability of	0.14285714285714285
of being	0.00089126559714795
being a	0.1111111111111111
a keyphrase	0.00245398773006135
keyphrase .	0.05263157894736842
classifiers	5.5800457563752025e-05
binary	0.00011160091512750405
classification	0.0004743038892918922
probability	0.0001953016014731321
the above	0.001384083044982699
above text	0.07692307692307693
we might	0.022222222222222223
might learn	0.038461538461538464
a rule	0.001226993865030675
rule that	0.3333333333333333
that says	0.0035460992907801418
says phrases	1.0
phrases with	0.0625
with initial	0.00546448087431694
initial capital	0.3333333333333333
capital letters	0.3333333333333333
letters are	0.1
are likely	0.016597510373443983
likely to	0.4375
be keyphrases	0.004219409282700422
rule	8.370068634562804e-05
says	2.7900228781876013e-05
initial	8.370068634562804e-05
<s> After	0.0023059185242121443
After training	0.3333333333333333
training a	0.03571428571428571
a learner	0.001226993865030675
learner ,	0.5
can select	0.0055248618784530384
select keyphrases	0.16666666666666666
keyphrases for	0.05714285714285714
for test	0.0036101083032490976
test documents	0.2
documents in	0.02631578947368421
following manner	0.06666666666666667
manner .	0.75
After	8.370068634562804e-05
learner	5.5800457563752025e-05
manner	0.00011160091512750405
We apply	0.14285714285714285
apply the	0.2
same example-generation	0.04
example-generation strategy	1.0
strategy to	0.6
the test	0.001384083044982699
then run	0.02857142857142857
run each	0.2
example through	0.012345679012345678
the learner	0.0006920415224913495
learner .	0.5
example-generation	2.7900228781876013e-05
strategy	0.00013950114390938006
We can	0.2857142857142857
can determine	0.011049723756906077
the keyphrases	0.001384083044982699
keyphrases by	0.02857142857142857
by looking	0.005714285714285714
looking at	0.2
at binary	0.014705882352941176
classification decisions	0.058823529411764705
decisions or	0.1
or probabilities	0.0045045045045045045
probabilities returned	0.09090909090909091
returned from	0.5
from our	0.009615384615384616
our learned	0.2
learned model	0.2
model .	0.06666666666666667
looking	0.00013950114390938006
probabilities	0.00030690251660063614
returned	0.00011160091512750405
<s> If	0.006149116064565719
If probabilities	0.1
probabilities are	0.09090909090909091
given ,	0.041666666666666664
a threshold	0.0036809815950920245
threshold is	0.25
If	0.00027900228781876013
threshold	0.00011160091512750405
Keyphrase extractors	0.25
extractors are	1.0
generally evaluated	0.09090909090909091
evaluated using	0.14285714285714285
using precision	0.01694915254237288
precision and	0.4
and recall	0.002890173410404624
recall .	0.6666666666666666
extractors	2.7900228781876013e-05
precision	0.00013950114390938006
recall	8.370068634562804e-05
<s> Precision	0.0007686395080707148
Precision measures	1.0
measures how	0.3333333333333333
how many	0.10344827586206896
many of	0.038461538461538464
the proposed	0.001384083044982699
proposed keyphrases	0.2222222222222222
keyphrases are	0.05714285714285714
are actually	0.004149377593360996
actually correct	0.3333333333333333
correct .	0.2
Precision	2.7900228781876013e-05
measures	0.00016740137269125608
actually	8.370068634562804e-05
<s> Recall	0.0023059185242121443
Recall measures	0.3333333333333333
the true	0.0006920415224913495
true keyphrases	0.5
keyphrases your	0.02857142857142857
your system	0.5
system proposed	0.010752688172043012
proposed .	0.1111111111111111
Recall	8.370068634562804e-05
true	5.5800457563752025e-05
The two	0.010416666666666666
two measures	0.034482758620689655
measures can	0.3333333333333333
be combined	0.004219409282700422
combined in	0.5
an F-score	0.007575757575757576
F-score ,	1.0
the harmonic	0.0006920415224913495
harmonic mean	1.0
mean of	0.5
two -LRB-	0.034482758620689655
-LRB- F	0.0027100271002710027
F =	1.0
= 2PR	0.1111111111111111
2PR \/	1.0
\/ -LRB-	0.3333333333333333
-LRB- P	0.0027100271002710027
P +	0.5
+ R	0.16666666666666666
R -RRB-	1.0
combined	5.5800457563752025e-05
F-score	2.7900228781876013e-05
harmonic	2.7900228781876013e-05
mean	5.5800457563752025e-05
F	2.7900228781876013e-05
=	0.0002511020590368841
2PR	2.7900228781876013e-05
P	5.5800457563752025e-05
+	0.00016740137269125608
R	2.7900228781876013e-05
<s> Matches	0.0007686395080707148
Matches between	1.0
keyphrases and	0.02857142857142857
be checked	0.004219409282700422
checked after	0.5
after stemming	0.08333333333333333
stemming or	0.5
or applying	0.0045045045045045045
applying some	0.25
text normalization	0.006289308176100629
Matches	2.7900228781876013e-05
checked	5.5800457563752025e-05
applying	0.00011160091512750405
<s> Design	0.0023059185242121443
Design choices	1.0
choices Designing	0.2
Designing a	1.0
supervised keyphrase	0.125
extraction system	0.06451612903225806
system involves	0.010752688172043012
involves deciding	0.1
deciding on	0.16666666666666666
on several	0.0047169811320754715
several choices	0.045454545454545456
choices -LRB-	0.2
-LRB- some	0.0027100271002710027
these apply	0.023809523809523808
apply to	0.4
to unsupervised	0.0026560424966799467
unsupervised ,	0.125
, too	0.0005614823133071309
too -RRB-	0.16666666666666666
: What	0.00980392156862745
What are	0.36363636363636365
are the	0.04564315352697095
examples ?	0.041666666666666664
Design	8.370068634562804e-05
choices	0.00013950114390938006
Designing	2.7900228781876013e-05
deciding	0.00016740137269125608
too	0.00016740137269125608
first choice	0.030303030303030304
choice is	0.25
is exactly	0.0020325203252032522
exactly how	0.3333333333333333
generate examples	0.05555555555555555
choice	0.0002232018302550081
exactly	8.370068634562804e-05
<s> Turney	0.0007686395080707148
Turney and	0.2222222222222222
and others	0.002890173410404624
others have	0.08333333333333333
have used	0.019230769230769232
used all	0.008849557522123894
possible unigrams	0.041666666666666664
unigrams ,	0.25
, bigrams	0.0011229646266142617
bigrams ,	1.0
and trigrams	0.002890173410404624
trigrams without	0.5
without intervening	0.07692307692307693
intervening punctuation	1.0
punctuation and	0.2857142857142857
after removing	0.08333333333333333
removing stopwords	0.5
stopwords .	1.0
unigrams	0.00033480274538251215
bigrams	5.5800457563752025e-05
trigrams	5.5800457563752025e-05
intervening	2.7900228781876013e-05
removing	5.5800457563752025e-05
stopwords	2.7900228781876013e-05
<s> Hulth	0.0023059185242121443
Hulth showed	0.3333333333333333
showed that	0.75
that you	0.0035460992907801418
you can	0.15384615384615385
can get	0.0055248618784530384
get some	0.14285714285714285
some improvement	0.012048192771084338
improvement by	0.25
selecting examples	0.2
examples to	0.041666666666666664
be sequences	0.004219409282700422
of tokens	0.0017825311942959
tokens that	0.14285714285714285
that match	0.0035460992907801418
match certain	0.16666666666666666
certain patterns	0.14285714285714285
patterns of	0.2
of part-of-speech	0.0017825311942959
part-of-speech tags	0.06666666666666667
tags .	0.3333333333333333
Hulth	8.370068634562804e-05
showed	0.00011160091512750405
improvement	0.00011160091512750405
tokens	0.0001953016014731321
match	0.00016740137269125608
certain	0.0001953016014731321
patterns	0.00013950114390938006
tags	0.00016740137269125608
<s> Ideally	0.0015372790161414297
Ideally ,	1.0
the mechanism	0.0006920415224913495
mechanism for	1.0
for generating	0.0036101083032490976
generating examples	0.2
examples produces	0.041666666666666664
produces all	0.25
known labeled	0.038461538461538464
labeled keyphrases	0.3333333333333333
keyphrases as	0.02857142857142857
as candidates	0.003484320557491289
candidates ,	0.2
, though	0.003368893879842785
though this	0.1
case .	0.17647058823529413
Ideally	5.5800457563752025e-05
mechanism	2.7900228781876013e-05
candidates	0.00013950114390938006
, if	0.005614823133071308
if we	0.07142857142857142
we use	0.022222222222222223
use only	0.027777777777777776
only unigrams	0.02631578947368421
trigrams ,	0.5
then we	0.05714285714285714
will never	0.02857142857142857
to extract	0.00398406374501992
extract a	0.25
known keyphrase	0.038461538461538464
keyphrase containing	0.05263157894736842
containing four	0.125
four words	0.14285714285714285
extract	0.00011160091512750405
<s> Thus	0.009223674096848577
Thus ,	0.9166666666666666
, recall	0.0005614823133071309
recall may	0.3333333333333333
may suffer	0.019230769230769232
suffer .	1.0
Thus	0.00033480274538251215
suffer	2.7900228781876013e-05
, generating	0.0005614823133071309
generating too	0.2
too many	0.3333333333333333
many examples	0.019230769230769232
examples can	0.041666666666666664
also lead	0.014492753623188406
lead to	1.0
to low	0.0013280212483399733
low precision	0.3333333333333333
precision .	0.2
lead	5.5800457563752025e-05
low	8.370068634562804e-05
features ?	0.038461538461538464
We also	0.14285714285714285
also need	0.014492753623188406
create features	0.058823529411764705
features that	0.07692307692307693
that describe	0.0035460992907801418
describe the	0.3333333333333333
are informative	0.004149377593360996
informative enough	0.5
enough to	0.2
to allow	0.00398406374501992
allow a	0.2
algorithm to	0.07142857142857142
to discriminate	0.0026560424966799467
discriminate keyphrases	0.3333333333333333
keyphrases from	0.02857142857142857
from non	0.009615384615384616
non -	1.0
- keyphrases	0.0625
describe	0.00016740137269125608
allow	0.00013950114390938006
non	2.7900228781876013e-05
<s> Typically	0.0007686395080707148
Typically features	1.0
features involve	0.038461538461538464
involve various	0.16666666666666666
various term	0.05555555555555555
term frequencies	0.05555555555555555
frequencies -LRB-	0.5
-LRB- how	0.008130081300813009
many times	0.019230769230769232
times a	0.2
a phrase	0.00245398773006135
phrase appears	0.1
appears in	0.2
the current	0.001384083044982699
current text	0.14285714285714285
or in	0.0045045045045045045
larger corpus	0.125
the length	0.001384083044982699
length of	0.25
, relative	0.0005614823133071309
relative position	0.3333333333333333
position of	0.25
first occurrence	0.030303030303030304
occurrence ,	0.5
, various	0.0005614823133071309
various boolean	0.05555555555555555
boolean syntactic	1.0
syntactic features	0.07692307692307693
features -LRB-	0.038461538461538464
, contains	0.0005614823133071309
contains all	0.1
all caps	0.023255813953488372
caps -RRB-	1.0
Typically	2.7900228781876013e-05
frequencies	5.5800457563752025e-05
times	0.00013950114390938006
position	0.00011160091512750405
occurrence	5.5800457563752025e-05
boolean	2.7900228781876013e-05
caps	2.7900228781876013e-05
The Turney	0.005208333333333333
paper used	0.09090909090909091
used about	0.008849557522123894
about 12	0.025
12 such	0.2
such features	0.008130081300813009
12	0.00013950114390938006
Hulth uses	0.3333333333333333
uses a	0.2857142857142857
a reduced	0.001226993865030675
reduced set	0.25
of features	0.00089126559714795
features ,	0.038461538461538464
which were	0.014492753623188406
were found	0.04878048780487805
found most	0.07142857142857142
most successful	0.034482758620689655
successful in	0.1111111111111111
the KEA	0.0006920415224913495
KEA -LRB-	1.0
-LRB- Keyphrase	0.0027100271002710027
Keyphrase Extraction	0.25
Extraction Algorithm	0.3333333333333333
Algorithm -RRB-	1.0
-RRB- work	0.0027100271002710027
work derived	0.041666666666666664
from Turney	0.009615384615384616
Turney 's	0.4444444444444444
's seminal	0.0196078431372549
seminal paper	1.0
paper .	0.09090909090909091
KEA	2.7900228781876013e-05
Algorithm	2.7900228781876013e-05
seminal	2.7900228781876013e-05
<s> How	0.0030745580322828594
How many	0.14285714285714285
many keyphrases	0.019230769230769232
keyphrases to	0.02857142857142857
to return	0.0026560424966799467
return ?	0.5
How	0.0001953016014731321
return	5.5800457563752025e-05
the end	0.001384083044982699
end ,	0.125
system will	0.010752688172043012
will need	0.02857142857142857
return a	0.5
of keyphrases	0.00267379679144385
test document	0.1
so we	0.03333333333333333
we need	0.13333333333333333
a way	0.006134969325153374
to limit	0.0026560424966799467
limit the	0.5
number .	0.046511627906976744
<s> Ensemble	0.0007686395080707148
Ensemble methods	1.0
i.e. ,	0.3684210526315789
, using	0.005614823133071308
using votes	0.01694915254237288
votes from	1.0
from several	0.009615384615384616
several classifiers	0.045454545454545456
classifiers -RRB-	0.5
-RRB- have	0.005420054200542005
produce numeric	0.045454545454545456
numeric scores	1.0
scores that	0.2
be thresholded	0.004219409282700422
thresholded to	1.0
a user-provided	0.001226993865030675
user-provided number	1.0
Ensemble	2.7900228781876013e-05
votes	2.7900228781876013e-05
numeric	2.7900228781876013e-05
scores	0.00013950114390938006
thresholded	2.7900228781876013e-05
user-provided	2.7900228781876013e-05
the technique	0.0006920415224913495
technique used	0.14285714285714285
used by	0.07964601769911504
by Turney	0.005714285714285714
Turney with	0.1111111111111111
with C4	0.00546448087431694
C4 .5	1.0
.5 decision	1.0
trees .	0.3333333333333333
C4	2.7900228781876013e-05
.5	2.7900228781876013e-05
Hulth used	0.3333333333333333
used a	0.02654867256637168
single binary	0.07142857142857142
binary classifier	0.25
classifier so	0.14285714285714285
the learning	0.0006920415224913495
algorithm implicitly	0.03571428571428571
implicitly determines	1.0
determines the	0.6666666666666666
the appropriate	0.0020761245674740486
appropriate number	0.25
implicitly	2.7900228781876013e-05
determines	8.370068634562804e-05
appropriate	0.00011160091512750405
What learning	0.09090909090909091
algorithm ?	0.03571428571428571
<s> Once	0.003843197540353574
Once examples	0.2
and features	0.001445086705202312
features are	0.11538461538461539
are created	0.012448132780082987
created ,	0.2857142857142857
learn to	0.07692307692307693
predict keyphrases	0.16666666666666666
Once	0.00013950114390938006
<s> Virtually	0.0007686395080707148
Virtually any	1.0
any supervised	0.03225806451612903
algorithm could	0.03571428571428571
could be	0.25
used ,	0.07079646017699115
, Naive	0.0005614823133071309
Naive Bayes	1.0
Bayes ,	0.3333333333333333
and rule	0.001445086705202312
rule induction	0.3333333333333333
induction .	1.0
Virtually	2.7900228781876013e-05
Naive	2.7900228781876013e-05
Bayes	8.370068634562804e-05
induction	5.5800457563752025e-05
of Turney	0.0017825311942959
's GenEx	0.0196078431372549
GenEx algorithm	1.0
algorithm ,	0.10714285714285714
a genetic	0.001226993865030675
genetic algorithm	1.0
learn parameters	0.07692307692307693
parameters for	0.5
a domain-specific	0.001226993865030675
domain-specific keyphrase	0.5
extraction algorithm	0.03225806451612903
algorithm .	0.14285714285714285
GenEx	2.7900228781876013e-05
genetic	5.5800457563752025e-05
domain-specific	5.5800457563752025e-05
The extractor	0.005208333333333333
extractor follows	0.5
follows a	0.5
of heuristics	0.00089126559714795
heuristics to	0.5
to identify	0.006640106241699867
identify keyphrases	0.08333333333333333
heuristics	5.5800457563752025e-05
The genetic	0.005208333333333333
algorithm optimizes	0.03571428571428571
optimizes parameters	1.0
for these	0.0036101083032490976
these heuristics	0.023809523809523808
heuristics with	0.5
to performance	0.0013280212483399733
performance on	0.05555555555555555
on training	0.0047169811320754715
documents with	0.05263157894736842
with known	0.01092896174863388
known key	0.038461538461538464
key phrases	0.16666666666666666
phrases .	0.3125
optimizes	2.7900228781876013e-05
<s> Unsupervised	0.003843197540353574
Unsupervised keyphrase	0.3333333333333333
: TextRank	0.0196078431372549
TextRank While	0.07142857142857142
While supervised	0.2
supervised methods	0.125
methods have	0.045454545454545456
have some	0.009615384615384616
some nice	0.012048192771084338
nice properties	0.25
properties ,	0.25
, like	0.0016844469399213925
like being	0.03571428571428571
being able	0.05555555555555555
produce interpretable	0.045454545454545456
interpretable rules	1.0
for what	0.007220216606498195
what features	0.03125
features characterize	0.038461538461538464
characterize a	0.5
keyphrase ,	0.05263157894736842
they also	0.025
also require	0.014492753623188406
large amount	0.043478260869565216
TextRank	0.0003906032029462642
While	0.00013950114390938006
nice	0.00011160091512750405
properties	0.00011160091512750405
interpretable	2.7900228781876013e-05
characterize	5.5800457563752025e-05
Many documents	0.08333333333333333
are needed	0.004149377593360996
, training	0.0005614823133071309
training on	0.03571428571428571
specific domain	0.14285714285714285
domain tends	0.05
tends to	1.0
to customize	0.0026560424966799467
customize the	0.5
extraction process	0.03225806451612903
to that	0.0026560424966799467
that domain	0.0035460992907801418
domain ,	0.15
the resulting	0.001384083044982699
resulting classifier	0.25
classifier is	0.14285714285714285
not necessarily	0.017857142857142856
necessarily portable	0.5
portable ,	0.3333333333333333
as some	0.003484320557491289
's results	0.0196078431372549
results demonstrate	0.047619047619047616
demonstrate .	1.0
tends	2.7900228781876013e-05
customize	5.5800457563752025e-05
necessarily	5.5800457563752025e-05
portable	8.370068634562804e-05
demonstrate	2.7900228781876013e-05
extraction removes	0.03225806451612903
removes the	1.0
the need	0.0020761245674740486
need for	0.14285714285714285
removes	2.7900228781876013e-05
It approaches	0.02631578947368421
approaches the	0.03571428571428571
problem from	0.022727272727272728
a different	0.0036809815950920245
different angle	0.02040816326530612
angle .	1.0
angle	2.7900228781876013e-05
<s> Instead	0.0015372790161414297
Instead of	1.0
of trying	0.00089126559714795
trying to	1.0
learn explicit	0.07692307692307693
explicit features	0.2
that characterize	0.0035460992907801418
characterize keyphrases	0.5
the TextRank	0.001384083044982699
TextRank algorithm	0.07142857142857142
algorithm exploits	0.03571428571428571
exploits the	1.0
text itself	0.006289308176100629
itself to	0.2
determine keyphrases	0.043478260869565216
that appear	0.014184397163120567
appear ``	0.0625
`` central	0.010582010582010581
central ''	0.6666666666666666
'' to	0.015463917525773196
same way	0.04
way that	0.125
that PageRank	0.0035460992907801418
PageRank selects	0.16666666666666666
selects important	0.5
important Web	0.0625
Web pages	0.2222222222222222
pages .	0.2857142857142857
Instead	8.370068634562804e-05
trying	0.00013950114390938006
exploits	2.7900228781876013e-05
central	8.370068634562804e-05
PageRank	0.00016740137269125608
selects	5.5800457563752025e-05
Recall this	0.3333333333333333
the notion	0.001384083044982699
notion of	0.75
`` prestige	0.005291005291005291
prestige ''	1.0
`` recommendation	0.010582010582010581
recommendation ''	1.0
'' from	0.005154639175257732
from social	0.009615384615384616
social networks	0.21428571428571427
networks .	0.21428571428571427
notion	0.00011160091512750405
prestige	2.7900228781876013e-05
recommendation	5.5800457563752025e-05
networks	0.0003906032029462642
this way	0.02197802197802198
way ,	0.041666666666666664
, TextRank	0.0011229646266142617
TextRank does	0.07142857142857142
does not	0.5
not rely	0.017857142857142856
rely on	0.8571428571428571
on any	0.018867924528301886
any previous	0.03225806451612903
previous training	0.3333333333333333
data at	0.012987012987012988
but rather	0.029411764705882353
rather can	0.0625
be run	0.004219409282700422
run on	0.2
any arbitrary	0.06451612903225806
arbitrary piece	0.3333333333333333
and it	0.0072254335260115606
it can	0.05128205128205128
can produce	0.0055248618784530384
output simply	0.038461538461538464
simply based	0.08333333333333333
text 's	0.006289308176100629
's intrinsic	0.0196078431372549
intrinsic properties	0.25
properties .	0.25
previous	8.370068634562804e-05
arbitrary	8.370068634562804e-05
Thus the	0.08333333333333333
the algorithm	0.0006920415224913495
is easily	0.0020325203252032522
easily portable	0.2222222222222222
portable to	0.3333333333333333
new domains	0.041666666666666664
domains and	0.25
and languages	0.001445086705202312
easily	0.0002511020590368841
<s> TextRank	0.0023059185242121443
TextRank is	0.07142857142857142
general purpose	0.09090909090909091
purpose graph-based	0.4
graph-based ranking	1.0
ranking algorithm	0.2857142857142857
algorithm for	0.07142857142857142
for NLP	0.0036101083032490976
graph-based	5.5800457563752025e-05
ranking	0.0001953016014731321
<s> Essentially	0.0007686395080707148
Essentially ,	1.0
it runs	0.008547008547008548
runs PageRank	1.0
PageRank on	0.16666666666666666
a graph	0.0036809815950920245
graph specially	0.07692307692307693
specially designed	1.0
designed for	0.14285714285714285
particular NLP	0.07692307692307693
NLP task	0.02127659574468085
Essentially	2.7900228781876013e-05
runs	2.7900228781876013e-05
graph	0.00036270297416438817
specially	2.7900228781876013e-05
For keyphrase	0.01639344262295082
it builds	0.008547008547008548
builds a	0.5
graph using	0.07692307692307693
using some	0.03389830508474576
some set	0.012048192771084338
units as	0.14285714285714285
as vertices	0.003484320557491289
vertices .	0.2222222222222222
builds	5.5800457563752025e-05
vertices	0.0002511020590368841
<s> Edges	0.0015372790161414297
Edges are	1.0
are based	0.02074688796680498
some measure	0.012048192771084338
measure of	0.18181818181818182
semantic or	0.047619047619047616
or lexical	0.009009009009009009
lexical similarity	0.07692307692307693
similarity between	0.2
text unit	0.006289308176100629
unit vertices	0.3333333333333333
Edges	5.5800457563752025e-05
similarity	0.00027900228781876013
unit	8.370068634562804e-05
<s> Unlike	0.0007686395080707148
Unlike PageRank	1.0
PageRank ,	0.16666666666666666
the edges	0.001384083044982699
edges are	0.14285714285714285
typically undirected	0.05555555555555555
undirected and	1.0
be weighted	0.004219409282700422
weighted to	0.3333333333333333
to reflect	0.0013280212483399733
reflect a	1.0
a degree	0.001226993865030675
of similarity	0.00089126559714795
similarity .	0.1
Unlike	2.7900228781876013e-05
edges	0.0001953016014731321
undirected	2.7900228781876013e-05
weighted	8.370068634562804e-05
reflect	2.7900228781876013e-05
Once the	0.2
the graph	0.004152249134948097
graph is	0.23076923076923078
is constructed	0.0040650406504065045
constructed ,	0.5
form a	0.15
a stochastic	0.001226993865030675
stochastic matrix	0.125
matrix ,	1.0
, combined	0.0005614823133071309
combined with	0.5
a damping	0.001226993865030675
damping factor	1.0
factor -LRB-	0.5
as in	0.027874564459930314
`` random	0.005291005291005291
random surfer	0.14285714285714285
surfer model	1.0
model ''	0.03333333333333333
the ranking	0.001384083044982699
ranking over	0.14285714285714285
over vertices	0.08333333333333333
vertices is	0.1111111111111111
is obtained	0.0020325203252032522
by finding	0.005714285714285714
finding the	0.4
the eigenvector	0.0006920415224913495
eigenvector corresponding	0.5
corresponding to	0.3333333333333333
to eigenvalue	0.0013280212483399733
eigenvalue 1	1.0
1 -LRB-	0.25
the stationary	0.0006920415224913495
stationary distribution	0.2857142857142857
distribution of	0.25
the random	0.0006920415224913495
random walk	0.5714285714285714
walk on	0.4
graph -RRB-	0.07692307692307693
constructed	5.5800457563752025e-05
matrix	2.7900228781876013e-05
damping	2.7900228781876013e-05
factor	5.5800457563752025e-05
random	0.0001953016014731321
surfer	2.7900228781876013e-05
eigenvector	5.5800457563752025e-05
eigenvalue	2.7900228781876013e-05
1	0.00011160091512750405
stationary	0.0001953016014731321
distribution	0.00011160091512750405
walk	0.00013950114390938006
choices What	0.4
What should	0.09090909090909091
should vertices	0.05263157894736842
vertices be	0.1111111111111111
be ?	0.004219409282700422
The vertices	0.005208333333333333
vertices should	0.1111111111111111
should correspond	0.05263157894736842
correspond to	1.0
we want	0.044444444444444446
want to	0.8333333333333334
to rank	0.00398406374501992
rank .	0.16666666666666666
correspond	5.5800457563752025e-05
want	0.00016740137269125608
rank	0.00016740137269125608
<s> Potentially	0.0007686395080707148
Potentially ,	1.0
we could	0.022222222222222223
could do	0.0625
do something	0.038461538461538464
something similar	1.0
the supervised	0.0006920415224913495
methods and	0.022727272727272728
and create	0.002890173410404624
a vertex	0.00245398773006135
vertex for	0.6666666666666666
, trigram	0.0011229646266142617
trigram ,	0.6666666666666666
Potentially	2.7900228781876013e-05
something	2.7900228781876013e-05
vertex	8.370068634562804e-05
to keep	0.0026560424966799467
keep the	0.3333333333333333
graph small	0.07692307692307693
small ,	0.2222222222222222
the authors	0.0006920415224913495
authors decide	0.2
decide to	0.25
rank individual	0.16666666666666666
individual unigrams	0.08333333333333333
unigrams in	0.25
a first	0.00245398773006135
step ,	0.13333333333333333
then include	0.02857142857142857
include a	0.1111111111111111
a second	0.0036809815950920245
step that	0.13333333333333333
that merges	0.0035460992907801418
merges highly	1.0
highly ranked	0.1111111111111111
ranked adjacent	0.2
adjacent unigrams	0.16666666666666666
unigrams to	0.08333333333333333
form multi-word	0.05
multi-word phrases	1.0
keep	8.370068634562804e-05
merges	2.7900228781876013e-05
ranked	0.00013950114390938006
adjacent	0.00016740137269125608
multi-word	2.7900228781876013e-05
This has	0.015873015873015872
a nice	0.00245398773006135
nice side	0.25
side effect	1.0
effect of	0.5
of allowing	0.00089126559714795
allowing us	0.3333333333333333
us to	0.5
produce keyphrases	0.045454545454545456
keyphrases of	0.02857142857142857
of arbitrary	0.00089126559714795
arbitrary length	0.3333333333333333
length .	0.125
side	2.7900228781876013e-05
effect	5.5800457563752025e-05
allowing	8.370068634562804e-05
us	5.5800457563752025e-05
we rank	0.022222222222222223
rank unigrams	0.16666666666666666
unigrams and	0.08333333333333333
and find	0.001445086705202312
find that	0.07692307692307693
`` advanced	0.005291005291005291
advanced ''	0.2
`` natural	0.015873015873015872
natural ''	0.02666666666666667
`` language	0.010582010582010581
language ''	0.013513513513513514
`` processing	0.010582010582010581
processing ''	0.037037037037037035
'' all	0.005154639175257732
all get	0.023255813953488372
get high	0.14285714285714285
high ranks	0.05555555555555555
ranks ,	0.5
we would	0.06666666666666667
would look	0.03773584905660377
look at	0.4
and see	0.001445086705202312
see that	0.05
these words	0.047619047619047616
words appear	0.009174311926605505
appear consecutively	0.0625
consecutively and	1.0
a final	0.001226993865030675
final keyphrase	0.1111111111111111
keyphrase using	0.05263157894736842
using all	0.01694915254237288
all four	0.023255813953488372
four together	0.14285714285714285
together .	0.125
advanced	0.00013950114390938006
ranks	5.5800457563752025e-05
look	0.00013950114390938006
consecutively	2.7900228781876013e-05
final	0.0002511020590368841
together	0.0002232018302550081
the unigrams	0.001384083044982699
unigrams placed	0.08333333333333333
placed in	1.0
graph can	0.07692307692307693
be filtered	0.012658227848101266
filtered by	0.3333333333333333
by part	0.005714285714285714
placed	8.370068634562804e-05
filtered	8.370068634562804e-05
authors found	0.2
that adjectives	0.0035460992907801418
adjectives and	0.3333333333333333
and nouns	0.001445086705202312
nouns were	0.1111111111111111
were the	0.024390243902439025
best to	0.1111111111111111
to include	0.009296148738379814
include .	0.037037037037037035
some linguistic	0.012048192771084338
linguistic knowledge	0.0625
knowledge comes	0.037037037037037035
comes into	0.2
into play	0.01282051282051282
play in	1.0
this step	0.01098901098901099
play	2.7900228781876013e-05
How should	0.14285714285714285
should we	0.05263157894736842
we create	0.044444444444444446
create edges	0.058823529411764705
edges ?	0.2857142857142857
created based	0.14285714285714285
on word	0.0047169811320754715
word co-occurrence	0.016666666666666666
co-occurrence in	0.3333333333333333
this application	0.01098901098901099
application of	0.2857142857142857
of TextRank	0.00089126559714795
TextRank .	0.07142857142857142
co-occurrence	8.370068634562804e-05
Two vertices	0.14285714285714285
vertices are	0.1111111111111111
are connected	0.004149377593360996
connected by	0.2
by an	0.011428571428571429
an edge	0.015151515151515152
edge if	0.3333333333333333
unigrams appear	0.08333333333333333
appear within	0.0625
within a	0.2777777777777778
a window	0.001226993865030675
window of	1.0
of size	0.00089126559714795
size N	0.16666666666666666
N in	0.3333333333333333
edge	8.370068634562804e-05
window	5.5800457563752025e-05
N	8.370068634562804e-05
<s> N	0.0007686395080707148
N is	0.3333333333333333
typically around	0.05555555555555555
around 2	0.125
2 --	0.2
-- 10	0.04
10 .	0.125
around	0.0002232018302550081
2	0.00013950114390938006
'' and	0.06701030927835051
'' might	0.010309278350515464
be linked	0.008438818565400843
linked in	0.3333333333333333
text about	0.012578616352201259
about NLP	0.025
linked	8.370068634562804e-05
<s> ``	0.003843197540353574
`` Natural	0.005291005291005291
Natural ''	0.07692307692307693
would also	0.018867924528301886
linked because	0.3333333333333333
because they	0.13333333333333333
they would	0.025
would both	0.018867924528301886
both appear	0.03225806451612903
same string	0.04
string of	1.0
of N	0.00089126559714795
N words	0.3333333333333333
string	0.00011160091512750405
These edges	0.058823529411764705
edges build	0.14285714285714285
build on	0.3333333333333333
`` text	0.005291005291005291
text cohesion	0.006289308176100629
cohesion ''	1.0
the idea	0.001384083044982699
idea that	0.2857142857142857
words that	0.009174311926605505
appear near	0.0625
near each	1.0
other are	0.014285714285714285
likely related	0.0625
related in	0.06666666666666667
a meaningful	0.00245398773006135
meaningful way	0.125
way and	0.041666666666666664
`` recommend	0.010582010582010581
recommend ''	1.0
'' each	0.005154639175257732
other to	0.014285714285714285
the reader	0.002768166089965398
reader .	0.2
cohesion	2.7900228781876013e-05
near	2.7900228781876013e-05
recommend	5.5800457563752025e-05
reader	0.00027900228781876013
How are	0.2857142857142857
the final	0.002768166089965398
final keyphrases	0.2222222222222222
keyphrases formed	0.02857142857142857
formed ?	0.4
formed	0.00013950114390938006
Since this	0.2
this method	0.01098901098901099
method simply	0.0625
simply ranks	0.08333333333333333
ranks the	0.5
the individual	0.001384083044982699
individual vertices	0.08333333333333333
vertices ,	0.1111111111111111
to threshold	0.0013280212483399733
threshold or	0.5
or produce	0.0045045045045045045
a limited	0.00245398773006135
The technique	0.005208333333333333
technique chosen	0.14285714285714285
chosen is	0.2
to set	0.00398406374501992
set a	0.05128205128205128
a count	0.001226993865030675
count T	0.2
T to	0.16666666666666666
a user-specified	0.001226993865030675
user-specified fraction	0.5
fraction of	1.0
the total	0.0006920415224913495
total number	0.5
of vertices	0.00089126559714795
vertices in	0.1111111111111111
graph .	0.15384615384615385
chosen	0.00013950114390938006
count	0.00013950114390938006
T	0.00016740137269125608
user-specified	5.5800457563752025e-05
fraction	2.7900228781876013e-05
total	5.5800457563752025e-05
Then the	0.4
the top	0.002768166089965398
top T	0.4
T vertices\/unigrams	0.16666666666666666
vertices\/unigrams are	1.0
are selected	0.004149377593360996
selected based	0.5
on their	0.009433962264150943
their stationary	0.029411764705882353
stationary probabilities	0.14285714285714285
probabilities .	0.18181818181818182
top	0.00013950114390938006
vertices\/unigrams	2.7900228781876013e-05
selected	5.5800457563752025e-05
A post	0.02
post -	1.0
- processing	0.0625
processing step	0.018518518518518517
step is	0.06666666666666667
to merge	0.0013280212483399733
merge adjacent	1.0
adjacent instances	0.16666666666666666
instances of	0.6666666666666666
these T	0.023809523809523808
T unigrams	0.3333333333333333
unigrams .	0.16666666666666666
post	2.7900228781876013e-05
merge	2.7900228781876013e-05
instances	8.370068634562804e-05
, potentially	0.0005614823133071309
potentially more	0.3333333333333333
more or	0.031578947368421054
less than	0.25
than T	0.022222222222222223
T final	0.16666666666666666
keyphrases will	0.02857142857142857
be produced	0.004219409282700422
produced ,	0.1111111111111111
number should	0.023255813953488372
be roughly	0.004219409282700422
roughly proportional	0.3333333333333333
proportional to	1.0
potentially	8.370068634562804e-05
roughly	8.370068634562804e-05
proportional	2.7900228781876013e-05
<s> Why	0.0015372790161414297
Why it	0.14285714285714285
it works	0.008547008547008548
works It	0.5
not initially	0.008928571428571428
initially clear	1.0
clear why	0.25
why applying	0.14285714285714285
applying PageRank	0.5
PageRank to	0.3333333333333333
a co-occurrence	0.001226993865030675
co-occurrence graph	0.6666666666666666
graph would	0.07692307692307693
produce useful	0.045454545454545456
useful keyphrases	0.07142857142857142
works	5.5800457563752025e-05
initially	2.7900228781876013e-05
clear	0.00011160091512750405
One way	0.07692307692307693
to think	0.0013280212483399733
think about	0.3333333333333333
about it	0.025
think	8.370068634562804e-05
A word	0.02
word that	0.03333333333333333
that appears	0.0035460992907801418
appears multiple	0.2
multiple times	0.07692307692307693
times throughout	0.2
throughout a	1.0
text may	0.006289308176100629
may have	0.038461538461538464
different co-occurring	0.02040816326530612
co-occurring neighbors	1.0
neighbors .	0.3333333333333333
throughout	2.7900228781876013e-05
co-occurring	2.7900228781876013e-05
about machine	0.025
the unigram	0.0006920415224913495
unigram ``	0.2
`` learning	0.021164021164021163
learning ''	0.11627906976744186
might co-occur	0.038461538461538464
co-occur with	0.5
`` machine	0.005291005291005291
machine ''	0.012658227848101266
, supervised	0.0005614823133071309
supervised ''	0.1875
`` un-supervised	0.005291005291005291
un-supervised ''	1.0
`` semi-supervised	0.005291005291005291
semi-supervised ''	0.5
different sentences	0.061224489795918366
co-occur	5.5800457563752025e-05
un-supervised	2.7900228781876013e-05
'' vertex	0.005154639175257732
vertex would	0.3333333333333333
a central	0.001226993865030675
central ``	0.3333333333333333
`` hub	0.005291005291005291
hub ''	1.0
that connects	0.0035460992907801418
connects to	1.0
these other	0.023809523809523808
other modifying	0.014285714285714285
modifying words	1.0
hub	2.7900228781876013e-05
connects	2.7900228781876013e-05
modifying	2.7900228781876013e-05
<s> Running	0.0007686395080707148
Running PageRank\/TextRank	1.0
PageRank\/TextRank on	1.0
is likely	0.006097560975609756
rank ``	0.16666666666666666
'' highly	0.005154639175257732
highly .	0.1111111111111111
Running	2.7900228781876013e-05
PageRank\/TextRank	2.7900228781876013e-05
<s> Similarly	0.0007686395080707148
Similarly ,	1.0
text contains	0.006289308176100629
phrase ``	0.1
`` supervised	0.026455026455026454
supervised classification	0.125
classification ''	0.29411764705882354
then there	0.02857142857142857
there would	0.025
be an	0.004219409282700422
edge between	0.3333333333333333
between ``	0.02564102564102564
`` classification	0.015873015873015872
Similarly	2.7900228781876013e-05
If ``	0.1
'' appears	0.005154639175257732
appears several	0.2
several other	0.045454545454545456
other places	0.014285714285714285
places and	0.5
thus has	0.1
has many	0.023809523809523808
many neighbors	0.019230769230769232
neighbors ,	0.3333333333333333
is importance	0.0020325203252032522
importance would	0.16666666666666666
would contribute	0.018867924528301886
contribute to	1.0
the importance	0.001384083044982699
importance of	0.5
importance	0.00016740137269125608
contribute	2.7900228781876013e-05
If it	0.1
it ends	0.017094017094017096
ends up	0.5
up with	0.13636363636363635
a high	0.0036809815950920245
high rank	0.05555555555555555
rank ,	0.16666666666666666
it will	0.017094017094017096
be selected	0.004219409282700422
selected as	0.5
as one	0.006968641114982578
, along	0.0005614823133071309
along with	1.0
and probably	0.001445086705202312
probably ``	0.25
ends	5.5800457563752025e-05
along	5.5800457563752025e-05
probably	0.00011160091512750405
final post-processing	0.1111111111111111
post-processing step	0.6666666666666666
would then	0.018867924528301886
then end	0.02857142857142857
end up	0.25
with keyphrases	0.00546448087431694
keyphrases ``	0.02857142857142857
post-processing	8.370068634562804e-05
In short	0.009523809523809525
short ,	0.125
the co-occurrence	0.0006920415224913495
graph will	0.15384615384615385
will contain	0.02857142857142857
contain densely	0.08333333333333333
densely connected	1.0
connected regions	0.2
regions for	0.5
for terms	0.0036101083032490976
terms that	0.07692307692307693
appear often	0.0625
often and	0.022727272727272728
different contexts	0.02040816326530612
contexts .	0.2857142857142857
densely	5.5800457563752025e-05
regions	5.5800457563752025e-05
A random	0.02
on this	0.014150943396226415
this graph	0.01098901098901099
will have	0.05714285714285714
a stationary	0.00245398773006135
distribution that	0.5
that assigns	0.0035460992907801418
assigns large	1.0
large probabilities	0.043478260869565216
probabilities to	0.09090909090909091
the terms	0.0006920415224913495
terms in	0.07692307692307693
the centers	0.0006920415224913495
centers of	1.0
the clusters	0.0006920415224913495
clusters .	1.0
assigns	2.7900228781876013e-05
centers	2.7900228781876013e-05
clusters	2.7900228781876013e-05
is similar	0.0040650406504065045
to densely	0.0013280212483399733
connected Web	0.2
pages getting	0.14285714285714285
getting ranked	0.25
ranked highly	0.4
highly by	0.1111111111111111
by PageRank	0.005714285714285714
PageRank .	0.16666666666666666
<s> Document	0.0015372790161414297
Document summarization	0.25
summarization Like	0.02
Like keyphrase	0.5
, document	0.0005614823133071309
summarization hopes	0.02
hopes to	1.0
Document	0.00011160091512750405
Like	5.5800457563752025e-05
hopes	2.7900228781876013e-05
The only	0.010416666666666666
only real	0.02631578947368421
real difference	0.1111111111111111
difference is	0.25
that now	0.0035460992907801418
now we	0.07692307692307693
are dealing	0.004149377593360996
dealing with	1.0
with larger	0.00546448087431694
larger text	0.0625
units --	0.14285714285714285
-- whole	0.04
sentences instead	0.013157894736842105
instead of	0.5714285714285714
and phrases	0.002890173410404624
dealing	5.5800457563752025e-05
<s> While	0.0023059185242121443
While some	0.2
some work	0.012048192771084338
work has	0.08333333333333333
been done	0.029411764705882353
done in	0.45454545454545453
in abstractive	0.0018726591760299626
abstractive summarization	0.3333333333333333
summarization -LRB-	0.04
-LRB- creating	0.0027100271002710027
an abstract	0.007575757575757576
abstract synopsis	1.0
synopsis like	1.0
like that	0.03571428571428571
the majority	0.0006920415224913495
majority of	1.0
are extractive	0.004149377593360996
extractive -LRB-	0.14285714285714285
-LRB- selecting	0.0027100271002710027
to place	0.0026560424966799467
place in	0.5
summary -RRB-	0.023809523809523808
abstract	2.7900228781876013e-05
synopsis	2.7900228781876013e-05
majority	2.7900228781876013e-05
place	0.00011160091512750405
<s> Before	0.0007686395080707148
Before getting	0.5
getting into	0.25
into the	0.10256410256410256
the details	0.0006920415224913495
details of	0.5
some summarization	0.012048192771084338
summarization methods	0.02
will mention	0.02857142857142857
mention how	0.3333333333333333
how summarization	0.034482758620689655
typically evaluated	0.05555555555555555
evaluated .	0.14285714285714285
Before	5.5800457563752025e-05
details	5.5800457563752025e-05
mention	8.370068634562804e-05
The most	0.026041666666666668
common way	0.08
way is	0.041666666666666664
is using	0.0040650406504065045
using the	0.1016949152542373
the so-called	0.0006920415224913495
so-called ROUGE	0.3333333333333333
ROUGE -LRB-	0.2
-LRB- Recall-Oriented	0.005420054200542005
Recall-Oriented Understudy	1.0
Understudy for	1.0
for Gisting	0.007220216606498195
Gisting Evaluation	1.0
Evaluation -RRB-	0.2222222222222222
-RRB- measure	0.0027100271002710027
measure -LRB-	0.09090909090909091
-LRB- http:\/\/haydn.isi.edu\/ROUGE\/	0.0027100271002710027
http:\/\/haydn.isi.edu\/ROUGE\/ -RRB-	1.0
so-called	8.370068634562804e-05
ROUGE	0.00013950114390938006
Recall-Oriented	5.5800457563752025e-05
Understudy	5.5800457563752025e-05
Gisting	5.5800457563752025e-05
http:\/\/haydn.isi.edu\/ROUGE\/	2.7900228781876013e-05
a recall-based	0.001226993865030675
recall-based measure	0.5
measure that	0.09090909090909091
that determines	0.0070921985815602835
determines how	0.3333333333333333
how well	0.20689655172413793
well a	0.03571428571428571
a system-generated	0.001226993865030675
system-generated summary	0.5
summary covers	0.023809523809523808
covers the	0.5
content present	0.08333333333333333
more human-generated	0.010526315789473684
human-generated model	0.5
model summaries	0.06666666666666667
summaries known	0.023255813953488372
as references	0.003484320557491289
references .	0.25
recall-based	5.5800457563752025e-05
system-generated	5.5800457563752025e-05
human-generated	5.5800457563752025e-05
is recall-based	0.0020325203252032522
recall-based to	0.5
to encourage	0.0013280212483399733
encourage systems	1.0
systems to	0.008928571428571428
include all	0.037037037037037035
the important	0.0006920415224913495
important topics	0.0625
topics in	0.14285714285714285
encourage	2.7900228781876013e-05
Recall can	0.3333333333333333
be computed	0.004219409282700422
computed with	0.5
to unigram	0.0013280212483399733
or 4-gram	0.0045045045045045045
4-gram matching	1.0
matching ,	0.2
though ROUGE-1	0.1
ROUGE-1 -LRB-	0.2
-LRB- unigram	0.0027100271002710027
unigram matching	0.2
matching -RRB-	0.2
-RRB- has	0.008130081300813009
been shown	0.014705882352941176
shown to	0.4
to correlate	0.0013280212483399733
correlate best	0.3333333333333333
best with	0.05555555555555555
with human	0.01092896174863388
human assessments	0.021739130434782608
assessments of	1.0
of system-generated	0.00089126559714795
system-generated summaries	0.5
the summaries	0.002768166089965398
summaries with	0.046511627906976744
with highest	0.01092896174863388
highest ROUGE-1	0.3333333333333333
ROUGE-1 values	0.2
values correlate	0.125
correlate with	0.6666666666666666
summaries humans	0.023255813953488372
humans deemed	0.08333333333333333
deemed the	0.5
best -RRB-	0.05555555555555555
computed	5.5800457563752025e-05
4-gram	2.7900228781876013e-05
ROUGE-1	0.00013950114390938006
correlate	8.370068634562804e-05
assessments	2.7900228781876013e-05
highest	8.370068634562804e-05
<s> ROUGE-1	0.0007686395080707148
ROUGE-1 is	0.2
is computed	0.0020325203252032522
computed as	0.5
as division	0.003484320557491289
division of	0.5
of count	0.00089126559714795
count of	0.4
of unigrams	0.0017825311942959
in reference	0.003745318352059925
reference that	0.125
in system	0.0018726591760299626
and count	0.001445086705202312
reference summary	0.375
division	5.5800457563752025e-05
If there	0.1
are multiple	0.004149377593360996
multiple references	0.07692307692307693
references ,	0.25
the ROUGE-1	0.0006920415224913495
ROUGE-1 scores	0.2
scores are	0.2
are averaged	0.004149377593360996
averaged .	1.0
averaged	2.7900228781876013e-05
<s> Because	0.0015372790161414297
Because ROUGE	0.5
ROUGE is	0.4
based only	0.018518518518518517
on content	0.0047169811320754715
content overlap	0.16666666666666666
overlap ,	0.25
determine if	0.21739130434782608
same general	0.04
general concepts	0.045454545454545456
concepts are	0.4
are discussed	0.004149377593360996
discussed between	0.14285714285714285
between an	0.02564102564102564
an automatic	0.015151515151515152
automatic summary	0.08695652173913043
summary and	0.047619047619047616
a reference	0.00245398773006135
not determine	0.008928571428571428
result is	0.18181818181818182
is coherent	0.0020325203252032522
coherent or	0.2
sentences flow	0.013157894736842105
flow together	1.0
together in	0.125
a sensible	0.001226993865030675
sensible manner	1.0
Because	5.5800457563752025e-05
overlap	0.00011160091512750405
flow	2.7900228781876013e-05
sensible	2.7900228781876013e-05
<s> High-order	0.0007686395080707148
High-order n-gram	1.0
n-gram ROUGE	0.5
ROUGE measures	0.2
measures try	0.16666666666666666
try to	1.0
to judge	0.0026560424966799467
judge fluency	0.25
fluency to	1.0
some degree	0.024096385542168676
degree .	0.16666666666666666
High-order	2.7900228781876013e-05
n-gram	5.5800457563752025e-05
try	8.370068634562804e-05
fluency	2.7900228781876013e-05
that ROUGE	0.0035460992907801418
the BLEU	0.0006920415224913495
BLEU measure	0.3333333333333333
measure for	0.09090909090909091
but BLEU	0.014705882352941176
BLEU is	0.3333333333333333
is precision	0.0020325203252032522
precision -	0.2
- based	0.1875
because translation	0.03333333333333333
systems favor	0.008928571428571428
favor accuracy	0.5
BLEU	8.370068634562804e-05
A promising	0.02
promising line	1.0
line in	0.3333333333333333
in document	0.003745318352059925
is adaptive	0.0020325203252032522
adaptive document\/text	0.3333333333333333
document\/text summarization	0.5
promising	2.7900228781876013e-05
line	8.370068634562804e-05
adaptive	8.370068634562804e-05
document\/text	5.5800457563752025e-05
of adaptive	0.00089126559714795
adaptive summarization	0.6666666666666666
summarization involves	0.02
involves preliminary	0.1
preliminary recognition	0.3333333333333333
of document\/text	0.00089126559714795
document\/text genre	0.5
genre and	0.5
and subsequent	0.001445086705202312
subsequent application	0.5
summarization algorithms	0.02
algorithms optimized	0.02857142857142857
optimized for	1.0
this genre	0.01098901098901099
genre .	0.5
preliminary	8.370068634562804e-05
genre	5.5800457563752025e-05
subsequent	5.5800457563752025e-05
optimized	2.7900228781876013e-05
<s> First	0.0007686395080707148
First summarizes	1.0
summarizes that	1.0
that perform	0.0035460992907801418
perform adaptive	0.09090909090909091
summarization have	0.02
been created	0.029411764705882353
created .	0.14285714285714285
First	2.7900228781876013e-05
summarizes	2.7900228781876013e-05
<s> Overview	0.0015372790161414297
Overview of	1.0
of supervised	0.00089126559714795
learning approaches	0.023255813953488372
approaches Supervised	0.03571428571428571
Supervised text	1.0
text summarization	0.006289308176100629
very much	0.024390243902439025
much like	0.045454545454545456
like supervised	0.03571428571428571
and we	0.001445086705202312
will not	0.11428571428571428
not spend	0.008928571428571428
spend much	1.0
much time	0.045454545454545456
time on	0.030303030303030304
on it	0.0047169811320754715
Overview	5.5800457563752025e-05
Supervised	2.7900228781876013e-05
spend	2.7900228781876013e-05
<s> Basically	0.0007686395080707148
Basically ,	1.0
if you	0.07142857142857142
you have	0.15384615384615385
a collection	0.00245398773006135
collection of	0.4
documents and	0.02631578947368421
and human-generated	0.001445086705202312
human-generated summaries	0.5
summaries for	0.023255813953488372
for them	0.007220216606498195
them ,	0.21052631578947367
, you	0.0005614823133071309
can learn	0.0055248618784530384
learn features	0.07692307692307693
make them	0.05
them good	0.05263157894736842
good candidates	0.23076923076923078
candidates for	0.2
for inclusion	0.0036101083032490976
inclusion in	1.0
Basically	2.7900228781876013e-05
collection	0.00013950114390938006
inclusion	2.7900228781876013e-05
<s> Features	0.0007686395080707148
Features might	1.0
might include	0.038461538461538464
include the	0.18518518518518517
the position	0.0006920415224913495
position in	0.5
the document	0.004152249134948097
document -LRB-	0.05555555555555555
first few	0.030303030303030304
few sentences	1.0
are probably	0.004149377593360996
probably important	0.25
important -RRB-	0.0625
Features	2.7900228781876013e-05
few	2.7900228781876013e-05
The main	0.015625
main difficulty	0.25
difficulty in	0.2857142857142857
in supervised	0.0018726591760299626
supervised extractive	0.0625
extractive summarization	0.42857142857142855
known summaries	0.038461538461538464
summaries must	0.023255813953488372
must be	0.42857142857142855
be manually	0.004219409282700422
manually created	0.25
created by	0.2857142857142857
by extracting	0.005714285714285714
extracting sentences	0.2
sentences so	0.013157894736842105
an original	0.007575757575757576
original training	0.07692307692307693
training document	0.03571428571428571
document can	0.027777777777777776
be labeled	0.004219409282700422
labeled as	0.3333333333333333
`` in	0.010582010582010581
in summary	0.003745318352059925
summary ''	0.047619047619047616
`` not	0.005291005291005291
not in	0.008928571428571428
not typically	0.017857142857142856
typically how	0.05555555555555555
how people	0.034482758620689655
people create	0.0625
create summaries	0.058823529411764705
summaries ,	0.06976744186046512
so simply	0.03333333333333333
simply using	0.08333333333333333
using journal	0.01694915254237288
journal abstracts	0.3333333333333333
abstracts or	0.5
or existing	0.0045045045045045045
existing summaries	0.2
is usually	0.016260162601626018
usually not	0.03125
not sufficient	0.008928571428571428
sufficient .	0.6
sufficient	0.00013950114390938006
The sentences	0.005208333333333333
in these	0.0056179775280898875
these summaries	0.047619047619047616
summaries do	0.023255813953488372
necessarily match	0.5
match up	0.16666666666666666
with sentences	0.00546448087431694
so it	0.06666666666666667
would difficult	0.018867924528301886
to assign	0.00398406374501992
assign labels	0.2
to examples	0.0013280212483399733
examples for	0.041666666666666664
training .	0.03571428571428571
Note ,	0.1111111111111111
these natural	0.023809523809523808
natural summaries	0.013333333333333334
summaries can	0.046511627906976744
can still	0.0055248618784530384
still be	0.06666666666666667
for evaluation	0.0036101083032490976
evaluation purposes	0.018518518518518517
purposes ,	0.25
since ROUGE-1	0.1
ROUGE-1 only	0.2
only cares	0.02631578947368421
cares about	1.0
about unigrams	0.025
cares	2.7900228781876013e-05
Unsupervised approaches	0.16666666666666666
TextRank and	0.14285714285714285
and LexRank	0.004335260115606936
LexRank The	0.08333333333333333
The unsupervised	0.005208333333333333
unsupervised approach	0.125
to summarization	0.0026560424966799467
also quite	0.014492753623188406
quite similar	0.125
similar in	0.037037037037037035
in spirit	0.0018726591760299626
spirit to	1.0
unsupervised keyphrase	0.125
and gets	0.001445086705202312
gets around	0.5
around the	0.375
issue of	0.125
of costly	0.00089126559714795
costly training	1.0
LexRank	0.00033480274538251215
spirit	2.7900228781876013e-05
gets	5.5800457563752025e-05
costly	2.7900228781876013e-05
Some unsupervised	0.047619047619047616
unsupervised summarization	0.25
summarization approaches	0.02
approaches are	0.03571428571428571
on finding	0.0047169811320754715
`` centroid	0.005291005291005291
centroid ''	0.5
'' sentence	0.005154639175257732
the mean	0.0006920415224913495
mean word	0.5
word vector	0.016666666666666666
vector of	0.3333333333333333
centroid	5.5800457563752025e-05
vector	8.370068634562804e-05
sentences can	0.039473684210526314
be ranked	0.004219409282700422
ranked with	0.2
with regard	0.02185792349726776
regard to	0.8
their similarity	0.029411764705882353
similarity to	0.1
this centroid	0.01098901098901099
centroid sentence	0.5
regard	0.00013950114390938006
A more	0.02
more principled	0.010526315789473684
principled way	1.0
estimate sentence	0.25
sentence importance	0.020833333333333332
importance is	0.16666666666666666
using random	0.01694915254237288
random walks	0.2857142857142857
walks and	0.5
and eigenvector	0.001445086705202312
eigenvector centrality	0.5
centrality .	0.5
principled	2.7900228781876013e-05
walks	5.5800457563752025e-05
centrality	5.5800457563752025e-05
<s> LexRank	0.0015372790161414297
LexRank is	0.08333333333333333
algorithm essentially	0.03571428571428571
essentially identical	0.125
to TextRank	0.0013280212483399733
TextRank ,	0.14285714285714285
and both	0.001445086705202312
both use	0.03225806451612903
use this	0.027777777777777776
approach for	0.02857142857142857
for document	0.0036101083032490976
two methods	0.034482758620689655
methods were	0.045454545454545456
developed by	0.038461538461538464
by different	0.005714285714285714
different groups	0.02040816326530612
groups at	0.2
same time	0.12
LexRank simply	0.08333333333333333
simply focused	0.08333333333333333
on summarization	0.0047169811320754715
but could	0.014705882352941176
could just	0.0625
just as	0.2222222222222222
as easily	0.006968641114982578
easily be	0.1111111111111111
for keyphrase	0.0036101083032490976
extraction or	0.03225806451612903
any other	0.06451612903225806
other NLP	0.014285714285714285
NLP ranking	0.02127659574468085
ranking task	0.14285714285714285
groups	0.00013950114390938006
just	0.0002511020590368841
the vertices	0.0006920415224913495
vertices ?	0.1111111111111111
In both	0.01904761904761905
both LexRank	0.03225806451612903
LexRank and	0.08333333333333333
and TextRank	0.001445086705202312
constructed by	0.5
by creating	0.005714285714285714
creating a	0.2857142857142857
each sentence	0.022222222222222223
sentence in	0.041666666666666664
The edges	0.005208333333333333
edges between	0.14285714285714285
some form	0.04819277108433735
semantic similarity	0.047619047619047616
similarity or	0.1
or content	0.0045045045045045045
overlap .	0.25
While LexRank	0.2
LexRank uses	0.08333333333333333
uses cosine	0.07142857142857142
cosine similarity	0.3333333333333333
similarity of	0.1
of TF-IDF	0.00089126559714795
TF-IDF vectors	1.0
vectors ,	0.3333333333333333
TextRank uses	0.14285714285714285
very similar	0.0975609756097561
similar measure	0.037037037037037035
measure based	0.09090909090909091
words two	0.009174311926605505
two sentences	0.06896551724137931
have in	0.019230769230769232
common -LRB-	0.04
-LRB- normalized	0.0027100271002710027
normalized by	1.0
sentences '	0.013157894736842105
' lengths	0.05263157894736842
lengths -RRB-	1.0
cosine	8.370068634562804e-05
TF-IDF	2.7900228781876013e-05
vectors	8.370068634562804e-05
normalized	2.7900228781876013e-05
lengths	2.7900228781876013e-05
The LexRank	0.005208333333333333
LexRank paper	0.08333333333333333
paper explored	0.09090909090909091
explored using	0.5
using unweighted	0.01694915254237288
unweighted edges	1.0
edges after	0.14285714285714285
after applying	0.08333333333333333
applying a	0.25
threshold to	0.25
the cosine	0.0006920415224913495
cosine values	0.3333333333333333
values ,	0.125
also experimented	0.014492753623188406
experimented with	1.0
with using	0.00546448087431694
using edges	0.01694915254237288
edges with	0.14285714285714285
with weights	0.00546448087431694
weights equal	0.2
equal to	1.0
the similarity	0.0006920415224913495
similarity score	0.1
score .	0.5
explored	5.5800457563752025e-05
unweighted	2.7900228781876013e-05
experimented	2.7900228781876013e-05
equal	2.7900228781876013e-05
score	0.00016740137269125608
uses continuous	0.07142857142857142
continuous similarity	0.16666666666666666
similarity scores	0.1
scores as	0.2
as weights	0.003484320557491289
weights .	0.4
are summaries	0.004149377593360996
summaries formed	0.023255813953488372
both algorithms	0.03225806451612903
are ranked	0.004149377593360996
ranked by	0.2
by applying	0.005714285714285714
resulting graph	0.25
A summary	0.02
summary is	0.047619047619047616
is formed	0.0020325203252032522
formed by	0.2
by combining	0.005714285714285714
combining the	0.25
top ranking	0.2
ranking sentences	0.14285714285714285
or length	0.0045045045045045045
length cutoff	0.125
cutoff to	1.0
the size	0.001384083044982699
size of	0.16666666666666666
combining	0.00011160091512750405
cutoff	2.7900228781876013e-05
LexRank differences	0.08333333333333333
differences It	0.3333333333333333
is worth	0.0040650406504065045
worth noting	0.5
noting that	1.0
that TextRank	0.0070921985815602835
TextRank was	0.14285714285714285
was applied	0.012987012987012988
summarization exactly	0.02
exactly as	0.3333333333333333
as described	0.006968641114982578
described here	0.16666666666666666
here ,	0.5
while LexRank	0.1
LexRank was	0.08333333333333333
was used	0.05194805194805195
as part	0.006968641114982578
larger summarization	0.0625
summarization system	0.06
system -LRB-	0.021505376344086023
-LRB- MEAD	0.0027100271002710027
MEAD -RRB-	1.0
that combines	0.0035460992907801418
combines the	1.0
the LexRank	0.0006920415224913495
LexRank score	0.08333333333333333
score -LRB-	0.16666666666666666
-LRB- stationary	0.0027100271002710027
stationary probability	0.14285714285714285
probability -RRB-	0.2857142857142857
-RRB- with	0.008130081300813009
with other	0.00546448087431694
other features	0.014285714285714285
features like	0.038461538461538464
like sentence	0.03571428571428571
sentence position	0.041666666666666664
position and	0.25
and length	0.001445086705202312
length using	0.125
a linear	0.00245398773006135
linear combination	0.14285714285714285
combination with	0.4
with either	0.00546448087431694
either user-specified	0.1
user-specified or	0.5
or automatically	0.009009009009009009
automatically tuned	0.047619047619047616
tuned weights	1.0
worth	5.5800457563752025e-05
noting	2.7900228781876013e-05
here	5.5800457563752025e-05
MEAD	2.7900228781876013e-05
combines	2.7900228781876013e-05
tuned	2.7900228781876013e-05
this case	0.01098901098901099
case ,	0.17647058823529413
some training	0.012048192771084338
documents might	0.02631578947368421
be needed	0.004219409282700422
needed ,	0.047619047619047616
though the	0.1
TextRank results	0.07142857142857142
results show	0.047619047619047616
show the	1.0
the additional	0.0006920415224913495
additional features	0.16666666666666666
are not	0.02074688796680498
not absolutely	0.008928571428571428
absolutely necessary	1.0
necessary .	0.1
show	2.7900228781876013e-05
absolutely	2.7900228781876013e-05
Another important	0.07692307692307693
important distinction	0.125
for single	0.0036101083032490976
single document	0.07142857142857142
LexRank has	0.08333333333333333
to multi-document	0.0013280212483399733
task remains	0.023809523809523808
remains the	0.25
same in	0.04
in both	0.0018726591760299626
both cases	0.03225806451612903
cases --	0.05555555555555555
-- only	0.04
to choose	0.0013280212483399733
choose from	0.5
from has	0.009615384615384616
has grown	0.011904761904761904
grown .	1.0
remains	0.00011160091512750405
choose	5.5800457563752025e-05
grown	2.7900228781876013e-05
when summarizing	0.02857142857142857
summarizing multiple	1.0
multiple documents	0.15384615384615385
a greater	0.001226993865030675
greater risk	0.3333333333333333
risk of	0.5
of selecting	0.00089126559714795
selecting duplicate	0.2
duplicate or	0.5
or highly	0.0045045045045045045
highly redundant	0.1111111111111111
redundant sentences	1.0
same summary	0.04
summarizing	2.7900228781876013e-05
greater	8.370068634562804e-05
risk	5.5800457563752025e-05
duplicate	5.5800457563752025e-05
redundant	2.7900228781876013e-05
<s> Imagine	0.0007686395080707148
Imagine you	1.0
articles on	0.125
particular event	0.07692307692307693
you want	0.07692307692307693
produce one	0.045454545454545456
one summary	0.015384615384615385
Imagine	2.7900228781876013e-05
<s> Each	0.003843197540353574
Each article	0.16666666666666666
article is	0.034482758620689655
many similar	0.019230769230769232
similar sentences	0.1111111111111111
you would	0.07692307692307693
would only	0.018867924528301886
only want	0.02631578947368421
include distinct	0.037037037037037035
distinct ideas	0.14285714285714285
Each	0.00016740137269125608
To address	0.1111111111111111
address this	0.25
this issue	0.01098901098901099
issue ,	0.125
, LexRank	0.0005614823133071309
LexRank applies	0.08333333333333333
applies a	0.2857142857142857
a heuristic	0.00245398773006135
heuristic post-processing	0.3333333333333333
that builds	0.0035460992907801418
builds up	0.5
up a	0.09090909090909091
summary by	0.023809523809523808
by adding	0.011428571428571429
adding sentences	0.5
in rank	0.0018726591760299626
rank order	0.16666666666666666
order ,	0.14285714285714285
but discards	0.014705882352941176
discards any	1.0
any sentences	0.03225806451612903
are too	0.004149377593360996
too similar	0.16666666666666666
to ones	0.0013280212483399733
ones already	0.1
already placed	0.2
address	0.00011160091512750405
applies	0.0001953016014731321
heuristic	8.370068634562804e-05
adding	5.5800457563752025e-05
discards	2.7900228781876013e-05
The method	0.005208333333333333
method used	0.0625
used is	0.008849557522123894
called Cross-Sentence	0.05555555555555555
Cross-Sentence Information	1.0
Information Subsumption	0.2
Subsumption -LRB-	1.0
-LRB- CSIS	0.0027100271002710027
CSIS -RRB-	0.5
Cross-Sentence	2.7900228781876013e-05
Subsumption	2.7900228781876013e-05
CSIS	5.5800457563752025e-05
Why unsupervised	0.14285714285714285
summarization works	0.02
works These	0.5
work based	0.041666666666666664
that sentences	0.0035460992907801418
sentences ``	0.02631578947368421
'' other	0.005154639175257732
other similar	0.014285714285714285
if one	0.03571428571428571
one sentence	0.03076923076923077
to many	0.005312084993359893
many others	0.019230769230769232
others ,	0.08333333333333333
will likely	0.05714285714285714
likely be	0.0625
sentence of	0.020833333333333332
of great	0.00089126559714795
great importance	0.3333333333333333
importance .	0.16666666666666666
The importance	0.005208333333333333
this sentence	0.01098901098901099
sentence also	0.020833333333333332
also stems	0.014492753623188406
stems from	0.5
`` recommending	0.005291005291005291
recommending ''	1.0
'' it	0.005154639175257732
stems	5.5800457563752025e-05
recommending	2.7900228781876013e-05
get ranked	0.14285714285714285
highly and	0.1111111111111111
and placed	0.001445086705202312
sentence must	0.020833333333333332
be similar	0.004219409282700422
many sentences	0.019230769230769232
are in	0.012448132780082987
in turn	0.009363295880149813
turn also	0.16666666666666666
also similar	0.014492753623188406
other sentences	0.014285714285714285
turn	0.00016740137269125608
This makes	0.015873015873015872
makes intuitive	0.125
intuitive sense	1.0
sense and	0.125
and allows	0.002890173410404624
allows the	0.375
be applied	0.012658227848101266
to any	0.00398406374501992
arbitrary new	0.3333333333333333
intuitive	2.7900228781876013e-05
The methods	0.010416666666666666
are domain-independent	0.004149377593360996
domain-independent and	1.0
and easily	0.001445086705202312
portable .	0.3333333333333333
domain-independent	2.7900228781876013e-05
One could	0.07692307692307693
could imagine	0.0625
imagine the	1.0
features indicating	0.038461538461538464
indicating important	1.0
important sentences	0.125
the news	0.001384083044982699
news domain	0.23076923076923078
domain might	0.05
might vary	0.038461538461538464
vary considerably	0.16666666666666666
considerably from	1.0
the biomedical	0.0006920415224913495
biomedical domain	1.0
domain .	0.3
imagine	2.7900228781876013e-05
indicating	2.7900228781876013e-05
vary	0.00016740137269125608
considerably	2.7900228781876013e-05
biomedical	2.7900228781876013e-05
the unsupervised	0.0006920415224913495
unsupervised ``	0.125
'' -	0.010309278350515464
based approach	0.018518518518518517
approach applies	0.02857142857142857
applies to	0.14285714285714285
any domain	0.03225806451612903
<s> Incorporating	0.0007686395080707148
Incorporating diversity	1.0
diversity :	0.25
: GRASSHOPPER	0.00980392156862745
GRASSHOPPER algorithm	0.3333333333333333
algorithm As	0.03571428571428571
As mentioned	0.16666666666666666
mentioned above	0.16666666666666666
, multi-document	0.0005614823133071309
multi-document extractive	0.25
summarization faces	0.02
faces a	1.0
a problem	0.0036809815950920245
potential redundancy	0.14285714285714285
redundancy .	0.3333333333333333
Incorporating	2.7900228781876013e-05
diversity	0.00011160091512750405
GRASSHOPPER	8.370068634562804e-05
faces	2.7900228781876013e-05
redundancy	8.370068634562804e-05
would like	0.03773584905660377
like to	0.07142857142857142
extract sentences	0.25
are both	0.008298755186721992
both ``	0.06451612903225806
, contain	0.0005614823133071309
contain the	0.16666666666666666
the main	0.001384083044982699
main ideas	0.125
ideas -RRB-	0.25
`` diverse	0.005291005291005291
diverse ''	0.5
they differ	0.025
differ from	0.3333333333333333
one another	0.015384615384615385
another -RRB-	0.07692307692307693
diverse	5.5800457563752025e-05
LexRank deals	0.08333333333333333
deals with	1.0
with diversity	0.00546448087431694
diversity as	0.25
heuristic final	0.3333333333333333
final stage	0.1111111111111111
stage using	0.2
using CSIS	0.01694915254237288
CSIS ,	0.5
systems have	0.044642857142857144
used similar	0.008849557522123894
similar methods	0.037037037037037035
as Maximal	0.003484320557491289
Maximal Marginal	1.0
Marginal Relevance	1.0
Relevance -LRB-	1.0
-LRB- MMR	0.0027100271002710027
MMR -RRB-	1.0
in trying	0.0018726591760299626
to eliminate	0.0026560424966799467
eliminate redundancy	0.5
redundancy in	0.6666666666666666
in information	0.0018726591760299626
retrieval results	0.14285714285714285
deals	0.00011160091512750405
stage	0.00013950114390938006
Maximal	2.7900228781876013e-05
Marginal	2.7900228781876013e-05
Relevance	2.7900228781876013e-05
MMR	2.7900228781876013e-05
eliminate	5.5800457563752025e-05
We have	0.14285714285714285
have developed	0.009615384615384616
developed a	0.11538461538461539
algorithm like	0.03571428571428571
like Page\/Lex\/TextRank	0.03571428571428571
Page\/Lex\/TextRank that	1.0
that handles	0.0035460992907801418
handles both	1.0
`` centrality	0.005291005291005291
centrality ''	0.5
`` diversity	0.005291005291005291
diversity ''	0.25
a unified	0.001226993865030675
unified mathematical	1.0
mathematical framework	0.5
framework based	0.25
on absorbing	0.0047169811320754715
absorbing Markov	0.3333333333333333
Markov chain	0.05555555555555555
chain random	1.0
walks .	0.5
Page\/Lex\/TextRank	2.7900228781876013e-05
handles	2.7900228781876013e-05
unified	2.7900228781876013e-05
framework	0.00011160091512750405
absorbing	8.370068634562804e-05
chain	2.7900228781876013e-05
An absorbing	0.0625
absorbing random	0.3333333333333333
walk is	0.2
is like	0.0040650406504065045
like a	0.07142857142857142
standard random	0.07142857142857142
walk ,	0.2
, except	0.0005614823133071309
except some	1.0
some states	0.012048192771084338
states are	0.25
are now	0.016597510373443983
now absorbing	0.07692307692307693
absorbing states	0.3333333333333333
states that	0.25
that act	0.0035460992907801418
act as	0.75
`` black	0.005291005291005291
black holes	1.0
holes ''	1.0
that cause	0.0035460992907801418
cause the	0.5
the walk	0.0006920415224913495
walk to	0.2
to end	0.0026560424966799467
end abruptly	0.125
abruptly at	1.0
at that	0.014705882352941176
that state	0.0035460992907801418
state .	0.07142857142857142
except	2.7900228781876013e-05
states	0.00011160091512750405
black	2.7900228781876013e-05
holes	2.7900228781876013e-05
cause	5.5800457563752025e-05
abruptly	2.7900228781876013e-05
state	0.0003906032029462642
The algorithm	0.005208333333333333
called GRASSHOPPER	0.05555555555555555
GRASSHOPPER for	0.3333333333333333
for reasons	0.0036101083032490976
reasons that	0.5
that should	0.0070921985815602835
should soon	0.05263157894736842
soon become	0.3333333333333333
become clear	0.25
clear .	0.25
reasons	5.5800457563752025e-05
soon	8.370068634562804e-05
addition to	0.5
to explicitly	0.0026560424966799467
explicitly promoting	0.25
promoting diversity	1.0
diversity during	0.25
ranking process	0.14285714285714285
process ,	0.027777777777777776
, GRASSHOPPER	0.0005614823133071309
GRASSHOPPER incorporates	0.3333333333333333
incorporates a	1.0
a prior	0.001226993865030675
prior ranking	0.3333333333333333
ranking -LRB-	0.14285714285714285
on sentence	0.0047169811320754715
summarization -RRB-	0.02
promoting	2.7900228781876013e-05
incorporates	2.7900228781876013e-05
<s> Maximum	0.0015372790161414297
Maximum entropy-based	0.3333333333333333
entropy-based summarization	1.0
summarization It	0.02
abstractive method	0.16666666666666666
Maximum	8.370068634562804e-05
entropy-based	2.7900228781876013e-05
<s> Even	0.0007686395080707148
Even though	1.0
though automating	0.1
automating abstractive	1.0
summarization research	0.02
most practical	0.017241379310344827
practical systems	0.5
of extractive	0.00089126559714795
Even	2.7900228781876013e-05
automating	2.7900228781876013e-05
practical	5.5800457563752025e-05
<s> Extracted	0.0007686395080707148
Extracted sentences	1.0
can form	0.0055248618784530384
a valid	0.001226993865030675
valid summary	1.0
summary in	0.047619047619047616
in itself	0.0018726591760299626
itself or	0.2
or form	0.0045045045045045045
basis for	0.3333333333333333
for further	0.010830324909747292
further condensation	0.125
condensation operations	1.0
operations .	1.0
Extracted	2.7900228781876013e-05
valid	2.7900228781876013e-05
condensation	2.7900228781876013e-05
operations	2.7900228781876013e-05
, evaluation	0.0005614823133071309
of extracted	0.00089126559714795
extracted summaries	1.0
be automated	0.004219409282700422
automated ,	0.14285714285714285
since it	0.2
a classification	0.001226993865030675
classification task	0.058823529411764705
extracted	2.7900228781876013e-05
the DUC	0.0006920415224913495
DUC 2001	1.0
2001 and	0.5
and 2002	0.001445086705202312
2002 evaluation	0.5
evaluation workshops	0.018518518518518517
workshops ,	0.5
, TNO	0.0005614823133071309
TNO developed	1.0
sentence extraction	0.020833333333333332
for multi-document	0.0036101083032490976
summarization in	0.04
DUC	2.7900228781876013e-05
2001	5.5800457563752025e-05
2002	5.5800457563752025e-05
workshops	5.5800457563752025e-05
TNO	2.7900228781876013e-05
The system	0.03125
system was	0.053763440860215055
was based	0.012987012987012988
hybrid system	0.5
system using	0.010752688172043012
a naive	0.001226993865030675
naive Bayes	0.5
Bayes classifier	0.3333333333333333
classifier and	0.14285714285714285
statistical language	0.030303030303030304
for modeling	0.0036101083032490976
modeling salience	0.14285714285714285
salience .	1.0
naive	5.5800457563752025e-05
salience	2.7900228781876013e-05
system exhibited	0.010752688172043012
exhibited good	1.0
good results	0.07692307692307693
results ,	0.09523809523809523
we wanted	0.022222222222222223
wanted to	1.0
to explore	0.0026560424966799467
explore the	0.25
the effectiveness	0.0006920415224913495
effectiveness of	0.3333333333333333
a maximum	0.00245398773006135
maximum entropy	0.5
entropy -LRB-	0.2
-LRB- ME	0.0027100271002710027
ME -RRB-	0.5
-RRB- classifier	0.0027100271002710027
classifier for	0.14285714285714285
the meeting	0.0006920415224913495
meeting summarization	1.0
summarization task	0.02
as ME	0.003484320557491289
ME is	0.5
is known	0.006097560975609756
known to	0.07692307692307693
be robust	0.004219409282700422
robust against	0.25
against feature	0.2
feature dependencies	0.07692307692307693
dependencies .	1.0
exhibited	2.7900228781876013e-05
wanted	2.7900228781876013e-05
explore	0.00011160091512750405
effectiveness	8.370068634562804e-05
maximum	0.00016740137269125608
entropy	0.00013950114390938006
ME	5.5800457563752025e-05
meeting	2.7900228781876013e-05
against	0.00013950114390938006
dependencies	5.5800457563752025e-05
Maximum entropy	0.6666666666666666
entropy has	0.2
has also	0.03571428571428571
also been	0.057971014492753624
applied successfully	0.06666666666666667
successfully for	0.3333333333333333
for summarization	0.0036101083032490976
the broadcast	0.0006920415224913495
broadcast news	1.0
successfully	8.370068634562804e-05
broadcast	2.7900228781876013e-05
<s> Aided	0.0007686395080707148
Aided summarization	0.3333333333333333
summarization Machine	0.02
Machine learning	0.1111111111111111
learning techniques	0.023255813953488372
techniques from	0.043478260869565216
from closely	0.009615384615384616
related fields	0.06666666666666667
fields such	0.16666666666666666
as information	0.003484320557491289
retrieval or	0.14285714285714285
or text	0.009009009009009009
text mining	0.012578616352201259
mining have	0.2
been successfully	0.014705882352941176
successfully adapted	0.3333333333333333
adapted to	1.0
to help	0.0026560424966799467
help automatic	0.1111111111111111
Aided	8.370068634562804e-05
adapted	2.7900228781876013e-05
<s> Apart	0.0007686395080707148
Apart from	1.0
from Fully	0.009615384615384616
Fully Automated	1.0
Automated Summarizers	0.5
Summarizers -LRB-	1.0
-LRB- FAS	0.0027100271002710027
FAS -RRB-	1.0
are systems	0.012448132780082987
systems that	0.0625
that aid	0.0035460992907801418
aid users	0.25
users with	0.1111111111111111
-LRB- MAHS	0.0027100271002710027
MAHS =	1.0
= Machine	0.1111111111111111
Machine Aided	0.1111111111111111
Aided Human	0.3333333333333333
Human Summarization	0.2
Summarization -RRB-	0.5
example by	0.024691358024691357
by highlighting	0.005714285714285714
highlighting candidate	1.0
candidate passages	0.3333333333333333
passages to	0.5
be included	0.004219409282700422
included in	0.125
and there	0.005780346820809248
that depend	0.0035460992907801418
depend on	1.0
on post-processing	0.0047169811320754715
post-processing by	0.3333333333333333
-LRB- HAMS	0.0027100271002710027
HAMS =	1.0
= Human	0.1111111111111111
Human Aided	0.2
Aided Machine	0.3333333333333333
Machine Summarization	0.1111111111111111
Apart	2.7900228781876013e-05
Fully	2.7900228781876013e-05
Summarizers	2.7900228781876013e-05
FAS	2.7900228781876013e-05
MAHS	2.7900228781876013e-05
Human	0.00013950114390938006
highlighting	2.7900228781876013e-05
candidate	8.370068634562804e-05
passages	5.5800457563752025e-05
depend	8.370068634562804e-05
HAMS	2.7900228781876013e-05
Evaluation An	0.1111111111111111
An ongoing	0.0625
ongoing issue	0.5
issue in	0.125
this field	0.02197802197802198
field is	0.037037037037037035
ongoing	5.5800457563752025e-05
Evaluation techniques	0.1111111111111111
techniques fall	0.043478260869565216
fall into	0.5
into intrinsic	0.01282051282051282
intrinsic and	0.25
and extrinsic	0.001445086705202312
extrinsic ,	0.16666666666666666
, inter-texual	0.0005614823133071309
inter-texual and	0.5
and intra-texual	0.001445086705202312
intra-texual .	1.0
fall	0.00011160091512750405
inter-texual	5.5800457563752025e-05
intra-texual	2.7900228781876013e-05
evaluation tests	0.037037037037037035
tests the	0.5
in of	0.0018726591760299626
of itself	0.00089126559714795
itself while	0.2
while an	0.05
an extrinsic	0.007575757575757576
summarization based	0.02
on how	0.009433962264150943
how it	0.06896551724137931
it affects	0.008547008547008548
affects the	1.0
the completion	0.0006920415224913495
completion of	1.0
other task	0.014285714285714285
affects	2.7900228781876013e-05
completion	2.7900228781876013e-05
Intrinsic evaluations	0.3333333333333333
evaluations have	0.16666666666666666
have assessed	0.009615384615384616
assessed mainly	1.0
mainly the	0.16666666666666666
the coherence	0.0006920415224913495
coherence and	0.6666666666666666
and informativeness	0.001445086705202312
informativeness of	0.6666666666666666
summaries .	0.13953488372093023
evaluations	0.00016740137269125608
assessed	2.7900228781876013e-05
coherence	8.370068634562804e-05
informativeness	8.370068634562804e-05
Extrinsic evaluations	0.5
evaluations ,	0.16666666666666666
, have	0.0011229646266142617
have tested	0.009615384615384616
tested the	0.5
the impact	0.001384083044982699
impact of	0.5
summarization on	0.02
like relevance	0.03571428571428571
relevance assessment	0.3333333333333333
assessment ,	1.0
, reading	0.0005614823133071309
reading comprehension	0.25
comprehension ,	0.14285714285714285
tested	5.5800457563752025e-05
impact	5.5800457563752025e-05
assessment	2.7900228781876013e-05
<s> Intra-texual	0.0007686395080707148
Intra-texual methods	1.0
methods assess	0.022727272727272728
assess the	0.3333333333333333
specific summarization	0.047619047619047616
the inter-texual	0.0006920415224913495
inter-texual ones	0.5
ones focus	0.1
on contrastive	0.0047169811320754715
contrastive analysis	1.0
of outputs	0.00089126559714795
outputs of	1.0
several summarization	0.045454545454545456
Intra-texual	2.7900228781876013e-05
assess	8.370068634562804e-05
contrastive	2.7900228781876013e-05
outputs	2.7900228781876013e-05
<s> Human	0.0023059185242121443
Human judgement	0.2
judgement often	0.3333333333333333
often has	0.045454545454545456
has wide	0.011904761904761904
wide variance	0.25
variance on	1.0
is considered	0.0040650406504065045
considered a	0.1111111111111111
`` good	0.005291005291005291
good ''	0.07692307692307693
'' summary	0.005154639175257732
that making	0.0035460992907801418
making the	0.2857142857142857
evaluation process	0.018518518518518517
process automatic	0.027777777777777776
automatic is	0.043478260869565216
particularly difficult	0.2
difficult .	0.07142857142857142
judgement	8.370068634562804e-05
wide	0.00011160091512750405
variance	2.7900228781876013e-05
is both	0.0020325203252032522
both time	0.03225806451612903
time and	0.09090909090909091
and labor	0.001445086705202312
labor intensive	0.5
intensive as	1.0
as it	0.003484320557491289
it requires	0.017094017094017096
requires humans	0.0625
humans to	0.08333333333333333
to read	0.0013280212483399733
read not	0.14285714285714285
summaries but	0.023255813953488372
also the	0.028985507246376812
labor	5.5800457563752025e-05
intensive	2.7900228781876013e-05
read	0.0001953016014731321
Other issues	0.14285714285714285
issues are	0.2
are those	0.004149377593360996
those concerning	0.045454545454545456
concerning coherence	1.0
and coverage	0.001445086705202312
coverage .	0.3333333333333333
concerning	2.7900228781876013e-05
One of	0.15384615384615385
the metrics	0.0006920415224913495
metrics used	0.1111111111111111
in NIST	0.0018726591760299626
NIST 's	0.5
's annual	0.0196078431372549
annual Document	0.5
Document Understanding	0.25
Understanding Conferences	0.5
Conferences ,	0.5
which research	0.007246376811594203
research groups	0.023809523809523808
groups submit	0.2
submit their	0.5
their systems	0.058823529411764705
systems for	0.017857142857142856
for both	0.0036101083032490976
both summarization	0.03225806451612903
summarization and	0.02
translation tasks	0.013513513513513514
the ROUGE	0.0006920415224913495
ROUGE metric	0.2
metric -LRB-	0.3333333333333333
annual	5.5800457563752025e-05
Conferences	5.5800457563752025e-05
submit	5.5800457563752025e-05
It essentially	0.02631578947368421
essentially calculates	0.125
calculates n-gram	1.0
n-gram overlaps	0.5
overlaps between	0.5
between automatically	0.02564102564102564
automatically generated	0.14285714285714285
generated summaries	0.06666666666666667
and previously-written	0.001445086705202312
previously-written human	1.0
human summaries	0.021739130434782608
calculates	2.7900228781876013e-05
overlaps	5.5800457563752025e-05
previously-written	2.7900228781876013e-05
A high	0.02
high level	0.16666666666666666
level of	0.35
of overlap	0.00089126559714795
overlap should	0.25
should indicate	0.05263157894736842
indicate a	0.3333333333333333
of shared	0.00089126559714795
shared concepts	0.5
concepts between	0.2
two summaries	0.034482758620689655
indicate	8.370068634562804e-05
that overlap	0.0035460992907801418
overlap metrics	0.25
metrics like	0.1111111111111111
like this	0.03571428571428571
are unable	0.004149377593360996
provide any	0.16666666666666666
any feedback	0.03225806451612903
feedback on	0.5
summary 's	0.047619047619047616
's coherence	0.0196078431372549
coherence .	0.3333333333333333
feedback	5.5800457563752025e-05
<s> Anaphor	0.0007686395080707148
Anaphor resolution	1.0
resolution remains	0.25
remains another	0.25
another problem	0.15384615384615385
problem yet	0.022727272727272728
yet to	0.5
be fully	0.008438818565400843
fully solved	0.16666666666666666
solved .	0.2
Anaphor	2.7900228781876013e-05
<s> Evaluating	0.0015372790161414297
Evaluating summaries	1.0
either manually	0.1
manually or	0.25
automatically ,	0.047619047619047616
a hard	0.00245398773006135
hard task	0.16666666666666666
Evaluating	5.5800457563752025e-05
in evaluation	0.0018726591760299626
evaluation comes	0.018518518518518517
comes from	0.4
the impossibility	0.0006920415224913495
impossibility of	1.0
of building	0.00089126559714795
building a	1.0
a fair	0.001226993865030675
fair gold-standard	1.0
gold-standard against	1.0
against which	0.2
the results	0.002768166089965398
results of	0.047619047619047616
systems can	0.026785714285714284
be compared	0.004219409282700422
impossibility	2.7900228781876013e-05
building	2.7900228781876013e-05
fair	2.7900228781876013e-05
gold-standard	2.7900228781876013e-05
also very	0.028985507246376812
very hard	0.024390243902439025
hard to	0.3333333333333333
determine what	0.043478260869565216
a correct	0.00245398773006135
correct summary	0.06666666666666667
is ,	0.018292682926829267
because there	0.06666666666666667
is always	0.0040650406504065045
always the	0.3333333333333333
good summary	0.15384615384615385
is quite	0.0020325203252032522
quite different	0.375
from any	0.009615384615384616
any human	0.03225806451612903
human summary	0.021739130434782608
summary used	0.023809523809523808
an approximation	0.015151515151515152
approximation to	0.3333333333333333
correct output	0.06666666666666667
approximation	0.00016740137269125608
<s> Current	0.0023059185242121443
Current difficulties	0.2
difficulties in	0.5
in evaluating	0.0018726591760299626
evaluating summaries	0.4
summaries automatically	0.023255813953488372
automatically The	0.047619047619047616
evaluate the	0.5
the informativeness	0.0006920415224913495
of automatic	0.0017825311942959
automatic summaries	0.13043478260869565
compare them	0.14285714285714285
them with	0.05263157894736842
with human-made	0.00546448087431694
human-made model	0.5
human-made	5.5800457563752025e-05
as content	0.003484320557491289
content selection	0.08333333333333333
selection is	1.0
not a	0.008928571428571428
a deterministic	0.00245398773006135
deterministic problem	0.25
, different	0.0016844469399213925
different people	0.02040816326530612
people would	0.0625
would choose	0.018867924528301886
choose different	0.5
even ,	0.037037037037037035
same person	0.04
person may	0.05263157894736842
may chose	0.019230769230769232
chose different	1.0
sentences at	0.013157894736842105
at different	0.014705882352941176
different times	0.02040816326530612
times ,	0.2
, showing	0.0005614823133071309
showing evidence	0.5
evidence of	0.5
of low	0.00089126559714795
low agreement	0.3333333333333333
agreement among	0.3333333333333333
among humans	0.125
humans as	0.08333333333333333
which sentences	0.007246376811594203
are good	0.004149377593360996
summary sentences	0.023809523809523808
selection	2.7900228781876013e-05
deterministic	0.00011160091512750405
chose	2.7900228781876013e-05
evidence	5.5800457563752025e-05
<s> Besides	0.0007686395080707148
Besides the	1.0
human variability	0.021739130434782608
variability ,	1.0
the semantic	0.001384083044982699
semantic equivalence	0.047619047619047616
equivalence is	0.5
is another	0.0040650406504065045
because two	0.03333333333333333
two distinct	0.034482758620689655
distinct sentences	0.14285714285714285
same meaning	0.04
meaning but	0.043478260869565216
but not	0.058823529411764705
not using	0.008928571428571428
same words	0.04
Besides	2.7900228781876013e-05
variability	2.7900228781876013e-05
This phenomenon	0.031746031746031744
phenomenon is	0.2
as paraphrase	0.003484320557491289
paraphrase .	1.0
paraphrase	2.7900228781876013e-05
can find	0.0055248618784530384
find an	0.15384615384615385
automatically evaluating	0.047619047619047616
summaries using	0.023255813953488372
using paraphrases	0.01694915254237288
paraphrases -LRB-	1.0
-LRB- ParaEval	0.0027100271002710027
ParaEval -RRB-	1.0
paraphrases	2.7900228781876013e-05
ParaEval	2.7900228781876013e-05
<s> Moreover	0.0030745580322828594
Moreover ,	1.0
most summarization	0.017241379310344827
systems perform	0.008928571428571428
perform an	0.09090909090909091
an extractive	0.007575757575757576
extractive approach	0.14285714285714285
, selecting	0.0005614823133071309
selecting and	0.2
and copying	0.001445086705202312
copying important	1.0
sentences from	0.02631578947368421
Moreover	0.00011160091512750405
copying	2.7900228781876013e-05
Although humans	0.125
humans can	0.08333333333333333
also cut	0.014492753623188406
cut and	1.0
and paste	0.001445086705202312
paste relevant	1.0
relevant information	0.14285714285714285
information of	0.021739130434782608
the times	0.0006920415224913495
times they	0.2
they rephrase	0.025
rephrase sentences	1.0
sentences when	0.013157894736842105
when necessary	0.02857142857142857
necessary ,	0.1
or they	0.0045045045045045045
they join	0.025
join different	1.0
different related	0.02040816326530612
related information	0.06666666666666667
into one	0.02564102564102564
cut	2.7900228781876013e-05
paste	2.7900228781876013e-05
rephrase	2.7900228781876013e-05
join	2.7900228781876013e-05
summaries qualitatively	0.023255813953488372
qualitatively The	1.0
main drawback	0.125
drawback of	1.0
evaluation systems	0.018518518518518517
systems existing	0.008928571428571428
existing so	0.2
so far	0.03333333333333333
far is	0.125
that we	0.010638297872340425
need at	0.047619047619047616
least one	0.2
one reference	0.015384615384615385
and for	0.001445086705202312
for some	0.018050541516245487
some methods	0.024096385542168676
methods more	0.022727272727272728
compare automatic	0.14285714285714285
with models	0.00546448087431694
qualitatively	2.7900228781876013e-05
drawback	2.7900228781876013e-05
hard and	0.16666666666666666
and expensive	0.002890173410404624
expensive task	0.14285714285714285
<s> Much	0.0023059185242121443
Much effort	0.3333333333333333
effort has	0.25
have corpus	0.009615384615384616
of texts	0.0017825311942959
texts and	0.058823529411764705
their corresponding	0.029411764705882353
corresponding summaries	0.16666666666666666
Much	8.370068634562804e-05
methods presented	0.022727272727272728
presented in	0.5
the previous	0.001384083044982699
previous Section	0.3333333333333333
Section ,	1.0
, not	0.0039303761931499155
only do	0.02631578947368421
do we	0.038461538461538464
have human-made	0.009615384615384616
human-made summaries	0.5
summaries available	0.023255813953488372
for comparison	0.0036101083032490976
comparison ,	0.3333333333333333
also manual	0.014492753623188406
manual annotation	0.5
annotation has	0.25
be performed	0.008438818565400843
in some	0.00749063670411985
them -LRB-	0.05263157894736842
e.g. SCU	0.017857142857142856
SCU in	1.0
the Pyramid	0.0006920415224913495
Pyramid Method	1.0
Method -RRB-	1.0
presented	0.00016740137269125608
Section	2.7900228781876013e-05
comparison	8.370068634562804e-05
SCU	2.7900228781876013e-05
Pyramid	2.7900228781876013e-05
Method	2.7900228781876013e-05
In any	0.01904761904761905
, what	0.0011229646266142617
evaluation methods	0.018518518518518517
need as	0.047619047619047616
an input	0.022727272727272728
summaries to	0.046511627906976744
to serve	0.0013280212483399733
as gold	0.003484320557491289
gold standards	0.16666666666666666
standards and	0.2
all perform	0.023255813953488372
perform a	0.2727272727272727
a quantitative	0.00245398773006135
quantitative evaluation	0.5
evaluation with	0.018518518518518517
to different	0.0013280212483399733
different similarity	0.02040816326530612
similarity metrics	0.1
metrics .	0.1111111111111111
To overcome	0.1111111111111111
overcome these	0.5
these problems	0.023809523809523808
we think	0.022222222222222223
think that	0.3333333333333333
the quantitative	0.0006920415224913495
evaluation might	0.018518518518518517
might not	0.07692307692307693
not be	0.10714285714285714
the only	0.0006920415224913495
only way	0.02631578947368421
evaluate summaries	0.25
a qualitative	0.00245398773006135
qualitative automatic	0.5
be also	0.004219409282700422
also important	0.014492753623188406
important .	0.0625
qualitative	5.5800457563752025e-05
<s> Therefore	0.0015372790161414297
Therefore ,	1.0
second aim	0.1
aim of	0.5
this paper	0.01098901098901099
paper is	0.09090909090909091
to suggest	0.0013280212483399733
suggest a	0.3333333333333333
a novel	0.001226993865030675
novel proposal	1.0
proposal for	1.0
evaluating automatically	0.2
automatically the	0.047619047619047616
qualitative manner	0.5
manner rather	0.25
than in	0.022222222222222223
quantitative one	0.25
Therefore	5.5800457563752025e-05
aim	5.5800457563752025e-05
suggest	8.370068634562804e-05
novel	2.7900228781876013e-05
proposal	2.7900228781876013e-05
<s> Our	0.0023059185242121443
Our evaluation	0.3333333333333333
evaluation approach	0.018518518518518517
a preliminary	0.001226993865030675
preliminary approach	0.3333333333333333
be studied	0.004219409282700422
studied more	1.0
more deeply	0.010526315789473684
deeply ,	1.0
and developed	0.002890173410404624
the future	0.001384083044982699
future .	0.3333333333333333
Our	8.370068634562804e-05
studied	2.7900228781876013e-05
deeply	2.7900228781876013e-05
<s> Its	0.0015372790161414297
Its main	0.5
main underlying	0.125
underlying idea	0.3333333333333333
idea is	0.14285714285714285
to define	0.0026560424966799467
define several	0.5
several quality	0.045454545454545456
quality criteria	0.1
criteria and	0.25
and check	0.001445086705202312
check how	0.5
how a	0.06896551724137931
a generated	0.001226993865030675
generated summary	0.06666666666666667
summary tackles	0.023809523809523808
tackles each	1.0
these ,	0.047619047619047616
that a	0.010638297872340425
reference model	0.125
model would	0.1
would not	0.018867924528301886
be necessary	0.008438818565400843
necessary anymore	0.1
anymore ,	1.0
, taking	0.0005614823133071309
taking only	0.2
only into	0.02631578947368421
into consideration	0.01282051282051282
consideration the	0.3333333333333333
the automatic	0.001384083044982699
original source	0.07692307692307693
source .	0.041666666666666664
Its	5.5800457563752025e-05
underlying	8.370068634562804e-05
define	5.5800457563752025e-05
check	5.5800457563752025e-05
tackles	2.7900228781876013e-05
anymore	2.7900228781876013e-05
taking	0.00013950114390938006
consideration	8.370068634562804e-05
Once performed	0.4
performed ,	0.2
it could	0.008547008547008548
used together	0.008849557522123894
together with	0.125
with any	0.00546448087431694
other automatic	0.014285714285714285
automatic methodology	0.043478260869565216
methodology to	0.5
measure summary	0.09090909090909091
's informativeness	0.0196078431372549
informativeness .	0.3333333333333333
Language Generation	0.08333333333333333
Generation -LRB-	0.5
-LRB- NLG	0.008130081300813009
NLG -RRB-	0.047619047619047616
the natural	0.001384083044982699
processing task	0.018518518518518517
of generating	0.00089126559714795
generating natural	0.2
language from	0.006756756756756757
machine representation	0.02531645569620253
representation system	0.05263157894736842
system such	0.010752688172043012
a knowledge	0.001226993865030675
base or	0.25
a logical	0.001226993865030675
logical form	0.16666666666666666
Generation	5.5800457563752025e-05
NLG	0.0005859048044193963
<s> Psycholinguists	0.0007686395080707148
Psycholinguists prefer	1.0
prefer the	0.5
term language	0.05555555555555555
language production	0.006756756756756757
production when	0.3333333333333333
such formal	0.008130081300813009
representations are	0.25
are interpreted	0.004149377593360996
interpreted as	1.0
as models	0.003484320557491289
for mental	0.0036101083032490976
mental representations	0.3333333333333333
representations .	0.25
Psycholinguists	2.7900228781876013e-05
interpreted	2.7900228781876013e-05
mental	8.370068634562804e-05
In a	0.01904761904761905
a sense	0.001226993865030675
sense ,	0.125
one can	0.015384615384615385
can say	0.0055248618784530384
say that	0.14285714285714285
that an	0.0035460992907801418
an NLG	0.007575757575757576
NLG system	0.09523809523809523
translator that	0.14285714285714285
that converts	0.0035460992907801418
converts a	1.0
computer based	0.022727272727272728
based representation	0.018518518518518517
representation into	0.05263157894736842
language representation	0.006756756756756757
converts	2.7900228781876013e-05
the methods	0.0006920415224913495
produce the	0.13636363636363635
final language	0.1111111111111111
language are	0.006756756756756757
are very	0.016597510373443983
very different	0.07317073170731707
from those	0.019230769230769232
those of	0.045454545454545456
a compiler	0.0036809815950920245
compiler due	0.3333333333333333
due to	0.4
the inherent	0.0006920415224913495
inherent expressivity	1.0
expressivity of	1.0
compiler	8.370068634562804e-05
inherent	2.7900228781876013e-05
expressivity	2.7900228781876013e-05
<s> NLG	0.0015372790161414297
NLG may	0.047619047619047616
understanding .	0.06060606060606061
The difference	0.005208333333333333
difference can	0.25
be put	0.004219409282700422
put this	0.25
way :	0.041666666666666664
: whereas	0.00980392156862745
whereas in	0.3333333333333333
in natural	0.013108614232209739
understanding the	0.12121212121212122
system needs	0.043010752688172046
needs to	0.4
to disambiguate	0.00398406374501992
disambiguate the	0.3333333333333333
input sentence	0.024390243902439025
sentence to	0.020833333333333332
the machine	0.0006920415224913495
representation language	0.10526315789473684
in NLG	0.0056179775280898875
NLG the	0.047619047619047616
make decisions	0.05
decisions about	0.2
about how	0.025
put a	0.25
a concept	0.001226993865030675
concept into	0.25
disambiguate	8.370068634562804e-05
concept	0.00011160091512750405
The simplest	0.005208333333333333
simplest -LRB-	1.0
and perhaps	0.001445086705202312
perhaps trivial	0.16666666666666666
trivial -RRB-	0.25
-RRB- examples	0.0027100271002710027
examples are	0.041666666666666664
that generate	0.0035460992907801418
generate form	0.05555555555555555
form letters	0.05
letters .	0.4
simplest	2.7900228781876013e-05
Such systems	0.125
systems do	0.008928571428571428
typically involve	0.05555555555555555
involve grammar	0.16666666666666666
grammar rules	0.13513513513513514
but may	0.029411764705882353
may generate	0.019230769230769232
a letter	0.001226993865030675
letter to	0.16666666666666666
a consumer	0.001226993865030675
consumer ,	1.0
e.g. stating	0.017857142857142856
stating that	1.0
a credit	0.00245398773006135
credit card	1.0
card spending	0.25
spending limit	1.0
limit is	0.25
is about	0.0020325203252032522
about to	0.025
be reached	0.004219409282700422
reached .	0.5
consumer	2.7900228781876013e-05
stating	2.7900228781876013e-05
credit	8.370068634562804e-05
card	0.00011160091512750405
spending	2.7900228781876013e-05
reached	5.5800457563752025e-05
<s> More	0.006149116064565719
More complex	0.1111111111111111
complex NLG	0.041666666666666664
NLG systems	0.23809523809523808
systems dynamically	0.008928571428571428
dynamically create	0.5
create texts	0.058823529411764705
texts to	0.11764705882352941
meet a	0.25
a communicative	0.001226993865030675
communicative goal	0.6666666666666666
goal .	0.14285714285714285
More	0.0002511020590368841
dynamically	5.5800457563752025e-05
As in	0.2222222222222222
in other	0.009363295880149813
other areas	0.02857142857142857
areas of	0.3333333333333333
this can	0.01098901098901099
done using	0.09090909090909091
using either	0.01694915254237288
either explicit	0.1
explicit models	0.2
models of	0.038461538461538464
language -LRB-	0.013513513513513514
, grammars	0.0005614823133071309
grammars -RRB-	0.14285714285714285
the domain	0.001384083044982699
models derived	0.038461538461538464
derived by	0.3333333333333333
by analyzing	0.011428571428571429
analyzing human-written	0.2
human-written texts	0.5
texts .	0.17647058823529413
areas	0.00016740137269125608
human-written	5.5800457563752025e-05
NLG is	0.09523809523809523
a fast-evolving	0.001226993865030675
fast-evolving field	1.0
fast-evolving	2.7900228781876013e-05
The best	0.005208333333333333
best single	0.05555555555555555
source for	0.041666666666666664
for up-to-date	0.0036101083032490976
up-to-date research	1.0
the area	0.001384083044982699
area is	0.18181818181818182
the SIGGEN	0.0006920415224913495
SIGGEN portion	1.0
portion of	1.0
the ACL	0.0006920415224913495
ACL Anthology	0.5
Anthology .	1.0
up-to-date	2.7900228781876013e-05
SIGGEN	2.7900228781876013e-05
portion	5.5800457563752025e-05
ACL	5.5800457563752025e-05
Anthology	2.7900228781876013e-05
<s> Perhaps	0.0007686395080707148
Perhaps the	1.0
the closest	0.0006920415224913495
closest the	0.5
field comes	0.037037037037037035
comes to	0.2
a specialist	0.001226993865030675
specialist textbook	1.0
textbook is	0.5
is Reiter	0.0020325203252032522
Reiter and	1.0
and Dale	0.001445086705202312
Dale -LRB-	1.0
-LRB- 2000	0.0027100271002710027
2000 -RRB-	0.3333333333333333
this book	0.01098901098901099
book does	0.125
not describe	0.008928571428571428
describe developments	0.16666666666666666
developments in	0.6666666666666666
field since	0.037037037037037035
since 2000	0.1
2000 .	0.3333333333333333
Perhaps	2.7900228781876013e-05
specialist	2.7900228781876013e-05
textbook	5.5800457563752025e-05
Reiter	2.7900228781876013e-05
Dale	2.7900228781876013e-05
2000	8.370068634562804e-05
This system	0.015873015873015872
system takes	0.010752688172043012
takes as	0.3333333333333333
input six	0.024390243902439025
six numbers	0.5
numbers ,	0.2857142857142857
which give	0.007246376811594203
give predicted	0.25
predicted pollen	0.5
pollen levels	0.6923076923076923
levels in	0.045454545454545456
of Scotland	0.0017825311942959
Scotland .	0.4
numbers	0.0001953016014731321
give	0.00011160091512750405
predicted	5.5800457563752025e-05
pollen	0.00036270297416438817
Scotland	0.00013950114390938006
<s> From	0.0007686395080707148
From these	1.0
these numbers	0.047619047619047616
system generates	0.010752688172043012
generates a	0.6666666666666666
short textual	0.125
textual summary	0.2
of pollen	0.0017825311942959
levels as	0.045454545454545456
From	2.7900228781876013e-05
generates	8.370068634562804e-05
the historical	0.0006920415224913495
historical data	1.0
data for	0.012987012987012988
for 1-July-2005	0.0036101083032490976
1-July-2005 ,	1.0
the software	0.0020761245674740486
software produces	0.037037037037037035
produces Grass	0.25
Grass pollen	1.0
levels for	0.13636363636363635
for Friday	0.010830324909747292
Friday have	1.0
have increased	0.028846153846153848
increased from	0.6
the moderate	0.0020761245674740486
moderate to	0.6
to high	0.00398406374501992
high levels	0.16666666666666666
levels of	0.3181818181818182
of yesterday	0.00267379679144385
yesterday with	0.6666666666666666
with values	0.01639344262295082
values of	0.5
of around	0.0017825311942959
around 6	0.375
6 to	0.75
to 7	0.00398406374501992
7 across	0.42857142857142855
across most	0.6
most parts	0.05172413793103448
the country	0.0020761245674740486
country .	0.5
historical	2.7900228781876013e-05
1-July-2005	2.7900228781876013e-05
Grass	0.00011160091512750405
Friday	8.370068634562804e-05
moderate	0.00013950114390938006
yesterday	8.370068634562804e-05
6	0.00011160091512750405
7	0.0001953016014731321
country	0.00011160091512750405
in Northern	0.0018726591760299626
Northern areas	0.3333333333333333
areas ,	0.16666666666666666
, pollen	0.0005614823133071309
levels will	0.09090909090909091
be moderate	0.004219409282700422
moderate with	0.2
of 4	0.0017825311942959
4 .	0.4
Northern	8.370068634562804e-05
4	0.00013950114390938006
the actual	0.0020761245674740486
actual forecast	0.2
forecast -LRB-	1.0
-LRB- written	0.0027100271002710027
human meteorologist	0.021739130434782608
meteorologist -RRB-	1.0
-RRB- from	0.0027100271002710027
from this	0.009615384615384616
this data	0.01098901098901099
data was	0.012987012987012988
was Pollen	0.012987012987012988
Pollen counts	1.0
counts are	1.0
are expected	0.004149377593360996
expected to	0.2857142857142857
to remain	0.0013280212483399733
remain high	1.0
high at	0.05555555555555555
at level	0.014705882352941176
level 6	0.05
6 over	0.25
over most	0.08333333333333333
Scotland ,	0.2
even level	0.037037037037037035
level 7	0.05
7 in	0.2857142857142857
the south	0.001384083044982699
south east	1.0
east .	1.0
forecast	2.7900228781876013e-05
meteorologist	2.7900228781876013e-05
Pollen	2.7900228781876013e-05
counts	2.7900228781876013e-05
remain	2.7900228781876013e-05
south	5.5800457563752025e-05
east	5.5800457563752025e-05
only relief	0.02631578947368421
relief is	1.0
the Northern	0.001384083044982699
Northern Isles	0.6666666666666666
Isles and	1.0
and far	0.002890173410404624
far northeast	0.25
northeast of	1.0
of mainland	0.0017825311942959
mainland Scotland	1.0
Scotland with	0.2
with medium	0.00546448087431694
medium levels	0.3333333333333333
pollen count	0.07692307692307693
count .	0.2
relief	2.7900228781876013e-05
Isles	5.5800457563752025e-05
northeast	5.5800457563752025e-05
mainland	5.5800457563752025e-05
medium	8.370068634562804e-05
<s> Comparing	0.0007686395080707148
Comparing these	1.0
these two	0.023809523809523808
two illustrates	0.034482758620689655
illustrates some	0.5
the choices	0.0006920415224913495
choices that	0.2
that NLG	0.0070921985815602835
systems must	0.008928571428571428
must make	0.07142857142857142
make ;	0.05
; these	0.0425531914893617
these are	0.047619047619047616
are further	0.004149377593360996
further discussed	0.125
Comparing	2.7900228781876013e-05
illustrates	5.5800457563752025e-05
<s> Stages	0.0007686395080707148
Stages The	1.0
The process	0.015625
generate text	0.05555555555555555
text can	0.006289308176100629
as keeping	0.003484320557491289
keeping a	0.5
of canned	0.00089126559714795
canned text	0.5
text that	0.025157232704402517
is copied	0.0020325203252032522
copied and	0.5
and pasted	0.001445086705202312
pasted ,	1.0
, possibly	0.0005614823133071309
possibly linked	0.5
linked with	0.3333333333333333
some glue	0.012048192771084338
glue text	1.0
Stages	2.7900228781876013e-05
keeping	5.5800457563752025e-05
canned	5.5800457563752025e-05
copied	5.5800457563752025e-05
pasted	2.7900228781876013e-05
glue	2.7900228781876013e-05
The results	0.005208333333333333
results may	0.047619047619047616
be satisfactory	0.004219409282700422
satisfactory in	1.0
in simple	0.0018726591760299626
simple domains	0.038461538461538464
domains such	0.125
as horoscope	0.003484320557491289
horoscope machines	1.0
machines or	0.25
or generators	0.0045045045045045045
generators of	0.5
of personalised	0.00089126559714795
personalised business	1.0
business letters	0.25
satisfactory	2.7900228781876013e-05
horoscope	2.7900228781876013e-05
machines	0.00011160091512750405
generators	5.5800457563752025e-05
personalised	2.7900228781876013e-05
a sophisticated	0.001226993865030675
sophisticated NLG	0.14285714285714285
include stages	0.037037037037037035
stages of	0.5
of planning	0.00089126559714795
planning and	0.5
and merging	0.001445086705202312
merging of	0.5
information to	0.08695652173913043
to enable	0.0013280212483399733
enable the	1.0
the generation	0.0006920415224913495
generation of	0.1111111111111111
that looks	0.0035460992907801418
looks natural	0.25
natural and	0.02666666666666667
and does	0.001445086705202312
not become	0.008928571428571428
become repetitive	0.25
repetitive .	0.5
sophisticated	0.0001953016014731321
stages	5.5800457563752025e-05
planning	5.5800457563752025e-05
merging	5.5800457563752025e-05
enable	5.5800457563752025e-05
repetitive	5.5800457563752025e-05
Typical stages	0.5
stages are	0.5
are :	0.008298755186721992
: Content	0.00980392156862745
Content determination	1.0
determination :	1.0
: Deciding	0.00980392156862745
Deciding what	1.0
what information	0.03125
to mention	0.0013280212483399733
mention in	0.3333333333333333
Content	2.7900228781876013e-05
determination	2.7900228781876013e-05
Deciding	2.7900228781876013e-05
the pollen	0.0006920415224913495
pollen example	0.07692307692307693
example above	0.012345679012345678
, deciding	0.0022459292532285235
deciding whether	0.3333333333333333
whether to	0.07692307692307693
explicitly mention	0.25
mention that	0.3333333333333333
that pollen	0.0035460992907801418
pollen level	0.15384615384615385
level is	0.05
is 7	0.0020325203252032522
Document structuring	0.25
structuring :	1.0
: Overall	0.00980392156862745
Overall organization	1.0
convey .	0.3333333333333333
structuring	2.7900228781876013e-05
Overall	2.7900228781876013e-05
deciding to	0.3333333333333333
to describe	0.0026560424966799467
the areas	0.001384083044982699
areas with	0.3333333333333333
with high	0.01092896174863388
high pollen	0.05555555555555555
levels first	0.045454545454545456
first ,	0.030303030303030304
, instead	0.0005614823133071309
with low	0.00546448087431694
low pollen	0.3333333333333333
levels .	0.045454545454545456
<s> Aggregation	0.0007686395080707148
Aggregation :	1.0
: Merging	0.00980392156862745
Merging of	1.0
of similar	0.0017825311942959
improve readability	0.07692307692307693
readability and	1.0
and naturalness	0.001445086705202312
naturalness .	1.0
Aggregation	2.7900228781876013e-05
Merging	2.7900228781876013e-05
readability	2.7900228781876013e-05
naturalness	2.7900228781876013e-05
, merging	0.0005614823133071309
merging the	0.5
sentences Grass	0.013157894736842105
yesterday and	0.3333333333333333
and Grass	0.001445086705202312
be around	0.004219409282700422
country into	0.25
the single	0.0006920415224913495
single sentence	0.07142857142857142
sentence Grass	0.020833333333333332
<s> Lexical	0.0015372790161414297
Lexical choice	0.5
choice :	0.125
: Putting	0.00980392156862745
Putting words	1.0
words to	0.009174311926605505
the concepts	0.0006920415224913495
Lexical	5.5800457563752025e-05
Putting	2.7900228781876013e-05
whether medium	0.07692307692307693
medium or	0.3333333333333333
or moderate	0.0045045045045045045
moderate should	0.2
used when	0.017699115044247787
when describing	0.05714285714285714
describing a	0.25
a pollen	0.001226993865030675
<s> Referring	0.0007686395080707148
Referring expression	1.0
expression generation	0.1
: Creating	0.0196078431372549
Creating referring	0.5
referring expressions	0.5
expressions that	0.3333333333333333
that identify	0.0035460992907801418
identify objects	0.08333333333333333
objects and	0.2
and regions	0.001445086705202312
regions .	0.5
Referring	2.7900228781876013e-05
Creating	5.5800457563752025e-05
expressions	8.370068634562804e-05
to use	0.013280212483399735
use in	0.013888888888888888
Scotland to	0.2
to refer	0.0013280212483399733
a certain	0.001226993865030675
certain region	0.14285714285714285
region in	1.0
in Scotland	0.0018726591760299626
region	2.7900228781876013e-05
This task	0.031746031746031744
task also	0.023809523809523808
also includes	0.014492753623188406
includes making	0.14285714285714285
making decisions	0.14285714285714285
about pronouns	0.025
pronouns and	0.5
other types	0.014285714285714285
of anaphora	0.00089126559714795
anaphora .	1.0
anaphora	2.7900228781876013e-05
<s> Realisation	0.0007686395080707148
Realisation :	1.0
Creating the	0.5
actual text	0.2
which should	0.007246376811594203
be correct	0.004219409282700422
correct according	0.06666666666666667
rules of	0.09302325581395349
of syntax	0.0017825311942959
, morphology	0.0011229646266142617
and orthography	0.001445086705202312
orthography .	0.5
Realisation	2.7900228781876013e-05
using will	0.01694915254237288
be for	0.004219409282700422
future tense	0.3333333333333333
tense of	0.5
of to	0.00089126559714795
be .	0.004219409282700422
tense	5.5800457563752025e-05
<s> Applications	0.0015372790161414297
Applications The	0.5
The popular	0.005208333333333333
popular media	0.1111111111111111
media has	0.16666666666666666
been especially	0.014705882352941176
especially interested	0.06666666666666667
interested in	1.0
systems which	0.017857142857142856
which generate	0.021739130434782608
generate jokes	0.05555555555555555
jokes -LRB-	1.0
see computational	0.05
computational humor	0.1
humor -RRB-	1.0
Applications	5.5800457563752025e-05
interested	2.7900228781876013e-05
jokes	2.7900228781876013e-05
humor	2.7900228781876013e-05
But from	0.16666666666666666
a commercial	0.00245398773006135
commercial perspective	0.09090909090909091
perspective ,	0.25
successful NLG	0.1111111111111111
NLG applications	0.047619047619047616
applications have	0.08
been data-to-text	0.014705882352941176
data-to-text systems	1.0
generate textual	0.05555555555555555
textual summaries	0.2
of databases	0.00089126559714795
databases and	0.125
data sets	0.03896103896103896
sets ;	0.09090909090909091
systems usually	0.017857142857142856
usually perform	0.03125
perform data	0.09090909090909091
data analysis	0.012987012987012988
analysis as	0.015384615384615385
as text	0.003484320557491289
text generation	0.006289308176100629
commercial	0.00030690251660063614
data-to-text	2.7900228781876013e-05
, several	0.0005614823133071309
several systems	0.045454545454545456
been built	0.014705882352941176
built that	0.3333333333333333
that produce	0.0035460992907801418
produce textual	0.045454545454545456
textual weather	0.2
weather forecasts	0.5714285714285714
forecasts from	0.2
from weather	0.009615384615384616
weather data	0.14285714285714285
built	8.370068634562804e-05
forecasts	0.00013950114390938006
The earliest	0.005208333333333333
earliest such	0.5
such system	0.008130081300813009
be deployed	0.004219409282700422
deployed was	0.5
was FoG	0.012987012987012988
FoG ,	0.5
by Environment	0.005714285714285714
Environment Canada	1.0
Canada to	0.16666666666666666
generate weather	0.05555555555555555
forecasts in	0.2
in French	0.0018726591760299626
and English	0.001445086705202312
English in	0.02702702702702703
the early	0.0020761245674740486
early 1990s	0.1
1990s .	0.3333333333333333
deployed	5.5800457563752025e-05
FoG	5.5800457563752025e-05
Environment	2.7900228781876013e-05
1990s	8.370068634562804e-05
The success	0.005208333333333333
of FoG	0.00089126559714795
FoG triggered	0.5
triggered other	1.0
other work	0.014285714285714285
both research	0.03225806451612903
and commercial	0.001445086705202312
commercial .	0.09090909090909091
triggered	2.7900228781876013e-05
this area	0.03296703296703297
area include	0.09090909090909091
include an	0.07407407407407407
an experiment	0.007575757575757576
experiment which	0.2
which showed	0.007246376811594203
that users	0.0035460992907801418
users sometimes	0.1111111111111111
sometimes preferred	0.07692307692307693
preferred computer-generated	1.0
computer-generated weather	1.0
forecasts to	0.2
to human-written	0.0013280212483399733
human-written ones	0.5
in part	0.0018726591760299626
part because	0.037037037037037035
the computer	0.001384083044982699
computer forecasts	0.022727272727272728
forecasts used	0.2
used more	0.008849557522123894
more consistent	0.010526315789473684
consistent terminology	1.0
terminology ,	1.0
demonstration that	0.2
that statistical	0.0035460992907801418
techniques could	0.043478260869565216
generate high-quality	0.05555555555555555
high-quality weather	1.0
forecasts .	0.2
preferred	2.7900228781876013e-05
computer-generated	2.7900228781876013e-05
consistent	2.7900228781876013e-05
terminology	2.7900228781876013e-05
high-quality	2.7900228781876013e-05
Recent applications	0.3333333333333333
applications include	0.08
the ARNS	0.0006920415224913495
ARNS system	1.0
system used	0.010752688172043012
to summarise	0.00398406374501992
summarise conditions	0.3333333333333333
conditions in	0.2
in US	0.0018726591760299626
US ports	0.14285714285714285
ports .	1.0
ARNS	2.7900228781876013e-05
summarise	8.370068634562804e-05
US	0.0001953016014731321
ports	2.7900228781876013e-05
the 1990s	0.001384083044982699
1990s there	0.3333333333333333
was considerable	0.012987012987012988
considerable interest	0.2
in using	0.0056179775280898875
using NLG	0.05084745762711865
NLG to	0.14285714285714285
summarise financial	0.3333333333333333
financial and	0.25
and business	0.001445086705202312
business data	0.25
example the	0.012345679012345678
the SPOTLIGHT	0.0006920415224913495
SPOTLIGHT system	1.0
system developed	0.010752688172043012
developed at	0.07692307692307693
at A.C.	0.014705882352941176
A.C. Nielsen	1.0
Nielsen automatically	1.0
generated readable	0.06666666666666667
readable English	0.3333333333333333
English text	0.02702702702702703
text based	0.006289308176100629
large amounts	0.043478260869565216
of retail	0.00089126559714795
retail sales	1.0
sales data	0.3333333333333333
SPOTLIGHT	2.7900228781876013e-05
A.C.	2.7900228781876013e-05
Nielsen	2.7900228781876013e-05
retail	2.7900228781876013e-05
sales	8.370068634562804e-05
More recently	0.1111111111111111
recently there	0.3333333333333333
is growing	0.0020325203252032522
growing interest	0.5
summarise electronic	0.3333333333333333
electronic medical	0.5
medical records	0.3333333333333333
records .	0.5
recently	8.370068634562804e-05
electronic	5.5800457563752025e-05
records	0.00011160091512750405
<s> Commercial	0.0015372790161414297
Commercial applications	0.5
applications in	0.08
area are	0.09090909090909091
are starting	0.004149377593360996
starting to	1.0
to appear	0.0026560424966799467
appear ,	0.0625
and researchers	0.001445086705202312
have shown	0.009615384615384616
shown that	0.2
NLG summaries	0.047619047619047616
of medical	0.0017825311942959
medical data	0.3333333333333333
data can	0.025974025974025976
be effective	0.008438818565400843
effective decision-support	0.16666666666666666
decision-support aids	1.0
aids for	1.0
for medical	0.0036101083032490976
medical professionals	0.16666666666666666
professionals .	1.0
Commercial	5.5800457563752025e-05
starting	2.7900228781876013e-05
decision-support	2.7900228781876013e-05
aids	2.7900228781876013e-05
professionals	2.7900228781876013e-05
There is	0.2727272727272727
also growing	0.014492753623188406
to enhance	0.0013280212483399733
enhance accessibility	1.0
accessibility ,	1.0
by describing	0.005714285714285714
describing graphs	0.25
graphs and	1.0
sets to	0.09090909090909091
to blind	0.0013280212483399733
blind people	0.75
people .	0.125
enhance	2.7900228781876013e-05
accessibility	2.7900228781876013e-05
graphs	2.7900228781876013e-05
blind	0.00011160091512750405
a highly	0.001226993865030675
highly interactive	0.1111111111111111
interactive use	0.25
of NLG	0.00089126559714795
the WYSIWYM	0.0006920415224913495
WYSIWYM framework	1.0
framework .	0.75
WYSIWYM	2.7900228781876013e-05
It stands	0.02631578947368421
stands for	1.0
for What	0.0036101083032490976
What you	0.09090909090909091
you see	0.07692307692307693
see is	0.05
what you	0.03125
you meant	0.07692307692307693
meant and	0.5
allows users	0.25
users to	0.2222222222222222
to see	0.0026560424966799467
see and	0.05
and manipulate	0.001445086705202312
manipulate the	0.3333333333333333
the continuously	0.0006920415224913495
continuously rendered	1.0
rendered view	1.0
view -LRB-	0.3333333333333333
NLG output	0.047619047619047616
output -RRB-	0.038461538461538464
an underlying	0.007575757575757576
underlying formal	0.3333333333333333
formal language	0.2222222222222222
language document	0.006756756756756757
NLG input	0.047619047619047616
input -RRB-	0.024390243902439025
, thereby	0.0005614823133071309
thereby editing	1.0
editing the	0.5
the formal	0.001384083044982699
language without	0.006756756756756757
without having	0.07692307692307693
having to	0.2
learn it	0.07692307692307693
stands	2.7900228781876013e-05
continuously	2.7900228781876013e-05
rendered	2.7900228781876013e-05
thereby	2.7900228781876013e-05
editing	5.5800457563752025e-05
having	0.00013950114390938006
Evaluation As	0.1111111111111111
other scientific	0.014285714285714285
scientific fields	0.5
, NLG	0.0005614823133071309
NLG researchers	0.047619047619047616
researchers need	0.1
to test	0.0026560424966799467
test how	0.1
well their	0.03571428571428571
, modules	0.0005614823133071309
modules ,	0.5
and algorithms	0.001445086705202312
algorithms work	0.02857142857142857
scientific	5.5800457563752025e-05
modules	5.5800457563752025e-05
are three	0.004149377593360996
three basic	0.3333333333333333
basic techniques	0.07692307692307693
techniques for	0.08695652173913043
evaluating NLG	0.2
systems :	0.008928571428571428
: task-based	0.00980392156862745
task-based -LRB-	0.25
-LRB- extrinsic	0.0027100271002710027
extrinsic -RRB-	0.16666666666666666
-RRB- evaluation	0.0027100271002710027
: give	0.0196078431372549
give the	0.5
the generated	0.001384083044982699
generated text	0.13333333333333333
and assess	0.001445086705202312
assess how	0.6666666666666666
well it	0.07142857142857142
it helps	0.008547008547008548
helps him	0.5
him perform	0.5
a task	0.0036809815950920245
task -LRB-	0.023809523809523808
or otherwise	0.0045045045045045045
otherwise achieves	0.5
achieves its	0.5
its communicative	0.02857142857142857
goal -RRB-	0.14285714285714285
task-based	0.00011160091512750405
helps	5.5800457563752025e-05
him	5.5800457563752025e-05
achieves	5.5800457563752025e-05
system which	0.010752688172043012
which generates	0.007246376811594203
generates summaries	0.3333333333333333
evaluated by	0.14285714285714285
by giving	0.005714285714285714
giving these	0.5
to doctors	0.0013280212483399733
doctors ,	0.3333333333333333
and assessing	0.001445086705202312
assessing whether	1.0
summaries helps	0.023255813953488372
helps doctors	0.5
doctors make	0.3333333333333333
make better	0.05
better decisions	0.1111111111111111
decisions .	0.1
giving	5.5800457563752025e-05
doctors	8.370068634562804e-05
assessing	2.7900228781876013e-05
<s> human	0.0007686395080707148
human ratings	0.08695652173913043
ratings :	0.1111111111111111
and ask	0.001445086705202312
ask him	0.25
him or	0.5
or her	0.009009009009009009
her to	0.5
to rate	0.0026560424966799467
rate the	0.09090909090909091
quality and	0.1
and usefulness	0.001445086705202312
usefulness of	1.0
her	5.5800457563752025e-05
rate	0.00030690251660063614
usefulness	2.7900228781876013e-05
<s> metrics	0.0007686395080707148
metrics :	0.1111111111111111
: compare	0.00980392156862745
compare generated	0.14285714285714285
generated texts	0.06666666666666667
to texts	0.0013280212483399733
texts written	0.058823529411764705
by people	0.011428571428571429
people from	0.0625
using an	0.03389830508474576
automatic metric	0.043478260869565216
metric such	0.3333333333333333
as BLEU	0.003484320557491289
BLEU .	0.3333333333333333
Generally speaking	0.4
we ultimately	0.022222222222222223
ultimately want	1.0
to know	0.0013280212483399733
know is	0.5
is how	0.0040650406504065045
how useful	0.034482758620689655
useful NLG	0.07142857142857142
are at	0.008298755186721992
at helping	0.014705882352941176
helping people	1.0
people ,	0.0625
first of	0.030303030303030304
above techniques	0.07692307692307693
techniques .	0.043478260869565216
ultimately	2.7900228781876013e-05
know	5.5800457563752025e-05
helping	2.7900228781876013e-05
, task-based	0.0005614823133071309
task-based evaluations	0.75
evaluations are	0.3333333333333333
are time-consuming	0.004149377593360996
time-consuming and	0.3333333333333333
be difficult	0.004219409282700422
to carry	0.0013280212483399733
carry out	1.0
out -LRB-	0.07142857142857142
-LRB- especially	0.005420054200542005
especially if	0.06666666666666667
if they	0.03571428571428571
require subjects	0.045454545454545456
subjects with	1.0
with specialised	0.00546448087431694
specialised expertise	0.5
expertise ,	1.0
as doctors	0.003484320557491289
doctors -RRB-	0.3333333333333333
carry	2.7900228781876013e-05
subjects	2.7900228781876013e-05
specialised	5.5800457563752025e-05
expertise	2.7900228781876013e-05
<s> Hence	0.0015372790161414297
Hence -LRB-	0.5
-RRB- task-based	0.005420054200542005
the exception	0.0006920415224913495
exception ,	1.0
the norm	0.0006920415224913495
norm .	1.0
Hence	5.5800457563752025e-05
exception	2.7900228781876013e-05
norm	2.7900228781876013e-05
In recent	0.01904761904761905
recent years	0.5
years researchers	0.047619047619047616
have started	0.009615384615384616
started trying	0.25
to assess	0.0013280212483399733
well human-ratings	0.03571428571428571
human-ratings and	1.0
and metrics	0.001445086705202312
metrics correlate	0.1111111111111111
with -LRB-	0.00546448087431694
-LRB- predict	0.0027100271002710027
predict -RRB-	0.16666666666666666
evaluations .	0.16666666666666666
started	0.00011160091512750405
human-ratings	2.7900228781876013e-05
Much of	0.3333333333333333
this work	0.01098901098901099
is being	0.006097560975609756
being conducted	0.05555555555555555
of Generation	0.00089126559714795
Generation Challenges	0.5
Challenges shared-task	1.0
shared-task events	1.0
events .	1.0
Challenges	2.7900228781876013e-05
shared-task	2.7900228781876013e-05
events	2.7900228781876013e-05
<s> Initial	0.0007686395080707148
Initial results	1.0
results suggest	0.047619047619047616
suggest that	0.3333333333333333
that human	0.0070921985815602835
ratings are	0.2222222222222222
are much	0.008298755186721992
much better	0.045454545454545456
better than	0.1111111111111111
than metrics	0.022222222222222223
metrics in	0.1111111111111111
this regard	0.01098901098901099
regard .	0.2
Initial	2.7900228781876013e-05
In other	0.01904761904761905
other words	0.02857142857142857
ratings usually	0.1111111111111111
usually do	0.03125
do predict	0.038461538461538464
predict task-effectiveness	0.3333333333333333
task-effectiveness at	0.5
least to	0.2
degree -LRB-	0.16666666666666666
-LRB- although	0.005420054200542005
although there	0.16666666666666666
are exceptions	0.004149377593360996
exceptions -RRB-	1.0
while ratings	0.05
ratings produced	0.1111111111111111
by metrics	0.005714285714285714
metrics often	0.1111111111111111
often do	0.022727272727272728
not predict	0.008928571428571428
task-effectiveness well	0.5
well .	0.07142857142857142
task-effectiveness	5.5800457563752025e-05
exceptions	2.7900228781876013e-05
These results	0.058823529411764705
results are	0.19047619047619047
very preliminary	0.024390243902439025
preliminary ,	0.3333333333333333
, hopefully	0.0005614823133071309
hopefully better	1.0
better data	0.1111111111111111
data will	0.012987012987012988
be available	0.004219409282700422
available soon	0.058823529411764705
soon .	0.3333333333333333
hopefully	2.7900228781876013e-05
are currently	0.008298755186721992
currently the	0.14285714285714285
most popular	0.05172413793103448
popular evaluation	0.1111111111111111
evaluation technique	0.018518518518518517
technique in	0.14285714285714285
NLG ;	0.047619047619047616
; this	0.06382978723404255
is contrast	0.0020325203252032522
contrast to	0.25
to machine	0.00398406374501992
where metrics	0.02857142857142857
metrics are	0.1111111111111111
very widely	0.024390243902439025
widely used	0.875
widely	0.0002232018302550081
a subtopic	0.001226993865030675
subtopic of	1.0
processing in	0.037037037037037035
in artificial	0.0018726591760299626
that deals	0.0035460992907801418
with machine	0.00546448087431694
machine reading	0.012658227848101266
comprehension .	0.42857142857142855
subtopic	2.7900228781876013e-05
of disassembling	0.00089126559714795
disassembling and	1.0
and parsing	0.001445086705202312
parsing input	0.03571428571428571
input is	0.024390243902439025
complex than	0.08333333333333333
than the	0.08888888888888889
the reverse	0.0006920415224913495
reverse process	0.5
of assembling	0.00089126559714795
assembling output	1.0
output in	0.038461538461538464
generation because	0.1111111111111111
because of	0.2
the occurrence	0.0006920415224913495
occurrence of	0.5
of unknown	0.00089126559714795
unknown and	1.0
and unexpected	0.001445086705202312
unexpected features	1.0
features in	0.038461538461538464
input and	0.04878048780487805
appropriate syntactic	0.25
syntactic and	0.15384615384615385
semantic schemes	0.047619047619047616
schemes to	0.5
to apply	0.0013280212483399733
to it	0.0013280212483399733
, factors	0.0005614823133071309
factors which	0.3333333333333333
are pre-determined	0.004149377593360996
pre-determined when	1.0
when outputting	0.02857142857142857
outputting language	0.5
disassembling	2.7900228781876013e-05
reverse	5.5800457563752025e-05
assembling	2.7900228781876013e-05
unknown	2.7900228781876013e-05
unexpected	2.7900228781876013e-05
schemes	5.5800457563752025e-05
factors	8.370068634562804e-05
pre-determined	2.7900228781876013e-05
outputting	5.5800457563752025e-05
is considerable	0.0020325203252032522
considerable commercial	0.2
commercial interest	0.09090909090909091
field because	0.037037037037037035
its application	0.02857142857142857
application to	0.07142857142857142
to news-gathering	0.0013280212483399733
news-gathering ,	1.0
, text	0.0016844469399213925
text categorization	0.006289308176100629
categorization ,	1.0
, voice-activation	0.0005614823133071309
voice-activation ,	1.0
, archiving	0.0005614823133071309
archiving and	1.0
and large-scale	0.001445086705202312
large-scale content-analysis	1.0
content-analysis .	1.0
news-gathering	2.7900228781876013e-05
categorization	2.7900228781876013e-05
voice-activation	2.7900228781876013e-05
archiving	2.7900228781876013e-05
large-scale	2.7900228781876013e-05
content-analysis	2.7900228781876013e-05
<s> Eight	0.0007686395080707148
Eight years	1.0
years after	0.047619047619047616
after John	0.08333333333333333
John McCarthy	0.125
McCarthy coined	1.0
coined the	1.0
term artificial	0.05555555555555555
intelligence ,	0.125
, Bobrow	0.0005614823133071309
Bobrow 's	1.0
's dissertation	0.0196078431372549
dissertation -LRB-	0.3333333333333333
-LRB- titled	0.0027100271002710027
titled Natural	1.0
Language Input	0.08333333333333333
Input for	0.5
a Computer	0.001226993865030675
Computer Problem	0.16666666666666666
Problem Solving	1.0
Solving System	0.5
System -RRB-	1.0
-RRB- showed	0.0027100271002710027
showed how	0.25
computer can	0.022727272727272728
can understand	0.0055248618784530384
understand simple	0.2857142857142857
simple natural	0.038461538461538464
solve algebra	0.25
algebra word	0.5
word problems	0.016666666666666666
problems .	0.17647058823529413
Eight	2.7900228781876013e-05
McCarthy	2.7900228781876013e-05
coined	2.7900228781876013e-05
Bobrow	2.7900228781876013e-05
titled	2.7900228781876013e-05
Input	5.5800457563752025e-05
Computer	0.00016740137269125608
Problem	2.7900228781876013e-05
System	2.7900228781876013e-05
A year	0.02
year later	0.16666666666666666
later ,	0.5
in 1965	0.0018726591760299626
1965 ,	0.5
, Joseph	0.0005614823133071309
Weizenbaum at	0.3333333333333333
at MIT	0.029411764705882353
MIT wrote	0.5
wrote ELIZA	0.16666666666666666
an interactive	0.007575757575757576
interactive program	0.25
program that	0.09090909090909091
that carried	0.0035460992907801418
carried on	0.5
a dialogue	0.00245398773006135
dialogue in	0.5
in English	0.009363295880149813
English on	0.02702702702702703
any topic	0.06451612903225806
popular being	0.1111111111111111
being psychotherapy	0.05555555555555555
psychotherapy .	1.0
later	0.00027900228781876013
1965	0.00011160091512750405
MIT	5.5800457563752025e-05
carried	5.5800457563752025e-05
dialogue	5.5800457563752025e-05
psychotherapy	2.7900228781876013e-05
<s> ELIZA	0.0023059185242121443
ELIZA worked	0.1111111111111111
worked by	0.2
by simple	0.005714285714285714
simple parsing	0.038461538461538464
parsing and	0.03571428571428571
and substitution	0.001445086705202312
of key	0.00089126559714795
key words	0.16666666666666666
into canned	0.01282051282051282
canned phrases	0.5
and Weizenbaum	0.001445086705202312
Weizenbaum sidestepped	0.3333333333333333
sidestepped the	1.0
of giving	0.00089126559714795
giving the	0.5
a database	0.0036809815950920245
database of	0.2
of real-world	0.00089126559714795
real-world knowledge	0.16666666666666666
knowledge or	0.037037037037037035
a rich	0.0036809815950920245
rich lexicon	0.6
lexicon .	0.1111111111111111
sidestepped	2.7900228781876013e-05
database	0.00027900228781876013
rich	0.00013950114390938006
<s> Yet	0.0007686395080707148
Yet ELIZA	1.0
ELIZA gained	0.1111111111111111
gained surprising	0.5
surprising popularity	1.0
popularity as	1.0
a toy	0.00245398773006135
toy project	0.5
project and	0.07692307692307693
be seen	0.012658227848101266
seen as	0.3
very early	0.024390243902439025
early precursor	0.1
precursor to	1.0
to current	0.0013280212483399733
current commercial	0.14285714285714285
commercial systems	0.09090909090909091
systems such	0.017857142857142856
as those	0.017421602787456445
those used	0.13636363636363635
by Ask.com	0.005714285714285714
Ask.com .	1.0
Yet	2.7900228781876013e-05
gained	5.5800457563752025e-05
surprising	2.7900228781876013e-05
popularity	2.7900228781876013e-05
toy	5.5800457563752025e-05
precursor	2.7900228781876013e-05
Ask.com	2.7900228781876013e-05
In 1969	0.01904761904761905
1969 Roger	0.5
Roger Schank	0.75
Schank at	0.2
at Stanford	0.014705882352941176
Stanford University	0.5
University introduced	0.1111111111111111
introduced the	1.0
the conceptual	0.0006920415224913495
conceptual dependency	0.5
dependency theory	0.2
theory for	0.07692307692307693
1969	5.5800457563752025e-05
Stanford	5.5800457563752025e-05
introduced	5.5800457563752025e-05
This model	0.031746031746031744
, partially	0.0005614823133071309
partially influenced	1.0
the work	0.001384083044982699
work of	0.08333333333333333
of Sydney	0.00089126559714795
Sydney Lamb	1.0
Lamb ,	1.0
was extensively	0.012987012987012988
extensively used	1.0
by Schank	0.005714285714285714
Schank 's	0.2
's students	0.0196078431372549
students at	0.6666666666666666
at Yale	0.029411764705882353
Yale University	0.5
University ,	0.1111111111111111
as Robert	0.003484320557491289
Robert Wilensky	0.25
, Wendy	0.0005614823133071309
Wendy Lehnert	1.0
and Janet	0.001445086705202312
Janet Kolodner	0.5
Kolodner .	1.0
partially	2.7900228781876013e-05
Sydney	2.7900228781876013e-05
Lamb	2.7900228781876013e-05
extensively	2.7900228781876013e-05
Yale	5.5800457563752025e-05
Wendy	2.7900228781876013e-05
Kolodner	2.7900228781876013e-05
In 1970	0.009523809523809525
1970 ,	0.3333333333333333
William A.	0.5
A. Woods	0.2
Woods introduced	1.0
the augmented	0.0006920415224913495
augmented transition	1.0
transition network	1.0
network -LRB-	0.16666666666666666
-LRB- ATN	0.0027100271002710027
ATN -RRB-	1.0
-RRB- to	0.01084010840108401
to represent	0.0013280212483399733
represent natural	0.1111111111111111
input .	0.04878048780487805
Woods	2.7900228781876013e-05
augmented	2.7900228781876013e-05
transition	2.7900228781876013e-05
network	0.00016740137269125608
ATN	2.7900228781876013e-05
of phrase	0.00089126559714795
phrase structure	0.2
structure rules	0.08333333333333333
rules ATNs	0.023255813953488372
ATNs used	0.3333333333333333
used an	0.008849557522123894
an equivalent	0.007575757575757576
equivalent set	0.2
of finite	0.00089126559714795
finite state	0.8
state automata	0.07142857142857142
automata that	1.0
were called	0.024390243902439025
called recursively	0.05555555555555555
recursively .	0.5
ATNs	8.370068634562804e-05
finite	0.00013950114390938006
automata	2.7900228781876013e-05
recursively	5.5800457563752025e-05
<s> ATNs	0.0007686395080707148
ATNs and	0.3333333333333333
their more	0.029411764705882353
more general	0.031578947368421054
general format	0.045454545454545456
format called	0.5
called ``	0.2777777777777778
`` generalized	0.005291005291005291
generalized ATNs	1.0
ATNs ''	0.3333333333333333
'' continued	0.005154639175257732
continued to	0.3333333333333333
of years	0.00089126559714795
years .	0.19047619047619047
format	5.5800457563752025e-05
generalized	2.7900228781876013e-05
continued	0.0002511020590368841
In 1971	0.009523809523809525
1971 Terry	0.3333333333333333
Terry Winograd	1.0
Winograd finished	0.3333333333333333
finished writing	0.5
writing SHRDLU	0.1111111111111111
SHRDLU for	0.16666666666666666
for his	0.007220216606498195
his PhD	0.08333333333333333
PhD thesis	1.0
thesis at	1.0
MIT .	0.5
1971	8.370068634562804e-05
Terry	2.7900228781876013e-05
Winograd	8.370068634562804e-05
finished	5.5800457563752025e-05
PhD	2.7900228781876013e-05
thesis	2.7900228781876013e-05
<s> SHRDLU	0.0015372790161414297
SHRDLU could	0.16666666666666666
could understand	0.0625
simple English	0.038461538461538464
English sentences	0.02702702702702703
a restricted	0.001226993865030675
restricted world	0.25
world of	0.06666666666666667
of children	0.00089126559714795
children 's	0.5
's blocks	0.0196078431372549
blocks to	0.25
to direct	0.0013280212483399733
direct a	0.16666666666666666
a robotic	0.001226993865030675
robotic arm	1.0
arm to	1.0
to move	0.0013280212483399733
move items	1.0
items .	0.5
children	5.5800457563752025e-05
robotic	2.7900228781876013e-05
arm	2.7900228781876013e-05
move	2.7900228781876013e-05
The successful	0.005208333333333333
successful demonstration	0.1111111111111111
of SHRDLU	0.00089126559714795
SHRDLU provided	0.16666666666666666
provided significant	0.2
significant momentum	0.1111111111111111
momentum for	1.0
for continued	0.0036101083032490976
continued research	0.2222222222222222
momentum	2.7900228781876013e-05
<s> Winograd	0.0007686395080707148
Winograd continued	0.3333333333333333
major influence	0.08333333333333333
influence in	1.0
field with	0.037037037037037035
his book	0.08333333333333333
book Language	0.125
Language as	0.08333333333333333
a Cognitive	0.001226993865030675
Cognitive Process	0.3333333333333333
Process .	1.0
influence	2.7900228781876013e-05
Process	2.7900228781876013e-05
<s> At	0.0023059185242121443
At Stanford	0.3333333333333333
Stanford ,	0.5
, Winograd	0.0005614823133071309
Winograd was	0.3333333333333333
was later	0.012987012987012988
later the	0.1
the adviser	0.0006920415224913495
adviser for	1.0
for Larry	0.0036101083032490976
Larry Page	0.5
Page ,	1.0
, who	0.0005614823133071309
who co-founded	0.1
co-founded Google	1.0
At	8.370068634562804e-05
adviser	2.7900228781876013e-05
Larry	5.5800457563752025e-05
Page	2.7900228781876013e-05
co-founded	2.7900228781876013e-05
the 1970s	0.0006920415224913495
1970s and	0.6666666666666666
and 1980s	0.002890173410404624
1980s the	0.1111111111111111
processing group	0.018518518518518517
group at	0.25
at SRI	0.014705882352941176
SRI International	1.0
International continued	1.0
and development	0.002890173410404624
development in	0.08333333333333333
group	0.00011160091512750405
SRI	2.7900228781876013e-05
International	2.7900228781876013e-05
A number	0.06
of commercial	0.00089126559714795
commercial efforts	0.18181818181818182
efforts based	0.14285714285714285
research were	0.023809523809523808
were undertaken	0.024390243902439025
undertaken ,	0.5
in 1982	0.0018726591760299626
1982 Gary	0.3333333333333333
Gary Hendrix	1.0
Hendrix formed	1.0
formed Symantec	0.2
Symantec Corporation	0.5
Corporation originally	0.25
originally as	0.5
a company	0.001226993865030675
company for	0.3333333333333333
for developing	0.007220216606498195
developing a	0.25
language interface	0.006756756756756757
interface for	0.25
for database	0.0036101083032490976
database queries	0.1
queries on	0.3333333333333333
on personal	0.0047169811320754715
personal computers	0.25
computers .	0.2222222222222222
efforts	0.0001953016014731321
undertaken	5.5800457563752025e-05
Gary	2.7900228781876013e-05
Hendrix	2.7900228781876013e-05
Symantec	5.5800457563752025e-05
Corporation	0.00011160091512750405
originally	5.5800457563752025e-05
company	8.370068634562804e-05
developing	0.00011160091512750405
interface	0.00011160091512750405
queries	8.370068634562804e-05
personal	0.00011160091512750405
the advent	0.0006920415224913495
advent of	1.0
of mouse	0.00089126559714795
mouse driven	1.0
driven ,	1.0
, graphic	0.0005614823133071309
graphic user	1.0
user interfaces	0.14285714285714285
interfaces Symantec	0.5
Symantec changed	0.5
changed direction	0.5
direction .	0.3333333333333333
advent	2.7900228781876013e-05
mouse	2.7900228781876013e-05
driven	2.7900228781876013e-05
graphic	2.7900228781876013e-05
interfaces	5.5800457563752025e-05
changed	5.5800457563752025e-05
direction	8.370068634562804e-05
other commercial	0.014285714285714285
efforts were	0.14285714285714285
were started	0.024390243902439025
started around	0.25
, Larry	0.0005614823133071309
Larry R.	0.5
R. Harris	0.16666666666666666
Harris at	0.1111111111111111
the Artificial	0.0006920415224913495
Artificial Intelligence	0.5
Intelligence Corporation	0.3333333333333333
Corporation and	0.25
and Roger	0.001445086705202312
Schank and	0.4
and his	0.001445086705202312
at Cognitive	0.014705882352941176
Cognitive Systems	0.3333333333333333
Systems corp.	0.08333333333333333
corp. .	1.0
Artificial	5.5800457563752025e-05
corp.	2.7900228781876013e-05
In 1983	0.009523809523809525
1983 ,	1.0
Michael Dyer	0.25
Dyer developed	1.0
developed the	0.15384615384615385
the BORIS	0.0006920415224913495
BORIS system	1.0
system at	0.010752688172043012
Yale which	0.5
which bore	0.007246376811594203
bore similarities	1.0
similarities to	0.5
of Roger	0.00089126559714795
and W.	0.001445086705202312
W. G.	0.5
G. Lehnart	0.5
Lehnart .	1.0
1983	2.7900228781876013e-05
Dyer	2.7900228781876013e-05
BORIS	2.7900228781876013e-05
bore	2.7900228781876013e-05
similarities	5.5800457563752025e-05
W.	5.5800457563752025e-05
Lehnart	2.7900228781876013e-05
<s> Scope	0.0007686395080707148
Scope and	1.0
The umbrella	0.005208333333333333
umbrella term	1.0
understanding ''	0.06060606060606061
a diverse	0.001226993865030675
diverse set	0.5
computer applications	0.022727272727272728
, ranging	0.0011229646266142617
ranging from	1.0
from small	0.019230769230769232
, relatively	0.0005614823133071309
relatively simple	1.0
simple tasks	0.038461538461538464
as short	0.003484320557491289
short commands	0.125
commands issued	0.2
issued to	1.0
to robots	0.0013280212483399733
robots ,	1.0
to highly	0.0013280212483399733
highly complex	0.1111111111111111
complex endeavors	0.041666666666666664
endeavors such	1.0
the full	0.0020761245674740486
full comprehension	0.2
of newspaper	0.00089126559714795
newspaper articles	0.3333333333333333
articles or	0.25
or poetry	0.0045045045045045045
poetry passages	1.0
passages .	0.5
Scope	2.7900228781876013e-05
umbrella	2.7900228781876013e-05
ranging	5.5800457563752025e-05
relatively	2.7900228781876013e-05
commands	0.00013950114390938006
issued	2.7900228781876013e-05
robots	2.7900228781876013e-05
endeavors	2.7900228781876013e-05
poetry	2.7900228781876013e-05
Many real	0.08333333333333333
world applications	0.06666666666666667
applications fall	0.04
fall between	0.25
two extremes	0.034482758620689655
extremes ,	1.0
for instance	0.018050541516245487
instance text	0.07142857142857142
text classification	0.006289308176100629
automatic analysis	0.043478260869565216
of emails	0.00089126559714795
emails and	0.5
their routing	0.029411764705882353
routing to	0.3333333333333333
suitable department	0.25
department in	0.5
a corporation	0.001226993865030675
corporation does	1.0
not require	0.008928571428571428
require in	0.045454545454545456
in depth	0.0018726591760299626
depth understanding	0.3333333333333333
but is	0.029411764705882353
is far	0.0040650406504065045
far more	0.25
the management	0.0006920415224913495
management of	0.2857142857142857
of simple	0.0017825311942959
simple queries	0.038461538461538464
queries to	0.3333333333333333
to database	0.0013280212483399733
database tables	0.1
tables with	0.3333333333333333
with fixed	0.00546448087431694
fixed schemata	0.5
schemata .	1.0
extremes	2.7900228781876013e-05
emails	5.5800457563752025e-05
routing	8.370068634562804e-05
department	5.5800457563752025e-05
corporation	2.7900228781876013e-05
depth	8.370068634562804e-05
management	0.0001953016014731321
tables	8.370068634562804e-05
fixed	5.5800457563752025e-05
schemata	2.7900228781876013e-05
<s> Throughout	0.0007686395080707148
Throughout the	1.0
the years	0.0006920415224913495
years various	0.047619047619047616
various attempts	0.05555555555555555
at processing	0.014705882352941176
processing natural	0.018518518518518517
language or	0.013513513513513514
or English-like	0.0045045045045045045
English-like sentences	0.3333333333333333
sentences presented	0.013157894736842105
presented to	0.16666666666666666
to computers	0.0013280212483399733
computers have	0.1111111111111111
have taken	0.009615384615384616
taken place	0.3333333333333333
place at	0.25
at varying	0.014705882352941176
varying degrees	1.0
degrees of	0.5
of complexity	0.00089126559714795
complexity .	0.08333333333333333
Throughout	2.7900228781876013e-05
English-like	8.370068634562804e-05
varying	2.7900228781876013e-05
degrees	5.5800457563752025e-05
Some attempts	0.047619047619047616
attempts have	0.16666666666666666
not resulted	0.008928571428571428
resulted in	1.0
in systems	0.003745318352059925
systems with	0.017857142857142856
with deep	0.00546448087431694
but have	0.029411764705882353
have helped	0.009615384615384616
helped overall	0.3333333333333333
overall system	0.16666666666666666
system usability	0.010752688172043012
usability .	1.0
resulted	5.5800457563752025e-05
helped	8.370068634562804e-05
usability	2.7900228781876013e-05
, Wayne	0.0005614823133071309
Wayne Ratliff	1.0
Ratliff originally	1.0
originally developed	0.5
the Vulcan	0.0006920415224913495
Vulcan program	0.5
program with	0.045454545454545456
an English-like	0.007575757575757576
English-like syntax	0.3333333333333333
to mimic	0.0013280212483399733
mimic the	1.0
the English	0.0020761245674740486
English speaking	0.02702702702702703
speaking computer	0.125
computer in	0.045454545454545456
in Star	0.0018726591760299626
Star Trek	1.0
Trek .	1.0
Wayne	2.7900228781876013e-05
Ratliff	2.7900228781876013e-05
Vulcan	5.5800457563752025e-05
mimic	2.7900228781876013e-05
Star	2.7900228781876013e-05
Trek	2.7900228781876013e-05
<s> Vulcan	0.0007686395080707148
Vulcan later	0.5
later became	0.1
became the	0.2
the dBase	0.0006920415224913495
dBase system	1.0
system whose	0.010752688172043012
whose easy-to-use	0.3333333333333333
easy-to-use syntax	1.0
syntax effectively	0.09090909090909091
effectively launched	0.3333333333333333
launched the	1.0
the personal	0.0006920415224913495
personal computer	0.25
computer database	0.022727272727272728
database industry	0.1
industry .	0.3333333333333333
dBase	2.7900228781876013e-05
easy-to-use	2.7900228781876013e-05
launched	2.7900228781876013e-05
industry	8.370068634562804e-05
Systems with	0.08333333333333333
an easy	0.007575757575757576
easy to	1.0
or English	0.0045045045045045045
English like	0.02702702702702703
like syntax	0.03571428571428571
syntax are	0.09090909090909091
are ,	0.004149377593360996
, quite	0.0005614823133071309
quite distinct	0.125
from systems	0.009615384615384616
that use	0.0070921985815602835
lexicon and	0.1111111111111111
and include	0.002890173410404624
internal representation	0.6
-LRB- often	0.005420054200542005
as first	0.003484320557491289
first order	0.030303030303030304
order logic	0.07142857142857142
logic -RRB-	0.25
the semantics	0.001384083044982699
semantics of	0.07142857142857142
language sentences	0.006756756756756757
easy	8.370068634562804e-05
Hence the	0.5
the breadth	0.0006920415224913495
breadth and	0.5
and depth	0.001445086705202312
depth of	0.3333333333333333
`` understanding	0.005291005291005291
'' aimed	0.005154639175257732
aimed at	1.0
at by	0.014705882352941176
system determine	0.010752688172043012
determine both	0.043478260869565216
both the	0.06451612903225806
the implied	0.0006920415224913495
implied challenges	1.0
challenges -RRB-	0.5
applications it	0.04
can deal	0.0055248618784530384
deal with	0.5
with .	0.00546448087431694
breadth	5.5800457563752025e-05
aimed	5.5800457563752025e-05
implied	2.7900228781876013e-05
challenges	5.5800457563752025e-05
The ``	0.010416666666666666
`` breadth	0.005291005291005291
breadth ''	0.5
'' of	0.005154639175257732
is measured	0.006097560975609756
measured by	0.5
the sizes	0.0006920415224913495
sizes of	0.6666666666666666
its vocabulary	0.02857142857142857
and grammar	0.002890173410404624
grammar .	0.10810810810810811
measured	0.00016740137269125608
sizes	8.370068634562804e-05
`` depth	0.005291005291005291
depth ''	0.3333333333333333
the degree	0.0006920415224913495
degree to	0.16666666666666666
which its	0.007246376811594203
its understanding	0.02857142857142857
understanding approximates	0.030303030303030304
approximates that	0.5
a fluent	0.001226993865030675
fluent native	1.0
approximates	5.5800457563752025e-05
fluent	2.7900228781876013e-05
At the	0.3333333333333333
the narrowest	0.0006920415224913495
narrowest and	1.0
and shallowest	0.001445086705202312
shallowest ,	1.0
, English-like	0.0005614823133071309
English-like command	0.3333333333333333
command interpreters	0.5
interpreters require	1.0
require minimal	0.045454545454545456
minimal complexity	1.0
complexity ,	0.16666666666666666
a small	0.00245398773006135
small range	0.1111111111111111
range of	0.5714285714285714
applications .	0.16
narrowest	2.7900228781876013e-05
shallowest	2.7900228781876013e-05
command	5.5800457563752025e-05
interpreters	2.7900228781876013e-05
minimal	2.7900228781876013e-05
range	0.0001953016014731321
<s> Narrow	0.0007686395080707148
Narrow but	1.0
but deep	0.014705882352941176
deep systems	0.14285714285714285
systems explore	0.008928571428571428
explore and	0.25
and model	0.001445086705202312
model mechanisms	0.03333333333333333
mechanisms of	0.5
of understanding	0.00089126559714795
but they	0.04411764705882353
they still	0.025
still have	0.06666666666666667
have limited	0.009615384615384616
limited application	0.1
application .	0.07142857142857142
Narrow	2.7900228781876013e-05
mechanisms	5.5800457563752025e-05
Systems that	0.3333333333333333
that attempt	0.0035460992907801418
to understand	0.00398406374501992
understand the	0.2857142857142857
the contents	0.0006920415224913495
contents of	1.0
document such	0.027777777777777776
a news	0.00245398773006135
news release	0.07692307692307693
release beyond	0.3333333333333333
beyond simple	0.16666666666666666
simple keyword	0.038461538461538464
keyword matching	1.0
matching and	0.2
judge its	0.25
its suitability	0.02857142857142857
suitability for	0.5
user are	0.07142857142857142
are broader	0.004149377593360996
broader and	1.0
require significant	0.045454545454545456
significant complexity	0.1111111111111111
still somewhat	0.06666666666666667
somewhat shallow	0.5
shallow .	0.16666666666666666
contents	2.7900228781876013e-05
release	8.370068634562804e-05
keyword	2.7900228781876013e-05
suitability	5.5800457563752025e-05
broader	2.7900228781876013e-05
somewhat	5.5800457563752025e-05
both very	0.03225806451612903
very broad	0.04878048780487805
broad and	0.25
and very	0.001445086705202312
very deep	0.024390243902439025
deep are	0.14285714285714285
are beyond	0.004149377593360996
current state	0.14285714285714285
state of	0.35714285714285715
the art	0.001384083044982699
art .	0.5
broad	0.00011160091512750405
art	5.5800457563752025e-05
<s> Components	0.0007686395080707148
Components and	1.0
and architecture	0.001445086705202312
architecture Regardless	0.5
Regardless of	1.0
the approach	0.0006920415224913495
approach used	0.02857142857142857
some common	0.012048192771084338
common components	0.04
components can	0.2
identified in	0.2
most natural	0.034482758620689655
understanding systems	0.030303030303030304
Components	2.7900228781876013e-05
architecture	5.5800457563752025e-05
Regardless	2.7900228781876013e-05
components	0.00013950114390938006
needs a	0.2
a lexicon	0.00245398773006135
lexicon of	0.2222222222222222
language and	0.013513513513513514
a parser	0.0036809815950920245
parser and	0.0625
rules to	0.06976744186046512
to break	0.0013280212483399733
break sentences	0.5
break	5.5800457563752025e-05
The construction	0.005208333333333333
lexicon with	0.1111111111111111
suitable ontology	0.25
ontology requires	0.5
requires significant	0.0625
significant effort	0.1111111111111111
effort ,	0.25
the Wordnet	0.0006920415224913495
Wordnet lexicon	1.0
lexicon required	0.1111111111111111
required many	0.14285714285714285
many person-years	0.019230769230769232
person-years of	1.0
of effort	0.00089126559714795
effort .	0.25
Wordnet	2.7900228781876013e-05
person-years	2.7900228781876013e-05
system also	0.010752688172043012
also needs	0.014492753623188406
a semantic	0.001226993865030675
semantic theory	0.09523809523809523
theory to	0.07692307692307693
to guide	0.0013280212483399733
the comprehension	0.0006920415224913495
The interpretation	0.005208333333333333
interpretation capabilities	0.5
capabilities of	0.2
understanding system	0.030303030303030304
system depend	0.010752688172043012
theory it	0.07692307692307693
uses .	0.07142857142857142
interpretation	5.5800457563752025e-05
<s> Competing	0.0007686395080707148
Competing semantic	1.0
semantic theories	0.047619047619047616
language have	0.006756756756756757
have specific	0.009615384615384616
specific trade	0.047619047619047616
trade offs	0.5
offs in	1.0
in their	0.00749063670411985
their suitability	0.029411764705882353
suitability as	0.5
computer automated	0.022727272727272728
automated semantic	0.14285714285714285
semantic interpretation	0.047619047619047616
interpretation .	0.5
Competing	2.7900228781876013e-05
trade	5.5800457563752025e-05
offs	2.7900228781876013e-05
These range	0.058823529411764705
range from	0.2857142857142857
from naive	0.009615384615384616
naive semantics	0.5
semantics or	0.14285714285714285
or stochastic	0.0045045045045045045
stochastic semantic	0.125
semantic analysis	0.09523809523809523
analysis to	0.015384615384615385
of pragmatics	0.00089126559714795
pragmatics to	0.3333333333333333
to derive	0.0013280212483399733
derive meaning	0.5
meaning from	0.043478260869565216
from context	0.009615384615384616
derive	5.5800457563752025e-05
<s> Advanced	0.0023059185242121443
Advanced applications	0.2
applications of	0.04
understanding also	0.030303030303030304
also attempt	0.014492753623188406
to incorporate	0.0013280212483399733
incorporate logical	1.0
logical inference	0.16666666666666666
inference within	0.25
within their	0.05555555555555555
their framework	0.029411764705882353
Advanced	0.00013950114390938006
incorporate	2.7900228781876013e-05
is generally	0.0020325203252032522
generally achieved	0.09090909090909091
by mapping	0.005714285714285714
mapping the	0.5
the derived	0.0006920415224913495
derived meaning	0.16666666666666666
meaning into	0.043478260869565216
of assertions	0.00089126559714795
assertions in	0.5
in predicate	0.0018726591760299626
predicate logic	1.0
logic ,	0.25
then using	0.02857142857142857
using logical	0.01694915254237288
logical deduction	0.16666666666666666
deduction to	1.0
to arrive	0.0013280212483399733
arrive at	1.0
at conclusions	0.014705882352941176
conclusions .	1.0
mapping	5.5800457563752025e-05
assertions	5.5800457563752025e-05
predicate	2.7900228781876013e-05
deduction	2.7900228781876013e-05
arrive	2.7900228781876013e-05
conclusions	2.7900228781876013e-05
on functional	0.0047169811320754715
functional languages	0.5
as Lisp	0.003484320557491289
Lisp hence	1.0
hence need	0.5
a subsystem	0.001226993865030675
subsystem for	1.0
the representation	0.0006920415224913495
of logical	0.00089126559714795
logical assertions	0.16666666666666666
assertions ,	0.5
while logic	0.05
logic oriented	0.25
oriented systems	1.0
those using	0.045454545454545456
language Prolog	0.006756756756756757
Prolog generally	1.0
generally rely	0.09090909090909091
on an	0.014150943396226415
an extension	0.007575757575757576
extension of	1.0
the built	0.0006920415224913495
built in	0.3333333333333333
in logical	0.0018726591760299626
logical representation	0.16666666666666666
representation framework	0.05263157894736842
functional	5.5800457563752025e-05
Lisp	2.7900228781876013e-05
hence	5.5800457563752025e-05
subsystem	2.7900228781876013e-05
oriented	2.7900228781876013e-05
Prolog	2.7900228781876013e-05
extension	2.7900228781876013e-05
The management	0.005208333333333333
of context	0.0017825311942959
context in	0.030303030303030304
understanding can	0.030303030303030304
can present	0.0055248618784530384
present special	0.16666666666666666
special challenges	0.2
challenges .	0.5
special	0.00013950114390938006
A large	0.02
large variety	0.043478260869565216
of examples	0.00089126559714795
and counter	0.001445086705202312
counter examples	1.0
examples have	0.041666666666666664
have resulted	0.009615384615384616
in multiple	0.0018726591760299626
multiple approaches	0.07692307692307693
formal modeling	0.1111111111111111
modeling of	0.14285714285714285
context ,	0.12121212121212122
each with	0.022222222222222223
with specific	0.00546448087431694
specific strengths	0.047619047619047616
strengths and	0.5
and weaknesses	0.001445086705202312
weaknesses .	1.0
counter	2.7900228781876013e-05
weaknesses	2.7900228781876013e-05
usually abbreviated	0.03125
abbreviated to	1.0
to OCR	0.0013280212483399733
OCR ,	0.14285714285714285
the mechanical	0.0006920415224913495
mechanical or	1.0
or electronic	0.0045045045045045045
electronic conversion	0.5
of scanned	0.00089126559714795
scanned images	0.3333333333333333
images of	0.3333333333333333
of handwritten	0.00089126559714795
handwritten ,	0.5
, typewritten	0.0011229646266142617
typewritten or	0.2
or printed	0.0045045045045045045
into machine-encoded	0.01282051282051282
machine-encoded text	1.0
abbreviated	2.7900228781876013e-05
mechanical	2.7900228781876013e-05
scanned	8.370068634562804e-05
images	0.00016740137269125608
handwritten	5.5800457563752025e-05
typewritten	0.00013950114390938006
machine-encoded	2.7900228781876013e-05
is widely	0.0040650406504065045
a form	0.001226993865030675
data entry	0.03896103896103896
entry from	0.25
from some	0.009615384615384616
some sort	0.012048192771084338
of original	0.00089126559714795
original paper	0.07692307692307693
paper data	0.09090909090909091
data source	0.012987012987012988
source ,	0.041666666666666664
, whether	0.0005614823133071309
whether documents	0.07692307692307693
, sales	0.0005614823133071309
sales receipts	0.3333333333333333
receipts ,	1.0
, mail	0.0005614823133071309
mail ,	0.5
any number	0.03225806451612903
of printed	0.0017825311942959
printed records	0.08333333333333333
receipts	2.7900228781876013e-05
mail	5.5800457563752025e-05
is crucial	0.0020325203252032522
crucial to	1.0
the computerization	0.0006920415224913495
computerization of	1.0
printed texts	0.08333333333333333
texts so	0.058823529411764705
be electronically	0.004219409282700422
electronically searched	1.0
searched ,	1.0
, stored	0.0005614823133071309
stored more	1.0
more compactly	0.010526315789473684
compactly ,	1.0
, displayed	0.0005614823133071309
displayed on-line	0.5
on-line ,	0.3333333333333333
and used	0.001445086705202312
machine processes	0.012658227848101266
processes such	0.2
as machine	0.003484320557491289
mining .	0.2
crucial	2.7900228781876013e-05
computerization	2.7900228781876013e-05
electronically	2.7900228781876013e-05
searched	5.5800457563752025e-05
stored	2.7900228781876013e-05
compactly	2.7900228781876013e-05
displayed	5.5800457563752025e-05
on-line	8.370068634562804e-05
processes	0.00013950114390938006
<s> OCR	0.0030745580322828594
OCR is	0.061224489795918366
in pattern	0.0018726591760299626
intelligence and	0.125
and computer	0.001445086705202312
computer vision	0.022727272727272728
vision .	1.0
vision	2.7900228781876013e-05
<s> Early	0.0015372790161414297
Early versions	0.5
versions needed	0.3333333333333333
be programmed	0.008438818565400843
programmed with	0.5
with images	0.00546448087431694
each character	0.022222222222222223
character ,	0.09090909090909091
and worked	0.001445086705202312
worked on	0.4
on one	0.009433962264150943
one font	0.015384615384615385
font at	0.3333333333333333
at a	0.058823529411764705
a time	0.00245398773006135
time .	0.12121212121212122
Early	5.5800457563752025e-05
versions	8.370068634562804e-05
programmed	5.5800457563752025e-05
font	8.370068634562804e-05
`` Intelligent	0.005291005291005291
Intelligent ''	0.3333333333333333
'' systems	0.015463917525773196
high degree	0.05555555555555555
of recognition	0.0017825311942959
recognition accuracy	0.05785123966942149
accuracy for	0.06451612903225806
for most	0.007220216606498195
most fonts	0.017241379310344827
fonts are	0.3333333333333333
now common	0.07692307692307693
Intelligent	8.370068634562804e-05
fonts	8.370068634562804e-05
are capable	0.008298755186721992
capable of	1.0
of reproducing	0.00089126559714795
reproducing formatted	1.0
formatted output	1.0
that closely	0.0035460992907801418
closely approximates	0.2
approximates the	0.5
original scanned	0.07692307692307693
scanned page	0.3333333333333333
page including	0.14285714285714285
including images	0.07142857142857142
images ,	0.3333333333333333
, columns	0.0005614823133071309
columns and	1.0
other non-textual	0.014285714285714285
non-textual components	1.0
components .	0.2
capable	5.5800457563752025e-05
reproducing	2.7900228781876013e-05
formatted	2.7900228781876013e-05
columns	2.7900228781876013e-05
non-textual	2.7900228781876013e-05
In 1914	0.009523809523809525
1914 ,	1.0
Emanuel Goldberg	0.5
Goldberg developed	0.5
machine that	0.012658227848101266
that read	0.0035460992907801418
read characters	0.14285714285714285
characters and	0.0625
and converted	0.001445086705202312
converted them	0.3333333333333333
them into	0.05263157894736842
into standard	0.01282051282051282
standard telegraph	0.07142857142857142
telegraph code	1.0
code .	0.42857142857142855
1914	2.7900228781876013e-05
Goldberg	5.5800457563752025e-05
converted	8.370068634562804e-05
telegraph	2.7900228781876013e-05
code	0.0001953016014731321
-RRB- Around	0.0027100271002710027
Around the	1.0
, Edmund	0.0005614823133071309
Edmund Fournier	1.0
Fournier d'Albe	1.0
d'Albe developed	1.0
the Optophone	0.0006920415224913495
Optophone ,	1.0
a handheld	0.001226993865030675
handheld scanner	1.0
scanner that	0.3333333333333333
that when	0.0035460992907801418
when moved	0.02857142857142857
moved across	1.0
across a	0.2
a printed	0.001226993865030675
printed page	0.08333333333333333
produced tones	0.1111111111111111
tones that	1.0
that corresponded	0.0035460992907801418
corresponded to	1.0
to specific	0.0013280212483399733
specific letters	0.047619047619047616
letters or	0.1
or characters	0.0045045045045045045
characters .	0.125
Around	2.7900228781876013e-05
Edmund	2.7900228781876013e-05
Fournier	2.7900228781876013e-05
d'Albe	2.7900228781876013e-05
Optophone	2.7900228781876013e-05
handheld	2.7900228781876013e-05
scanner	8.370068634562804e-05
moved	2.7900228781876013e-05
tones	2.7900228781876013e-05
corresponded	2.7900228781876013e-05
<s> Goldberg	0.0007686395080707148
Goldberg continued	0.5
develop OCR	0.2
OCR technology	0.1836734693877551
for data	0.007220216606498195
entry .	0.25
<s> Later	0.0007686395080707148
Later ,	1.0
he proposed	0.14285714285714285
proposed photographing	0.1111111111111111
photographing data	1.0
data records	0.012987012987012988
records and	0.25
using photocells	0.01694915254237288
photocells ,	1.0
, matching	0.0005614823133071309
matching the	0.2
the photos	0.0006920415224913495
photos against	1.0
against a	0.2
a template	0.00245398773006135
template containing	0.25
containing the	0.375
desired identification	0.2
identification pattern	0.2
pattern .	0.16666666666666666
Later	2.7900228781876013e-05
photographing	2.7900228781876013e-05
photocells	2.7900228781876013e-05
photos	2.7900228781876013e-05
template	0.00011160091512750405
In 1929	0.009523809523809525
1929 Gustav	1.0
Gustav Tauschek	1.0
Tauschek had	0.5
had similar	0.07142857142857142
similar ideas	0.037037037037037035
ideas ,	0.25
and obtained	0.001445086705202312
obtained a	0.2857142857142857
a patent	0.00245398773006135
patent on	0.75
on OCR	0.0047169811320754715
OCR in	0.04081632653061224
Germany .	0.5
1929	2.7900228781876013e-05
Gustav	2.7900228781876013e-05
Tauschek	5.5800457563752025e-05
patent	0.00011160091512750405
<s> Paul	0.0007686395080707148
Paul W.	0.2
W. Handel	0.5
Handel also	1.0
also obtained	0.014492753623188406
a US	0.00245398773006135
US patent	0.2857142857142857
on such	0.0047169811320754715
such template-matching	0.008130081300813009
template-matching OCR	1.0
technology in	0.045454545454545456
in USA	0.0018726591760299626
USA in	1.0
in 1933	0.0018726591760299626
1933 -LRB-	1.0
-LRB- U.S.	0.005420054200542005
U.S. Patent	0.42857142857142855
Patent 1,915,993	0.3333333333333333
1,915,993 -RRB-	1.0
Handel	2.7900228781876013e-05
template-matching	2.7900228781876013e-05
USA	2.7900228781876013e-05
1933	2.7900228781876013e-05
U.S.	0.0001953016014731321
Patent	8.370068634562804e-05
1,915,993	2.7900228781876013e-05
In 1935	0.009523809523809525
1935 Tauschek	1.0
Tauschek was	0.5
was also	0.025974025974025976
also granted	0.014492753623188406
granted a	1.0
on his	0.0047169811320754715
his method	0.08333333333333333
method -LRB-	0.0625
Patent 2,026,329	0.3333333333333333
2,026,329 -RRB-	1.0
1935	2.7900228781876013e-05
granted	2.7900228781876013e-05
2,026,329	2.7900228781876013e-05
In 1949	0.009523809523809525
1949 RCA	0.5
RCA engineers	0.2
engineers worked	1.0
first primitive	0.030303030303030304
primitive computer-type	1.0
computer-type OCR	1.0
OCR to	0.061224489795918366
help blind	0.1111111111111111
people for	0.0625
the US	0.001384083044982699
US Veterans	0.14285714285714285
Veterans Administration	1.0
Administration ,	1.0
but instead	0.014705882352941176
of converting	0.0017825311942959
converting the	0.5
the printed	0.0006920415224913495
printed characters	0.08333333333333333
characters to	0.0625
machine language	0.0379746835443038
, their	0.0005614823133071309
their device	0.029411764705882353
device converted	0.5
converted it	0.3333333333333333
then spoke	0.02857142857142857
spoke the	1.0
the letters	0.0006920415224913495
letters :	0.1
: an	0.00980392156862745
an early	0.007575757575757576
early text-to-speech	0.1
text-to-speech technology	0.25
technology .	0.09090909090909091
RCA	0.00013950114390938006
engineers	2.7900228781876013e-05
primitive	2.7900228781876013e-05
computer-type	2.7900228781876013e-05
Veterans	2.7900228781876013e-05
Administration	2.7900228781876013e-05
converting	5.5800457563752025e-05
device	5.5800457563752025e-05
spoke	2.7900228781876013e-05
It proved	0.02631578947368421
proved far	0.3333333333333333
far too	0.125
too expensive	0.3333333333333333
expensive and	0.14285714285714285
and was	0.001445086705202312
was not	0.025974025974025976
not pursued	0.008928571428571428
pursued after	1.0
after testing	0.08333333333333333
testing .	0.2
proved	8.370068634562804e-05
pursued	2.7900228781876013e-05
David H.	0.25
H. Shepard	0.5
Shepard ,	0.3333333333333333
a cryptanalyst	0.001226993865030675
cryptanalyst at	1.0
the Armed	0.0006920415224913495
Armed Forces	1.0
Forces Security	1.0
Security Agency	1.0
Agency in	0.5
States ,	0.14285714285714285
, addressed	0.0005614823133071309
addressed the	0.5
converting printed	0.5
printed messages	0.08333333333333333
messages into	0.5
into machine	0.01282051282051282
computer processing	0.022727272727272728
processing and	0.018518518518518517
and built	0.001445086705202312
built a	0.3333333333333333
machine to	0.012658227848101266
this ,	0.04395604395604396
, called	0.0005614823133071309
`` Gismo	0.010582010582010581
Gismo .	0.5
. ''	0.00546021840873635
Shepard	8.370068634562804e-05
cryptanalyst	2.7900228781876013e-05
Armed	2.7900228781876013e-05
Forces	2.7900228781876013e-05
Security	2.7900228781876013e-05
Agency	5.5800457563752025e-05
messages	5.5800457563752025e-05
Gismo	5.5800457563752025e-05
He received	0.125
received a	0.5
patent for	0.25
his ``	0.08333333333333333
`` Apparatus	0.005291005291005291
Apparatus for	1.0
for Reading	0.0036101083032490976
Reading ''	0.5
in 1953	0.0018726591760299626
1953 U.S.	1.0
Patent 2,663,758	0.3333333333333333
2,663,758 .	1.0
Apparatus	2.7900228781876013e-05
Reading	5.5800457563752025e-05
1953	2.7900228781876013e-05
2,663,758	2.7900228781876013e-05
Gismo ''	0.5
'' could	0.005154639175257732
could read	0.0625
read 23	0.14285714285714285
23 letters	1.0
letters of	0.2
English alphabet	0.05405405405405406
alphabet ,	0.6666666666666666
, comprehend	0.0005614823133071309
comprehend Morse	1.0
Morse Code	1.0
Code ,	1.0
, read	0.0011229646266142617
read musical	0.14285714285714285
musical notations	1.0
notations ,	0.5
read aloud	0.14285714285714285
aloud from	1.0
from printed	0.009615384615384616
printed pages	0.08333333333333333
and duplicate	0.001445086705202312
duplicate typewritten	0.5
typewritten pages	0.2
23	2.7900228781876013e-05
alphabet	8.370068634562804e-05
comprehend	2.7900228781876013e-05
Morse	2.7900228781876013e-05
Code	2.7900228781876013e-05
musical	2.7900228781876013e-05
aloud	2.7900228781876013e-05
<s> Shepard	0.0007686395080707148
Shepard went	0.3333333333333333
went on	0.2
to found	0.0013280212483399733
found Intelligent	0.07142857142857142
Intelligent Machines	0.3333333333333333
Machines Research	1.0
Research Corporation	0.125
Corporation -LRB-	0.5
-LRB- IMR	0.0027100271002710027
IMR -RRB-	0.5
which soon	0.007246376811594203
soon developed	0.3333333333333333
the world	0.0020761245674740486
world 's	0.06666666666666667
's first	0.0196078431372549
first commercial	0.06060606060606061
commercial OCR	0.18181818181818182
OCR systems	0.08163265306122448
went	0.00013950114390938006
Machines	2.7900228781876013e-05
IMR	5.5800457563752025e-05
In 1955	0.009523809523809525
commercial system	0.09090909090909091
was installed	0.012987012987012988
installed at	0.6666666666666666
the Reader	0.0006920415224913495
Reader 's	1.0
's Digest	0.058823529411764705
Digest ,	0.3333333333333333
which used	0.007246376811594203
used OCR	0.008849557522123894
input sales	0.024390243902439025
sales reports	0.3333333333333333
reports into	0.4
Reader	8.370068634562804e-05
Digest	8.370068634562804e-05
It converted	0.02631578947368421
converted the	0.3333333333333333
the typewritten	0.0006920415224913495
typewritten reports	0.2
into punched	0.01282051282051282
punched cards	1.0
cards for	1.0
for input	0.0036101083032490976
input into	0.024390243902439025
the magazine	0.0006920415224913495
magazine 's	1.0
's subscription	0.0196078431372549
subscription department	1.0
department ,	0.5
for help	0.0036101083032490976
help in	0.1111111111111111
in processing	0.0018726591760299626
processing the	0.018518518518518517
the shipment	0.0006920415224913495
shipment of	1.0
of 15-20	0.00089126559714795
15-20 million	1.0
million books	0.3333333333333333
books a	1.0
a year	0.001226993865030675
punched	2.7900228781876013e-05
cards	2.7900228781876013e-05
magazine	2.7900228781876013e-05
subscription	2.7900228781876013e-05
shipment	2.7900228781876013e-05
15-20	2.7900228781876013e-05
million	8.370068634562804e-05
books	2.7900228781876013e-05
The second	0.005208333333333333
second system	0.1
was sold	0.012987012987012988
sold to	0.3333333333333333
the Standard	0.0006920415224913495
Standard Oil	0.5
Oil Company	1.0
Company for	0.5
for reading	0.007220216606498195
reading credit	0.125
card imprints	0.25
imprints for	1.0
for billing	0.0036101083032490976
billing purposes	1.0
purposes .	0.5
sold	8.370068634562804e-05
Standard	5.5800457563752025e-05
Oil	2.7900228781876013e-05
Company	5.5800457563752025e-05
imprints	2.7900228781876013e-05
billing	2.7900228781876013e-05
Other systems	0.14285714285714285
systems sold	0.008928571428571428
sold by	0.3333333333333333
by IMR	0.005714285714285714
IMR during	0.5
late 1950s	0.1111111111111111
1950s included	0.25
included a	0.125
a bill	0.001226993865030675
bill stub	0.5
stub reader	1.0
reader to	0.1
the Ohio	0.0006920415224913495
Ohio Bell	1.0
Bell Telephone	1.0
Telephone Company	1.0
Company and	0.5
a page	0.001226993865030675
page scanner	0.14285714285714285
scanner to	0.3333333333333333
States Air	0.14285714285714285
Air Force	0.6666666666666666
Force for	0.5
and transmitting	0.001445086705202312
transmitting by	1.0
by teletype	0.005714285714285714
teletype typewritten	1.0
typewritten messages	0.2
messages .	0.5
bill	5.5800457563752025e-05
stub	2.7900228781876013e-05
Ohio	2.7900228781876013e-05
Bell	2.7900228781876013e-05
Telephone	2.7900228781876013e-05
Air	8.370068634562804e-05
Force	5.5800457563752025e-05
transmitting	2.7900228781876013e-05
teletype	2.7900228781876013e-05
<s> IBM	0.0007686395080707148
IBM and	0.3333333333333333
others were	0.08333333333333333
were later	0.024390243902439025
later licensed	0.1
licensed on	1.0
on Shepard	0.0047169811320754715
Shepard 's	0.3333333333333333
's OCR	0.0196078431372549
OCR patents	0.02040816326530612
patents .	1.0
licensed	2.7900228781876013e-05
patents	2.7900228781876013e-05
In about	0.009523809523809525
about 1965	0.025
, Reader	0.0005614823133071309
Digest and	0.3333333333333333
and RCA	0.001445086705202312
RCA collaborated	0.2
collaborated to	1.0
to build	0.0013280212483399733
an OCR	0.007575757575757576
OCR Document	0.02040816326530612
Document reader	0.25
reader designed	0.2
to digitize	0.0013280212483399733
digitize the	1.0
the serial	0.0006920415224913495
serial numbers	1.0
numbers on	0.14285714285714285
on Reader	0.0047169811320754715
Digest coupons	0.3333333333333333
coupons returned	1.0
from advertisements	0.009615384615384616
advertisements .	1.0
collaborated	2.7900228781876013e-05
digitize	2.7900228781876013e-05
serial	2.7900228781876013e-05
coupons	2.7900228781876013e-05
advertisements	5.5800457563752025e-05
The fonts	0.005208333333333333
fonts used	0.3333333333333333
used on	0.008849557522123894
the documents	0.0020761245674740486
documents were	0.02631578947368421
were printed	0.024390243902439025
printed by	0.08333333333333333
an RCA	0.015151515151515152
RCA Drum	0.2
Drum printer	1.0
printer using	1.0
the OCR-A	0.0006920415224913495
OCR-A font	1.0
font .	0.6666666666666666
Drum	2.7900228781876013e-05
printer	2.7900228781876013e-05
OCR-A	2.7900228781876013e-05
The reader	0.005208333333333333
reader was	0.2
was connected	0.012987012987012988
connected directly	0.2
directly to	0.4
to an	0.0013280212483399733
RCA 301	0.2
301 computer	1.0
computer -LRB-	0.022727272727272728
-LRB- one	0.0027100271002710027
first solid	0.030303030303030304
solid state	1.0
state computers	0.07142857142857142
computers -RRB-	0.1111111111111111
301	2.7900228781876013e-05
solid	2.7900228781876013e-05
This reader	0.015873015873015872
was followed	0.012987012987012988
a specialised	0.001226993865030675
specialised document	0.5
document reader	0.027777777777777776
reader installed	0.1
at TWA	0.014705882352941176
TWA where	1.0
reader processed	0.1
processed Airline	0.16666666666666666
Airline Ticket	1.0
Ticket stock	1.0
stock .	0.6666666666666666
TWA	2.7900228781876013e-05
Airline	2.7900228781876013e-05
Ticket	2.7900228781876013e-05
stock	8.370068634562804e-05
The readers	0.005208333333333333
readers processed	0.5
processed documents	0.16666666666666666
documents at	0.02631578947368421
a rate	0.001226993865030675
rate of	0.2727272727272727
of 1,500	0.00089126559714795
1,500 documents	1.0
documents per	0.02631578947368421
per minute	0.25
minute ,	1.0
and checked	0.001445086705202312
checked each	0.5
each document	0.022222222222222223
, rejecting	0.0005614823133071309
rejecting those	0.3333333333333333
those it	0.045454545454545456
not able	0.008928571428571428
process correctly	0.027777777777777776
correctly .	1.0
readers	5.5800457563752025e-05
1,500	2.7900228781876013e-05
per	0.00011160091512750405
minute	2.7900228781876013e-05
rejecting	8.370068634562804e-05
correctly	2.7900228781876013e-05
product became	0.14285714285714285
became part	0.2
the RCA	0.0006920415224913495
RCA product	0.2
product line	0.14285714285714285
line as	0.3333333333333333
a reader	0.001226993865030675
process ``	0.027777777777777776
`` Turn	0.005291005291005291
Turn around	1.0
around Documents	0.125
Documents ''	1.0
'' such	0.005154639175257732
those utility	0.045454545454545456
utility and	0.5
and insurance	0.001445086705202312
insurance bills	1.0
bills returned	1.0
returned with	0.25
with payments	0.00546448087431694
payments .	1.0
Turn	2.7900228781876013e-05
Documents	2.7900228781876013e-05
insurance	2.7900228781876013e-05
bills	2.7900228781876013e-05
payments	2.7900228781876013e-05
The United	0.005208333333333333
States Postal	0.14285714285714285
Postal Service	1.0
Service has	1.0
been using	0.029411764705882353
using OCR	0.05084745762711865
OCR machines	0.02040816326530612
machines to	0.25
to sort	0.0013280212483399733
sort mail	0.3333333333333333
mail since	0.5
since 1965	0.1
1965 based	0.25
on technology	0.0047169811320754715
technology devised	0.045454545454545456
devised primarily	0.5
primarily by	0.5
the prolific	0.0006920415224913495
prolific inventor	1.0
inventor Jacob	1.0
Jacob Rabinow	1.0
Rabinow .	1.0
Postal	2.7900228781876013e-05
Service	2.7900228781876013e-05
devised	5.5800457563752025e-05
prolific	2.7900228781876013e-05
inventor	2.7900228781876013e-05
Jacob	2.7900228781876013e-05
Rabinow	2.7900228781876013e-05
first use	0.030303030303030304
of OCR	0.0035650623885918
in Europe	0.003745318352059925
Europe was	0.2
the British	0.0006920415224913495
British General	0.3333333333333333
General Post	1.0
Post Office	0.5
Office -LRB-	1.0
-LRB- GPO	0.0027100271002710027
GPO -RRB-	1.0
British	8.370068634562804e-05
General	2.7900228781876013e-05
Post	5.5800457563752025e-05
Office	2.7900228781876013e-05
GPO	2.7900228781876013e-05
In 1965	0.009523809523809525
1965 it	0.25
it began	0.008547008547008548
began planning	0.14285714285714285
planning an	0.5
an entire	0.007575757575757576
entire banking	0.3333333333333333
banking system	1.0
the National	0.001384083044982699
National Giro	0.3333333333333333
Giro ,	1.0
that revolutionized	0.0035460992907801418
revolutionized bill	1.0
bill payment	0.5
payment systems	1.0
systems in	0.008928571428571428
the UK	0.002768166089965398
UK .	0.5
banking	2.7900228781876013e-05
National	8.370068634562804e-05
Giro	2.7900228781876013e-05
revolutionized	2.7900228781876013e-05
payment	2.7900228781876013e-05
UK	0.00011160091512750405
<s> Canada	0.0007686395080707148
Canada Post	0.16666666666666666
Post has	0.5
systems since	0.008928571428571428
since 1971	0.1
1971 -LRB-	0.3333333333333333
systems read	0.008928571428571428
read the	0.14285714285714285
the name	0.001384083044982699
name and	0.2
and address	0.001445086705202312
address of	0.25
the addressee	0.0006920415224913495
addressee at	1.0
first mechanized	0.030303030303030304
mechanized sorting	1.0
sorting center	1.0
center ,	1.0
and print	0.001445086705202312
print a	1.0
a routing	0.001226993865030675
routing bar	0.3333333333333333
bar code	1.0
code on	0.14285714285714285
the envelope	0.0006920415224913495
envelope based	1.0
the postal	0.0006920415224913495
postal code	1.0
addressee	2.7900228781876013e-05
mechanized	2.7900228781876013e-05
sorting	2.7900228781876013e-05
center	2.7900228781876013e-05
print	2.7900228781876013e-05
bar	5.5800457563752025e-05
envelope	2.7900228781876013e-05
postal	2.7900228781876013e-05
To avoid	0.1111111111111111
avoid confusion	1.0
confusion with	1.0
the human-readable	0.0006920415224913495
human-readable address	1.0
address field	0.25
field which	0.037037037037037035
be located	0.004219409282700422
located anywhere	1.0
anywhere on	1.0
the letter	0.0006920415224913495
letter ,	0.16666666666666666
, special	0.0005614823133071309
special ink	0.2
ink -LRB-	1.0
-LRB- orange	0.0027100271002710027
orange in	1.0
in visible	0.0018726591760299626
visible light	0.3333333333333333
light -RRB-	0.3333333333333333
used that	0.008849557522123894
is clearly	0.0040650406504065045
clearly visible	0.3333333333333333
visible under	0.3333333333333333
under ultraviolet	0.2
ultraviolet light	1.0
light .	0.3333333333333333
avoid	2.7900228781876013e-05
confusion	2.7900228781876013e-05
human-readable	2.7900228781876013e-05
located	2.7900228781876013e-05
anywhere	2.7900228781876013e-05
ink	2.7900228781876013e-05
orange	2.7900228781876013e-05
visible	8.370068634562804e-05
light	8.370068634562804e-05
clearly	8.370068634562804e-05
ultraviolet	2.7900228781876013e-05
<s> Envelopes	0.0007686395080707148
Envelopes may	1.0
may then	0.019230769230769232
then be	0.02857142857142857
be processed	0.004219409282700422
with equipment	0.00546448087431694
equipment based	0.3333333333333333
on simple	0.0047169811320754715
simple bar	0.038461538461538464
code readers	0.14285714285714285
readers .	0.5
Envelopes	2.7900228781876013e-05
<s> Importance	0.0007686395080707148
Importance of	1.0
the Blind	0.001384083044982699
Blind In	0.5
In 1974	0.009523809523809525
1974 Ray	1.0
Ray Kurzweil	1.0
Kurzweil started	0.14285714285714285
started the	0.25
the company	0.0006920415224913495
company Kurzweil	0.3333333333333333
Kurzweil Computer	0.2857142857142857
Computer Products	0.3333333333333333
Products ,	0.5
, Inc.	0.0011229646266142617
Inc. and	0.5
and continued	0.001445086705202312
continued development	0.1111111111111111
of omni-font	0.00089126559714795
omni-font OCR	1.0
which could	0.007246376811594203
could recognize	0.0625
recognize text	0.1111111111111111
text printed	0.006289308176100629
printed in	0.08333333333333333
in virtually	0.0018726591760299626
virtually any	0.5
any font	0.03225806451612903
Importance	2.7900228781876013e-05
Blind	5.5800457563752025e-05
1974	2.7900228781876013e-05
Ray	2.7900228781876013e-05
Kurzweil	0.0001953016014731321
Products	5.5800457563752025e-05
Inc.	5.5800457563752025e-05
omni-font	2.7900228781876013e-05
recognize	0.0002511020590368841
virtually	5.5800457563752025e-05
He decided	0.125
decided that	0.3333333333333333
best application	0.05555555555555555
this technology	0.01098901098901099
technology would	0.045454545454545456
be to	0.008438818565400843
a reading	0.001226993865030675
reading machine	0.125
machine for	0.012658227848101266
the blind	0.0006920415224913495
blind ,	0.25
which would	0.014492753623188406
would allow	0.018867924528301886
allow blind	0.2
people to	0.125
computer read	0.022727272727272728
read text	0.14285714285714285
them out	0.05263157894736842
out loud	0.07142857142857142
loud .	1.0
loud	2.7900228781876013e-05
This device	0.015873015873015872
device required	0.5
required the	0.14285714285714285
the invention	0.0006920415224913495
invention of	1.0
of two	0.0017825311942959
two enabling	0.034482758620689655
enabling technologies	1.0
technologies --	0.25
the CCD	0.0006920415224913495
CCD flatbed	1.0
flatbed scanner	1.0
scanner and	0.3333333333333333
the text-to-speech	0.0006920415224913495
text-to-speech synthesizer	0.25
synthesizer .	1.0
invention	2.7900228781876013e-05
enabling	2.7900228781876013e-05
technologies	0.00011160091512750405
CCD	2.7900228781876013e-05
flatbed	2.7900228781876013e-05
synthesizer	2.7900228781876013e-05
On January	0.16666666666666666
January 13	0.25
13 ,	0.5
1976 the	0.5
the successful	0.0006920415224913495
successful finished	0.1111111111111111
finished product	0.5
product was	0.14285714285714285
was unveiled	0.012987012987012988
unveiled during	1.0
a widely-reported	0.001226993865030675
widely-reported news	1.0
news conference	0.07692307692307693
conference headed	0.5
headed by	1.0
by Kurzweil	0.005714285714285714
Kurzweil and	0.14285714285714285
the leaders	0.0006920415224913495
leaders of	1.0
National Federation	0.3333333333333333
Federation of	1.0
Blind -LRB-	0.5
unveiled	2.7900228781876013e-05
widely-reported	2.7900228781876013e-05
conference	5.5800457563752025e-05
headed	2.7900228781876013e-05
leaders	2.7900228781876013e-05
Federation	2.7900228781876013e-05
In 1978	0.009523809523809525
1978 Kurzweil	0.3333333333333333
Products began	0.5
began selling	0.14285714285714285
selling a	1.0
commercial version	0.09090909090909091
the optical	0.0006920415224913495
optical character	1.0
recognition computer	0.01652892561983471
selling	2.7900228781876013e-05
optical	5.5800457563752025e-05
<s> LexisNexis	0.0007686395080707148
LexisNexis was	1.0
was one	0.012987012987012988
first customers	0.030303030303030304
customers ,	0.5
and bought	0.001445086705202312
bought the	1.0
to upload	0.0013280212483399733
upload paper	1.0
paper legal	0.09090909090909091
legal and	0.3333333333333333
and news	0.001445086705202312
news documents	0.07692307692307693
documents onto	0.02631578947368421
onto its	1.0
its nascent	0.02857142857142857
nascent online	1.0
online databases	0.125
databases .	0.5
LexisNexis	2.7900228781876013e-05
customers	5.5800457563752025e-05
bought	2.7900228781876013e-05
upload	2.7900228781876013e-05
onto	2.7900228781876013e-05
nascent	2.7900228781876013e-05
Two years	0.42857142857142855
years later	0.14285714285714285
, Kurzweil	0.0016844469399213925
Kurzweil sold	0.14285714285714285
sold his	0.3333333333333333
his company	0.08333333333333333
company to	0.3333333333333333
to Xerox	0.0013280212483399733
Xerox ,	0.5
which had	0.007246376811594203
had an	0.07142857142857142
an interest	0.007575757575757576
in further	0.0018726591760299626
further commercializing	0.125
commercializing paper-to-computer	1.0
paper-to-computer text	1.0
text conversion	0.006289308176100629
conversion .	0.3333333333333333
Xerox	5.5800457563752025e-05
commercializing	2.7900228781876013e-05
paper-to-computer	2.7900228781876013e-05
<s> Xerox	0.0007686395080707148
Xerox eventually	0.5
eventually spun	1.0
spun it	1.0
it off	0.008547008547008548
off as	0.5
as Scansoft	0.003484320557491289
Scansoft ,	1.0
which merged	0.007246376811594203
merged with	1.0
with Nuance	0.00546448087431694
Nuance Communications	0.6666666666666666
Communications -LRB-	1.0
eventually	2.7900228781876013e-05
spun	2.7900228781876013e-05
off	5.5800457563752025e-05
Scansoft	2.7900228781876013e-05
merged	2.7900228781876013e-05
Nuance	8.370068634562804e-05
Communications	5.5800457563752025e-05
OCR software	0.08163265306122448
software Desktop	0.037037037037037035
Desktop &	1.0
& Server	0.125
Server OCR	1.0
OCR Software	0.02040816326530612
Software OCR	0.5
software and	0.037037037037037035
and ICR	0.002890173410404624
ICR software	0.3333333333333333
software technology	0.037037037037037035
technology are	0.045454545454545456
are analytical	0.004149377593360996
analytical artificial	0.5
intelligence systems	0.125
that consider	0.0035460992907801418
consider sequences	0.25
of characters	0.0017825311942959
characters rather	0.0625
than whole	0.022222222222222223
whole words	0.1111111111111111
Desktop	2.7900228781876013e-05
Server	2.7900228781876013e-05
Software	5.5800457563752025e-05
ICR	8.370068634562804e-05
<s> Based	0.0007686395080707148
Based on	1.0
of sequential	0.00089126559714795
sequential lines	1.0
lines and	0.3333333333333333
and curves	0.001445086705202312
curves ,	1.0
, OCR	0.0011229646266142617
OCR and	0.02040816326530612
ICR make	0.3333333333333333
make `	0.05
` best	0.0625
best guesses	0.05555555555555555
guesses '	1.0
' at	0.05263157894736842
at characters	0.014705882352941176
characters using	0.0625
using database	0.01694915254237288
database look-up	0.1
look-up tables	1.0
tables to	0.3333333333333333
to closely	0.0013280212483399733
closely associate	0.2
associate or	0.5
or match	0.0045045045045045045
match the	0.3333333333333333
the strings	0.0006920415224913495
strings of	1.0
characters that	0.0625
that form	0.0035460992907801418
form words	0.05
Based	2.7900228781876013e-05
sequential	2.7900228781876013e-05
lines	8.370068634562804e-05
curves	2.7900228781876013e-05
guesses	2.7900228781876013e-05
look-up	2.7900228781876013e-05
associate	5.5800457563752025e-05
strings	5.5800457563752025e-05
<s> WebOCR	0.0015372790161414297
WebOCR &	0.75
& OnlineOCR	0.25
OnlineOCR With	0.3333333333333333
With IT	0.14285714285714285
IT technology	1.0
technology development	0.045454545454545456
development ,	0.16666666666666666
the platform	0.0006920415224913495
platform for	0.5
for people	0.007220216606498195
use software	0.013888888888888888
software has	0.037037037037037035
been changed	0.014705882352941176
changed from	0.5
from single	0.009615384615384616
single PC	0.07142857142857142
PC platform	0.25
platform to	0.5
to multi-platforms	0.0013280212483399733
multi-platforms such	1.0
as PC	0.003484320557491289
PC +	0.25
+ Web-based	0.16666666666666666
Web-based +	0.3333333333333333
+ Cloud	0.16666666666666666
Cloud Computing	1.0
Computing +	0.5
+ Mobile	0.16666666666666666
Mobile devices	0.3333333333333333
devices .	0.5
WebOCR	0.00011160091512750405
OnlineOCR	8.370068634562804e-05
IT	2.7900228781876013e-05
platform	5.5800457563752025e-05
PC	0.00011160091512750405
multi-platforms	2.7900228781876013e-05
Web-based	8.370068634562804e-05
Cloud	2.7900228781876013e-05
Mobile	8.370068634562804e-05
devices	0.00011160091512750405
After 30	0.3333333333333333
30 years	0.6666666666666666
years development	0.09523809523809523
software started	0.037037037037037035
started to	0.25
to adapt	0.0013280212483399733
adapt to	1.0
new application	0.041666666666666664
application requirements	0.07142857142857142
requirements .	0.5
30	8.370068634562804e-05
adapt	2.7900228781876013e-05
requirements	5.5800457563752025e-05
WebOCR also	0.25
as OnlineOCR	0.003484320557491289
OnlineOCR or	0.3333333333333333
or Web-based	0.0045045045045045045
Web-based OCR	0.6666666666666666
OCR service	0.04081632653061224
service ,	0.4
, has	0.0005614823133071309
been a	0.029411764705882353
new trend	0.041666666666666664
trend to	1.0
meet larger	0.25
larger volume	0.0625
volume and	0.25
and larger	0.002890173410404624
larger group	0.0625
group of	0.5
of users	0.0017825311942959
users after	0.1111111111111111
after 30	0.08333333333333333
the desktop	0.0006920415224913495
desktop OCR	1.0
OCR .	0.02040816326530612
trend	5.5800457563752025e-05
desktop	2.7900228781876013e-05
<s> Internet	0.0007686395080707148
Internet and	0.5
and broadband	0.001445086705202312
broadband technologies	1.0
technologies have	0.25
have made	0.009615384615384616
made WebOCR	0.0625
OnlineOCR practically	0.3333333333333333
practically available	1.0
available to	0.058823529411764705
to both	0.00398406374501992
both individual	0.03225806451612903
individual users	0.08333333333333333
users and	0.1111111111111111
and enterprise	0.001445086705202312
enterprise customers	1.0
customers .	0.5
Internet	5.5800457563752025e-05
broadband	2.7900228781876013e-05
practically	2.7900228781876013e-05
enterprise	2.7900228781876013e-05
Since 2000	0.2
2000 ,	0.3333333333333333
some major	0.012048192771084338
major OCR	0.16666666666666666
OCR vendors	0.02040816326530612
vendors began	0.25
began offering	0.14285714285714285
offering WebOCR	1.0
& Online	0.125
Online software	0.5
software ,	0.037037037037037035
of new	0.00089126559714795
new entrants	0.041666666666666664
entrants companies	1.0
companies to	0.5
to seize	0.0013280212483399733
seize the	1.0
the opportunity	0.0006920415224913495
opportunity to	0.5
develop innovative	0.2
innovative Web-based	1.0
are free	0.004149377593360996
free of	0.25
of charge	0.00089126559714795
charge services	1.0
services .	0.6666666666666666
vendors	0.00011160091512750405
offering	2.7900228781876013e-05
entrants	2.7900228781876013e-05
seize	2.7900228781876013e-05
opportunity	5.5800457563752025e-05
innovative	2.7900228781876013e-05
free	0.00011160091512750405
charge	2.7900228781876013e-05
services	8.370068634562804e-05
<s> Application-Oriented	0.0007686395080707148
Application-Oriented OCR	1.0
OCR Since	0.02040816326530612
Since OCR	0.2
technology has	0.045454545454545456
more widely	0.010526315789473684
widely applied	0.125
to paper-intensive	0.0013280212483399733
paper-intensive industry	1.0
industry ,	0.3333333333333333
is facing	0.0020325203252032522
facing more	1.0
complex images	0.041666666666666664
images environment	0.16666666666666666
environment in	0.16666666666666666
world .	0.13333333333333333
Application-Oriented	5.5800457563752025e-05
paper-intensive	2.7900228781876013e-05
facing	2.7900228781876013e-05
environment	0.00016740137269125608
example :	0.024691358024691357
: complicated	0.00980392156862745
complicated backgrounds	0.3333333333333333
backgrounds ,	1.0
, degraded-images	0.0005614823133071309
degraded-images ,	1.0
, heavy-noise	0.0005614823133071309
heavy-noise ,	1.0
, paper	0.0005614823133071309
paper skew	0.09090909090909091
skew ,	1.0
, picture	0.0005614823133071309
picture distortion	0.25
distortion ,	1.0
, low-resolution	0.0005614823133071309
low-resolution ,	1.0
, disturbed	0.0005614823133071309
disturbed by	1.0
by grid	0.005714285714285714
grid &	1.0
& lines	0.125
lines ,	0.3333333333333333
text image	0.006289308176100629
image consisting	0.3333333333333333
of special	0.00089126559714795
special fonts	0.2
fonts ,	0.3333333333333333
, symbols	0.0005614823133071309
symbols ,	0.3333333333333333
, glossary	0.0011229646266142617
glossary words	0.5
and etc.	0.001445086705202312
backgrounds	2.7900228781876013e-05
degraded-images	2.7900228781876013e-05
heavy-noise	2.7900228781876013e-05
skew	2.7900228781876013e-05
picture	0.00011160091512750405
distortion	2.7900228781876013e-05
low-resolution	2.7900228781876013e-05
disturbed	2.7900228781876013e-05
grid	2.7900228781876013e-05
symbols	8.370068634562804e-05
glossary	5.5800457563752025e-05
<s> All	0.0007686395080707148
All the	1.0
the factors	0.0006920415224913495
factors affect	0.3333333333333333
affect OCR	0.3333333333333333
OCR products	0.02040816326530612
products '	0.25
' stability	0.05263157894736842
stability in	1.0
in recognition	0.003745318352059925
All	2.7900228781876013e-05
affect	8.370068634562804e-05
products	0.00011160091512750405
stability	2.7900228781876013e-05
the major	0.001384083044982699
technology providers	0.045454545454545456
providers began	1.0
develop dedicated	0.2
dedicated OCR	0.3333333333333333
each for	0.022222222222222223
for special	0.0036101083032490976
special types	0.2
of images	0.00089126559714795
images .	0.16666666666666666
providers	2.7900228781876013e-05
They combine	0.3333333333333333
combine various	0.6666666666666666
various optimization	0.05555555555555555
optimization methods	1.0
methods related	0.022727272727272728
the special	0.0006920415224913495
special image	0.2
image ,	0.3333333333333333
as business	0.003484320557491289
business rules	0.25
standard expression	0.07142857142857142
expression ,	0.2
glossary or	0.5
or dictionary	0.0045045045045045045
dictionary and	0.14285714285714285
and rich	0.001445086705202312
rich information	0.2
information contained	0.021739130434782608
contained in	1.0
in color	0.0018726591760299626
color images	1.0
improve the	0.07692307692307693
the recognition	0.001384083044982699
combine	8.370068634562804e-05
optimization	2.7900228781876013e-05
contained	2.7900228781876013e-05
color	2.7900228781876013e-05
Such strategy	0.125
customize OCR	0.5
`` Application-Oriented	0.005291005291005291
OCR ''	0.04081632653061224
`` Customized	0.005291005291005291
Customized OCR	1.0
, widely	0.0005614823133071309
the fields	0.0006920415224913495
of Business-card	0.00089126559714795
Business-card OCR	1.0
, Invoice	0.0005614823133071309
Invoice OCR	1.0
, Screenshot	0.0005614823133071309
Screenshot OCR	1.0
, ID	0.0005614823133071309
ID card	1.0
card OCR	0.25
, Driver-license	0.0005614823133071309
Driver-license OCR	1.0
OCR or	0.02040816326530612
or Auto	0.0045045045045045045
Auto plant	1.0
plant OCR	1.0
Customized	2.7900228781876013e-05
Business-card	2.7900228781876013e-05
Invoice	2.7900228781876013e-05
Screenshot	2.7900228781876013e-05
ID	2.7900228781876013e-05
Driver-license	2.7900228781876013e-05
Auto	2.7900228781876013e-05
plant	2.7900228781876013e-05
<s> See	0.0007686395080707148
See also	0.5
also :	0.028985507246376812
: List	0.00980392156862745
List of	1.0
of optical	0.00089126559714795
recognition software	0.024793388429752067
software Current	0.037037037037037035
Current state	0.2
technology This	0.045454545454545456
This section	0.031746031746031744
section needs	0.16666666666666666
needs additional	0.1
additional citations	0.16666666666666666
citations for	0.3333333333333333
for verification	0.0036101083032490976
verification .	1.0
See	0.00016740137269125608
List	5.5800457563752025e-05
citations	8.370068634562804e-05
verification	2.7900228781876013e-05
help improve	0.1111111111111111
article by	0.034482758620689655
adding citations	0.5
citations to	0.6666666666666666
to reliable	0.0013280212483399733
reliable sources	0.25
sources .	0.3333333333333333
sources	0.00016740137269125608
<s> Unsourced	0.0007686395080707148
Unsourced material	1.0
material may	0.5
be challenged	0.004219409282700422
challenged and	1.0
and removed	0.001445086705202312
removed .	1.0
Unsourced	2.7900228781876013e-05
material	5.5800457563752025e-05
challenged	2.7900228781876013e-05
removed	2.7900228781876013e-05
May 2009	0.5
2009 -RRB-	0.3333333333333333
-RRB- Commissioned	0.0027100271002710027
Commissioned by	1.0
the U.S.	0.002768166089965398
U.S. Department	0.14285714285714285
Department of	1.0
of Energy	0.00089126559714795
Energy -LRB-	1.0
-LRB- DOE	0.0027100271002710027
DOE -RRB-	1.0
the Information	0.0006920415224913495
Information Science	0.2
Science Research	0.5
Research Institute	0.125
Institute -LRB-	1.0
-LRB- ISRI	0.0027100271002710027
ISRI -RRB-	1.0
-RRB- had	0.0027100271002710027
had the	0.07142857142857142
the mission	0.0006920415224913495
mission to	1.0
to foster	0.0013280212483399733
foster the	1.0
the improvement	0.0006920415224913495
improvement of	0.5
of automated	0.00089126559714795
automated technologies	0.14285714285714285
technologies for	0.25
for understanding	0.0036101083032490976
understanding machine	0.030303030303030304
machine printed	0.012658227848101266
printed documents	0.08333333333333333
it conducted	0.008547008547008548
conducted the	0.2
most authoritative	0.017241379310344827
authoritative of	1.0
the Annual	0.0006920415224913495
Annual Test	1.0
Test of	1.0
OCR Accuracy	0.02040816326530612
Accuracy for	0.14285714285714285
for 5	0.0036101083032490976
5 consecutive	0.5
consecutive years	0.5
years in	0.047619047619047616
the mid-90s	0.0006920415224913495
mid-90s .	1.0
Commissioned	2.7900228781876013e-05
Department	2.7900228781876013e-05
Energy	2.7900228781876013e-05
DOE	2.7900228781876013e-05
Science	5.5800457563752025e-05
Institute	2.7900228781876013e-05
ISRI	2.7900228781876013e-05
mission	2.7900228781876013e-05
foster	2.7900228781876013e-05
authoritative	2.7900228781876013e-05
Annual	2.7900228781876013e-05
Test	2.7900228781876013e-05
5	5.5800457563752025e-05
consecutive	5.5800457563752025e-05
mid-90s	2.7900228781876013e-05
<s> Recognition	0.0015372790161414297
Recognition of	0.25
of Latin-script	0.00089126559714795
Latin-script ,	1.0
typewritten text	0.2
text is	0.025157232704402517
is still	0.008130081300813009
still not	0.06666666666666667
not 100	0.008928571428571428
100 %	0.6666666666666666
% accurate	0.05128205128205128
accurate even	0.14285714285714285
even where	0.037037037037037035
where clear	0.02857142857142857
clear imaging	0.25
imaging is	1.0
is available	0.0020325203252032522
available .	0.17647058823529413
Recognition	0.0002232018302550081
Latin-script	2.7900228781876013e-05
100	8.370068634562804e-05
imaging	2.7900228781876013e-05
One study	0.07692307692307693
study based	0.25
on recognition	0.0047169811320754715
of 19th	0.00089126559714795
19th -	1.0
- and	0.125
and early	0.001445086705202312
early 20th-century	0.1
20th-century newspaper	1.0
newspaper pages	0.3333333333333333
pages concluded	0.14285714285714285
concluded that	1.0
that character-by-character	0.0035460992907801418
character-by-character OCR	1.0
OCR accuracy	0.02040816326530612
for commercial	0.0036101083032490976
software varied	0.037037037037037035
varied from	1.0
from 71	0.009615384615384616
71 %	1.0
% to	0.05128205128205128
to 98	0.0013280212483399733
98 %	1.0
% ;	0.02564102564102564
; total	0.02127659574468085
total accuracy	0.5
accuracy can	0.03225806451612903
achieved only	0.1
only by	0.05263157894736842
human review	0.021739130434782608
review .	0.3333333333333333
19th	2.7900228781876013e-05
20th-century	2.7900228781876013e-05
concluded	5.5800457563752025e-05
character-by-character	2.7900228781876013e-05
varied	2.7900228781876013e-05
71	2.7900228781876013e-05
98	8.370068634562804e-05
review	8.370068634562804e-05
Other areas	0.14285714285714285
areas --	0.16666666666666666
-- including	0.04
including recognition	0.07142857142857142
of hand	0.00089126559714795
hand printing	0.07142857142857142
printing ,	1.0
, cursive	0.0005614823133071309
cursive handwriting	0.2
handwriting ,	0.5
and printed	0.001445086705202312
other scripts	0.014285714285714285
those East	0.045454545454545456
East Asian	1.0
Asian language	1.0
language characters	0.006756756756756757
characters which	0.125
which have	0.014492753623188406
many strokes	0.019230769230769232
strokes for	1.0
single character	0.07142857142857142
character -RRB-	0.045454545454545456
-RRB- --	0.0027100271002710027
still the	0.06666666666666667
subject of	0.25
of active	0.00089126559714795
active research	0.5
printing	2.7900228781876013e-05
cursive	0.00013950114390938006
handwriting	5.5800457563752025e-05
East	2.7900228781876013e-05
Asian	2.7900228781876013e-05
strokes	2.7900228781876013e-05
active	5.5800457563752025e-05
Accuracy rates	0.2857142857142857
rates can	0.125
be measured	0.004219409282700422
measured in	0.16666666666666666
in several	0.003745318352059925
several ways	0.045454545454545456
ways ,	0.25
and how	0.004335260115606936
how they	0.10344827586206896
are measured	0.004149377593360996
measured can	0.16666666666666666
can greatly	0.0055248618784530384
greatly affect	0.14285714285714285
affect the	0.3333333333333333
the reported	0.0006920415224913495
reported accuracy	0.2
accuracy rate	0.06451612903225806
rate .	0.09090909090909091
rates	0.0002232018302550081
reported	0.00013950114390938006
if word	0.03571428571428571
word context	0.016666666666666666
context -LRB-	0.06060606060606061
-LRB- basically	0.0027100271002710027
basically a	1.0
not used	0.017857142857142856
to correct	0.0013280212483399733
correct software	0.06666666666666667
software finding	0.037037037037037035
finding non-existent	0.2
non-existent words	1.0
a character	0.001226993865030675
character error	0.045454545454545456
error rate	0.4166666666666667
of 1	0.00089126559714795
1 %	0.5
% -LRB-	0.07692307692307693
-LRB- 99	0.0027100271002710027
99 %	1.0
% accuracy	0.10256410256410256
accuracy -RRB-	0.06451612903225806
-RRB- may	0.0027100271002710027
may result	0.019230769230769232
result in	0.09090909090909091
an error	0.007575757575757576
of 5	0.00089126559714795
5 %	0.5
-LRB- 95	0.0027100271002710027
95 %	1.0
or worse	0.0045045045045045045
worse if	1.0
the measurement	0.0006920415224913495
measurement is	0.5
on whether	0.0047169811320754715
whether each	0.07692307692307693
each whole	0.022222222222222223
whole word	0.1111111111111111
word was	0.016666666666666666
was recognized	0.012987012987012988
recognized with	0.16666666666666666
with no	0.01092896174863388
no incorrect	0.07692307692307693
incorrect letters	0.3333333333333333
basically	2.7900228781876013e-05
non-existent	2.7900228781876013e-05
99	2.7900228781876013e-05
95	0.00011160091512750405
worse	2.7900228781876013e-05
measurement	5.5800457563752025e-05
recognized	0.00016740137269125608
incorrect	8.370068634562804e-05
<s> On-line	0.0023059185242121443
On-line character	0.6666666666666666
recognition is	0.0743801652892562
sometimes confused	0.07692307692307693
with Optical	0.00546448087431694
Optical Character	0.3333333333333333
Character Recognition	1.0
Recognition -LRB-	0.125
see Handwriting	0.05
Handwriting recognition	1.0
recognition -RRB-	0.008264462809917356
On-line	8.370068634562804e-05
Character	5.5800457563752025e-05
Handwriting	2.7900228781876013e-05
an instance	0.007575757575757576
of off-line	0.00089126559714795
off-line character	1.0
system recognizes	0.010752688172043012
recognizes the	1.0
the fixed	0.0006920415224913495
fixed static	0.5
static shape	1.0
shape of	1.0
the character	0.0006920415224913495
while on-line	0.05
on-line character	0.3333333333333333
recognition instead	0.008264462809917356
instead recognizes	0.14285714285714285
the dynamic	0.0006920415224913495
dynamic motion	0.2
motion during	1.0
during handwriting	0.1
handwriting .	0.5
off-line	2.7900228781876013e-05
recognizes	8.370068634562804e-05
static	2.7900228781876013e-05
shape	2.7900228781876013e-05
motion	2.7900228781876013e-05
, on-line	0.0005614823133071309
on-line recognition	0.3333333333333333
as that	0.003484320557491289
that used	0.0035460992907801418
for gestures	0.0036101083032490976
gestures in	0.5
the Penpoint	0.0006920415224913495
Penpoint OS	1.0
OS or	0.5
the Tablet	0.0006920415224913495
Tablet PC	1.0
PC can	0.25
can tell	0.0055248618784530384
tell whether	0.3333333333333333
whether a	0.15384615384615385
a horizontal	0.001226993865030675
horizontal mark	1.0
mark was	0.3333333333333333
was drawn	0.012987012987012988
drawn right-to-left	1.0
right-to-left ,	1.0
or left-to-right	0.0045045045045045045
left-to-right .	1.0
Penpoint	2.7900228781876013e-05
OS	5.5800457563752025e-05
Tablet	5.5800457563752025e-05
tell	8.370068634562804e-05
horizontal	2.7900228781876013e-05
drawn	2.7900228781876013e-05
right-to-left	2.7900228781876013e-05
left-to-right	2.7900228781876013e-05
also referred	0.014492753623188406
by other	0.005714285714285714
other terms	0.014285714285714285
terms such	0.07692307692307693
as dynamic	0.003484320557491289
dynamic character	0.2
, real-time	0.0005614823133071309
real-time character	0.5
and Intelligent	0.001445086705202312
Intelligent Character	0.3333333333333333
Recognition or	0.125
or ICR	0.0045045045045045045
ICR .	0.3333333333333333
On-line systems	0.3333333333333333
for recognizing	0.0036101083032490976
recognizing hand-printed	0.2
hand-printed text	0.5
text on	0.006289308176100629
the fly	0.0006920415224913495
fly have	1.0
have become	0.009615384615384616
become well	0.25
well known	0.03571428571428571
as commercial	0.003484320557491289
commercial products	0.09090909090909091
products in	0.25
in recent	0.003745318352059925
years -LRB-	0.047619047619047616
see Tablet	0.05
PC history	0.25
history -RRB-	0.25
hand-printed	0.00011160091512750405
fly	2.7900228781876013e-05
<s> Among	0.0007686395080707148
Among these	1.0
input devices	0.04878048780487805
devices for	0.25
for personal	0.0036101083032490976
personal digital	0.25
digital assistants	0.14285714285714285
assistants such	1.0
those running	0.045454545454545456
running Palm	0.3333333333333333
Palm OS	1.0
OS .	0.5
Among	2.7900228781876013e-05
assistants	2.7900228781876013e-05
Palm	2.7900228781876013e-05
The Apple	0.005208333333333333
Apple Newton	1.0
Newton pioneered	1.0
pioneered this	0.3333333333333333
this product	0.01098901098901099
product .	0.14285714285714285
Apple	2.7900228781876013e-05
Newton	2.7900228781876013e-05
algorithms used	0.02857142857142857
these devices	0.023809523809523808
devices take	0.25
the order	0.001384083044982699
, speed	0.0005614823133071309
and direction	0.001445086705202312
direction of	0.3333333333333333
of individual	0.0017825311942959
individual lines	0.08333333333333333
lines segments	0.3333333333333333
segments at	0.2
at input	0.014705882352941176
input are	0.024390243902439025
known .	0.038461538461538464
user can	0.07142857142857142
be retrained	0.004219409282700422
retrained to	1.0
only specific	0.02631578947368421
specific letter	0.047619047619047616
letter shapes	0.3333333333333333
shapes .	0.3333333333333333
retrained	2.7900228781876013e-05
shapes	8.370068634562804e-05
methods can	0.022727272727272728
in software	0.0018726591760299626
software that	0.037037037037037035
that scans	0.0035460992907801418
scans paper	1.0
paper documents	0.09090909090909091
so accurate	0.03333333333333333
accurate recognition	0.14285714285714285
of hand-printed	0.0017825311942959
hand-printed documents	0.25
documents is	0.02631578947368421
still largely	0.06666666666666667
largely an	0.2
an open	0.015151515151515152
open problem	0.25
scans	2.7900228781876013e-05
largely	0.00013950114390938006
rates of	0.375
of 80	0.00089126559714795
80 %	1.0
to 90	0.0013280212483399733
% on	0.02564102564102564
on neat	0.0047169811320754715
neat ,	1.0
, clean	0.0005614823133071309
clean hand-printed	0.5
hand-printed characters	0.25
achieved ,	0.2
that accuracy	0.0035460992907801418
rate still	0.09090909090909091
still translates	0.06666666666666667
translates to	1.0
to dozens	0.0013280212483399733
dozens of	1.0
of errors	0.00089126559714795
errors per	0.2
per page	0.25
, making	0.0005614823133071309
the technology	0.0006920415224913495
technology useful	0.045454545454545456
useful only	0.07142857142857142
only in	0.05263157894736842
in very	0.0056179775280898875
limited applications	0.1
80	2.7900228781876013e-05
neat	2.7900228781876013e-05
translates	2.7900228781876013e-05
dozens	2.7900228781876013e-05
of cursive	0.00089126559714795
cursive text	0.2
an active	0.007575757575757576
active area	0.5
with recognition	0.00546448087431694
recognition rates	0.01652892561983471
rates even	0.125
even lower	0.037037037037037035
lower than	0.2
than that	0.044444444444444446
lower	0.00013950114390938006
<s> Higher	0.0007686395080707148
Higher rates	1.0
of general	0.00089126559714795
general cursive	0.045454545454545456
cursive script	0.4
script will	0.25
likely not	0.0625
be possible	0.008438818565400843
possible without	0.041666666666666664
without the	0.07692307692307693
of contextual	0.00089126559714795
contextual or	0.5
or grammatical	0.0045045045045045045
grammatical information	0.09090909090909091
Higher	2.7900228781876013e-05
script	0.00011160091512750405
contextual	5.5800457563752025e-05
, recognizing	0.0005614823133071309
recognizing entire	0.2
entire words	0.3333333333333333
dictionary is	0.14285714285714285
is easier	0.0040650406504065045
easier than	0.25
than trying	0.022222222222222223
to parse	0.005312084993359893
parse individual	0.1111111111111111
individual characters	0.08333333333333333
characters from	0.0625
from script	0.009615384615384616
script .	0.5
<s> Reading	0.0007686395080707148
Reading the	0.5
the Amount	0.0006920415224913495
Amount line	1.0
line of	0.3333333333333333
a cheque	0.001226993865030675
cheque -LRB-	1.0
always a	0.3333333333333333
a written-out	0.001226993865030675
written-out number	1.0
number -RRB-	0.046511627906976744
example where	0.012345679012345678
where using	0.02857142857142857
a smaller	0.001226993865030675
smaller dictionary	0.14285714285714285
dictionary can	0.14285714285714285
can increase	0.0055248618784530384
increase recognition	0.25
rates greatly	0.125
greatly .	0.2857142857142857
Amount	2.7900228781876013e-05
cheque	2.7900228781876013e-05
written-out	2.7900228781876013e-05
smaller	0.0001953016014731321
<s> Knowledge	0.0007686395080707148
Knowledge of	0.5
grammar of	0.05405405405405406
being scanned	0.05555555555555555
scanned can	0.3333333333333333
also help	0.014492753623188406
help determine	0.1111111111111111
if a	0.03571428571428571
word is	0.06666666666666667
a verb	0.007361963190184049
, allowing	0.0005614823133071309
allowing greater	0.3333333333333333
greater accuracy	0.3333333333333333
The shapes	0.005208333333333333
shapes of	0.6666666666666666
individual cursive	0.08333333333333333
cursive characters	0.2
characters themselves	0.0625
themselves simply	0.25
simply do	0.08333333333333333
not contain	0.008928571428571428
contain enough	0.08333333333333333
enough information	0.2
to accurately	0.0013280212483399733
accurately -LRB-	0.5
-LRB- greater	0.0027100271002710027
greater than	0.3333333333333333
than 98	0.022222222222222223
% -RRB-	0.02564102564102564
-RRB- recognize	0.0027100271002710027
recognize all	0.1111111111111111
all handwritten	0.023255813953488372
handwritten cursive	0.5
themselves	0.00011160091512750405
is necessary	0.0040650406504065045
necessary to	0.2
understand that	0.14285714285714285
that OCR	0.0035460992907801418
basic technology	0.07692307692307693
technology also	0.045454545454545456
in advanced	0.0018726591760299626
advanced scanning	0.4
scanning applications	0.5
scanning	5.5800457563752025e-05
<s> Due	0.0007686395080707148
Due to	1.0
an advanced	0.007575757575757576
scanning solution	0.5
solution can	1.0
be unique	0.004219409282700422
unique and	1.0
and patented	0.001445086705202312
patented and	1.0
not easily	0.026785714285714284
easily copied	0.1111111111111111
copied despite	0.5
despite being	0.3333333333333333
being based	0.05555555555555555
this basic	0.01098901098901099
basic OCR	0.07692307692307693
Due	2.7900228781876013e-05
solution	2.7900228781876013e-05
unique	2.7900228781876013e-05
patented	2.7900228781876013e-05
For more	0.03278688524590164
complex recognition	0.041666666666666664
recognition problems	0.008264462809917356
, intelligent	0.0005614823133071309
intelligent character	1.0
generally used	0.09090909090909091
as artificial	0.003484320557491289
artificial neural	0.09090909090909091
neural networks	0.5333333333333333
networks can	0.07142857142857142
made indifferent	0.0625
indifferent to	1.0
both affine	0.03225806451612903
affine and	1.0
and non-linear	0.001445086705202312
non-linear transformations	1.0
transformations .	0.5
intelligent	2.7900228781876013e-05
neural	0.0004185034317281402
indifferent	2.7900228781876013e-05
affine	2.7900228781876013e-05
non-linear	2.7900228781876013e-05
A technique	0.02
technique which	0.14285714285714285
is having	0.0020325203252032522
having considerable	0.2
considerable success	0.2
success in	0.2
recognizing difficult	0.2
difficult words	0.03571428571428571
and character	0.001445086705202312
character groups	0.045454545454545456
groups within	0.2
within documents	0.05555555555555555
documents generally	0.02631578947368421
generally amenable	0.09090909090909091
amenable to	1.0
to computer	0.0013280212483399733
computer OCR	0.022727272727272728
to submit	0.0013280212483399733
submit them	0.5
them automatically	0.05263157894736842
automatically to	0.047619047619047616
to humans	0.0013280212483399733
humans in	0.08333333333333333
the reCAPTCHA	0.0006920415224913495
reCAPTCHA system	1.0
amenable	2.7900228781876013e-05
reCAPTCHA	2.7900228781876013e-05
In corpus	0.009523809523809525
, part-of-speech	0.0011229646266142617
part-of-speech tagging	0.4666666666666667
tagging -LRB-	0.04
POS tagging	0.38461538461538464
tagging or	0.08
or POST	0.0045045045045045045
POST -RRB-	1.0
called grammatical	0.05555555555555555
grammatical tagging	0.18181818181818182
or word-category	0.0045045045045045045
word-category disambiguation	1.0
disambiguation ,	0.1
of marking	0.00089126559714795
marking up	0.5
-LRB- corpus	0.0027100271002710027
as corresponding	0.003484320557491289
particular part	0.07692307692307693
speech ,	0.07236842105263158
on both	0.0047169811320754715
both its	0.03225806451612903
its definition	0.02857142857142857
definition ,	0.4
its context	0.02857142857142857
context --	0.030303030303030304
-- i.e.	0.04
i.e. relationship	0.05263157894736842
relationship with	0.16666666666666666
with adjacent	0.00546448087431694
adjacent and	0.16666666666666666
related words	0.06666666666666667
phrase ,	0.1
, sentence	0.0005614823133071309
or paragraph	0.0045045045045045045
paragraph .	0.3333333333333333
POST	2.7900228781876013e-05
word-category	2.7900228781876013e-05
A simplified	0.02
simplified form	0.5
is commonly	0.0040650406504065045
commonly taught	0.125
taught to	0.3333333333333333
to school-age	0.0013280212483399733
school-age children	1.0
children ,	0.5
words as	0.009174311926605505
as nouns	0.003484320557491289
, verbs	0.0011229646266142617
verbs ,	0.6
, adjectives	0.0005614823133071309
adjectives ,	0.3333333333333333
, adverbs	0.0005614823133071309
adverbs ,	1.0
simplified	5.5800457563752025e-05
school-age	2.7900228781876013e-05
verbs	0.00013950114390938006
adverbs	2.7900228781876013e-05
, POS	0.0005614823133071309
tagging is	0.08
now done	0.07692307692307693
using algorithms	0.01694915254237288
algorithms which	0.02857142857142857
which associate	0.007246376811594203
associate discrete	0.5
discrete terms	0.3333333333333333
terms ,	0.07692307692307693
as hidden	0.003484320557491289
hidden parts	0.125
in accordance	0.0018726591760299626
accordance with	1.0
of descriptive	0.00089126559714795
descriptive tags	0.3333333333333333
hidden	0.0002232018302550081
accordance	2.7900228781876013e-05
<s> POS-tagging	0.0007686395080707148
POS-tagging algorithms	1.0
algorithms fall	0.02857142857142857
into two	0.01282051282051282
two distinctive	0.034482758620689655
distinctive groups	0.5
groups :	0.2
: rule-based	0.00980392156862745
rule-based and	0.14285714285714285
and stochastic	0.001445086705202312
stochastic .	0.125
POS-tagging	2.7900228781876013e-05
distinctive	5.5800457563752025e-05
<s> E.	0.0007686395080707148
E. Brill	0.25
Brill 's	0.3333333333333333
's tagger	0.0196078431372549
first and	0.030303030303030304
and widely	0.001445086705202312
used English	0.008849557522123894
English POS-taggers	0.02702702702702703
POS-taggers ,	1.0
, employs	0.0005614823133071309
employs rule-based	0.5
rule-based algorithms	0.14285714285714285
Brill	8.370068634562804e-05
POS-taggers	2.7900228781876013e-05
employs	5.5800457563752025e-05
not rare	0.008928571428571428
rare --	0.25
-- in	0.04
as opposed	0.003484320557491289
opposed to	1.0
many artificial	0.019230769230769232
artificial languages	0.09090909090909091
languages -RRB-	0.04
large percentage	0.043478260869565216
percentage of	1.0
of word-forms	0.00089126559714795
word-forms are	1.0
are ambiguous	0.004149377593360996
ambiguous .	0.25
opposed	2.7900228781876013e-05
percentage	2.7900228781876013e-05
word-forms	2.7900228781876013e-05
, even	0.0039303761931499155
even ``	0.037037037037037035
`` dogs	0.021164021164021163
dogs ''	0.5714285714285714
usually thought	0.03125
thought of	0.6666666666666666
of as	0.0017825311942959
as just	0.003484320557491289
just a	0.2222222222222222
a plural	0.001226993865030675
plural noun	0.4
verb :	0.07692307692307693
The sailor	0.005208333333333333
sailor dogs	0.2
dogs the	0.14285714285714285
the barmaid	0.0006920415224913495
barmaid .	0.16666666666666666
dogs	0.0001953016014731321
sailor	0.00013950114390938006
barmaid	0.00016740137269125608
<s> Performing	0.0007686395080707148
Performing grammatical	1.0
tagging will	0.04
will indicate	0.02857142857142857
indicate that	0.3333333333333333
verb ,	0.38461538461538464
the more	0.0034602076124567475
more common	0.010526315789473684
common plural	0.04
since one	0.1
words must	0.009174311926605505
main verb	0.125
the noun	0.0006920415224913495
noun reading	0.07142857142857142
reading is	0.125
is less	0.0020325203252032522
less likely	0.16666666666666666
likely following	0.0625
following ``	0.06666666666666667
`` sailor	0.010582010582010581
sailor ''	0.4
-LRB- sailor	0.005420054200542005
sailor !	0.2
! <\s>	1.0
Performing	2.7900228781876013e-05
!	2.7900228781876013e-05
<s> 	0.0007686395080707148
 dogs	0.25
dogs -RRB-	0.14285714285714285
	0.00011160091512750405
<s> Semantic	0.0007686395080707148
Semantic analysis	0.3333333333333333
analysis can	0.03076923076923077
can then	0.0055248618784530384
then extrapolate	0.02857142857142857
extrapolate that	1.0
`` barmaid	0.010582010582010581
barmaid ''	0.3333333333333333
'' implicate	0.005154639175257732
implicate ``	1.0
as 1	0.003484320557491289
1 -RRB-	0.25
the nautical	0.0006920415224913495
nautical context	0.5
sailor 	0.2
 <verb>	0.25
<verb> 	1.0
 barmaid	0.5
barmaid -RRB-	0.5
and 2	0.001445086705202312
2 -RRB-	0.2
-RRB- an	0.0027100271002710027
an action	0.007575757575757576
action applied	0.2
the object	0.0006920415224913495
object ``	0.5
-LRB- -LRB-	0.0027100271002710027
-LRB- subject	0.0027100271002710027
subject -RRB-	0.125
-RRB- dogs	0.0027100271002710027
dogs 	0.14285714285714285
extrapolate	2.7900228781876013e-05
implicate	2.7900228781876013e-05
nautical	5.5800457563752025e-05
<verb>	2.7900228781876013e-05
object	5.5800457563752025e-05
this context	0.02197802197802198
a nautical	0.001226993865030675
nautical term	0.5
term meaning	0.05555555555555555
meaning ``	0.043478260869565216
`` fastens	0.005291005291005291
fastens -LRB-	1.0
-LRB- a	0.013550135501355014
a watertight	0.001226993865030675
watertight barmaid	1.0
-RRB- securely	0.0027100271002710027
securely ;	1.0
; applies	0.02127659574468085
a dog	0.001226993865030675
dog to	0.3333333333333333
to ''	0.0026560424966799467
fastens	2.7900228781876013e-05
watertight	2.7900228781876013e-05
securely	2.7900228781876013e-05
dog	8.370068634562804e-05
`` Dogged	0.005291005291005291
Dogged ''	1.0
be either	0.004219409282700422
either an	0.1
an adjective	0.03787878787878788
adjective or	0.42857142857142855
a past-tense	0.001226993865030675
past-tense verb	1.0
verb .	0.15384615384615385
Dogged	2.7900228781876013e-05
past-tense	2.7900228781876013e-05
<s> Just	0.0007686395080707148
Just which	1.0
which parts	0.007246376811594203
speech a	0.006578947368421052
can represent	0.011049723756906077
represent varies	0.1111111111111111
varies greatly	1.0
Just	2.7900228781876013e-05
varies	5.5800457563752025e-05
<s> Trained	0.0007686395080707148
Trained linguists	1.0
linguists can	0.3333333333333333
can identify	0.0055248618784530384
grammatical parts	0.09090909090909091
speech to	0.019736842105263157
to various	0.0013280212483399733
various fine	0.05555555555555555
fine degrees	0.5
degrees depending	0.5
the tagging	0.001384083044982699
tagging system	0.04
Trained	2.7900228781876013e-05
fine	5.5800457563752025e-05
<s> Schools	0.0007686395080707148
Schools commonly	1.0
commonly teach	0.125
teach that	1.0
are 9	0.004149377593360996
9 parts	1.0
speech in	0.013157894736842105
English :	0.02702702702702703
: noun	0.00980392156862745
, article	0.0016844469399213925
, adjective	0.0005614823133071309
adjective ,	0.14285714285714285
, preposition	0.0005614823133071309
preposition ,	1.0
, pronoun	0.0005614823133071309
pronoun ,	1.0
, adverb	0.0005614823133071309
adverb ,	1.0
, conjunction	0.0005614823133071309
conjunction ,	0.3333333333333333
and interjection	0.001445086705202312
interjection .	1.0
Schools	2.7900228781876013e-05
teach	2.7900228781876013e-05
9	2.7900228781876013e-05
preposition	8.370068634562804e-05
pronoun	2.7900228781876013e-05
adverb	2.7900228781876013e-05
conjunction	8.370068634562804e-05
interjection	2.7900228781876013e-05
are clearly	0.004149377593360996
clearly many	0.3333333333333333
many more	0.019230769230769232
more categories	0.010526315789473684
categories and	0.2222222222222222
and sub-categories	0.001445086705202312
sub-categories .	1.0
categories	0.0002511020590368841
sub-categories	2.7900228781876013e-05
For nouns	0.01639344262295082
, plural	0.0005614823133071309
, possessive	0.0005614823133071309
possessive ,	1.0
and singular	0.001445086705202312
singular forms	0.25
forms can	0.16666666666666666
be distinguished	0.004219409282700422
distinguished .	1.0
possessive	2.7900228781876013e-05
singular	0.00011160091512750405
distinguished	2.7900228781876013e-05
many languages	0.019230769230769232
languages words	0.02
also marked	0.014492753623188406
marked for	0.6666666666666666
for their	0.007220216606498195
their ``	0.029411764705882353
`` case	0.005291005291005291
case ''	0.058823529411764705
-LRB- role	0.0027100271002710027
role as	0.25
as subject	0.003484320557491289
, object	0.0005614823133071309
object ,	0.5
, grammatical	0.0005614823133071309
grammatical gender	0.09090909090909091
gender ,	1.0
on ;	0.0047169811320754715
; while	0.02127659574468085
while verbs	0.05
verbs are	0.2
are marked	0.004149377593360996
for tense	0.0036101083032490976
tense ,	0.5
, aspect	0.0005614823133071309
aspect ,	0.5
things .	0.3333333333333333
gender	2.7900228781876013e-05
aspect	5.5800457563752025e-05
In part-of-speech	0.009523809523809525
tagging by	0.04
computer ,	0.022727272727272728
is typical	0.0020325203252032522
typical to	0.1111111111111111
distinguish from	0.2
from 50	0.009615384615384616
50 to	0.3333333333333333
to 150	0.0013280212483399733
150 separate	0.5
separate parts	0.1
for English	0.0036101083032490976
, NN	0.0005614823133071309
NN for	1.0
for singular	0.007220216606498195
singular common	0.25
common nouns	0.08
, NNS	0.0005614823133071309
NNS for	1.0
for plural	0.0036101083032490976
plural common	0.2
, NP	0.0005614823133071309
NP for	1.0
singular proper	0.25
proper nouns	0.14285714285714285
nouns -LRB-	0.1111111111111111
POS tags	0.15384615384615385
tags used	0.3333333333333333
Corpus -RRB-	0.1875
50	8.370068634562804e-05
150	5.5800457563752025e-05
NN	2.7900228781876013e-05
NNS	2.7900228781876013e-05
NP	2.7900228781876013e-05
<s> Work	0.0015372790161414297
Work on	0.5
on stochastic	0.0047169811320754715
stochastic methods	0.125
methods for	0.045454545454545456
for tagging	0.0036101083032490976
tagging Koine	0.04
Koine Greek	1.0
Greek -LRB-	0.3333333333333333
-LRB- DeRose	0.0027100271002710027
DeRose 1990	0.2
1990 -RRB-	0.6666666666666666
has used	0.011904761904761904
used over	0.008849557522123894
over 1,000	0.08333333333333333
1,000 parts	0.5
and found	0.001445086705202312
that about	0.0035460992907801418
about as	0.025
as many	0.006968641114982578
many words	0.038461538461538464
words were	0.01834862385321101
were ambiguous	0.024390243902439025
ambiguous there	0.08333333333333333
there as	0.025
Work	5.5800457563752025e-05
Koine	2.7900228781876013e-05
Greek	8.370068634562804e-05
DeRose	0.00013950114390938006
1990	8.370068634562804e-05
1,000	5.5800457563752025e-05
A morphosyntactic	0.02
morphosyntactic descriptor	1.0
descriptor in	1.0
of morphologically	0.00089126559714795
morphologically rich	1.0
rich languages	0.2
languages can	0.04
be expressed	0.012658227848101266
expressed like	0.16666666666666666
like Ncmsan	0.03571428571428571
Ncmsan ,	1.0
means Category	0.16666666666666666
Category =	0.5
= Noun	0.1111111111111111
Noun ,	1.0
, Type	0.0005614823133071309
Type =	1.0
= common	0.1111111111111111
common ,	0.08
, Gender	0.0005614823133071309
Gender =	1.0
= masculine	0.1111111111111111
masculine ,	1.0
, Number	0.0005614823133071309
Number =	1.0
= singular	0.1111111111111111
singular ,	0.25
, Case	0.0005614823133071309
Case =	1.0
= accusative	0.1111111111111111
accusative ,	1.0
, Animate	0.0005614823133071309
Animate =	1.0
= no.	0.1111111111111111
no. .	1.0
morphosyntactic	2.7900228781876013e-05
descriptor	2.7900228781876013e-05
morphologically	2.7900228781876013e-05
expressed	0.00016740137269125608
Ncmsan	2.7900228781876013e-05
Category	5.5800457563752025e-05
Noun	2.7900228781876013e-05
Type	2.7900228781876013e-05
Gender	2.7900228781876013e-05
masculine	2.7900228781876013e-05
Number	2.7900228781876013e-05
Case	2.7900228781876013e-05
accusative	2.7900228781876013e-05
Animate	2.7900228781876013e-05
no.	2.7900228781876013e-05
<s> History	0.0015372790161414297
History The	0.5
The Brown	0.015625
Corpus Research	0.0625
Research on	0.125
on part-of-speech	0.0047169811320754715
tagging has	0.04
been closely	0.014705882352941176
closely tied	0.2
tied to	1.0
to corpus	0.0013280212483399733
linguistics .	0.05
History	5.5800457563752025e-05
tied	2.7900228781876013e-05
first major	0.06060606060606061
major corpus	0.08333333333333333
English for	0.02702702702702703
computer analysis	0.022727272727272728
analysis was	0.03076923076923077
was the	0.05194805194805195
Corpus developed	0.0625
at Brown	0.029411764705882353
Brown University	0.14285714285714285
University by	0.1111111111111111
by Henry	0.005714285714285714
Henry Kucera	0.5
Kucera and	1.0
and Nelson	0.001445086705202312
Nelson Francis	1.0
Francis ,	1.0
the mid-1960s	0.0006920415224913495
mid-1960s .	1.0
Kucera	2.7900228781876013e-05
Nelson	2.7900228781876013e-05
Francis	2.7900228781876013e-05
mid-1960s	2.7900228781876013e-05
It consists	0.02631578947368421
of about	0.00089126559714795
about 1,000,000	0.025
1,000,000 words	1.0
of running	0.00089126559714795
running English	0.3333333333333333
English prose	0.02702702702702703
prose text	1.0
, made	0.0011229646266142617
made up	0.0625
up of	0.045454545454545456
500 samples	0.5
samples from	0.5
from randomly	0.009615384615384616
randomly chosen	1.0
chosen publications	0.2
publications .	1.0
1,000,000	2.7900228781876013e-05
prose	2.7900228781876013e-05
samples	5.5800457563752025e-05
randomly	2.7900228781876013e-05
publications	2.7900228781876013e-05
Each sample	0.16666666666666666
sample is	0.3333333333333333
is 2,000	0.0020325203252032522
2,000 or	0.5
more words	0.010526315789473684
-LRB- ending	0.0027100271002710027
ending at	1.0
first sentence-end	0.030303030303030304
sentence-end after	1.0
after 2,000	0.08333333333333333
2,000 words	0.5
the corpus	0.0006920415224913495
corpus contains	0.03225806451612903
contains only	0.1
only complete	0.02631578947368421
complete sentences	1.0
2,000	5.5800457563752025e-05
ending	2.7900228781876013e-05
sentence-end	2.7900228781876013e-05
complete	2.7900228781876013e-05
Corpus was	0.125
was painstakingly	0.012987012987012988
painstakingly ``	1.0
`` tagged	0.010582010582010581
tagged ''	0.6666666666666666
with part-of-speech	0.00546448087431694
part-of-speech markers	0.06666666666666667
markers over	0.3333333333333333
over many	0.08333333333333333
many years	0.019230769230769232
painstakingly	2.7900228781876013e-05
tagged	8.370068634562804e-05
markers	8.370068634562804e-05
A first	0.02
first approximation	0.030303030303030304
approximation was	0.16666666666666666
was done	0.012987012987012988
done with	0.18181818181818182
a program	0.0049079754601227
program by	0.045454545454545456
by Greene	0.005714285714285714
Greene and	1.0
and Rubin	0.001445086705202312
Rubin ,	1.0
which consisted	0.007246376811594203
consisted of	1.0
a huge	0.001226993865030675
huge handmade	1.0
handmade list	1.0
what categories	0.03125
categories could	0.1111111111111111
could co-occur	0.0625
co-occur at	0.5
all .	0.023255813953488372
Greene	2.7900228781876013e-05
Rubin	2.7900228781876013e-05
consisted	2.7900228781876013e-05
huge	2.7900228781876013e-05
handmade	2.7900228781876013e-05
article then	0.034482758620689655
then noun	0.02857142857142857
noun can	0.07142857142857142
can occur	0.0055248618784530384
occur ,	0.2
but article	0.014705882352941176
article verb	0.034482758620689655
-LRB- arguably	0.0027100271002710027
arguably -RRB-	0.5
-RRB- can	0.008130081300813009
not .	0.017857142857142856
occur	0.00013950114390938006
arguably	5.5800457563752025e-05
The program	0.005208333333333333
program got	0.045454545454545456
got about	1.0
about 70	0.05
70 %	0.75
% correct	0.02564102564102564
got	2.7900228781876013e-05
Its results	0.5
results were	0.047619047619047616
were repeatedly	0.024390243902439025
repeatedly reviewed	1.0
reviewed and	1.0
and corrected	0.001445086705202312
corrected by	1.0
and later	0.001445086705202312
later users	0.1
users sent	0.1111111111111111
sent in	1.0
in errata	0.0018726591760299626
errata ,	1.0
that by	0.0035460992907801418
late 70s	0.1111111111111111
70s the	1.0
tagging was	0.08
was nearly	0.012987012987012988
nearly perfect	0.5
perfect -LRB-	1.0
-LRB- allowing	0.0027100271002710027
allowing for	0.3333333333333333
cases on	0.05555555555555555
which even	0.007246376811594203
even human	0.037037037037037035
human speakers	0.021739130434782608
speakers might	0.25
not agree	0.008928571428571428
agree -RRB-	0.3333333333333333
repeatedly	2.7900228781876013e-05
reviewed	2.7900228781876013e-05
corrected	2.7900228781876013e-05
sent	2.7900228781876013e-05
errata	2.7900228781876013e-05
70s	2.7900228781876013e-05
nearly	5.5800457563752025e-05
perfect	2.7900228781876013e-05
agree	8.370068634562804e-05
corpus has	0.03225806451612903
for innumerable	0.0036101083032490976
innumerable studies	1.0
studies of	0.25
of word-frequency	0.00089126559714795
word-frequency and	1.0
and of	0.001445086705202312
part-of-speech ,	0.06666666666666667
and inspired	0.001445086705202312
inspired the	1.0
similar ``	0.037037037037037035
'' corpora	0.005154639175257732
corpora in	0.09090909090909091
innumerable	2.7900228781876013e-05
word-frequency	2.7900228781876013e-05
inspired	2.7900228781876013e-05
Statistics derived	0.3333333333333333
analyzing it	0.2
it formed	0.008547008547008548
formed the	0.2
most later	0.017241379310344827
later part-of-speech	0.1
tagging systems	0.04
as CLAWS	0.003484320557491289
CLAWS -LRB-	0.25
and VOLSUNGA	0.001445086705202312
VOLSUNGA .	1.0
CLAWS	0.00011160091512750405
VOLSUNGA	2.7900228781876013e-05
by this	0.005714285714285714
time -LRB-	0.06060606060606061
-LRB- 2005	0.0027100271002710027
2005 -RRB-	1.0
-RRB- it	0.0027100271002710027
been superseded	0.014705882352941176
superseded by	1.0
by larger	0.005714285714285714
larger corpora	0.0625
corpora such	0.09090909090909091
the 100	0.0006920415224913495
100 million	0.3333333333333333
million word	0.3333333333333333
word British	0.016666666666666666
British National	0.3333333333333333
National Corpus	0.3333333333333333
Corpus .	0.0625
2005	2.7900228781876013e-05
superseded	2.7900228781876013e-05
For some	0.01639344262295082
some time	0.024096385542168676
was considered	0.012987012987012988
considered an	0.1111111111111111
an inseparable	0.007575757575757576
inseparable part	1.0
are certain	0.004149377593360996
certain cases	0.14285714285714285
cases where	0.16666666666666666
speech can	0.013157894736842105
be decided	0.004219409282700422
decided without	0.3333333333333333
without understanding	0.07692307692307693
or even	0.02252252252252252
even the	0.07407407407407407
the pragmatics	0.0006920415224913495
pragmatics of	0.3333333333333333
inseparable	2.7900228781876013e-05
extremely expensive	0.25
especially because	0.06666666666666667
because analyzing	0.03333333333333333
analyzing the	0.2
the higher	0.0006920415224913495
higher levels	0.2857142857142857
levels is	0.045454545454545456
much harder	0.045454545454545456
harder when	0.14285714285714285
when multiple	0.02857142857142857
multiple part-of-speech	0.07692307692307693
part-of-speech possibilities	0.06666666666666667
possibilities must	0.2
considered for	0.1111111111111111
possibilities	0.00013950114390938006
<s> Use	0.0007686395080707148
Use of	0.5
of Hidden	0.00089126559714795
Hidden Markov	1.0
Markov Models	0.16666666666666666
Models In	0.3333333333333333
the mid	0.0006920415224913495
mid 1980s	1.0
, researchers	0.0011229646266142617
researchers in	0.1
Europe began	0.2
use hidden	0.013888888888888888
hidden Markov	0.875
models -LRB-	0.11538461538461539
-LRB- HMMs	0.005420054200542005
HMMs -RRB-	0.25
disambiguate parts	0.3333333333333333
when working	0.02857142857142857
working to	0.14285714285714285
to tag	0.0013280212483399733
tag the	0.0625
the Lancaster-Oslo-Bergen	0.0006920415224913495
Lancaster-Oslo-Bergen Corpus	1.0
Corpus of	0.0625
of British	0.00089126559714795
British English	0.3333333333333333
Use	5.5800457563752025e-05
Hidden	0.00016740137269125608
Models	8.370068634562804e-05
mid	2.7900228781876013e-05
HMMs	0.0002232018302550081
Lancaster-Oslo-Bergen	2.7900228781876013e-05
<s> HMMs	0.0023059185242121443
HMMs involve	0.125
involve counting	0.16666666666666666
counting cases	1.0
cases -LRB-	0.05555555555555555
as from	0.003484320557491289
and making	0.002890173410404624
making a	0.14285714285714285
a table	0.0036809815950920245
table of	0.42857142857142855
the probabilities	0.002768166089965398
probabilities of	0.2727272727272727
of certain	0.00089126559714795
certain sequences	0.14285714285714285
sequences .	0.2222222222222222
counting	2.7900228781876013e-05
, once	0.0005614823133071309
once you	1.0
you 've	0.15384615384615385
've seen	0.5
seen an	0.2
an article	0.015151515151515152
article such	0.034482758620689655
as `	0.003484320557491289
` the	0.0625
the '	0.0006920415224913495
perhaps the	0.16666666666666666
next word	0.2857142857142857
noun 40	0.07142857142857142
40 %	1.0
adjective 40	0.14285714285714285
% ,	0.05128205128205128
number 20	0.023255813953488372
20 %	1.0
once	2.7900228781876013e-05
've	5.5800457563752025e-05
40	5.5800457563752025e-05
20	2.7900228781876013e-05
<s> Knowing	0.0007686395080707148
Knowing this	1.0
program can	0.045454545454545456
can decide	0.0055248618784530384
decide that	0.25
`` can	0.005291005291005291
can ''	0.011049723756906077
in ``	0.0056179775280898875
the can	0.0006920415224913495
more likely	0.010526315789473684
noun than	0.07142857142857142
a modal	0.001226993865030675
modal .	1.0
Knowing	2.7900228781876013e-05
modal	2.7900228781876013e-05
The same	0.010416666666666666
same method	0.04
method can	0.0625
can of	0.0055248618784530384
of course	0.0017825311942959
course be	0.3333333333333333
to benefit	0.0013280212483399733
benefit from	1.0
from knowledge	0.009615384615384616
about following	0.025
following words	0.06666666666666667
course	8.370068634562804e-05
benefit	8.370068634562804e-05
More advanced	0.1111111111111111
advanced -LRB-	0.2
`` higher	0.005291005291005291
higher order	0.14285714285714285
order ''	0.07142857142857142
-RRB- HMMs	0.0027100271002710027
HMMs learn	0.125
learn the	0.07692307692307693
probabilities not	0.09090909090909091
only of	0.02631578947368421
of pairs	0.0017825311942959
pairs ,	1.0
but triples	0.014705882352941176
triples or	0.3333333333333333
even larger	0.037037037037037035
larger sequences	0.0625
pairs	5.5800457563752025e-05
triples	8.370068634562804e-05
So ,	0.3333333333333333
've just	0.5
just seen	0.1111111111111111
next item	0.14285714285714285
item may	1.0
be very	0.012658227848101266
very likely	0.024390243902439025
likely a	0.0625
a preposition	0.001226993865030675
or noun	0.0045045045045045045
but much	0.014705882352941176
much less	0.045454545454545456
likely another	0.0625
another verb	0.07692307692307693
item	2.7900228781876013e-05
When several	0.14285714285714285
several ambiguous	0.045454545454545456
ambiguous words	0.16666666666666666
words occur	0.009174311926605505
occur together	0.2
together ,	0.125
the possibilities	0.0006920415224913495
possibilities multiply	0.2
multiply .	1.0
multiply	2.7900228781876013e-05
is easy	0.0020325203252032522
to enumerate	0.0013280212483399733
enumerate every	1.0
every combination	0.3333333333333333
combination and	0.2
a relative	0.001226993865030675
relative probability	0.3333333333333333
probability to	0.14285714285714285
by multiplying	0.005714285714285714
multiplying together	1.0
together the	0.125
each choice	0.022222222222222223
choice in	0.125
turn .	0.16666666666666666
enumerate	2.7900228781876013e-05
every	8.370068634562804e-05
multiplying	2.7900228781876013e-05
The combination	0.005208333333333333
highest probability	0.3333333333333333
probability is	0.14285714285714285
then chosen	0.02857142857142857
chosen .	0.2
The European	0.005208333333333333
European group	0.3333333333333333
group developed	0.25
developed CLAWS	0.038461538461538464
CLAWS ,	0.5
a tagging	0.001226993865030675
tagging program	0.04
that did	0.0070921985815602835
did exactly	0.2
exactly this	0.3333333333333333
and achieved	0.001445086705202312
achieved accuracy	0.2
accuracy in	0.03225806451612903
the 93-95	0.0006920415224913495
93-95 %	1.0
% range	0.02564102564102564
range .	0.14285714285714285
did	0.00013950114390938006
93-95	2.7900228781876013e-05
worth remembering	0.5
remembering ,	1.0
as Eugene	0.003484320557491289
Eugene Charniak	1.0
Charniak points	1.0
points out	0.5
out in	0.14285714285714285
in Statistical	0.0018726591760299626
Statistical techniques	0.1111111111111111
language parsing	0.013513513513513514
parsing ,	0.07142857142857142
that merely	0.0035460992907801418
merely assigning	0.5
assigning the	1.0
common tag	0.04
tag to	0.0625
each known	0.022222222222222223
known word	0.038461538461538464
word and	0.016666666666666666
the tag	0.001384083044982699
tag ``	0.0625
`` proper	0.005291005291005291
proper noun	0.14285714285714285
noun ''	0.07142857142857142
all unknowns	0.023255813953488372
unknowns ,	1.0
, will	0.0011229646266142617
will approach	0.02857142857142857
approach 90	0.02857142857142857
accuracy because	0.03225806451612903
because many	0.03333333333333333
are unambiguous	0.004149377593360996
unambiguous .	0.5
remembering	2.7900228781876013e-05
Eugene	2.7900228781876013e-05
Charniak	2.7900228781876013e-05
assigning	2.7900228781876013e-05
unknowns	2.7900228781876013e-05
unambiguous	5.5800457563752025e-05
<s> CLAWS	0.0015372790161414297
CLAWS pioneered	0.25
pioneered the	0.3333333333333333
of HMM-based	0.00089126559714795
HMM-based part	0.3333333333333333
but was	0.014705882352941176
was quite	0.012987012987012988
quite expensive	0.125
expensive since	0.14285714285714285
it enumerated	0.008547008547008548
enumerated all	1.0
all possibilities	0.023255813953488372
possibilities .	0.2
HMM-based	8.370068634562804e-05
enumerated	2.7900228781876013e-05
It sometimes	0.02631578947368421
sometimes had	0.07692307692307693
had to	0.07142857142857142
to resort	0.0013280212483399733
resort to	1.0
to backup	0.0013280212483399733
backup methods	1.0
methods when	0.022727272727272728
when there	0.02857142857142857
there were	0.075
were simply	0.024390243902439025
simply too	0.08333333333333333
many -LRB-	0.019230769230769232
Corpus contains	0.0625
contains a	0.1
a case	0.001226993865030675
case with	0.058823529411764705
with 17	0.00546448087431694
17 ambiguous	1.0
a row	0.001226993865030675
row ,	1.0
are words	0.004149377593360996
words such	0.01834862385321101
`` still	0.005291005291005291
still ''	0.06666666666666667
represent as	0.1111111111111111
many as	0.019230769230769232
as 7	0.003484320557491289
7 distinct	0.14285714285714285
distinct parts	0.14285714285714285
speech -RRB-	0.02631578947368421
resort	2.7900228781876013e-05
backup	2.7900228781876013e-05
17	2.7900228781876013e-05
row	2.7900228781876013e-05
HMMs underlie	0.125
underlie the	1.0
the functioning	0.0006920415224913495
functioning of	0.3333333333333333
of stochastic	0.00089126559714795
stochastic taggers	0.125
taggers and	0.2857142857142857
in various	0.0056179775280898875
various algorithms	0.05555555555555555
algorithms one	0.02857142857142857
most widely	0.017241379310344827
used being	0.008849557522123894
being the	0.05555555555555555
the bi-directional	0.0006920415224913495
bi-directional inference	1.0
inference algorithm	0.25
underlie	2.7900228781876013e-05
functioning	8.370068634562804e-05
bi-directional	2.7900228781876013e-05
<s> Dynamic	0.0023059185242121443
Dynamic Programming	0.2
Programming methods	0.3333333333333333
methods In	0.022727272727272728
In 1987	0.009523809523809525
1987 ,	0.6666666666666666
, Steven	0.0005614823133071309
Steven DeRose	1.0
DeRose and	0.2
and Ken	0.001445086705202312
Ken Church	1.0
Church independently	0.3333333333333333
independently developed	1.0
developed dynamic	0.038461538461538464
dynamic programming	0.2
programming algorithms	0.2
solve the	0.25
same problem	0.04
problem in	0.09090909090909091
in vastly	0.0018726591760299626
vastly less	1.0
less time	0.08333333333333333
Dynamic	0.00013950114390938006
Programming	8.370068634562804e-05
Steven	2.7900228781876013e-05
Ken	2.7900228781876013e-05
Church	8.370068634562804e-05
independently	2.7900228781876013e-05
programming	0.00013950114390938006
vastly	2.7900228781876013e-05
<s> Their	0.0015372790161414297
Their methods	0.5
were similar	0.024390243902439025
the Viterbi	0.002768166089965398
Viterbi algorithm	1.0
algorithm known	0.03571428571428571
known for	0.038461538461538464
time in	0.030303030303030304
other fields	0.014285714285714285
fields .	0.16666666666666666
Their	5.5800457563752025e-05
Viterbi	0.00011160091512750405
<s> DeRose	0.0015372790161414297
DeRose used	0.2
while Church	0.05
Church used	0.3333333333333333
of triples	0.00089126559714795
triples and	0.3333333333333333
of estimating	0.00089126559714795
estimating the	1.0
the values	0.0006920415224913495
values for	0.125
for triples	0.0036101083032490976
triples that	0.3333333333333333
were rare	0.024390243902439025
rare or	0.25
or nonexistent	0.0045045045045045045
nonexistent in	1.0
Corpus -LRB-	0.0625
-LRB- actual	0.0027100271002710027
actual measurement	0.2
measurement of	0.5
of triple	0.00089126559714795
triple probabilities	1.0
probabilities would	0.09090909090909091
much larger	0.09090909090909091
estimating	2.7900228781876013e-05
nonexistent	2.7900228781876013e-05
triple	2.7900228781876013e-05
<s> Both	0.0015372790161414297
Both methods	0.3333333333333333
methods achieved	0.022727272727272728
accuracy over	0.03225806451612903
over 95	0.08333333333333333
Both	8.370068634562804e-05
DeRose 's	0.4
's 1990	0.0196078431372549
1990 dissertation	0.3333333333333333
dissertation at	0.3333333333333333
University included	0.1111111111111111
included analyses	0.125
analyses of	0.2
specific error	0.047619047619047616
error types	0.08333333333333333
types ,	0.07142857142857142
, probabilities	0.0005614823133071309
probabilities ,	0.09090909090909091
other related	0.014285714285714285
related data	0.06666666666666667
and replicated	0.001445086705202312
replicated his	1.0
his work	0.08333333333333333
work for	0.041666666666666664
for Greek	0.0036101083032490976
Greek ,	0.3333333333333333
where it	0.02857142857142857
it proved	0.008547008547008548
proved similarly	0.3333333333333333
similarly effective	1.0
effective .	0.3333333333333333
replicated	2.7900228781876013e-05
similarly	2.7900228781876013e-05
These findings	0.058823529411764705
findings were	1.0
were surprisingly	0.024390243902439025
surprisingly disruptive	0.3333333333333333
disruptive to	1.0
findings	2.7900228781876013e-05
disruptive	2.7900228781876013e-05
The accuracy	0.010416666666666666
accuracy reported	0.03225806451612903
reported was	0.2
was higher	0.012987012987012988
higher than	0.14285714285714285
the typical	0.0006920415224913495
typical accuracy	0.1111111111111111
of very	0.0017825311942959
very sophisticated	0.024390243902439025
sophisticated algorithms	0.2857142857142857
that integrated	0.0035460992907801418
integrated part	0.3333333333333333
speech choice	0.006578947368421052
choice with	0.125
with many	0.00546448087431694
many higher	0.019230769230769232
linguistic analysis	0.0625
: syntax	0.00980392156862745
, DeRose	0.0005614823133071309
's and	0.0196078431372549
and Church	0.001445086705202312
Church 's	0.3333333333333333
's methods	0.0196078431372549
methods did	0.022727272727272728
did fail	0.2
fail for	0.3333333333333333
known cases	0.038461538461538464
where semantics	0.02857142857142857
semantics is	0.07142857142857142
required ,	0.14285714285714285
but those	0.014705882352941176
those proved	0.045454545454545456
proved negligibly	0.3333333333333333
negligibly rare	1.0
negligibly	2.7900228781876013e-05
This convinced	0.015873015873015872
convinced many	1.0
many in	0.019230769230769232
that part-of-speech	0.0035460992907801418
tagging could	0.04
could usefully	0.0625
usefully be	1.0
be separated	0.004219409282700422
separated out	0.3333333333333333
out from	0.07142857142857142
other levels	0.014285714285714285
of processing	0.00089126559714795
processing ;	0.018518518518518517
this in	0.01098901098901099
turn simplified	0.16666666666666666
simplified the	0.5
theory and	0.07692307692307693
and practice	0.001445086705202312
practice of	0.5
of computerized	0.0017825311942959
computerized language	0.5
language analysis	0.006756756756756757
and encouraged	0.001445086705202312
encouraged researchers	1.0
researchers to	0.1
find ways	0.07692307692307693
ways to	0.125
to separate	0.0013280212483399733
separate out	0.1
out other	0.07142857142857142
other pieces	0.014285714285714285
pieces as	1.0
convinced	2.7900228781876013e-05
usefully	2.7900228781876013e-05
practice	5.5800457563752025e-05
computerized	5.5800457563752025e-05
encouraged	2.7900228781876013e-05
pieces	2.7900228781876013e-05
<s> Markov	0.0007686395080707148
Models are	0.3333333333333333
now the	0.07692307692307693
the standard	0.001384083044982699
standard method	0.07142857142857142
method for	0.125
for part-of-speech	0.007220216606498195
part-of-speech assignment	0.06666666666666667
assignment .	0.5
assignment	5.5800457563752025e-05
Unsupervised taggers	0.16666666666666666
taggers The	0.14285714285714285
methods already	0.022727272727272728
already discussed	0.2
discussed involve	0.14285714285714285
involve working	0.16666666666666666
working from	0.14285714285714285
a pre-existing	0.001226993865030675
pre-existing corpus	0.5
corpus to	0.03225806451612903
learn tag	0.07692307692307693
tag probabilities	0.0625
to bootstrap	0.0013280212483399733
bootstrap using	1.0
using ``	0.01694915254237288
`` unsupervised	0.005291005291005291
unsupervised ''	0.125
'' tagging	0.005154639175257732
tagging .	0.08
bootstrap	2.7900228781876013e-05
Unsupervised tagging	0.16666666666666666
tagging techniques	0.04
techniques use	0.043478260869565216
use an	0.013888888888888888
an untagged	0.007575757575757576
untagged corpus	1.0
corpus for	0.03225806451612903
their training	0.029411764705882353
the tagset	0.0006920415224913495
tagset by	1.0
by induction	0.005714285714285714
untagged	2.7900228781876013e-05
tagset	2.7900228781876013e-05
<s> That	0.0023059185242121443
That is	1.0
they observe	0.025
observe patterns	1.0
patterns in	0.2
in word	0.0018726591760299626
word use	0.016666666666666666
and derive	0.001445086705202312
derive part-of-speech	0.5
part-of-speech categories	0.06666666666666667
categories themselves	0.1111111111111111
themselves .	0.25
That	8.370068634562804e-05
observe	2.7900228781876013e-05
, statistics	0.0011229646266142617
statistics readily	0.125
readily reveal	0.3333333333333333
reveal that	1.0
the ''	0.0006920415224913495
`` a	0.005291005291005291
a ''	0.001226993865030675
`` an	0.005291005291005291
an ''	0.007575757575757576
'' occur	0.005154639175257732
occur in	0.4
in similar	0.0018726591760299626
similar contexts	0.037037037037037035
contexts ,	0.2857142857142857
while ``	0.05
`` eat	0.005291005291005291
eat ''	1.0
'' occurs	0.005154639175257732
occurs in	1.0
different ones	0.02040816326530612
ones .	0.2
reveal	2.7900228781876013e-05
eat	2.7900228781876013e-05
occurs	8.370068634562804e-05
With sufficient	0.14285714285714285
sufficient iteration	0.2
iteration ,	1.0
, similarity	0.0005614823133071309
similarity classes	0.1
words emerge	0.009174311926605505
emerge that	1.0
are remarkably	0.004149377593360996
remarkably similar	1.0
to those	0.0026560424966799467
those human	0.045454545454545456
human linguists	0.021739130434782608
linguists would	0.3333333333333333
would expect	0.018867924528301886
expect ;	0.3333333333333333
the differences	0.0006920415224913495
differences themselves	0.3333333333333333
themselves sometimes	0.25
sometimes suggest	0.07692307692307693
suggest valuable	0.3333333333333333
valuable new	0.5
new insights	0.041666666666666664
insights .	1.0
iteration	2.7900228781876013e-05
emerge	2.7900228781876013e-05
remarkably	2.7900228781876013e-05
expect	8.370068634562804e-05
valuable	5.5800457563752025e-05
insights	2.7900228781876013e-05
These two	0.058823529411764705
two categories	0.034482758620689655
categories can	0.1111111111111111
be further	0.004219409282700422
further subdivided	0.125
subdivided into	1.0
into rule-based	0.01282051282051282
rule-based ,	0.14285714285714285
, stochastic	0.0005614823133071309
and neural	0.002890173410404624
neural approaches	0.06666666666666667
subdivided	2.7900228781876013e-05
Other taggers	0.14285714285714285
and methods	0.001445086705202312
methods Some	0.022727272727272728
current major	0.14285714285714285
major algorithms	0.08333333333333333
tagging include	0.04
, Brill	0.0005614823133071309
Brill Tagger	0.3333333333333333
Tagger ,	1.0
, Constraint	0.0005614823133071309
Constraint Grammar	1.0
Grammar ,	1.0
the Baum-Welch	0.0006920415224913495
Baum-Welch algorithm	1.0
algorithm -LRB-	0.03571428571428571
the forward-backward	0.0006920415224913495
forward-backward algorithm	1.0
algorithm -RRB-	0.03571428571428571
Tagger	2.7900228781876013e-05
Constraint	2.7900228781876013e-05
Grammar	2.7900228781876013e-05
Baum-Welch	2.7900228781876013e-05
forward-backward	2.7900228781876013e-05
<s> Hidden	0.0023059185242121443
Markov model	0.4444444444444444
model and	0.03333333333333333
and visible	0.001445086705202312
visible Markov	0.3333333333333333
model taggers	0.03333333333333333
taggers can	0.14285714285714285
can both	0.0055248618784530384
both be	0.03225806451612903
be implemented	0.008438818565400843
implemented using	0.2
The Brill	0.005208333333333333
Brill tagger	0.3333333333333333
tagger is	0.1111111111111111
is unusual	0.0020325203252032522
unusual in	1.0
in that	0.003745318352059925
it learns	0.008547008547008548
learns a	1.0
of patterns	0.00089126559714795
patterns ,	0.2
then applies	0.02857142857142857
applies those	0.14285714285714285
those patterns	0.045454545454545456
patterns rather	0.2
than optimizing	0.022222222222222223
optimizing a	1.0
statistical quantity	0.030303030303030304
quantity .	0.3333333333333333
unusual	2.7900228781876013e-05
learns	2.7900228781876013e-05
optimizing	2.7900228781876013e-05
quantity	8.370068634562804e-05
Many machine	0.08333333333333333
learning methods	0.023255813953488372
have also	0.009615384615384616
of POS	0.0017825311942959
Methods such	0.25
as SVM	0.003484320557491289
SVM ,	1.0
, Maximum	0.0005614823133071309
entropy classifier	0.2
classifier ,	0.14285714285714285
, Perceptron	0.0005614823133071309
Perceptron ,	1.0
and Nearest-neighbor	0.001445086705202312
Nearest-neighbor have	1.0
have all	0.009615384615384616
all been	0.023255813953488372
been tried	0.029411764705882353
tried ,	0.3333333333333333
and most	0.001445086705202312
most can	0.017241379310344827
can achieve	0.0055248618784530384
achieve accuracy	0.5
accuracy above	0.03225806451612903
above 95	0.07692307692307693
SVM	2.7900228781876013e-05
Perceptron	2.7900228781876013e-05
Nearest-neighbor	2.7900228781876013e-05
achieve	5.5800457563752025e-05
A direct	0.02
direct comparison	0.16666666666666666
comparison of	0.3333333333333333
several methods	0.045454545454545456
methods is	0.022727272727272728
is reported	0.0020325203252032522
reported -LRB-	0.2
-LRB- with	0.008130081300813009
with references	0.00546448087431694
-RRB- at	0.0027100271002710027
at .	0.014705882352941176
This comparison	0.015873015873015872
comparison uses	0.3333333333333333
uses the	0.07142857142857142
Penn tag	0.2222222222222222
tag set	0.3125
set on	0.02564102564102564
Treebank data	0.16666666666666666
are directly	0.004149377593360996
directly comparable	0.2
comparable .	1.0
comparable	2.7900228781876013e-05
many significant	0.019230769230769232
significant taggers	0.1111111111111111
taggers are	0.14285714285714285
not included	0.008928571428571428
included -LRB-	0.125
-LRB- perhaps	0.0027100271002710027
perhaps because	0.16666666666666666
the labor	0.0006920415224913495
labor involved	0.5
involved in	0.16666666666666666
in reconfiguring	0.0018726591760299626
reconfiguring them	1.0
them for	0.05263157894736842
this particular	0.01098901098901099
particular dataset	0.07692307692307693
dataset -RRB-	1.0
reconfiguring	2.7900228781876013e-05
dataset	2.7900228781876013e-05
it should	0.008547008547008548
should not	0.05263157894736842
be assumed	0.004219409282700422
assumed that	1.0
results reported	0.047619047619047616
reported there	0.2
best that	0.1111111111111111
achieved with	0.2
given approach	0.08333333333333333
approach ;	0.02857142857142857
; nor	0.02127659574468085
nor even	1.0
been achieved	0.029411764705882353
approach .	0.05714285714285714
assumed	2.7900228781876013e-05
nor	2.7900228781876013e-05
<s> Issues	0.0015372790161414297
Issues While	0.5
While there	0.2
is broad	0.0020325203252032522
broad agreement	0.25
agreement about	0.3333333333333333
about basic	0.025
basic categories	0.07692307692307693
categories ,	0.1111111111111111
of edge	0.00089126559714795
edge cases	0.3333333333333333
cases make	0.05555555555555555
make it	0.1
to settle	0.0013280212483399733
settle on	1.0
single ``	0.07142857142857142
`` correct	0.005291005291005291
correct ''	0.06666666666666667
'' set	0.005154639175257732
of tags	0.00089126559714795
tags ,	0.3333333333333333
even in	0.07407407407407407
single language	0.07142857142857142
language such	0.006756756756756757
Issues	5.5800457563752025e-05
settle	2.7900228781876013e-05
is hard	0.0020325203252032522
to say	0.00398406374501992
say whether	0.14285714285714285
whether ``	0.07692307692307693
`` fire	0.005291005291005291
fire ''	0.5
is functioning	0.0020325203252032522
functioning as	0.6666666666666666
noun in	0.07142857142857142
the big	0.0006920415224913495
big green	0.5
green fire	1.0
fire truck	0.5
truck A	1.0
A second	0.02
second important	0.1
important example	0.0625
example is	0.012345679012345678
the use\/mention	0.0006920415224913495
use\/mention distinction	1.0
distinction ,	0.2
following example	0.13333333333333333
where ``	0.02857142857142857
`` blue	0.010582010582010581
blue ''	1.0
clearly not	0.3333333333333333
not functioning	0.008928571428571428
adjective -LRB-	0.14285714285714285
Corpus tag	0.125
set appends	0.02564102564102564
appends the	1.0
the suffix	0.0006920415224913495
suffix ''	1.0
- NC	0.0625
NC ''	1.0
such cases	0.016260162601626018
cases -RRB-	0.05555555555555555
: the	0.0196078431372549
word ``	0.016666666666666666
'' has	0.010309278350515464
has 4	0.011904761904761904
4 letters	0.2
fire	5.5800457563752025e-05
big	5.5800457563752025e-05
green	2.7900228781876013e-05
truck	2.7900228781876013e-05
use\/mention	2.7900228781876013e-05
blue	5.5800457563752025e-05
appends	2.7900228781876013e-05
suffix	2.7900228781876013e-05
NC	2.7900228781876013e-05
Words in	0.25
language other	0.006756756756756757
other than	0.014285714285714285
`` main	0.005291005291005291
main ''	0.125
'' text	0.005154639175257732
, are	0.0011229646266142617
are commonly	0.004149377593360996
commonly tagged	0.125
tagged as	0.3333333333333333
`` foreign	0.005291005291005291
foreign ''	0.5
usually in	0.09375
in addition	0.0056179775280898875
a tag	0.001226993865030675
tag for	0.0625
the role	0.001384083044982699
role the	0.25
the foreign	0.0006920415224913495
foreign word	0.5
is actually	0.0040650406504065045
actually playing	0.3333333333333333
playing in	1.0
foreign	5.5800457563752025e-05
playing	2.7900228781876013e-05
also many	0.014492753623188406
where POS	0.02857142857142857
POS categories	0.07692307692307693
`` words	0.005291005291005291
words ''	0.01834862385321101
'' do	0.005154639175257732
not map	0.008928571428571428
map one	0.5
to one	0.0026560424966799467
: David	0.00980392156862745
David 's	0.25
's gonna	0.0196078431372549
gonna do	1.0
do n't	0.07692307692307693
n't vice	0.25
vice versa	1.0
versa first-cut	1.0
first-cut can	1.0
not pre	0.008928571428571428
pre -	1.0
and post-secondary	0.001445086705202312
post-secondary look	1.0
look -LRB-	0.2
word -RRB-	0.016666666666666666
-RRB- up	0.0027100271002710027
up In	0.045454545454545456
the last	0.0020761245674740486
last example	0.2
`` look	0.005291005291005291
look ''	0.2
`` up	0.005291005291005291
up ''	0.045454545454545456
'' arguably	0.005154639175257732
arguably function	0.5
function as	0.125
single verbal	0.07142857142857142
verbal unit	1.0
unit ,	0.3333333333333333
, despite	0.0005614823133071309
despite the	0.3333333333333333
words coming	0.009174311926605505
coming between	1.0
between them	0.05128205128205128
them .	0.10526315789473684
gonna	2.7900228781876013e-05
n't	0.00011160091512750405
vice	2.7900228781876013e-05
versa	2.7900228781876013e-05
first-cut	2.7900228781876013e-05
pre	2.7900228781876013e-05
post-secondary	2.7900228781876013e-05
verbal	2.7900228781876013e-05
coming	2.7900228781876013e-05
Some tag	0.047619047619047616
tag sets	0.25
sets -LRB-	0.09090909090909091
as Penn	0.003484320557491289
Penn -RRB-	0.1111111111111111
-RRB- break	0.0027100271002710027
break hyphenated	0.5
hyphenated words	1.0
, contractions	0.0005614823133071309
contractions ,	0.5
and possessives	0.001445086705202312
possessives into	1.0
separate tokens	0.1
tokens ,	0.14285714285714285
, thus	0.0011229646266142617
thus avoiding	0.1
avoiding some	0.5
some but	0.012048192771084338
but far	0.014705882352941176
far from	0.125
from all	0.009615384615384616
all such	0.023255813953488372
such problems	0.008130081300813009
hyphenated	2.7900228781876013e-05
contractions	5.5800457563752025e-05
possessives	2.7900228781876013e-05
avoiding	5.5800457563752025e-05
is unclear	0.0020325203252032522
unclear whether	1.0
whether it	0.07692307692307693
is best	0.0020325203252032522
to treat	0.0013280212483399733
treat words	0.5
`` be	0.010582010582010581
be ''	0.008438818565400843
`` have	0.005291005291005291
have ''	0.009615384615384616
`` do	0.005291005291005291
do ''	0.038461538461538464
as categories	0.003484320557491289
categories in	0.1111111111111111
their own	0.029411764705882353
own right	0.16666666666666666
right -LRB-	0.1
or as	0.009009009009009009
as simply	0.003484320557491289
simply verbs	0.08333333333333333
verbs -LRB-	0.2
the LOB	0.0006920415224913495
LOB Corpus	1.0
Corpus and	0.125
Treebank -RRB-	0.16666666666666666
unclear	2.7900228781876013e-05
treat	5.5800457563752025e-05
LOB	5.5800457563752025e-05
has more	0.011904761904761904
more forms	0.010526315789473684
forms than	0.16666666666666666
than other	0.022222222222222223
other English	0.014285714285714285
English verbs	0.02702702702702703
and occurs	0.001445086705202312
in quite	0.0018726591760299626
different grammatical	0.02040816326530612
grammatical contexts	0.09090909090909091
, complicating	0.0005614823133071309
complicating the	1.0
issue .	0.25
complicating	2.7900228781876013e-05
popular ``	0.1111111111111111
'' for	0.005154639175257732
for POS	0.0036101083032490976
tagging for	0.04
for American	0.0036101083032490976
American English	0.2
English is	0.02702702702702703
is probably	0.0020325203252032522
probably the	0.25
set ,	0.05128205128205128
, developed	0.0005614823133071309
Treebank project	0.16666666666666666
project .	0.07692307692307693
is largely	0.0020325203252032522
largely similar	0.2
the earlier	0.0006920415224913495
earlier Brown	0.25
and LOB	0.001445086705202312
sets ,	0.09090909090909091
though much	0.1
much smaller	0.045454545454545456
smaller .	0.14285714285714285
earlier	0.00011160091512750405
, tag	0.0005614823133071309
sets from	0.09090909090909091
the Eagles	0.0006920415224913495
Eagles Guidelines	1.0
Guidelines see	0.5
see wide	0.05
wide use	0.25
include versions	0.037037037037037035
versions for	0.3333333333333333
for multiple	0.0036101083032490976
multiple languages	0.07692307692307693
Eagles	2.7900228781876013e-05
Guidelines	5.5800457563752025e-05
<s> POS	0.0007686395080707148
tagging work	0.04
of languages	0.00089126559714795
the set	0.001384083044982699
used varies	0.008849557522123894
greatly with	0.14285714285714285
with language	0.00546448087431694
<s> Tags	0.0007686395080707148
Tags usually	1.0
usually are	0.03125
are designed	0.004149377593360996
include overt	0.037037037037037035
overt morphological	1.0
morphological distinctions	0.3333333333333333
distinctions -LRB-	0.5
-LRB- this	0.0027100271002710027
this makes	0.01098901098901099
sets for	0.09090909090909091
for heavily	0.0036101083032490976
heavily inflected	1.0
inflected languages	1.0
as Greek	0.003484320557491289
Greek and	0.3333333333333333
and Latin	0.001445086705202312
Latin very	0.25
very large	0.024390243902439025
large ;	0.043478260869565216
and makes	0.001445086705202312
makes tagging	0.125
tagging words	0.04
in agglutinative	0.0018726591760299626
agglutinative languages	1.0
an Inuit	0.007575757575757576
Inuit virtually	1.0
virtually impossible	0.5
impossible .	0.5
Tags	2.7900228781876013e-05
overt	2.7900228781876013e-05
heavily	2.7900228781876013e-05
inflected	5.5800457563752025e-05
Latin	0.00011160091512750405
agglutinative	2.7900228781876013e-05
Inuit	2.7900228781876013e-05
, Petrov	0.0005614823133071309
Petrov ,	1.0
, D.	0.0005614823133071309
D. Das	0.2
Das ,	1.0
and R.	0.001445086705202312
R. McDonald	0.16666666666666666
McDonald -LRB-	1.0
`` A	0.005291005291005291
A Universal	0.02
Universal Part-of-Speech	1.0
Part-of-Speech Tagset	1.0
Tagset ''	1.0
'' http:\/\/arxiv.org\/abs\/1104.2086	0.005154639175257732
http:\/\/arxiv.org\/abs\/1104.2086 -RRB-	1.0
have proposed	0.009615384615384616
universal ''	0.3333333333333333
'' tag	0.005154639175257732
with 12	0.00546448087431694
12 categories	0.2
categories -LRB-	0.1111111111111111
, no	0.0016844469399213925
no subtypes	0.07692307692307693
subtypes of	1.0
of nouns	0.00089126559714795
, punctuation	0.0005614823133071309
punctuation ,	0.2857142857142857
etc. ;	0.045454545454545456
; no	0.02127659574468085
no distinction	0.07692307692307693
distinction of	0.2
an infinitive	0.007575757575757576
infinitive marker	1.0
marker vs.	1.0
vs. preposition	0.08333333333333333
Petrov	2.7900228781876013e-05
Das	2.7900228781876013e-05
McDonald	2.7900228781876013e-05
Universal	2.7900228781876013e-05
Part-of-Speech	2.7900228781876013e-05
Tagset	2.7900228781876013e-05
http:\/\/arxiv.org\/abs\/1104.2086	2.7900228781876013e-05
subtypes	2.7900228781876013e-05
infinitive	2.7900228781876013e-05
marker	2.7900228781876013e-05
Whether a	0.5
small set	0.1111111111111111
broad tags	0.25
larger set	0.0625
more precise	0.010526315789473684
precise ones	0.3333333333333333
is preferable	0.0020325203252032522
preferable ,	1.0
, depends	0.0005614823133071309
purpose at	0.2
at hand	0.014705882352941176
hand .	0.07142857142857142
preferable	2.7900228781876013e-05
Automatic tagging	0.1111111111111111
easier on	0.125
on smaller	0.0047169811320754715
smaller tag-sets	0.14285714285714285
tag-sets .	1.0
tag-sets	2.7900228781876013e-05
A different	0.04
different issue	0.02040816326530612
issue is	0.125
cases are	0.05555555555555555
in fact	0.0018726591760299626
fact ambiguous	0.09090909090909091
<s> Beatrice	0.0007686395080707148
Beatrice Santorini	1.0
Santorini gives	1.0
gives examples	0.5
examples in	0.041666666666666664
`` Part-of-speech	0.005291005291005291
Part-of-speech Tagging	0.5
Tagging Guidelines	1.0
Guidelines for	0.5
Treebank Project	0.16666666666666666
Project ,	1.0
, ''	0.0016844469399213925
-LRB- 3rd	0.0027100271002710027
3rd rev	1.0
rev ,	1.0
, June	0.0005614823133071309
June 1990	1.0
including the	0.07142857142857142
following -LRB-	0.06666666666666667
-LRB- p.	0.0027100271002710027
p. 32	1.0
32 -RRB-	1.0
-RRB- case	0.0027100271002710027
case in	0.058823529411764705
which entertaining	0.007246376811594203
entertaining can	0.5
can function	0.0055248618784530384
function either	0.125
is no	0.0020325203252032522
no evident	0.07692307692307693
evident way	0.5
decide :	0.25
The Duchess	0.005208333333333333
Duchess was	1.0
was entertaining	0.012987012987012988
entertaining last	0.5
last night	0.2
night .	1.0
Beatrice	2.7900228781876013e-05
Santorini	2.7900228781876013e-05
gives	5.5800457563752025e-05
Tagging	2.7900228781876013e-05
Project	2.7900228781876013e-05
3rd	2.7900228781876013e-05
rev	2.7900228781876013e-05
June	2.7900228781876013e-05
p.	2.7900228781876013e-05
32	2.7900228781876013e-05
entertaining	5.5800457563752025e-05
evident	5.5800457563752025e-05
Duchess	2.7900228781876013e-05
night	2.7900228781876013e-05
In computer	0.009523809523809525
science and	0.1
, parsing	0.0016844469399213925
or ,	0.0045045045045045045
more formally	0.010526315789473684
formally ,	0.5
syntactic analysis	0.15384615384615385
of analyzing	0.00089126559714795
analyzing a	0.2
a sequence	0.007361963190184049
sequence of	0.875
tokens -LRB-	0.14285714285714285
, words	0.0011229646266142617
its grammatical	0.02857142857142857
grammatical structure	0.09090909090909091
structure with	0.08333333333333333
given -LRB-	0.041666666666666664
less -RRB-	0.08333333333333333
-RRB- formal	0.0027100271002710027
formal grammar	0.2222222222222222
formally	5.5800457563752025e-05
sequence	0.0002232018302550081
Parsing can	0.2
linguistic term	0.0625
term ,	0.05555555555555555
instance when	0.07142857142857142
when discussing	0.05714285714285714
discussing how	0.5
how phrases	0.034482758620689655
phrases are	0.0625
are divided	0.004149377593360996
divided up	0.3333333333333333
in garden	0.0018726591760299626
garden path	1.0
path sentences	0.5
discussing	5.5800457563752025e-05
garden	2.7900228781876013e-05
path	5.5800457563752025e-05
Parsing is	0.4
also an	0.014492753623188406
an earlier	0.007575757575757576
earlier term	0.25
the diagramming	0.001384083044982699
diagramming of	1.0
still used	0.06666666666666667
of inflected	0.00089126559714795
the Romance	0.0006920415224913495
Romance languages	1.0
languages or	0.02
or Latin	0.0045045045045045045
Latin .	0.25
diagramming	5.5800457563752025e-05
Romance	2.7900228781876013e-05
The term	0.020833333333333332
term parsing	0.05555555555555555
parsing comes	0.03571428571428571
from Latin	0.009615384615384616
Latin pars	0.25
pars -LRB-	1.0
-LRB- rtinis	0.0027100271002710027
rtinis -RRB-	1.0
, meaning	0.0005614823133071309
meaning part	0.043478260869565216
part -LRB-	0.037037037037037035
-LRB- of	0.005420054200542005
pars	2.7900228781876013e-05
rtinis	2.7900228781876013e-05
a common	0.00245398773006135
common term	0.04
term used	0.1111111111111111
in psycholinguistics	0.0018726591760299626
psycholinguistics when	0.5
describing language	0.25
language comprehension	0.006756756756756757
parsing refers	0.03571428571428571
refers to	1.0
the way	0.002768166089965398
human beings	0.021739130434782608
beings ,	1.0
, rather	0.0011229646266142617
than computers	0.022222222222222223
computers ,	0.2222222222222222
, analyze	0.0005614823133071309
analyze a	0.25
or phrase	0.0045045045045045045
phrase -LRB-	0.1
-LRB- in	0.005420054200542005
in spoken	0.003745318352059925
spoken language	0.14285714285714285
text -RRB-	0.006289308176100629
-RRB- ``	0.0027100271002710027
of grammatical	0.00089126559714795
grammatical constituents	0.09090909090909091
constituents ,	0.5
, identifying	0.0016844469399213925
the parts	0.0006920415224913495
syntactic relations	0.07692307692307693
etc. ''	0.045454545454545456
'' This	0.005154639175257732
This term	0.015873015873015872
term is	0.05555555555555555
common when	0.04
discussing what	0.5
what linguistic	0.03125
linguistic cues	0.0625
cues help	1.0
help speakers	0.1111111111111111
speakers to	0.25
parse garden-path	0.1111111111111111
garden-path sentences	1.0
refers	0.00013950114390938006
beings	2.7900228781876013e-05
constituents	5.5800457563752025e-05
cues	2.7900228781876013e-05
garden-path	2.7900228781876013e-05
The parser	0.005208333333333333
parser often	0.0625
often uses	0.022727272727272728
separate lexical	0.1
lexical analyser	0.07692307692307693
analyser to	1.0
create tokens	0.058823529411764705
tokens from	0.14285714285714285
the sequence	0.0006920415224913495
input characters	0.024390243902439025
analyser	2.7900228781876013e-05
<s> Parsers	0.0015372790161414297
Parsers may	0.5
programmed by	0.5
hand or	0.14285714285714285
or may	0.009009009009009009
be -LRB-	0.004219409282700422
-LRB- semi	0.0027100271002710027
semi -	1.0
- -RRB-	0.0625
-RRB- automatically	0.0027100271002710027
generated -LRB-	0.06666666666666667
some programming	0.012048192771084338
programming languages	0.6
-RRB- by	0.0027100271002710027
tool .	0.5
Parsers	5.5800457563752025e-05
semi	2.7900228781876013e-05
Human languages	0.2
languages See	0.02
: Category	0.00980392156862745
Category :	0.5
: Natural	0.00980392156862745
parsing In	0.03571428571428571
some machine	0.012048192771084338
and natural	0.005780346820809248
human languages	0.021739130434782608
languages are	0.02
are parsed	0.004149377593360996
parsed by	0.75
parsed	0.00011160091512750405
Human sentences	0.2
easily parsed	0.1111111111111111
by programs	0.005714285714285714
programs ,	0.18181818181818182
as there	0.003484320557491289
is substantial	0.0020325203252032522
substantial ambiguity	0.2
ambiguity in	0.125
whose usage	0.3333333333333333
usage is	1.0
convey meaning	0.3333333333333333
meaning -LRB-	0.043478260869565216
or semantics	0.0045045045045045045
semantics -RRB-	0.07142857142857142
-RRB- amongst	0.0027100271002710027
amongst a	1.0
a potentially	0.001226993865030675
potentially unlimited	0.3333333333333333
unlimited range	1.0
of possibilities	0.00089126559714795
possibilities but	0.2
but only	0.014705882352941176
are germane	0.004149377593360996
germane to	1.0
particular case	0.07692307692307693
usage	2.7900228781876013e-05
amongst	2.7900228781876013e-05
unlimited	2.7900228781876013e-05
germane	2.7900228781876013e-05
So an	0.3333333333333333
an utterance	0.015151515151515152
utterance ``	0.3333333333333333
`` Man	0.010582010582010581
Man bites	0.5
bites dog	0.3333333333333333
dog ''	0.3333333333333333
'' versus	0.005154639175257732
versus ``	1.0
`` Dog	0.005291005291005291
Dog bites	1.0
bites man	0.3333333333333333
man ''	1.0
is definite	0.0020325203252032522
definite on	1.0
one detail	0.015384615384615385
detail but	0.5
but in	0.029411764705882353
language might	0.006756756756756757
might appear	0.038461538461538464
appear as	0.0625
Man dog	0.5
dog bites	0.3333333333333333
bites ''	0.3333333333333333
a reliance	0.001226993865030675
reliance on	1.0
the larger	0.0006920415224913495
larger context	0.0625
context to	0.030303030303030304
between those	0.02564102564102564
those two	0.045454545454545456
two possibilities	0.034482758620689655
possibilities ,	0.2
if indeed	0.03571428571428571
indeed that	0.3333333333333333
that difference	0.0035460992907801418
difference was	0.25
was of	0.012987012987012988
of concern	0.00089126559714795
concern .	1.0
utterance	8.370068634562804e-05
Man	5.5800457563752025e-05
bites	8.370068634562804e-05
versus	2.7900228781876013e-05
Dog	2.7900228781876013e-05
man	2.7900228781876013e-05
definite	2.7900228781876013e-05
detail	5.5800457563752025e-05
reliance	2.7900228781876013e-05
indeed	8.370068634562804e-05
concern	2.7900228781876013e-05
is difficult	0.008130081300813009
to prepare	0.0013280212483399733
prepare formal	1.0
formal rules	0.1111111111111111
describe informal	0.16666666666666666
informal behavior	0.5
behavior even	0.5
even though	0.07407407407407407
though it	0.2
is clear	0.0020325203252032522
clear that	0.25
some rules	0.012048192771084338
rules are	0.023255813953488372
are being	0.008298755186721992
being followed	0.05555555555555555
followed .	0.25
prepare	2.7900228781876013e-05
behavior	5.5800457563752025e-05
In order	0.01904761904761905
parse natural	0.1111111111111111
language data	0.006756756756756757
researchers must	0.1
must first	0.07142857142857142
first agree	0.030303030303030304
agree on	0.3333333333333333
grammar to	0.02702702702702703
The choice	0.005208333333333333
choice of	0.25
syntax is	0.09090909090909091
is affected	0.0020325203252032522
affected by	1.0
by both	0.005714285714285714
both linguistic	0.03225806451612903
linguistic and	0.0625
and computational	0.001445086705202312
computational concerns	0.1
concerns ;	0.5
; for	0.0425531914893617
instance some	0.07142857142857142
some parsing	0.012048192771084338
parsing systems	0.03571428571428571
systems use	0.05357142857142857
use lexical	0.027777777777777776
lexical functional	0.07692307692307693
functional grammar	0.5
parsing for	0.03571428571428571
for grammars	0.0036101083032490976
grammars of	0.07142857142857142
type is	0.14285714285714285
be NP-complete	0.004219409282700422
NP-complete .	1.0
affected	2.7900228781876013e-05
NP-complete	2.7900228781876013e-05
<s> Head-driven	0.0007686395080707148
Head-driven phrase	1.0
structure grammar	0.08333333333333333
grammar is	0.05405405405405406
another linguistic	0.07692307692307693
linguistic formalism	0.0625
formalism which	1.0
been popular	0.014705882352941176
popular in	0.1111111111111111
parsing community	0.03571428571428571
community ,	1.0
but other	0.014705882352941176
other research	0.014285714285714285
research efforts	0.023809523809523808
efforts have	0.5714285714285714
have focused	0.019230769230769232
on less	0.0047169811320754715
less complex	0.08333333333333333
complex formalisms	0.041666666666666664
formalisms such	0.5
the one	0.0006920415224913495
one used	0.015384615384615385
Head-driven	2.7900228781876013e-05
formalism	2.7900228781876013e-05
community	2.7900228781876013e-05
formalisms	5.5800457563752025e-05
Shallow parsing	0.5
parsing aims	0.03571428571428571
aims to	0.6666666666666666
find only	0.07692307692307693
the boundaries	0.0020761245674740486
boundaries of	0.09090909090909091
of major	0.00089126559714795
major constituents	0.08333333333333333
constituents such	0.5
as noun	0.003484320557491289
noun phrases	0.07142857142857142
Another popular	0.07692307692307693
popular strategy	0.1111111111111111
strategy for	0.2
for avoiding	0.0036101083032490976
avoiding linguistic	0.5
linguistic controversy	0.0625
controversy is	1.0
is dependency	0.0020325203252032522
dependency grammar	0.2
grammar parsing	0.02702702702702703
parsing .	0.10714285714285714
controversy	2.7900228781876013e-05
<s> Most	0.0015372790161414297
Most modern	0.5
modern parsers	0.2
parsers are	0.15384615384615385
least partly	0.2
partly statistical	1.0
statistical ;	0.030303030303030304
; that	0.02127659574468085
they rely	0.025
data which	0.012987012987012988
has already	0.011904761904761904
been annotated	0.014705882352941176
annotated -LRB-	0.5
-LRB- parsed	0.0027100271002710027
hand -RRB-	0.07142857142857142
Most	5.5800457563752025e-05
partly	2.7900228781876013e-05
approach allows	0.02857142857142857
to gather	0.0013280212483399733
gather information	1.0
the frequency	0.0006920415224913495
frequency with	0.5
with which	0.00546448087431694
which various	0.007246376811594203
various constructions	0.05555555555555555
constructions occur	1.0
in specific	0.003745318352059925
specific contexts	0.047619047619047616
gather	2.7900228781876013e-05
frequency	5.5800457563752025e-05
constructions	2.7900228781876013e-05
-LRB- See	0.01084010840108401
See machine	0.16666666666666666
Approaches which	0.3333333333333333
used include	0.008849557522123894
include straightforward	0.037037037037037035
straightforward PCFGs	1.0
PCFGs -LRB-	1.0
-LRB- probabilistic	0.0027100271002710027
probabilistic context-free	0.14285714285714285
context-free grammars	0.36363636363636365
, maximum	0.0005614823133071309
entropy ,	0.2
neural nets	0.06666666666666667
nets .	1.0
straightforward	2.7900228781876013e-05
PCFGs	2.7900228781876013e-05
context-free	0.00030690251660063614
nets	2.7900228781876013e-05
Most of	0.5
successful systems	0.1111111111111111
lexical statistics	0.07692307692307693
statistics -LRB-	0.125
-LRB- that	0.01084010840108401
they consider	0.025
the identities	0.0006920415224913495
identities of	1.0
words involved	0.009174311926605505
involved ,	0.16666666666666666
as their	0.006968641114982578
their part	0.029411764705882353
identities	2.7900228781876013e-05
However such	0.02702702702702703
such systems	0.008130081300813009
are vulnerable	0.004149377593360996
vulnerable to	1.0
to overfitting	0.0013280212483399733
overfitting and	0.5
require some	0.045454545454545456
of smoothing	0.00089126559714795
smoothing to	1.0
vulnerable	2.7900228781876013e-05
smoothing	2.7900228781876013e-05
-RRB- Parsing	0.0027100271002710027
Parsing algorithms	0.2
language can	0.006756756756756757
grammar having	0.02702702702702703
having `	0.2
` nice	0.0625
nice '	0.25
' properties	0.05263157894736842
properties as	0.25
as with	0.006968641114982578
with manually	0.00546448087431694
manually designed	0.25
designed grammars	0.14285714285714285
grammars for	0.07142857142857142
for programming	0.0036101083032490976
mentioned earlier	0.3333333333333333
earlier some	0.25
some grammar	0.012048192771084338
grammar formalisms	0.02702702702702703
formalisms are	0.5
parse computationally	0.1111111111111111
computationally ;	0.5
; in	0.02127659574468085
even if	0.1111111111111111
desired structure	0.2
structure is	0.08333333333333333
not context-free	0.008928571428571428
context-free ,	0.09090909090909091
of context-free	0.00089126559714795
context-free approximation	0.09090909090909091
first pass	0.030303030303030304
pass .	1.0
computationally	5.5800457563752025e-05
pass	2.7900228781876013e-05
<s> Algorithms	0.0015372790161414297
Algorithms which	0.5
which use	0.007246376811594203
use context-free	0.013888888888888888
grammars often	0.07142857142857142
often rely	0.022727272727272728
some variant	0.012048192771084338
variant of	1.0
the CKY	0.0006920415224913495
CKY algorithm	1.0
usually with	0.0625
some heuristic	0.012048192771084338
heuristic to	0.3333333333333333
to prune	0.0013280212483399733
prune away	1.0
away unlikely	0.5
unlikely analyses	1.0
analyses to	0.2
to save	0.0013280212483399733
save time	1.0
Algorithms	5.5800457563752025e-05
variant	2.7900228781876013e-05
CKY	2.7900228781876013e-05
prune	2.7900228781876013e-05
away	5.5800457563752025e-05
unlikely	2.7900228781876013e-05
save	2.7900228781876013e-05
See chart	0.16666666666666666
chart parsing	1.0
chart	2.7900228781876013e-05
However some	0.02702702702702703
systems trade	0.008928571428571428
trade speed	0.5
speed for	0.14285714285714285
for accuracy	0.0036101083032490976
accuracy using	0.03225806451612903
using ,	0.01694915254237288
, linear-time	0.0005614823133071309
linear-time versions	1.0
versions of	0.3333333333333333
the shift-reduce	0.0006920415224913495
shift-reduce algorithm	1.0
linear-time	2.7900228781876013e-05
shift-reduce	2.7900228781876013e-05
A somewhat	0.02
somewhat recent	0.5
recent development	0.125
development has	0.08333333333333333
been parse	0.014705882352941176
parse reranking	0.1111111111111111
reranking in	1.0
parser proposes	0.0625
proposes some	1.0
some large	0.012048192771084338
of analyses	0.00089126559714795
analyses ,	0.2
system selects	0.010752688172043012
selects the	0.5
best option	0.05555555555555555
option .	1.0
reranking	2.7900228781876013e-05
proposes	2.7900228781876013e-05
option	2.7900228781876013e-05
<s> Programming	0.0015372790161414297
Programming languages	0.6666666666666666
languages The	0.02
parser is	0.1875
is as	0.0020325203252032522
compiler or	0.3333333333333333
or interpreter	0.009009009009009009
interpreter .	0.5
interpreter	5.5800457563752025e-05
This parses	0.015873015873015872
parses the	0.5
source code	0.041666666666666664
code of	0.14285714285714285
computer programming	0.022727272727272728
programming language	0.2
create some	0.058823529411764705
of internal	0.00089126559714795
languages tend	0.02
tend to	1.0
be specified	0.004219409282700422
specified in	1.0
a context-free	0.0036809815950920245
context-free grammar	0.45454545454545453
grammar because	0.02702702702702703
because fast	0.03333333333333333
fast and	1.0
and efficient	0.002890173410404624
efficient parsers	0.3333333333333333
parsers can	0.07692307692307693
be written	0.004219409282700422
written for	0.038461538461538464
tend	5.5800457563752025e-05
specified	2.7900228781876013e-05
fast	2.7900228781876013e-05
Parsers are	0.5
are written	0.004149377593360996
or generated	0.0045045045045045045
generated by	0.06666666666666667
by parser	0.005714285714285714
parser generators	0.0625
generators .	0.5
<s> Context-free	0.0007686395080707148
Context-free grammars	1.0
grammars are	0.07142857142857142
are limited	0.004149377593360996
limited in	0.1
extent to	0.25
which they	0.014492753623188406
express all	0.2
the requirements	0.0006920415224913495
requirements of	0.5
Context-free	2.7900228781876013e-05
<s> Informally	0.0007686395080707148
Informally ,	1.0
the reason	0.0006920415224913495
reason is	0.25
the memory	0.0006920415224913495
memory of	0.5
is limited	0.0020325203252032522
limited .	0.2
Informally	2.7900228781876013e-05
reason	0.00011160091512750405
grammar can	0.02702702702702703
not remember	0.008928571428571428
remember the	1.0
the presence	0.0006920415224913495
presence of	1.0
a construct	0.001226993865030675
construct over	0.3333333333333333
over an	0.08333333333333333
an arbitrarily	0.007575757575757576
arbitrarily long	1.0
long input	0.5
input ;	0.024390243902439025
language in	0.006756756756756757
which ,	0.007246376811594203
a name	0.00245398773006135
name must	0.2
be declared	0.004219409282700422
declared before	0.5
before it	0.16666666666666666
it may	0.017094017094017096
be referenced	0.004219409282700422
referenced .	1.0
remember	2.7900228781876013e-05
presence	2.7900228781876013e-05
arbitrarily	2.7900228781876013e-05
referenced	2.7900228781876013e-05
More powerful	0.1111111111111111
powerful grammars	1.0
grammars that	0.07142857142857142
express this	0.2
this constraint	0.01098901098901099
constraint ,	1.0
be parsed	0.004219409282700422
parsed efficiently	0.25
efficiently .	1.0
powerful	2.7900228781876013e-05
constraint	2.7900228781876013e-05
efficiently	2.7900228781876013e-05
common strategy	0.04
a relaxed	0.001226993865030675
relaxed parser	1.0
parser for	0.0625
grammar which	0.05405405405405406
which accepts	0.007246376811594203
accepts a	0.5
a superset	0.001226993865030675
superset of	1.0
desired language	0.2
language constructs	0.006756756756756757
constructs -LRB-	0.3333333333333333
it accepts	0.008547008547008548
accepts some	0.5
some invalid	0.012048192771084338
invalid constructs	1.0
constructs -RRB-	0.3333333333333333
; later	0.02127659574468085
the unwanted	0.0006920415224913495
unwanted constructs	1.0
constructs can	0.3333333333333333
filtered out	0.3333333333333333
out .	0.07142857142857142
relaxed	2.7900228781876013e-05
accepts	5.5800457563752025e-05
superset	2.7900228781876013e-05
constructs	8.370068634562804e-05
invalid	2.7900228781876013e-05
unwanted	2.7900228781876013e-05
of process	0.00089126559714795
process Flow	0.027777777777777776
Flow of	1.0
typical parser	0.1111111111111111
parser The	0.125
example demonstrates	0.012345679012345678
demonstrates the	1.0
the common	0.0006920415224913495
common case	0.04
of parsing	0.0017825311942959
parsing a	0.03571428571428571
computer language	0.022727272727272728
language with	0.006756756756756757
with two	0.01092896174863388
two levels	0.034482758620689655
of grammar	0.0017825311942959
grammar :	0.02702702702702703
: lexical	0.00980392156862745
lexical and	0.15384615384615385
and syntactic	0.002890173410404624
syntactic .	0.07692307692307693
Flow	2.7900228781876013e-05
demonstrates	2.7900228781876013e-05
first stage	0.030303030303030304
stage is	0.4
the token	0.0006920415224913495
token generation	0.25
generation ,	0.1111111111111111
lexical analysis	0.07692307692307693
by which	0.005714285714285714
input character	0.024390243902439025
character stream	0.045454545454545456
stream is	0.5
is split	0.0040650406504065045
split into	0.5
into meaningful	0.02564102564102564
meaningful symbols	0.125
symbols defined	0.3333333333333333
defined by	0.16666666666666666
a grammar	0.00245398773006135
of regular	0.00089126559714795
regular expressions	1.0
expressions .	0.6666666666666666
token	0.00011160091512750405
split	0.00011160091512750405
regular	2.7900228781876013e-05
a calculator	0.00245398773006135
calculator program	0.5
program would	0.045454545454545456
at an	0.014705882352941176
input such	0.024390243902439025
`` 12	0.010582010582010581
12 \*	0.4
\* -LRB-	0.25
-LRB- 3	0.005420054200542005
3 +4	0.2
+4 -RRB-	1.0
-RRB- ^	0.0027100271002710027
^ 2	0.3333333333333333
2 ''	0.2
and split	0.001445086705202312
split it	0.25
the tokens	0.001384083044982699
tokens 12	0.14285714285714285
12 ,	0.2
, \*	0.0005614823133071309
\* ,	0.5
-LRB- ,	0.0027100271002710027
, 3	0.0005614823133071309
3 ,	0.2
, +	0.0011229646266142617
+ ,	0.3333333333333333
, 4	0.0005614823133071309
4 ,	0.2
, -RRB-	0.0005614823133071309
, ^	0.0011229646266142617
^ ,	0.6666666666666666
, 2	0.0005614823133071309
2 ,	0.2
meaningful symbol	0.125
symbol in	0.25
an arithmetic	0.007575757575757576
arithmetic expression	1.0
expression .	0.2
calculator	5.5800457563752025e-05
\*	0.00011160091512750405
3	0.00013950114390938006
+4	2.7900228781876013e-05
^	8.370068634562804e-05
arithmetic	2.7900228781876013e-05
The lexer	0.005208333333333333
lexer would	1.0
would contain	0.018867924528301886
contain rules	0.08333333333333333
to tell	0.0013280212483399733
tell it	0.3333333333333333
it that	0.008547008547008548
the characters	0.0006920415224913495
characters \*	0.0625
and -RRB-	0.001445086705202312
-RRB- mark	0.0027100271002710027
mark the	0.3333333333333333
new token	0.041666666666666664
token ,	0.25
so meaningless	0.03333333333333333
meaningless tokens	1.0
tokens like	0.14285714285714285
like ``	0.10714285714285714
\* ''	0.25
or ''	0.0045045045045045045
3 ''	0.2
'' will	0.005154639175257732
be generated	0.004219409282700422
lexer	2.7900228781876013e-05
meaningless	2.7900228781876013e-05
The next	0.005208333333333333
next stage	0.2857142857142857
is parsing	0.0020325203252032522
parsing or	0.07142857142857142
or syntactic	0.0045045045045045045
is checking	0.0020325203252032522
checking that	1.0
tokens form	0.14285714285714285
form an	0.05
an allowable	0.007575757575757576
allowable expression	0.5
checking	2.7900228781876013e-05
usually done	0.0625
with reference	0.00546448087431694
which recursively	0.007246376811594203
recursively defines	0.5
defines components	0.5
components that	0.2
up an	0.045454545454545456
an expression	0.007575757575757576
order in	0.07142857142857142
they must	0.025
must appear	0.07142857142857142
appear .	0.0625
not all	0.017857142857142856
all rules	0.023255813953488372
rules defining	0.023255813953488372
defining programming	1.0
expressed by	0.16666666666666666
by context-free	0.005714285714285714
grammars alone	0.07142857142857142
alone ,	0.25
example type	0.012345679012345678
type validity	0.07142857142857142
validity and	1.0
and proper	0.001445086705202312
proper declaration	0.14285714285714285
declaration of	1.0
of identifiers	0.00089126559714795
identifiers .	1.0
defining	2.7900228781876013e-05
validity	2.7900228781876013e-05
declaration	2.7900228781876013e-05
identifiers	2.7900228781876013e-05
These rules	0.058823529411764705
be formally	0.004219409282700422
formally expressed	0.5
expressed with	0.16666666666666666
with attribute	0.00546448087431694
attribute grammars	0.5
attribute	5.5800457563752025e-05
The final	0.005208333333333333
final phase	0.1111111111111111
phase is	1.0
is semantic	0.0020325203252032522
semantic parsing	0.047619047619047616
or analysis	0.0045045045045045045
working out	0.14285714285714285
out the	0.21428571428571427
the implications	0.0006920415224913495
implications of	1.0
the expression	0.001384083044982699
expression just	0.1
just validated	0.1111111111111111
validated and	1.0
and taking	0.001445086705202312
taking the	0.6
appropriate action	0.25
action .	0.2
phase	2.7900228781876013e-05
implications	2.7900228781876013e-05
validated	2.7900228781876013e-05
calculator or	0.5
interpreter ,	0.5
the action	0.0006920415224913495
action is	0.2
expression or	0.1
or program	0.0045045045045045045
program ,	0.045454545454545456
compiler ,	0.3333333333333333
, would	0.0016844469399213925
would generate	0.018867924528301886
generate some	0.05555555555555555
of code	0.00089126559714795
<s> Attribute	0.0007686395080707148
Attribute grammars	1.0
grammars can	0.07142857142857142
define these	0.5
these actions	0.023809523809523808
actions .	1.0
Attribute	2.7900228781876013e-05
actions	5.5800457563752025e-05
of parser	0.0017825311942959
essentially to	0.125
if and	0.03571428571428571
how the	0.034482758620689655
input can	0.024390243902439025
start symbol	0.2857142857142857
symbol of	0.25
This can	0.015873015873015872
in essentially	0.0018726591760299626
essentially two	0.125
two ways	0.034482758620689655
: Top-down	0.00980392156862745
Top-down parsing	1.0
parsing -	0.07142857142857142
- Top-down	0.0625
parsing can	0.07142857142857142
find left-most	0.07692307692307693
left-most derivations	0.5
derivations of	1.0
an input-stream	0.007575757575757576
input-stream by	1.0
by searching	0.005714285714285714
searching for	0.3333333333333333
for parse	0.0036101083032490976
parse trees	0.2222222222222222
trees using	0.16666666666666666
a top-down	0.001226993865030675
top-down expansion	0.25
expansion of	0.3333333333333333
the given	0.001384083044982699
given formal	0.041666666666666664
Top-down	5.5800457563752025e-05
left-most	5.5800457563752025e-05
derivations	5.5800457563752025e-05
input-stream	2.7900228781876013e-05
top-down	0.00011160091512750405
<s> Tokens	0.0007686395080707148
Tokens are	1.0
are consumed	0.004149377593360996
consumed from	1.0
from left	0.009615384615384616
left to	0.16666666666666666
to right	0.0013280212483399733
right .	0.3
Tokens	2.7900228781876013e-05
consumed	2.7900228781876013e-05
<s> Inclusive	0.0007686395080707148
Inclusive choice	1.0
to accommodate	0.0026560424966799467
accommodate ambiguity	0.4
ambiguity by	0.125
by expanding	0.005714285714285714
expanding all	1.0
all alternative	0.023255813953488372
alternative right-hand-sides	0.3333333333333333
right-hand-sides of	1.0
Inclusive	2.7900228781876013e-05
accommodate	0.00013950114390938006
expanding	2.7900228781876013e-05
right-hand-sides	2.7900228781876013e-05
<s> Bottom-up	0.0007686395080707148
Bottom-up parsing	1.0
- A	0.0625
A parser	0.02
parser can	0.0625
can start	0.0055248618784530384
start with	0.14285714285714285
and attempt	0.001445086705202312
to rewrite	0.0013280212483399733
rewrite it	1.0
Bottom-up	2.7900228781876013e-05
rewrite	2.7900228781876013e-05
<s> Intuitively	0.0007686395080707148
Intuitively ,	1.0
parser attempts	0.0625
attempts to	0.5
to locate	0.0013280212483399733
locate the	1.0
most basic	0.017241379310344827
basic elements	0.07692307692307693
elements ,	0.25
then the	0.05714285714285714
the elements	0.0006920415224913495
elements containing	0.25
containing these	0.125
Intuitively	2.7900228781876013e-05
locate	2.7900228781876013e-05
elements	0.00011160091512750405
<s> LR	0.0007686395080707148
LR parsers	1.0
of bottom-up	0.00089126559714795
bottom-up parsers	1.0
parsers .	0.07692307692307693
LR	5.5800457563752025e-05
bottom-up	2.7900228781876013e-05
Another term	0.07692307692307693
is Shift-Reduce	0.0020325203252032522
Shift-Reduce parsing	1.0
Shift-Reduce	2.7900228781876013e-05
<s> LL	0.0015372790161414297
LL parsers	1.0
parsers and	0.07692307692307693
and recursive-descent	0.001445086705202312
recursive-descent parser	1.0
parser are	0.0625
of top-down	0.0017825311942959
top-down parsers	0.25
parsers which	0.07692307692307693
not accommodate	0.017857142857142856
accommodate left	0.2
left recursive	0.16666666666666666
recursive productions	1.0
productions .	1.0
LL	5.5800457563752025e-05
recursive-descent	2.7900228781876013e-05
recursive	2.7900228781876013e-05
productions	2.7900228781876013e-05
Although it	0.125
been believed	0.014705882352941176
believed that	1.0
that simple	0.0035460992907801418
simple implementations	0.038461538461538464
top-down parsing	0.5
accommodate direct	0.2
direct and	0.16666666666666666
and indirect	0.001445086705202312
indirect left-recursion	1.0
left-recursion and	1.0
and may	0.002890173410404624
may require	0.038461538461538464
require exponential	0.045454545454545456
exponential time	0.5
and space	0.001445086705202312
space complexity	0.2
complexity while	0.08333333333333333
while parsing	0.05
parsing ambiguous	0.03571428571428571
ambiguous context-free	0.08333333333333333
more sophisticated	0.021052631578947368
for top-down	0.0036101083032490976
parsing have	0.03571428571428571
by Frost	0.005714285714285714
Frost ,	1.0
, Hafiz	0.0005614823133071309
Hafiz ,	1.0
and Callaghan	0.001445086705202312
Callaghan which	1.0
which accommodate	0.007246376811594203
ambiguity and	0.125
and left	0.001445086705202312
left recursion	0.16666666666666666
recursion in	1.0
in polynomial	0.0018726591760299626
polynomial time	1.0
and which	0.001445086705202312
generate polynomial-size	0.05555555555555555
polynomial-size representations	1.0
representations of	0.25
the potentially	0.0006920415224913495
potentially exponential	0.3333333333333333
exponential number	0.5
of parse	0.00089126559714795
believed	2.7900228781876013e-05
indirect	2.7900228781876013e-05
left-recursion	2.7900228781876013e-05
exponential	5.5800457563752025e-05
space	0.00013950114390938006
Frost	2.7900228781876013e-05
Hafiz	2.7900228781876013e-05
Callaghan	2.7900228781876013e-05
recursion	2.7900228781876013e-05
polynomial	2.7900228781876013e-05
polynomial-size	2.7900228781876013e-05
Their algorithm	0.5
is able	0.0020325203252032522
produce both	0.045454545454545456
both left-most	0.03225806451612903
left-most and	0.5
and right-most	0.001445086705202312
right-most derivations	1.0
input with	0.024390243902439025
given CFG	0.041666666666666664
CFG -LRB-	1.0
-LRB- context-free	0.0027100271002710027
right-most	2.7900228781876013e-05
CFG	2.7900228781876013e-05
distinction with	0.2
to parsers	0.0013280212483399733
parsers is	0.07692307692307693
is whether	0.0020325203252032522
parser generates	0.0625
a leftmost	0.00245398773006135
leftmost derivation	1.0
derivation or	0.25
a rightmost	0.00245398773006135
rightmost derivation	1.0
derivation -LRB-	0.5
see context-free	0.05
leftmost	5.5800457563752025e-05
derivation	0.00011160091512750405
rightmost	5.5800457563752025e-05
parsers will	0.15384615384615385
derivation and	0.25
and LR	0.001445086705202312
although usually	0.16666666666666666
in reverse	0.0018726591760299626
reverse -RRB-	0.5
In information	0.009523809523809525
retrieval and	0.2857142857142857
, question	0.0011229646266142617
question answering	0.21428571428571427
answering -LRB-	0.08333333333333333
-LRB- QA	0.0027100271002710027
QA -RRB-	0.047619047619047616
automatically answering	0.047619047619047616
answering a	0.08333333333333333
a question	0.008588957055214725
question posed	0.047619047619047616
posed in	0.6666666666666666
QA	0.0005859048044193963
posed	8.370068634562804e-05
To find	0.1111111111111111
the answer	0.009688581314878892
answer to	0.16666666666666666
a QA	0.0049079754601227
QA computer	0.047619047619047616
program may	0.045454545454545456
may use	0.019230769230769232
use either	0.013888888888888888
either a	0.2
a pre-structured	0.001226993865030675
pre-structured database	1.0
database or	0.2
language documents	0.006756756756756757
corpus such	0.03225806451612903
Web or	0.1111111111111111
or some	0.013513513513513514
some local	0.012048192771084338
local collection	0.3333333333333333
collection -RRB-	0.2
pre-structured	2.7900228781876013e-05
<s> QA	0.0007686395080707148
QA research	0.047619047619047616
research attempts	0.047619047619047616
to deal	0.0013280212483399733
a wide	0.00245398773006135
wide range	0.5
of question	0.00267379679144385
question types	0.023809523809523808
types including	0.07142857142857142
including :	0.14285714285714285
: fact	0.00980392156862745
, list	0.0005614823133071309
list ,	0.09090909090909091
, definition	0.0005614823133071309
, How	0.0005614823133071309
How ,	0.14285714285714285
, Why	0.0005614823133071309
Why ,	0.14285714285714285
, hypothetical	0.0005614823133071309
hypothetical ,	1.0
, semantically	0.0005614823133071309
semantically constrained	1.0
constrained ,	1.0
and cross-lingual	0.001445086705202312
cross-lingual questions	0.5
questions .	0.07692307692307693
hypothetical	2.7900228781876013e-05
semantically	2.7900228781876013e-05
constrained	2.7900228781876013e-05
cross-lingual	5.5800457563752025e-05
<s> Search	0.0015372790161414297
Search collections	0.5
collections vary	0.25
vary from	0.16666666666666666
small local	0.1111111111111111
local document	0.3333333333333333
document collections	0.027777777777777776
collections ,	0.5
to internal	0.0013280212483399733
internal organization	0.2
organization documents	0.2
to compiled	0.0013280212483399733
compiled newswire	1.0
newswire reports	1.0
reports ,	0.2
Web .	0.2222222222222222
Search	5.5800457563752025e-05
collections	0.00011160091512750405
compiled	2.7900228781876013e-05
newswire	2.7900228781876013e-05
<s> Closed-domain	0.0007686395080707148
Closed-domain question	1.0
answering deals	0.16666666666666666
with questions	0.01092896174863388
questions under	0.038461538461538464
under a	0.2
domain -LRB-	0.05
, medicine	0.0005614823133071309
medicine or	1.0
or automotive	0.0045045045045045045
automotive maintenance	1.0
maintenance -RRB-	1.0
an easier	0.007575757575757576
easier task	0.125
task because	0.023809523809523808
because NLP	0.03333333333333333
can exploit	0.0055248618784530384
exploit domain-specific	1.0
domain-specific knowledge	0.5
knowledge frequently	0.037037037037037035
frequently formalized	0.5
formalized in	1.0
in ontologies	0.0018726591760299626
ontologies .	0.5
Closed-domain	2.7900228781876013e-05
medicine	2.7900228781876013e-05
automotive	2.7900228781876013e-05
maintenance	2.7900228781876013e-05
exploit	2.7900228781876013e-05
frequently	5.5800457563752025e-05
formalized	2.7900228781876013e-05
<s> Alternatively	0.0015372790161414297
Alternatively ,	1.0
, closed-domain	0.0005614823133071309
closed-domain might	1.0
might refer	0.038461538461538464
a situation	0.001226993865030675
situation where	0.5
where only	0.02857142857142857
only a	0.05263157894736842
limited type	0.1
of questions	0.004456327985739751
are accepted	0.004149377593360996
accepted ,	1.0
as questions	0.003484320557491289
questions asking	0.038461538461538464
asking for	0.5
for descriptive	0.0036101083032490976
descriptive rather	0.3333333333333333
than procedural	0.022222222222222223
procedural information	1.0
Alternatively	5.5800457563752025e-05
closed-domain	2.7900228781876013e-05
situation	5.5800457563752025e-05
accepted	2.7900228781876013e-05
asking	5.5800457563752025e-05
procedural	2.7900228781876013e-05
<s> Open-domain	0.0007686395080707148
Open-domain question	1.0
questions about	0.15384615384615385
about nearly	0.025
nearly anything	0.5
anything ,	1.0
only rely	0.02631578947368421
on general	0.0047169811320754715
general ontologies	0.045454545454545456
ontologies and	0.16666666666666666
and world	0.001445086705202312
world knowledge	0.13333333333333333
knowledge .	0.037037037037037035
Open-domain	2.7900228781876013e-05
anything	2.7900228781876013e-05
, these	0.0011229646266142617
usually have	0.03125
have much	0.009615384615384616
available from	0.058823529411764705
which to	0.007246376811594203
extract the	0.25
, current	0.0005614823133071309
current QA	0.14285714285714285
QA systems	0.2857142857142857
use text	0.013888888888888888
text documents	0.006289308176100629
documents as	0.02631578947368421
their underlying	0.029411764705882353
underlying knowledge	0.3333333333333333
knowledge source	0.037037037037037035
source and	0.041666666666666664
and combine	0.001445086705202312
various natural	0.05555555555555555
processing techniques	0.037037037037037035
to search	0.0013280212483399733
search for	0.09090909090909091
the answers	0.0006920415224913495
answers .	0.08333333333333333
Current QA	0.2
systems typically	0.008928571428571428
typically include	0.05555555555555555
question classifier	0.023809523809523808
classifier module	0.14285714285714285
module that	0.3333333333333333
question and	0.023809523809523808
of answer	0.00089126559714795
module	8.370068634562804e-05
After the	0.3333333333333333
the question	0.011072664359861591
question is	0.09523809523809523
analyzed ,	0.2
system typically	0.010752688172043012
typically uses	0.05555555555555555
uses several	0.07142857142857142
several modules	0.045454545454545456
modules that	0.5
that apply	0.0035460992907801418
apply increasingly	0.2
increasingly complex	0.3333333333333333
complex NLP	0.08333333333333333
NLP techniques	0.0425531914893617
techniques on	0.043478260869565216
a gradually	0.001226993865030675
gradually reduced	1.0
reduced amount	0.25
gradually	2.7900228781876013e-05
document retrieval	0.027777777777777776
retrieval module	0.14285714285714285
module uses	0.3333333333333333
uses search	0.07142857142857142
engines to	0.3333333333333333
documents or	0.02631578947368421
paragraphs in	0.25
document set	0.027777777777777776
set that	0.02564102564102564
to contain	0.0013280212483399733
<s> Subsequently	0.0007686395080707148
Subsequently a	1.0
a filter	0.001226993865030675
filter preselects	0.5
preselects small	1.0
small text	0.1111111111111111
text fragments	0.006289308176100629
fragments that	1.0
that contain	0.010638297872340425
contain strings	0.08333333333333333
same type	0.04
type as	0.07142857142857142
the expected	0.001384083044982699
expected answer	0.14285714285714285
Subsequently	2.7900228781876013e-05
filter	5.5800457563752025e-05
preselects	2.7900228781876013e-05
fragments	2.7900228781876013e-05
is ``	0.0040650406504065045
`` Who	0.010582010582010581
Who invented	0.5
invented Penicillin	0.5
Penicillin ''	1.0
'' the	0.005154639175257732
the filter	0.0006920415224913495
filter returns	0.5
returns text	1.0
contain names	0.08333333333333333
names of	0.14285714285714285
of people	0.00089126559714795
Who	5.5800457563752025e-05
Penicillin	2.7900228781876013e-05
returns	2.7900228781876013e-05
<s> Finally	0.0007686395080707148
Finally ,	1.0
an answer	0.015151515151515152
answer extraction	0.06666666666666667
extraction module	0.03225806451612903
module looks	0.3333333333333333
looks for	0.25
further clues	0.125
clues in	0.3333333333333333
answer candidate	0.03333333333333333
candidate can	0.3333333333333333
can indeed	0.0055248618784530384
indeed answer	0.3333333333333333
answer the	0.03333333333333333
question .	0.047619047619047616
Finally	2.7900228781876013e-05
clues	8.370068634562804e-05
answering methods	0.08333333333333333
methods QA	0.022727272727272728
QA is	0.047619047619047616
very dependent	0.024390243902439025
dependent on	0.6666666666666666
good search	0.07692307692307693
search corpus	0.09090909090909091
corpus -	0.03225806451612903
- for	0.0625
for without	0.0036101083032490976
without documents	0.07692307692307693
documents containing	0.02631578947368421
answer ,	0.03333333333333333
is little	0.0020325203252032522
little any	0.3333333333333333
any QA	0.03225806451612903
QA system	0.23809523809523808
system can	0.010752688172043012
do .	0.038461538461538464
dependent	8.370068634562804e-05
It thus	0.02631578947368421
thus makes	0.1
makes sense	0.125
sense that	0.125
that larger	0.0035460992907801418
larger collection	0.0625
collection sizes	0.2
sizes generally	0.3333333333333333
generally lend	0.09090909090909091
lend well	1.0
well to	0.03571428571428571
better QA	0.1111111111111111
QA performance	0.047619047619047616
performance ,	0.1111111111111111
, unless	0.0005614823133071309
unless the	1.0
question domain	0.023809523809523808
domain is	0.05
is orthogonal	0.0020325203252032522
orthogonal to	1.0
the collection	0.0006920415224913495
collection .	0.2
lend	2.7900228781876013e-05
unless	2.7900228781876013e-05
orthogonal	2.7900228781876013e-05
The notion	0.010416666666666666
data redundancy	0.012987012987012988
in massive	0.0018726591760299626
massive collections	1.0
the web	0.001384083044982699
web ,	0.125
, means	0.0005614823133071309
that nuggets	0.0035460992907801418
nuggets of	1.0
information are	0.021739130434782608
be phrased	0.004219409282700422
phrased in	1.0
different ways	0.02040816326530612
ways in	0.125
in differing	0.0018726591760299626
differing contexts	1.0
contexts and	0.14285714285714285
and documents	0.001445086705202312
, leading	0.0005614823133071309
to two	0.0013280212483399733
two benefits	0.034482758620689655
benefits :	0.5
: By	0.00980392156862745
By having	0.3333333333333333
having the	0.2
right information	0.1
information appear	0.021739130434782608
many forms	0.019230769230769232
forms ,	0.16666666666666666
the burden	0.0006920415224913495
burden on	1.0
the QA	0.0006920415224913495
perform complex	0.09090909090909091
is lessened	0.0020325203252032522
lessened .	1.0
massive	2.7900228781876013e-05
nuggets	2.7900228781876013e-05
phrased	2.7900228781876013e-05
differing	5.5800457563752025e-05
benefits	5.5800457563752025e-05
By	8.370068634562804e-05
burden	2.7900228781876013e-05
lessened	2.7900228781876013e-05
<s> Correct	0.0007686395080707148
Correct answers	1.0
answers can	0.08333333333333333
filtered from	0.3333333333333333
from false	0.009615384615384616
false positives	0.5
positives by	1.0
by relying	0.005714285714285714
relying on	1.0
correct answer	0.06666666666666667
appear more	0.0625
more times	0.010526315789473684
times in	0.2
documents than	0.02631578947368421
than instances	0.022222222222222223
of incorrect	0.00089126559714795
incorrect ones	0.3333333333333333
Correct	2.7900228781876013e-05
false	5.5800457563752025e-05
positives	2.7900228781876013e-05
relying	2.7900228781876013e-05
Issues In	0.5
In 2002	0.009523809523809525
2002 a	0.5
a group	0.001226993865030675
of researchers	0.00089126559714795
researchers wrote	0.1
wrote a	0.16666666666666666
a roadmap	0.001226993865030675
roadmap of	1.0
answering .	0.16666666666666666
roadmap	2.7900228781876013e-05
following issues	0.06666666666666667
issues were	0.2
were identified	0.024390243902439025
identified .	0.2
Question classes	0.2857142857142857
classes Different	0.2
questions -LRB-	0.038461538461538464
of Lichtenstein	0.00089126559714795
Lichtenstein ?	1.0
'' <\s>	0.041237113402061855
Lichtenstein	2.7900228781876013e-05
<s> vs.	0.0015372790161414297
vs. ``	0.16666666666666666
a rainbow	0.001226993865030675
rainbow form	1.0
form ?	0.05
rainbow	2.7900228781876013e-05
`` Did	0.005291005291005291
Did Marilyn	1.0
Marilyn Monroe	1.0
Monroe and	1.0
and Cary	0.001445086705202312
Cary Grant	1.0
Grant ever	1.0
ever appear	1.0
a movie	0.00245398773006135
movie together	0.3333333333333333
together ?	0.125
Did	2.7900228781876013e-05
Marilyn	2.7900228781876013e-05
Monroe	2.7900228781876013e-05
Cary	2.7900228781876013e-05
Grant	2.7900228781876013e-05
ever	2.7900228781876013e-05
movie	8.370068634562804e-05
<s> require	0.0007686395080707148
of different	0.0017825311942959
different strategies	0.02040816326530612
strategies to	0.5
classes are	0.2
are arranged	0.004149377593360996
arranged hierarchically	1.0
hierarchically in	1.0
in taxonomies	0.0018726591760299626
taxonomies .	1.0
arranged	2.7900228781876013e-05
hierarchically	2.7900228781876013e-05
taxonomies	2.7900228781876013e-05
Question processing	0.14285714285714285
processing The	0.018518518518518517
same information	0.04
information request	0.021739130434782608
request can	1.0
expressed in	0.16666666666666666
various ways	0.1111111111111111
some interrogative	0.012048192771084338
interrogative -LRB-	1.0
Who is	0.5
the president	0.001384083044982699
president of	1.0
States ?	0.14285714285714285
request	2.7900228781876013e-05
interrogative	2.7900228781876013e-05
president	5.5800457563752025e-05
<s> and	0.0007686395080707148
and some	0.002890173410404624
some assertive	0.012048192771084338
assertive -LRB-	1.0
`` Tell	0.005291005291005291
Tell me	1.0
me the	1.0
name of	0.2
assertive	2.7900228781876013e-05
Tell	2.7900228781876013e-05
me	2.7900228781876013e-05
A semantic	0.02
semantic model	0.047619047619047616
model of	0.03333333333333333
question understanding	0.023809523809523808
understanding and	0.030303030303030304
and processing	0.001445086705202312
processing would	0.018518518518518517
would recognize	0.018867924528301886
recognize equivalent	0.1111111111111111
equivalent questions	0.2
questions ,	0.3076923076923077
of how	0.00089126559714795
are presented	0.004149377593360996
presented .	0.16666666666666666
would enable	0.018867924528301886
complex question	0.041666666666666664
question into	0.023809523809523808
of simpler	0.0017825311942959
simpler questions	0.3333333333333333
would identify	0.018867924528301886
identify ambiguities	0.08333333333333333
ambiguities and	0.25
and treat	0.001445086705202312
treat them	0.5
them in	0.05263157894736842
context or	0.030303030303030304
or by	0.0045045045045045045
by interactive	0.005714285714285714
interactive clarification	0.25
clarification .	0.3333333333333333
simpler	8.370068634562804e-05
clarification	8.370068634562804e-05
<s> Context	0.0007686395080707148
Context and	1.0
and QA	0.001445086705202312
QA Questions	0.047619047619047616
Questions are	1.0
usually asked	0.03125
asked within	0.3333333333333333
a context	0.00245398773006135
context and	0.12121212121212122
and answers	0.001445086705202312
answers are	0.08333333333333333
are provided	0.004149377593360996
provided within	0.2
within that	0.05555555555555555
that specific	0.0035460992907801418
specific context	0.047619047619047616
Context	2.7900228781876013e-05
Questions	2.7900228781876013e-05
asked	8.370068634562804e-05
The context	0.005208333333333333
context can	0.030303030303030304
to clarify	0.0013280212483399733
clarify a	1.0
, resolve	0.0005614823133071309
ambiguities or	0.25
or keep	0.0045045045045045045
keep track	0.3333333333333333
track of	1.0
an investigation	0.007575757575757576
investigation performed	1.0
performed through	0.1
through a	0.25
clarify	2.7900228781876013e-05
track	2.7900228781876013e-05
investigation	2.7900228781876013e-05
-LRB- For	0.005420054200542005
Why did	0.14285714285714285
did Joe	0.2
Joe Biden	1.0
Biden visit	0.3333333333333333
visit Iraq	0.5
Iraq in	0.5
in January	0.003745318352059925
January 2010	0.5
2010 ?	0.3333333333333333
Joe	2.7900228781876013e-05
Biden	8.370068634562804e-05
visit	5.5800457563752025e-05
Iraq	5.5800457563752025e-05
<s> might	0.0007686395080707148
be asking	0.004219409282700422
asking why	0.5
why Vice	0.14285714285714285
Vice President	1.0
President Biden	0.25
Biden visited	0.3333333333333333
visited and	1.0
not President	0.008928571428571428
President Obama	0.25
Obama ,	1.0
, why	0.0011229646266142617
why he	0.2857142857142857
he went	0.2857142857142857
went to	0.4
to Iraq	0.0013280212483399733
Iraq and	0.5
not Afghanistan	0.008928571428571428
Afghanistan or	1.0
other country	0.014285714285714285
country ,	0.25
went in	0.2
2010 and	0.3333333333333333
not before	0.008928571428571428
before or	0.16666666666666666
or after	0.0045045045045045045
after ,	0.08333333333333333
or what	0.009009009009009009
what Biden	0.03125
Biden was	0.3333333333333333
was hoping	0.012987012987012988
hoping to	1.0
to accomplish	0.0013280212483399733
accomplish with	1.0
with his	0.00546448087431694
his visit	0.08333333333333333
visit .	0.5
Vice	2.7900228781876013e-05
visited	2.7900228781876013e-05
Obama	2.7900228781876013e-05
Afghanistan	2.7900228781876013e-05
hoping	2.7900228781876013e-05
accomplish	2.7900228781876013e-05
If the	0.4
related questions	0.06666666666666667
previous questions	0.3333333333333333
questions and	0.038461538461538464
their answers	0.029411764705882353
answers might	0.08333333333333333
might shed	0.038461538461538464
shed light	1.0
light on	0.3333333333333333
the questioner	0.002768166089965398
questioner 's	0.25
's intent	0.0196078431372549
intent .	1.0
shed	2.7900228781876013e-05
questioner	0.00011160091512750405
intent	2.7900228781876013e-05
<s> Data	0.0007686395080707148
Data sources	1.0
sources for	0.16666666666666666
for QA	0.010830324909747292
QA Before	0.047619047619047616
Before a	0.5
question can	0.023809523809523808
be answered	0.004219409282700422
answered ,	0.2
it must	0.008547008547008548
be known	0.004219409282700422
known what	0.038461538461538464
what knowledge	0.03125
knowledge sources	0.037037037037037035
sources are	0.16666666666666666
available and	0.058823529411764705
and relevant	0.001445086705202312
relevant .	0.14285714285714285
Data	2.7900228781876013e-05
answered	0.00013950114390938006
not present	0.026785714285714284
data sources	0.025974025974025976
sources ,	0.16666666666666666
no matter	0.07692307692307693
matter how	0.3333333333333333
well the	0.03571428571428571
question processing	0.07142857142857142
and answer	0.001445086705202312
extraction is	0.06451612903225806
correct result	0.06666666666666667
result will	0.09090909090909091
be obtained	0.004219409282700422
obtained .	0.14285714285714285
<s> Answer	0.0015372790161414297
Answer extraction	0.6666666666666666
extraction Answer	0.03225806451612903
extraction depends	0.03225806451612903
answer type	0.06666666666666667
type provided	0.07142857142857142
provided by	0.4
by question	0.005714285714285714
actual data	0.2
data where	0.012987012987012988
answer is	0.06666666666666667
is searched	0.0020325203252032522
the search	0.0006920415224913495
search method	0.09090909090909091
method and	0.0625
and on	0.002890173410404624
question focus	0.023809523809523808
focus and	0.14285714285714285
Answer	8.370068634562804e-05
Answer formulation	0.3333333333333333
formulation The	1.0
The result	0.005208333333333333
system should	0.010752688172043012
be presented	0.004219409282700422
way as	0.041666666666666664
as natural	0.003484320557491289
natural as	0.013333333333333334
formulation	2.7900228781876013e-05
, simple	0.0011229646266142617
simple extraction	0.038461538461538464
is sufficient	0.0040650406504065045
question classification	0.023809523809523808
classification indicates	0.058823529411764705
indicates that	1.0
name -LRB-	0.2
organization ,	0.2
, shop	0.0005614823133071309
shop or	1.0
or disease	0.0045045045045045045
disease ,	1.0
a quantity	0.001226993865030675
quantity -LRB-	0.3333333333333333
-LRB- monetary	0.0027100271002710027
monetary value	1.0
value ,	0.3333333333333333
, length	0.0005614823133071309
, size	0.0005614823133071309
size ,	0.16666666666666666
, distance	0.0005614823133071309
distance ,	0.6666666666666666
a date	0.001226993865030675
date -LRB-	0.6666666666666666
`` On	0.005291005291005291
On what	0.16666666666666666
what day	0.03125
day did	1.0
did Christmas	0.2
Christmas fall	1.0
fall in	0.25
in 1989	0.0018726591760299626
1989 ?	0.5
indicates	2.7900228781876013e-05
shop	2.7900228781876013e-05
disease	2.7900228781876013e-05
monetary	2.7900228781876013e-05
value	8.370068634562804e-05
distance	8.370068634562804e-05
date	8.370068634562804e-05
day	2.7900228781876013e-05
Christmas	2.7900228781876013e-05
<s> the	0.0007686395080707148
single datum	0.07142857142857142
datum is	1.0
datum	2.7900228781876013e-05
For other	0.01639344262295082
other cases	0.02857142857142857
the presentation	0.0006920415224913495
presentation of	1.0
answer may	0.03333333333333333
of fusion	0.00089126559714795
fusion techniques	1.0
techniques that	0.08695652173913043
that combine	0.0035460992907801418
combine the	0.3333333333333333
the partial	0.0006920415224913495
partial answers	1.0
answers from	0.16666666666666666
from multiple	0.009615384615384616
presentation	2.7900228781876013e-05
fusion	2.7900228781876013e-05
partial	2.7900228781876013e-05
Real time	0.5
time question	0.030303030303030304
answering There	0.08333333333333333
is need	0.0020325203252032522
developing Q&A	0.25
Q&A systems	1.0
of extracting	0.00089126559714795
extracting answers	0.2
from large	0.009615384615384616
large data	0.043478260869565216
sets in	0.09090909090909091
several seconds	0.045454545454545456
seconds ,	1.0
size and	0.3333333333333333
and multitude	0.001445086705202312
multitude of	1.0
sources or	0.16666666666666666
the ambiguity	0.0006920415224913495
ambiguity of	0.125
Q&A	2.7900228781876013e-05
seconds	2.7900228781876013e-05
multitude	2.7900228781876013e-05
<s> Multilingual	0.0007686395080707148
Multilingual -LRB-	1.0
or cross-lingual	0.0045045045045045045
cross-lingual -RRB-	0.5
-RRB- question	0.0027100271002710027
answering The	0.08333333333333333
The ability	0.005208333333333333
to answer	0.00398406374501992
answer a	0.03333333333333333
language using	0.006756756756756757
answer corpus	0.03333333333333333
even several	0.037037037037037035
several -RRB-	0.045454545454545456
Multilingual	2.7900228781876013e-05
This allows	0.031746031746031744
to consult	0.0013280212483399733
consult information	1.0
information that	0.021739130434782608
not use	0.017857142857142856
use directly	0.013888888888888888
directly .	0.2
consult	2.7900228781876013e-05
also Machine	0.014492753623188406
<s> Interactive	0.0007686395080707148
Interactive QA	0.5
QA It	0.047619047619047616
often the	0.045454545454545456
case that	0.058823529411764705
information need	0.021739130434782608
need is	0.047619047619047616
not well	0.008928571428571428
well captured	0.03571428571428571
captured by	1.0
processing part	0.018518518518518517
part may	0.037037037037037035
may fail	0.019230769230769232
fail to	0.3333333333333333
to classify	0.0013280212483399733
classify properly	0.5
properly the	0.5
question or	0.023809523809523808
information needed	0.021739130434782608
for extracting	0.0036101083032490976
extracting and	0.2
and generating	0.001445086705202312
generating the	0.2
easily retrieved	0.1111111111111111
retrieved .	1.0
Interactive	5.5800457563752025e-05
captured	2.7900228781876013e-05
classify	5.5800457563752025e-05
retrieved	2.7900228781876013e-05
In such	0.009523809523809525
questioner might	0.25
might want	0.038461538461538464
want not	0.16666666666666666
only to	0.02631578947368421
to reformulate	0.0013280212483399733
reformulate the	1.0
but to	0.014705882352941176
dialogue with	0.5
reformulate	2.7900228781876013e-05
system might	0.010752688172043012
might ask	0.038461538461538464
ask for	0.25
a clarification	0.001226993865030675
clarification of	0.6666666666666666
what sense	0.03125
sense a	0.125
being used	0.05555555555555555
what type	0.03125
information is	0.043478260869565216
being asked	0.05555555555555555
asked for	0.3333333333333333
for .	0.0036101083032490976
Advanced reasoning	0.2
reasoning for	0.14285714285714285
QA More	0.047619047619047616
More sophisticated	0.3333333333333333
sophisticated questioners	0.14285714285714285
questioners expect	1.0
expect answers	0.3333333333333333
answers that	0.08333333333333333
are outside	0.004149377593360996
outside the	0.5
of written	0.0035650623885918
texts or	0.058823529411764705
or structured	0.0045045045045045045
structured databases	0.16666666666666666
questioners	2.7900228781876013e-05
To upgrade	0.1111111111111111
upgrade a	1.0
system with	0.010752688172043012
with such	0.00546448087431694
such capabilities	0.008130081300813009
capabilities ,	0.2
to integrate	0.0013280212483399733
integrate reasoning	1.0
reasoning components	0.14285714285714285
components operating	0.2
operating on	0.5
knowledge bases	0.037037037037037035
bases ,	1.0
, encoding	0.0005614823133071309
encoding world	1.0
knowledge and	0.07407407407407407
and common-sense	0.001445086705202312
common-sense reasoning	1.0
reasoning mechanisms	0.14285714285714285
mechanisms ,	0.5
as knowledge	0.003484320557491289
knowledge specific	0.037037037037037035
specific to	0.047619047619047616
of domains	0.00089126559714795
domains .	0.25
upgrade	2.7900228781876013e-05
integrate	2.7900228781876013e-05
operating	5.5800457563752025e-05
bases	2.7900228781876013e-05
encoding	2.7900228781876013e-05
common-sense	2.7900228781876013e-05
<s> User	0.0007686395080707148
User profiling	0.5
profiling for	1.0
QA The	0.047619047619047616
The user	0.005208333333333333
user profile	0.07142857142857142
profile captures	0.3333333333333333
captures data	1.0
data about	0.012987012987012988
questioner ,	0.5
, comprising	0.0005614823133071309
comprising context	0.5
context data	0.030303030303030304
, domain	0.0005614823133071309
domain of	0.1
interest ,	0.09090909090909091
, reasoning	0.0005614823133071309
reasoning schemes	0.14285714285714285
schemes frequently	0.5
frequently used	0.5
, common	0.0005614823133071309
common ground	0.04
ground established	1.0
established within	1.0
within different	0.05555555555555555
different dialogues	0.02040816326530612
dialogues between	1.0
user ,	0.07142857142857142
so forth	0.03333333333333333
forth .	1.0
User	5.5800457563752025e-05
profiling	2.7900228781876013e-05
profile	8.370068634562804e-05
captures	2.7900228781876013e-05
ground	2.7900228781876013e-05
established	2.7900228781876013e-05
dialogues	2.7900228781876013e-05
forth	2.7900228781876013e-05
The profile	0.005208333333333333
profile may	0.3333333333333333
be represented	0.008438818565400843
represented as	0.3333333333333333
a predefined	0.001226993865030675
predefined template	1.0
template ,	0.25
where each	0.02857142857142857
each template	0.022222222222222223
template slot	0.25
slot represents	1.0
represents a	0.75
different profile	0.02040816326530612
profile feature	0.3333333333333333
represented	0.00016740137269125608
predefined	2.7900228781876013e-05
slot	2.7900228781876013e-05
represents	0.00011160091512750405
<s> Profile	0.0007686395080707148
Profile templates	1.0
templates may	1.0
be nested	0.004219409282700422
nested one	1.0
one within	0.015384615384615385
within another	0.05555555555555555
Profile	2.7900228781876013e-05
templates	2.7900228781876013e-05
nested	2.7900228781876013e-05
History Some	0.5
early AI	0.2
AI systems	0.6666666666666666
were question	0.024390243902439025
answering systems	0.08333333333333333
Two of	0.2857142857142857
most famous	0.034482758620689655
famous QA	0.3333333333333333
of that	0.0017825311942959
that time	0.0035460992907801418
time are	0.030303030303030304
are BASEBALL	0.004149377593360996
BASEBALL and	0.5
and LUNAR	0.001445086705202312
LUNAR ,	0.6666666666666666
1960s .	0.3333333333333333
BASEBALL	5.5800457563752025e-05
LUNAR	8.370068634562804e-05
<s> BASEBALL	0.0007686395080707148
BASEBALL answered	0.5
answered questions	0.6
US baseball	0.14285714285714285
baseball league	1.0
league over	1.0
over a	0.08333333333333333
a period	0.00245398773006135
period of	0.5
one year	0.015384615384615385
baseball	2.7900228781876013e-05
league	2.7900228781876013e-05
period	5.5800457563752025e-05
<s> LUNAR	0.0007686395080707148
turn ,	0.16666666666666666
, answered	0.0005614823133071309
the geological	0.0006920415224913495
geological analysis	1.0
of rocks	0.00089126559714795
rocks returned	1.0
returned by	0.25
the Apollo	0.0006920415224913495
Apollo moon	1.0
moon missions	1.0
missions .	1.0
geological	2.7900228781876013e-05
rocks	2.7900228781876013e-05
Apollo	2.7900228781876013e-05
moon	2.7900228781876013e-05
missions	2.7900228781876013e-05
Both QA	0.3333333333333333
were very	0.04878048780487805
very effective	0.024390243902439025
their chosen	0.029411764705882353
chosen domains	0.2
, LUNAR	0.0005614823133071309
LUNAR was	0.3333333333333333
was demonstrated	0.012987012987012988
demonstrated at	1.0
a lunar	0.001226993865030675
lunar science	1.0
science convention	0.1
convention in	1.0
in 1971	0.0018726591760299626
1971 and	0.3333333333333333
answer 90	0.03333333333333333
the questions	0.0006920415224913495
questions in	0.038461538461538464
its domain	0.05714285714285714
domain posed	0.05
posed by	0.3333333333333333
people untrained	0.0625
untrained on	1.0
demonstrated	2.7900228781876013e-05
lunar	2.7900228781876013e-05
convention	2.7900228781876013e-05
untrained	2.7900228781876013e-05
<s> Further	0.0023059185242121443
Further restricted-domain	0.3333333333333333
restricted-domain QA	1.0
following years	0.06666666666666667
Further	8.370068634562804e-05
restricted-domain	2.7900228781876013e-05
The common	0.005208333333333333
common feature	0.04
feature of	0.23076923076923078
all these	0.023255813953488372
systems is	0.026785714285714284
they had	0.025
had a	0.2857142857142857
a core	0.001226993865030675
core database	0.5
or knowledge	0.0045045045045045045
knowledge system	0.037037037037037035
system that	0.03225806451612903
that was	0.010638297872340425
was hand-written	0.012987012987012988
hand-written by	0.14285714285714285
by experts	0.005714285714285714
experts of	1.0
the chosen	0.0006920415224913495
chosen domain	0.2
core	5.5800457563752025e-05
experts	2.7900228781876013e-05
systems included	0.008928571428571428
included question-answering	0.125
question-answering abilities	0.5
abilities .	1.0
question-answering	5.5800457563752025e-05
abilities	2.7900228781876013e-05
famous early	0.3333333333333333
early systems	0.1
are SHRDLU	0.004149377593360996
SHRDLU and	0.16666666666666666
ELIZA .	0.1111111111111111
SHRDLU simulated	0.16666666666666666
simulated the	0.5
the operation	0.0006920415224913495
operation of	0.5
a robot	0.001226993865030675
robot in	0.5
toy world	0.5
world -LRB-	0.06666666666666667
blocks world	0.25
world ''	0.06666666666666667
it offered	0.008547008547008548
offered the	1.0
possibility to	0.25
to ask	0.0013280212483399733
the robot	0.0006920415224913495
robot questions	0.5
the state	0.001384083044982699
simulated	5.5800457563752025e-05
robot	5.5800457563752025e-05
offered	2.7900228781876013e-05
<s> Again	0.0007686395080707148
Again ,	1.0
the strength	0.001384083044982699
strength of	0.6
this system	0.01098901098901099
the choice	0.0006920415224913495
very specific	0.024390243902439025
domain and	0.05
very simple	0.04878048780487805
simple world	0.038461538461538464
world with	0.06666666666666667
with rules	0.00546448087431694
of physics	0.00089126559714795
physics that	1.0
were easy	0.024390243902439025
to encode	0.0013280212483399733
encode in	1.0
Again	2.7900228781876013e-05
strength	0.00013950114390938006
physics	2.7900228781876013e-05
encode	2.7900228781876013e-05
in contrast	0.0018726591760299626
, simulated	0.0005614823133071309
simulated a	0.5
a conversation	0.001226993865030675
a psychologist	0.001226993865030675
psychologist .	1.0
psychologist	2.7900228781876013e-05
ELIZA was	0.1111111111111111
to converse	0.0013280212483399733
converse on	1.0
topic by	0.125
by resorting	0.005714285714285714
resorting to	1.0
to very	0.0013280212483399733
simple rules	0.038461538461538464
that detected	0.0035460992907801418
detected important	0.5
important words	0.0625
the person	0.002768166089965398
person 's	0.21052631578947367
's input	0.0196078431372549
converse	2.7900228781876013e-05
resorting	2.7900228781876013e-05
detected	5.5800457563752025e-05
It had	0.02631578947368421
very rudimentary	0.024390243902439025
rudimentary way	0.5
answer questions	0.03333333333333333
own it	0.16666666666666666
it led	0.008547008547008548
led to	0.6666666666666666
of chatterbots	0.00089126559714795
chatterbots such	0.5
ones that	0.1
that participate	0.0035460992907801418
participate in	1.0
the annual	0.0006920415224913495
annual Loebner	0.5
Loebner prize	1.0
prize .	1.0
participate	2.7900228781876013e-05
Loebner	2.7900228781876013e-05
prize	2.7900228781876013e-05
The 1970s	0.005208333333333333
1980s saw	0.1111111111111111
saw the	1.0
of comprehensive	0.00089126559714795
comprehensive theories	0.2
theories in	0.2
which led	0.007246376811594203
of ambitious	0.00089126559714795
ambitious projects	1.0
projects in	0.5
in text	0.0018726591760299626
text comprehension	0.006289308176100629
comprehension and	0.14285714285714285
and question	0.001445086705202312
saw	2.7900228781876013e-05
ambitious	2.7900228781876013e-05
projects	5.5800457563752025e-05
One example	0.07692307692307693
the Unix	0.001384083044982699
Unix Consultant	0.5
Consultant -LRB-	1.0
-LRB- UC	0.0027100271002710027
UC -RRB-	0.5
that answered	0.0035460992907801418
questions pertaining	0.038461538461538464
pertaining to	1.0
Unix operating	0.5
operating system	0.5
Unix	5.5800457563752025e-05
Consultant	2.7900228781876013e-05
UC	5.5800457563752025e-05
pertaining	2.7900228781876013e-05
system had	0.010752688172043012
comprehensive hand-crafted	0.2
hand-crafted knowledge	0.5
base of	0.25
it aimed	0.008547008547008548
at phrasing	0.014705882352941176
phrasing the	1.0
accommodate various	0.2
phrasing	2.7900228781876013e-05
Another project	0.07692307692307693
project was	0.07692307692307693
was LILOG	0.012987012987012988
LILOG ,	0.5
a text-understanding	0.001226993865030675
text-understanding system	1.0
that operated	0.0035460992907801418
operated on	0.5
of tourism	0.00089126559714795
tourism information	1.0
information in	0.043478260869565216
a German	0.001226993865030675
German city	0.25
city .	1.0
LILOG	5.5800457563752025e-05
text-understanding	2.7900228781876013e-05
operated	5.5800457563752025e-05
tourism	2.7900228781876013e-05
city	2.7900228781876013e-05
The systems	0.005208333333333333
the UC	0.0006920415224913495
UC and	0.5
and LILOG	0.001445086705202312
LILOG projects	0.5
projects never	0.5
never went	0.2
went past	0.2
past the	0.3333333333333333
the stage	0.0006920415224913495
stage of	0.4
simple demonstrations	0.038461538461538464
demonstrations ,	1.0
they helped	0.025
helped the	0.3333333333333333
of theories	0.00089126559714795
theories on	0.2
on computational	0.0047169811320754715
linguistics and	0.05
and reasoning	0.002890173410404624
reasoning .	0.14285714285714285
past	8.370068634562804e-05
demonstrations	2.7900228781876013e-05
An increasing	0.0625
increasing number	0.3333333333333333
systems include	0.008928571428571428
Web as	0.1111111111111111
one more	0.015384615384615385
more corpus	0.010526315789473684
. .	0.00078003120124805
these tools	0.023809523809523808
tools mostly	0.16666666666666666
mostly work	0.5
using shallow	0.01694915254237288
shallow methods	0.16666666666666666
above --	0.07692307692307693
-- thus	0.04
thus returning	0.1
returning a	1.0
an excerpt	0.007575757575757576
excerpt containing	1.0
the probable	0.0006920415224913495
probable answer	1.0
answer highlighted	0.03333333333333333
highlighted ,	1.0
, plus	0.0005614823133071309
plus some	1.0
some context	0.012048192771084338
mostly	5.5800457563752025e-05
returning	5.5800457563752025e-05
excerpt	2.7900228781876013e-05
probable	2.7900228781876013e-05
highlighted	2.7900228781876013e-05
plus	2.7900228781876013e-05
, highly-specialized	0.0005614823133071309
highly-specialized natural	1.0
language question-answering	0.006756756756756757
question-answering engines	0.5
engines ,	0.3333333333333333
as EAGLi	0.003484320557491289
EAGLi for	1.0
for health	0.0036101083032490976
health and	1.0
and life	0.001445086705202312
life scientists	0.25
scientists ,	1.0
been made	0.014705882352941176
made available	0.0625
highly-specialized	2.7900228781876013e-05
EAGLi	2.7900228781876013e-05
health	2.7900228781876013e-05
scientists	2.7900228781876013e-05
The Future	0.005208333333333333
Future of	0.5
of Question	0.00089126559714795
Question Answering	0.14285714285714285
Answering QA	1.0
been extended	0.014705882352941176
extended in	1.0
years to	0.047619047619047616
explore critical	0.25
critical new	0.25
new scientific	0.041666666666666664
scientific and	0.5
and practical	0.001445086705202312
practical dimensions	0.5
dimensions For	0.3333333333333333
been developed	0.014705882352941176
developed to	0.038461538461538464
automatically answer	0.047619047619047616
answer temporal	0.03333333333333333
temporal and	0.5
and geospatial	0.001445086705202312
geospatial questions	1.0
, definitional	0.0005614823133071309
definitional questions	1.0
, biographical	0.0005614823133071309
biographical questions	1.0
, multilingual	0.0005614823133071309
multilingual questions	0.3333333333333333
and questions	0.001445086705202312
questions from	0.038461538461538464
from multimedia	0.009615384615384616
multimedia -LRB-	0.5
, audio	0.0011229646266142617
audio ,	1.0
, imagery	0.0005614823133071309
imagery ,	1.0
, video	0.0011229646266142617
video -RRB-	0.2
Future	5.5800457563752025e-05
Answering	2.7900228781876013e-05
extended	2.7900228781876013e-05
temporal	5.5800457563752025e-05
geospatial	2.7900228781876013e-05
definitional	2.7900228781876013e-05
biographical	2.7900228781876013e-05
audio	5.5800457563752025e-05
imagery	2.7900228781876013e-05
video	0.00013950114390938006
<s> Additional	0.0007686395080707148
Additional aspects	1.0
aspects such	0.14285714285714285
as interactivity	0.003484320557491289
interactivity -LRB-	1.0
often required	0.022727272727272728
required for	0.14285714285714285
for clarification	0.0036101083032490976
questions or	0.038461538461538464
or answers	0.0045045045045045045
answers -RRB-	0.08333333333333333
, answer	0.0005614823133071309
answer reuse	0.03333333333333333
reuse ,	1.0
and knowledge	0.001445086705202312
knowledge representation	0.037037037037037035
reasoning to	0.14285714285714285
support question	0.25
answering have	0.08333333333333333
been explored	0.014705882352941176
explored .	0.5
Additional	2.7900228781876013e-05
interactivity	2.7900228781876013e-05
reuse	2.7900228781876013e-05
<s> Future	0.0007686395080707148
Future research	0.5
research may	0.023809523809523808
may explore	0.019230769230769232
explore what	0.25
what kinds	0.03125
kinds of	1.0
questions can	0.038461538461538464
be asked	0.004219409282700422
asked and	0.3333333333333333
and answered	0.001445086705202312
answered about	0.2
about social	0.025
including sentiment	0.07142857142857142
sentiment analysis	0.52
analysis .	0.09230769230769231
kinds	2.7900228781876013e-05
sentiment	0.0006975057195469003
A relationship	0.02
extraction task	0.03225806451612903
task requires	0.023809523809523808
the detection	0.0006920415224913495
detection and	0.5
and classification	0.001445086705202312
classification of	0.058823529411764705
semantic relationship	0.047619047619047616
relationship mentions	0.16666666666666666
mentions within	0.3333333333333333
of artifacts	0.00089126559714795
artifacts ,	1.0
typically from	0.05555555555555555
or XML	0.0045045045045045045
XML documents	1.0
detection	5.5800457563752025e-05
artifacts	2.7900228781876013e-05
XML	2.7900228781876013e-05
information extraction	0.021739130434782608
but IE	0.014705882352941176
IE additionally	0.3333333333333333
additionally requires	1.0
the removal	0.0006920415224913495
removal of	1.0
of repeated	0.00089126559714795
repeated relations	0.5
relations -LRB-	0.08333333333333333
-LRB- disambiguation	0.0027100271002710027
and generally	0.001445086705202312
generally refers	0.09090909090909091
different relationships	0.02040816326530612
relationships .	0.16666666666666666
additionally	2.7900228781876013e-05
removal	2.7900228781876013e-05
Approaches One	0.3333333333333333
One approach	0.07692307692307693
problem involves	0.045454545454545456
of domain	0.00089126559714795
domain ontologies	0.1
Another approach	0.15384615384615385
approach involves	0.02857142857142857
involves visual	0.1
visual detection	0.5
detection of	0.5
of meaningful	0.00089126559714795
meaningful relationships	0.125
relationships in	0.16666666666666666
in parametric	0.0018726591760299626
parametric values	1.0
of objects	0.00089126559714795
objects listed	0.2
listed on	1.0
a data	0.001226993865030675
data table	0.012987012987012988
table that	0.14285714285714285
that shift	0.0035460992907801418
shift positions	1.0
positions as	1.0
table is	0.14285714285714285
is permuted	0.0020325203252032522
permuted automatically	1.0
automatically as	0.047619047619047616
as controlled	0.003484320557491289
controlled by	1.0
software user	0.037037037037037035
visual	5.5800457563752025e-05
parametric	2.7900228781876013e-05
listed	2.7900228781876013e-05
shift	2.7900228781876013e-05
positions	2.7900228781876013e-05
permuted	2.7900228781876013e-05
controlled	2.7900228781876013e-05
The poor	0.005208333333333333
poor coverage	1.0
coverage ,	0.3333333333333333
, rarity	0.0005614823133071309
rarity and	1.0
development cost	0.08333333333333333
cost related	0.5
to structured	0.0013280212483399733
structured resources	0.16666666666666666
resources such	0.16666666666666666
as semantic	0.003484320557491289
semantic lexicons	0.047619047619047616
lexicons -LRB-	0.5
e.g. WordNet	0.017857142857142856
WordNet ,	0.5
, UMLS	0.0005614823133071309
UMLS -RRB-	1.0
and domain	0.001445086705202312
ontologies -LRB-	0.16666666666666666
the Gene	0.0006920415224913495
Gene Ontology	1.0
Ontology -RRB-	1.0
has given	0.011904761904761904
given rise	0.041666666666666664
rise to	0.5
new approaches	0.041666666666666664
approaches based	0.03571428571428571
on broad	0.0047169811320754715
broad ,	0.25
, dynamic	0.0005614823133071309
dynamic background	0.2
background knowledge	0.3333333333333333
knowledge on	0.037037037037037035
the Web	0.001384083044982699
poor	2.7900228781876013e-05
rarity	2.7900228781876013e-05
UMLS	2.7900228781876013e-05
Gene	2.7900228781876013e-05
Ontology	2.7900228781876013e-05
rise	5.5800457563752025e-05
background	8.370068634562804e-05
the ARCHILES	0.0006920415224913495
ARCHILES technique	1.0
technique uses	0.14285714285714285
uses only	0.07142857142857142
only Wikipedia	0.02631578947368421
Wikipedia and	0.5
and search	0.001445086705202312
search engine	0.09090909090909091
engine page	0.16666666666666666
page count	0.14285714285714285
count for	0.2
for acquiring	0.0036101083032490976
acquiring coarse-grained	1.0
coarse-grained relations	1.0
relations to	0.08333333333333333
to construct	0.0013280212483399733
construct lightweight	0.3333333333333333
lightweight ontologies	1.0
ARCHILES	2.7900228781876013e-05
acquiring	2.7900228781876013e-05
coarse-grained	2.7900228781876013e-05
lightweight	2.7900228781876013e-05
The relationships	0.005208333333333333
relationships can	0.16666666666666666
represented using	0.16666666666666666
of formalisms\/languages	0.00089126559714795
formalisms\/languages .	1.0
formalisms\/languages	2.7900228781876013e-05
One such	0.07692307692307693
such representation	0.008130081300813009
data on	0.012987012987012988
Web is	0.1111111111111111
is RDF	0.0020325203252032522
RDF .	1.0
RDF	2.7900228781876013e-05
<s> Jump	0.0007686395080707148
Jump to	1.0
to :	0.0013280212483399733
: navigation	0.00980392156862745
navigation ,	0.5
, search	0.0011229646266142617
search Sentence	0.09090909090909091
Sentence boundary	0.2
disambiguation -LRB-	0.1
-LRB- SBD	0.0027100271002710027
SBD -RRB-	1.0
sentence breaking	0.020833333333333332
breaking ,	0.5
processing of	0.037037037037037035
of deciding	0.00089126559714795
deciding where	0.16666666666666666
where sentences	0.05714285714285714
sentences begin	0.013157894736842105
begin and	0.3333333333333333
and end	0.001445086705202312
end .	0.125
Jump	2.7900228781876013e-05
navigation	5.5800457563752025e-05
SBD	2.7900228781876013e-05
Often natural	0.3333333333333333
processing tools	0.018518518518518517
tools require	0.16666666666666666
require their	0.045454545454545456
their input	0.029411764705882353
be divided	0.004219409282700422
into sentences	0.01282051282051282
sentences for	0.013157894736842105
of reasons	0.00089126559714795
reasons .	0.5
However sentence	0.02702702702702703
boundary identification	0.16666666666666666
identification is	0.2
is challenging	0.0020325203252032522
challenging because	1.0
because punctuation	0.03333333333333333
marks are	0.25
often ambiguous	0.022727272727272728
challenging	2.7900228781876013e-05
period may	0.5
may denote	0.019230769230769232
denote an	0.5
an abbreviation	0.007575757575757576
abbreviation ,	0.5
, decimal	0.0005614823133071309
decimal point	1.0
point ,	0.6666666666666666
an ellipsis	0.007575757575757576
ellipsis ,	1.0
or an	0.009009009009009009
an email	0.007575757575757576
email address	0.5
address -	0.25
- not	0.0625
denote	5.5800457563752025e-05
decimal	2.7900228781876013e-05
point	8.370068634562804e-05
ellipsis	2.7900228781876013e-05
email	5.5800457563752025e-05
<s> About	0.0007686395080707148
About 47	0.5
47 %	1.0
the periods	0.0006920415224913495
periods in	0.3333333333333333
Journal corpus	0.3333333333333333
corpus denote	0.03225806451612903
denote abbreviations	0.5
abbreviations .	0.2
47	2.7900228781876013e-05
As well	0.05555555555555555
well ,	0.03571428571428571
question marks	0.023809523809523808
marks and	0.25
and exclamation	0.001445086705202312
exclamation marks	1.0
marks may	0.25
may appear	0.019230769230769232
in embedded	0.0018726591760299626
embedded quotations	0.25
quotations ,	1.0
, emoticons	0.0005614823133071309
emoticons ,	1.0
computer code	0.022727272727272728
code ,	0.14285714285714285
and slang	0.001445086705202312
slang .	1.0
exclamation	2.7900228781876013e-05
quotations	2.7900228781876013e-05
emoticons	2.7900228781876013e-05
slang	2.7900228781876013e-05
Languages like	0.3333333333333333
like Japanese	0.03571428571428571
and Chinese	0.001445086705202312
Chinese have	0.14285714285714285
have unambiguous	0.009615384615384616
unambiguous sentence-ending	0.5
sentence-ending markers	1.0
markers .	0.3333333333333333
sentence-ending	2.7900228781876013e-05
-LRB- b	0.0027100271002710027
b -RRB-	1.0
-RRB- If	0.005420054200542005
the preceding	0.0006920415224913495
preceding token	1.0
token is	0.5
is on	0.0040650406504065045
on my	0.0047169811320754715
my hand-compiled	1.0
hand-compiled list	1.0
of abbreviations	0.0017825311942959
abbreviations ,	0.4
then it	0.05714285714285714
it does	0.008547008547008548
does n't	0.1
n't end	0.25
end a	0.125
b	2.7900228781876013e-05
preceding	2.7900228781876013e-05
my	2.7900228781876013e-05
hand-compiled	2.7900228781876013e-05
-LRB- c	0.0027100271002710027
c -RRB-	1.0
next token	0.14285714285714285
is capitalized	0.0020325203252032522
ends a	0.5
c	2.7900228781876013e-05
This strategy	0.015873015873015872
strategy gets	0.2
gets about	0.5
about 95	0.025
sentences correct	0.013157894736842105
rules from	0.023255813953488372
documents where	0.02631578947368421
sentence breaks	0.020833333333333332
breaks are	0.5
are pre-marked	0.004149377593360996
pre-marked .	1.0
breaks	5.5800457563752025e-05
pre-marked	2.7900228781876013e-05
<s> Solutions	0.0007686395080707148
Solutions have	1.0
been based	0.014705882352941176
entropy model	0.2
Solutions	2.7900228781876013e-05
The SATZ	0.005208333333333333
SATZ architecture	1.0
architecture uses	0.5
a neural	0.001226993865030675
neural network	0.3333333333333333
network to	0.16666666666666666
disambiguate sentence	0.3333333333333333
boundaries and	0.09090909090909091
and achieves	0.001445086705202312
achieves 98.5	0.5
98.5 %	1.0
SATZ	2.7900228781876013e-05
98.5	2.7900228781876013e-05
or opinion	0.0045045045045045045
opinion mining	0.2
mining refers	0.2
the application	0.0006920415224913495
, computational	0.0005614823133071309
text analytics	0.006289308176100629
analytics to	1.0
identify and	0.08333333333333333
and extract	0.001445086705202312
extract subjective	0.25
in source	0.0018726591760299626
source materials	0.041666666666666664
materials .	0.5
analytics	2.7900228781876013e-05
, sentiment	0.0005614823133071309
analysis aims	0.015384615384615385
the attitude	0.0006920415224913495
attitude of	0.5
a speaker	0.00245398773006135
speaker or	0.05555555555555555
a writer	0.001226993865030675
writer with	1.0
some topic	0.012048192771084338
topic or	0.125
overall contextual	0.16666666666666666
contextual polarity	0.5
polarity of	0.25
attitude	5.5800457563752025e-05
writer	2.7900228781876013e-05
The attitude	0.005208333333333333
attitude may	0.5
be his	0.004219409282700422
his or	0.08333333333333333
her judgement	0.5
judgement or	0.3333333333333333
or evaluation	0.0045045045045045045
evaluation -LRB-	0.018518518518518517
see appraisal	0.05
appraisal theory	1.0
theory -RRB-	0.07692307692307693
, affective	0.0005614823133071309
affective state	1.0
state -LRB-	0.07142857142857142
say ,	0.2857142857142857
the emotional	0.001384083044982699
emotional state	0.25
author when	0.3333333333333333
writing -RRB-	0.1111111111111111
intended emotional	0.2
emotional communication	0.25
communication -LRB-	0.4
emotional effect	0.25
effect the	0.5
author wishes	0.3333333333333333
wishes to	1.0
have on	0.009615384615384616
reader -RRB-	0.1
appraisal	2.7900228781876013e-05
affective	5.5800457563752025e-05
emotional	0.00011160091512750405
wishes	2.7900228781876013e-05
Advanced ,	0.2
`` beyond	0.005291005291005291
beyond polarity	0.16666666666666666
'' sentiment	0.005154639175257732
sentiment classification	0.04
classification looks	0.058823529411764705
looks ,	0.25
at emotional	0.014705882352941176
emotional states	0.25
states such	0.25
`` angry	0.005291005291005291
angry ,	0.5
'' ``	0.005154639175257732
`` sad	0.005291005291005291
sad ,	1.0
`` happy	0.005291005291005291
happy .	1.0
angry	5.5800457563752025e-05
sad	2.7900228781876013e-05
happy	2.7900228781876013e-05
Early work	0.5
work in	0.125
that area	0.0035460992907801418
area includes	0.09090909090909091
includes Turney	0.14285714285714285
and Pang	0.001445086705202312
Pang who	0.3333333333333333
who applied	0.1
applied different	0.06666666666666667
different methods	0.02040816326530612
for detecting	0.0036101083032490976
detecting the	1.0
the polarity	0.0006920415224913495
of product	0.00089126559714795
product reviews	0.14285714285714285
reviews and	0.16666666666666666
and movie	0.001445086705202312
movie reviews	0.3333333333333333
reviews respectively	0.16666666666666666
respectively .	1.0
Pang	8.370068634562804e-05
detecting	2.7900228781876013e-05
respectively	2.7900228781876013e-05
is at	0.0020325203252032522
document level	0.027777777777777776
level .	0.05
One can	0.07692307692307693
also classify	0.014492753623188406
classify a	0.5
document 's	0.027777777777777776
's polarity	0.0196078431372549
polarity on	0.125
a multi-way	0.001226993865030675
multi-way scale	1.0
scale ,	0.3333333333333333
was attempted	0.012987012987012988
attempted by	1.0
by Pang	0.005714285714285714
Pang and	0.3333333333333333
and Snyder	0.001445086705202312
Snyder -LRB-	0.5
among others	0.125
others -RRB-	0.08333333333333333
: expanded	0.00980392156862745
expanded the	1.0
the basic	0.001384083044982699
basic task	0.07692307692307693
of classifying	0.00089126559714795
classifying a	0.4
movie review	0.3333333333333333
review as	0.3333333333333333
as either	0.003484320557491289
either positive	0.1
negative to	0.125
to predicting	0.0013280212483399733
predicting star	0.5
star ratings	0.5
ratings on	0.1111111111111111
on either	0.0047169811320754715
a 3	0.001226993865030675
3 or	0.2
a 4	0.001226993865030675
4 star	0.2
star scale	0.5
while Snyder	0.05
Snyder performed	0.5
performed an	0.1
an in-depth	0.007575757575757576
in-depth analysis	0.3333333333333333
of restaurant	0.00089126559714795
restaurant reviews	0.5
reviews ,	0.5
, predicting	0.0005614823133071309
predicting ratings	0.5
ratings for	0.1111111111111111
for various	0.0036101083032490976
various aspects	0.05555555555555555
given restaurant	0.041666666666666664
restaurant ,	0.5
the food	0.0006920415224913495
food and	1.0
and atmosphere	0.001445086705202312
atmosphere -LRB-	1.0
a five-star	0.001226993865030675
five-star scale	1.0
scale -RRB-	0.16666666666666666
multi-way	2.7900228781876013e-05
scale	0.00016740137269125608
attempted	2.7900228781876013e-05
Snyder	5.5800457563752025e-05
expanded	2.7900228781876013e-05
predicting	5.5800457563752025e-05
star	5.5800457563752025e-05
restaurant	5.5800457563752025e-05
food	2.7900228781876013e-05
atmosphere	2.7900228781876013e-05
five-star	2.7900228781876013e-05
different method	0.02040816326530612
determining sentiment	0.16666666666666666
sentiment is	0.04
a scaling	0.001226993865030675
scaling system	1.0
system whereby	0.010752688172043012
whereby words	1.0
words commonly	0.009174311926605505
commonly associated	0.125
associated with	0.25
with having	0.00546448087431694
having a	0.2
a negative	0.001226993865030675
negative ,	0.125
, neutral	0.0005614823133071309
neutral or	0.5
or positive	0.0045045045045045045
positive sentiment	0.14285714285714285
sentiment with	0.04
with them	0.01639344262295082
given an	0.041666666666666664
an associated	0.007575757575757576
associated number	0.25
number on	0.023255813953488372
a -5	0.001226993865030675
-5 to	1.0
to +5	0.0013280212483399733
+5 scale	1.0
scale -LRB-	0.16666666666666666
most negative	0.017241379310344827
negative up	0.125
to most	0.0013280212483399733
most positive	0.017241379310344827
positive -RRB-	0.14285714285714285
and when	0.001445086705202312
of unstructured	0.00089126559714795
unstructured text	1.0
analyzed using	0.2
using natural	0.01694915254237288
the subsequent	0.0006920415224913495
subsequent concepts	0.5
are analyzed	0.004149377593360996
analyzed for	0.2
for an	0.0036101083032490976
they relate	0.025
relate to	1.0
the concept	0.001384083044982699
concept -LRB-	0.25
scaling	2.7900228781876013e-05
whereby	2.7900228781876013e-05
neutral	5.5800457563752025e-05
-5	2.7900228781876013e-05
+5	2.7900228781876013e-05
unstructured	2.7900228781876013e-05
relate	5.5800457563752025e-05
Each concept	0.16666666666666666
concept is	0.25
then given	0.02857142857142857
a score	0.001226993865030675
score based	0.16666666666666666
way sentiment	0.041666666666666664
sentiment words	0.04
words relate	0.009174311926605505
concept ,	0.25
their associated	0.029411764705882353
associated score	0.25
allows movement	0.125
movement to	1.0
sophisticated understanding	0.14285714285714285
of sentiment	0.004456327985739751
sentiment based	0.04
an 11	0.007575757575757576
11 point	1.0
point scale	0.3333333333333333
scale .	0.16666666666666666
movement	2.7900228781876013e-05
11	2.7900228781876013e-05
, texts	0.0005614823133071309
texts can	0.058823529411764705
be given	0.004219409282700422
a positive	0.001226993865030675
negative sentiment	0.125
sentiment strength	0.04
strength score	0.2
score if	0.16666666666666666
the sentiment	0.001384083044982699
sentiment in	0.08
text rather	0.006289308176100629
overall polarity	0.16666666666666666
polarity and	0.125
and strength	0.001445086705202312
Another research	0.07692307692307693
research direction	0.023809523809523808
direction is	0.3333333333333333
is subjectivity\/objectivity	0.0020325203252032522
subjectivity\/objectivity identification	1.0
identification .	0.2
subjectivity\/objectivity	2.7900228781876013e-05
commonly defined	0.125
defined as	0.16666666666666666
as classifying	0.003484320557491289
given text	0.041666666666666664
-LRB- usually	0.005420054200542005
usually a	0.03125
sentence -RRB-	0.041666666666666664
two classes	0.034482758620689655
classes :	0.2
: objective	0.00980392156862745
objective or	0.2
problem can	0.022727272727272728
can sometimes	0.0055248618784530384
sometimes be	0.07692307692307693
than polarity	0.022222222222222223
polarity classification	0.125
classification :	0.058823529411764705
the subjectivity	0.0006920415224913495
subjectivity of	0.5
phrases may	0.0625
may depend	0.019230769230769232
their context	0.029411764705882353
an objective	0.007575757575757576
objective document	0.2
document may	0.05555555555555555
may contain	0.038461538461538464
contain subjective	0.08333333333333333
subjective sentences	0.16666666666666666
article quoting	0.034482758620689655
quoting people	1.0
people 's	0.0625
's opinions	0.0196078431372549
opinions -RRB-	0.5
subjectivity	5.5800457563752025e-05
quoting	2.7900228781876013e-05
opinions	5.5800457563752025e-05
as mentioned	0.003484320557491289
mentioned by	0.16666666666666666
by Su	0.005714285714285714
Su ,	1.0
, results	0.0005614823133071309
are largely	0.004149377593360996
largely dependent	0.2
of subjectivity	0.00089126559714795
subjectivity used	0.5
when annotating	0.02857142857142857
annotating texts	1.0
Su	2.7900228781876013e-05
annotating	2.7900228781876013e-05
, Pang	0.0005614823133071309
Pang showed	0.3333333333333333
that removing	0.0035460992907801418
removing objective	0.5
objective sentences	0.2
document before	0.027777777777777776
before classifying	0.16666666666666666
classifying its	0.2
its polarity	0.02857142857142857
polarity helped	0.125
helped improve	0.3333333333333333
improve performance	0.07692307692307693
performance .	0.16666666666666666
The more	0.005208333333333333
more fine-grained	0.010526315789473684
fine-grained analysis	1.0
analysis model	0.015384615384615385
the feature\/aspect-based	0.0006920415224913495
feature\/aspect-based sentiment	1.0
fine-grained	2.7900228781876013e-05
feature\/aspect-based	2.7900228781876013e-05
It refers	0.02631578947368421
to determining	0.0013280212483399733
the opinions	0.0006920415224913495
opinions or	0.5
or sentiments	0.0045045045045045045
sentiments expressed	1.0
expressed on	0.3333333333333333
on different	0.0047169811320754715
different features	0.02040816326530612
features or	0.038461538461538464
or aspects	0.0045045045045045045
of entities	0.00089126559714795
entities ,	0.2857142857142857
a cell	0.00245398773006135
cell phone	1.0
phone ,	0.5
a digital	0.00245398773006135
digital camera	0.14285714285714285
camera ,	0.5
a bank	0.001226993865030675
bank .	1.0
sentiments	2.7900228781876013e-05
cell	5.5800457563752025e-05
camera	5.5800457563752025e-05
bank	2.7900228781876013e-05
A feature	0.02
feature or	0.07692307692307693
or aspect	0.0045045045045045045
aspect is	0.5
an attribute	0.007575757575757576
attribute or	0.5
or component	0.0045045045045045045
an entity	0.007575757575757576
the screen	0.0006920415224913495
screen of	1.0
the picture	0.001384083044982699
picture quality	0.25
a camera	0.001226993865030675
camera .	0.5
screen	2.7900228781876013e-05
involves several	0.1
several sub-problems	0.045454545454545456
sub-problems ,	1.0
identifying relevant	0.16666666666666666
relevant entities	0.14285714285714285
, extracting	0.0005614823133071309
extracting their	0.2
their features\/aspects	0.029411764705882353
features\/aspects ,	1.0
and determining	0.001445086705202312
determining whether	0.16666666666666666
whether an	0.07692307692307693
an opinion	0.007575757575757576
opinion expressed	0.2
on each	0.0047169811320754715
each feature\/aspect	0.022222222222222223
feature\/aspect is	1.0
is positive	0.0020325203252032522
positive ,	0.14285714285714285
, negative	0.0005614823133071309
negative or	0.125
or neutral	0.0045045045045045045
neutral .	0.5
sub-problems	2.7900228781876013e-05
features\/aspects	2.7900228781876013e-05
feature\/aspect	2.7900228781876013e-05
More detailed	0.1111111111111111
detailed discussions	0.5
discussions about	0.3333333333333333
about this	0.025
this level	0.01098901098901099
in Liu	0.0018726591760299626
Liu 's	1.0
's NLP	0.0196078431372549
NLP Handbook	0.02127659574468085
Handbook chapter	1.0
chapter ,	1.0
`` Sentiment	0.005291005291005291
Sentiment Analysis	0.16666666666666666
Analysis and	0.2
and Subjectivity	0.001445086705202312
Subjectivity ''	1.0
detailed	5.5800457563752025e-05
discussions	8.370068634562804e-05
Liu	2.7900228781876013e-05
Handbook	2.7900228781876013e-05
chapter	2.7900228781876013e-05
Subjectivity	2.7900228781876013e-05
Methods Computers	0.25
Computers can	1.0
can perform	0.0055248618784530384
perform automated	0.09090909090909091
automated sentiment	0.14285714285714285
of digital	0.00089126559714795
digital texts	0.14285714285714285
texts ,	0.11764705882352941
using elements	0.01694915254237288
elements from	0.25
learning such	0.023255813953488372
as latent	0.003484320557491289
latent semantic	1.0
, support	0.0005614823133071309
support vector	0.25
vector machines	0.3333333333333333
machines ,	0.25
`` bag	0.005291005291005291
bag of	1.0
and Semantic	0.001445086705202312
Semantic Orientation	0.3333333333333333
Orientation --	1.0
-- Pointwise	0.04
Pointwise Mutual	1.0
Mutual Information	1.0
Information -LRB-	0.2
See Peter	0.16666666666666666
Peter Turney	1.0
's work	0.0196078431372549
area -RRB-	0.09090909090909091
Computers	2.7900228781876013e-05
latent	2.7900228781876013e-05
bag	2.7900228781876013e-05
Orientation	2.7900228781876013e-05
Pointwise	2.7900228781876013e-05
Mutual	2.7900228781876013e-05
Peter	2.7900228781876013e-05
sophisticated methods	0.14285714285714285
methods try	0.022727272727272728
to detect	0.0013280212483399733
detect the	1.0
the holder	0.0006920415224913495
holder of	1.0
a sentiment	0.00245398773006135
sentiment -LRB-	0.04
person who	0.05263157894736842
who maintains	0.1
maintains that	1.0
that affective	0.0035460992907801418
state -RRB-	0.07142857142857142
target -LRB-	0.09090909090909091
the entity	0.0006920415224913495
entity about	0.2
about which	0.025
the affect	0.0006920415224913495
affect is	0.3333333333333333
is felt	0.0020325203252032522
felt -RRB-	1.0
detect	2.7900228781876013e-05
holder	2.7900228781876013e-05
maintains	2.7900228781876013e-05
felt	2.7900228781876013e-05
To mine	0.1111111111111111
mine the	1.0
the opinion	0.0006920415224913495
and get	0.001445086705202312
the feature	0.0006920415224913495
feature which	0.07692307692307693
been opinionated	0.014705882352941176
opinionated ,	1.0
grammatical relationships	0.09090909090909091
relationships of	0.16666666666666666
mine	2.7900228781876013e-05
opinionated	2.7900228781876013e-05
<s> Grammatical	0.0007686395080707148
Grammatical dependency	1.0
dependency relations	0.2
relations are	0.08333333333333333
are obtained	0.008298755186721992
by deep	0.005714285714285714
deep parsing	0.14285714285714285
parsing of	0.07142857142857142
Grammatical	2.7900228781876013e-05
<s> Open	0.0007686395080707148
Open source	1.0
source software	0.041666666666666664
software tools	0.037037037037037035
tools deploy	0.16666666666666666
deploy machine	1.0
statistics ,	0.125
to automate	0.0026560424966799467
automate sentiment	0.3333333333333333
analysis on	0.015384615384615385
on large	0.0047169811320754715
large collections	0.043478260869565216
collections of	0.25
including web	0.07142857142857142
web pages	0.125
, online	0.0016844469399213925
online news	0.125
news ,	0.07692307692307693
, internet	0.0005614823133071309
internet discussion	1.0
discussion groups	0.5
groups ,	0.2
, web	0.0005614823133071309
web blogs	0.125
blogs ,	0.5
media .	0.16666666666666666
Open	2.7900228781876013e-05
deploy	2.7900228781876013e-05
internet	2.7900228781876013e-05
blogs	5.5800457563752025e-05
Evaluation The	0.1111111111111111
analysis system	0.015384615384615385
in principle	0.0018726591760299626
principle ,	1.0
, how	0.0005614823133071309
it agrees	0.008547008547008548
agrees with	1.0
human judgments	0.021739130434782608
judgments .	1.0
principle	2.7900228781876013e-05
agrees	2.7900228781876013e-05
judgments	2.7900228781876013e-05
usually measured	0.03125
by precision	0.005714285714285714
human raters	0.021739130434782608
raters typically	1.0
typically agree	0.05555555555555555
agree about	0.3333333333333333
see Inter-rater	0.05
Inter-rater reliability	1.0
reliability -RRB-	0.5
raters	2.7900228781876013e-05
Inter-rater	2.7900228781876013e-05
a 70	0.001226993865030675
accurate program	0.14285714285714285
program is	0.045454545454545456
is doing	0.0020325203252032522
doing as	0.5
as humans	0.003484320557491289
humans ,	0.16666666666666666
though such	0.1
such accuracy	0.008130081300813009
accuracy may	0.03225806451612903
not sound	0.008928571428571428
sound impressive	0.05
impressive .	0.5
If a	0.1
program were	0.045454545454545456
were ``	0.024390243902439025
`` right	0.005291005291005291
right ''	0.1
'' 100	0.005154639175257732
, humans	0.0005614823133071309
humans would	0.08333333333333333
would still	0.018867924528301886
still disagree	0.06666666666666667
disagree with	0.3333333333333333
it about	0.008547008547008548
about 30	0.025
30 %	0.3333333333333333
since they	0.1
they disagree	0.025
disagree that	0.3333333333333333
that much	0.0035460992907801418
much about	0.045454545454545456
about any	0.025
any answer	0.03225806451612903
disagree	8.370068634562804e-05
sophisticated measures	0.14285714285714285
applied ,	0.06666666666666667
but evaluation	0.014705882352941176
analysis systems	0.015384615384615385
systems remains	0.008928571428571428
remains a	0.25
complex matter	0.041666666666666664
matter .	0.3333333333333333
For sentiment	0.01639344262295082
analysis tasks	0.015384615384615385
tasks returning	0.03125
a scale	0.001226993865030675
scale rather	0.16666666666666666
binary judgement	0.25
judgement ,	0.3333333333333333
, correlation	0.0005614823133071309
correlation is	0.5
a better	0.00245398773006135
better measure	0.1111111111111111
measure than	0.09090909090909091
than precision	0.022222222222222223
precision because	0.2
it takes	0.008547008547008548
takes into	0.3333333333333333
account how	0.3333333333333333
how close	0.034482758620689655
close the	1.0
the predicted	0.0006920415224913495
predicted value	0.5
value is	0.3333333333333333
target value	0.09090909090909091
value .	0.3333333333333333
correlation	5.5800457563752025e-05
close	2.7900228781876013e-05
test the	0.1
the relationship	0.0006920415224913495
relationship between	0.16666666666666666
between Internet	0.02564102564102564
Internet financial	0.5
financial message	0.25
message boards	0.5
boards and	1.0
the behavior	0.0006920415224913495
behavior of	0.5
the stock	0.0006920415224913495
stock market	0.3333333333333333
market to	0.3333333333333333
find a	0.15384615384615385
a strong	0.00245398773006135
strong correlation	0.25
correlation between	0.5
between posts	0.02564102564102564
posts and	1.0
and volume	0.001445086705202312
of stock	0.00089126559714795
boards	2.7900228781876013e-05
market	8.370068634562804e-05
strong	0.00011160091512750405
posts	2.7900228781876013e-05
and Web	0.001445086705202312
Web 2.0	0.1111111111111111
2.0 The	0.5
The rise	0.005208333333333333
rise of	0.5
media such	0.16666666666666666
as blogs	0.003484320557491289
blogs and	0.5
networks has	0.07142857142857142
has fueled	0.011904761904761904
fueled interest	1.0
in sentiment	0.0018726591760299626
2.0	5.5800457563752025e-05
fueled	2.7900228781876013e-05
the proliferation	0.0006920415224913495
proliferation of	1.0
of reviews	0.00089126559714795
, ratings	0.0005614823133071309
ratings ,	0.1111111111111111
, recommendations	0.0005614823133071309
recommendations and	1.0
other forms	0.014285714285714285
of online	0.00089126559714795
online expression	0.125
online opinion	0.125
opinion has	0.2
has turned	0.011904761904761904
turned into	1.0
a kind	0.001226993865030675
of virtual	0.00089126559714795
virtual currency	1.0
currency for	1.0
for businesses	0.0036101083032490976
businesses looking	0.5
looking to	0.4
to market	0.0013280212483399733
market their	0.3333333333333333
their products	0.029411764705882353
products ,	0.25
identify new	0.08333333333333333
new opportunities	0.041666666666666664
opportunities and	1.0
and manage	0.001445086705202312
manage their	1.0
their reputations	0.029411764705882353
reputations .	1.0
proliferation	2.7900228781876013e-05
recommendations	2.7900228781876013e-05
turned	5.5800457563752025e-05
virtual	2.7900228781876013e-05
currency	2.7900228781876013e-05
businesses	5.5800457563752025e-05
opportunities	2.7900228781876013e-05
manage	2.7900228781876013e-05
reputations	2.7900228781876013e-05
As businesses	0.05555555555555555
businesses look	0.5
look to	0.2
automate the	0.3333333333333333
of filtering	0.00089126559714795
filtering out	1.0
the noise	0.0006920415224913495
noise ,	0.125
, understanding	0.0005614823133071309
the conversations	0.0006920415224913495
conversations ,	0.3333333333333333
the relevant	0.0006920415224913495
relevant content	0.14285714285714285
and actioning	0.001445086705202312
actioning it	1.0
it appropriately	0.008547008547008548
appropriately ,	0.5
many are	0.019230769230769232
now looking	0.07692307692307693
filtering	2.7900228781876013e-05
noise	0.0002232018302550081
actioning	2.7900228781876013e-05
appropriately	5.5800457563752025e-05
If web	0.1
web 2.0	0.125
2.0 was	0.5
was all	0.012987012987012988
all about	0.023255813953488372
about democratizing	0.025
democratizing publishing	0.5
publishing ,	1.0
web may	0.125
may well	0.019230769230769232
well be	0.03571428571428571
be based	0.004219409282700422
on democratizing	0.0047169811320754715
democratizing data	0.5
mining of	0.2
content that	0.08333333333333333
getting published	0.25
published .	0.14285714285714285
democratizing	5.5800457563752025e-05
publishing	2.7900228781876013e-05
One step	0.07692307692307693
step towards	0.06666666666666667
towards this	1.0
this aim	0.01098901098901099
aim is	0.5
is accomplished	0.0020325203252032522
accomplished in	1.0
in research	0.0018726591760299626
towards	2.7900228781876013e-05
accomplished	2.7900228781876013e-05
Several research	0.3333333333333333
research teams	0.023809523809523808
teams in	0.5
in universities	0.0018726591760299626
universities around	1.0
world currently	0.06666666666666667
currently focus	0.14285714285714285
on understanding	0.0047169811320754715
the dynamics	0.0006920415224913495
dynamics of	0.5
in e-communities	0.0018726591760299626
e-communities through	0.5
through sentiment	0.125
universities	2.7900228781876013e-05
dynamics	5.5800457563752025e-05
e-communities	5.5800457563752025e-05
The CyberEmotions	0.005208333333333333
CyberEmotions project	1.0
, recently	0.0005614823133071309
recently identified	0.3333333333333333
identified the	0.2
role of	0.25
of negative	0.00089126559714795
negative emotions	0.125
emotions in	1.0
in driving	0.0018726591760299626
driving social	1.0
networks discussions	0.07142857142857142
discussions .	0.3333333333333333
CyberEmotions	2.7900228781876013e-05
emotions	2.7900228781876013e-05
driving	2.7900228781876013e-05
analysis could	0.015384615384615385
could therefore	0.0625
therefore help	0.2
help understand	0.1111111111111111
understand why	0.14285714285714285
why certain	0.14285714285714285
certain e-communities	0.14285714285714285
e-communities die	0.5
die or	1.0
or fade	0.0045045045045045045
fade away	1.0
away -LRB-	0.5
, MySpace	0.0005614823133071309
MySpace -RRB-	1.0
-RRB- while	0.0027100271002710027
others seem	0.08333333333333333
seem to	0.5
to grow	0.0013280212483399733
grow without	1.0
without limits	0.07692307692307693
limits -LRB-	1.0
, Facebook	0.0005614823133071309
Facebook -RRB-	1.0
die	2.7900228781876013e-05
fade	2.7900228781876013e-05
MySpace	2.7900228781876013e-05
grow	2.7900228781876013e-05
limits	2.7900228781876013e-05
Facebook	2.7900228781876013e-05
problem is	0.11363636363636363
that most	0.0035460992907801418
most sentiment	0.017241379310344827
analysis algorithms	0.015384615384615385
algorithms use	0.02857142857142857
use simple	0.013888888888888888
simple terms	0.038461538461538464
terms to	0.07692307692307693
to express	0.0013280212483399733
express sentiment	0.2
sentiment about	0.04
about a	0.025
a product	0.001226993865030675
product or	0.14285714285714285
or service	0.0045045045045045045
service .	0.2
, cultural	0.0005614823133071309
cultural factors	1.0
factors ,	0.3333333333333333
, linguistic	0.0005614823133071309
linguistic nuances	0.0625
nuances and	1.0
and differing	0.001445086705202312
contexts make	0.14285714285714285
it extremely	0.008547008547008548
to turn	0.0013280212483399733
turn a	0.16666666666666666
a string	0.00245398773006135
written text	0.11538461538461539
a simple	0.001226993865030675
simple pro	0.038461538461538464
pro or	1.0
or con	0.0045045045045045045
con sentiment	1.0
sentiment .	0.04
cultural	2.7900228781876013e-05
nuances	2.7900228781876013e-05
pro	2.7900228781876013e-05
con	2.7900228781876013e-05
The fact	0.005208333333333333
humans often	0.08333333333333333
often disagree	0.022727272727272728
disagree on	0.3333333333333333
sentiment of	0.04
text illustrates	0.006289308176100629
illustrates how	0.5
how big	0.034482758620689655
big a	0.5
task it	0.023809523809523808
is for	0.0020325203252032522
for computers	0.0036101083032490976
computers to	0.1111111111111111
get this	0.14285714285714285
this right	0.01098901098901099
The shorter	0.005208333333333333
shorter the	0.5
the string	0.0006920415224913495
harder it	0.14285714285714285
it becomes	0.03418803418803419
becomes .	0.25
shorter	5.5800457563752025e-05
becomes	0.00011160091512750405
<s> n	0.0007686395080707148
n Computer	0.5
Computer Science	0.16666666666666666
Science ,	0.5
, Speech	0.0016844469399213925
of spoken	0.0017825311942959
spoken words	0.14285714285714285
into text	0.038461538461538464
n	5.5800457563752025e-05
`` automatic	0.005291005291005291
recognition ''	0.01652892561983471
`` ASR	0.005291005291005291
ASR ''	0.16666666666666666
`` computer	0.005291005291005291
computer speech	0.022727272727272728
`` speech	0.005291005291005291
to text	0.0026560424966799467
text ''	0.006289308176100629
or just	0.0045045045045045045
just ``	0.1111111111111111
`` STT	0.005291005291005291
STT ''	1.0
ASR	0.00016740137269125608
STT	2.7900228781876013e-05
Speech Recognition	0.0967741935483871
Recognition is	0.125
is technology	0.0020325203252032522
technology that	0.045454545454545456
can translate	0.0055248618784530384
translate spoken	0.16666666666666666
Some SR	0.047619047619047616
SR systems	0.3333333333333333
use ``	0.013888888888888888
`` training	0.005291005291005291
training ''	0.03571428571428571
'' where	0.005154639175257732
where an	0.02857142857142857
an individual	0.007575757575757576
individual speaker	0.08333333333333333
speaker reads	0.05555555555555555
reads sections	0.5
the SR	0.0006920415224913495
SR system	0.3333333333333333
SR	8.370068634562804e-05
reads	5.5800457563752025e-05
systems analyze	0.008928571428571428
analyze the	0.25
's specific	0.0196078431372549
specific voice	0.047619047619047616
voice and	0.07692307692307693
and use	0.004335260115606936
to fine	0.0013280212483399733
fine tune	0.5
tune the	1.0
that person	0.0035460992907801418
's speech	0.0196078431372549
, resulting	0.0005614823133071309
resulting in	0.25
in more	0.0018726591760299626
accurate transcription	0.14285714285714285
transcription .	0.5
voice	0.00036270297416438817
tune	2.7900228781876013e-05
transcription	5.5800457563752025e-05
that do	0.0035460992907801418
use training	0.027777777777777776
training are	0.07142857142857142
are called	0.008298755186721992
`` Speaker	0.010582010582010581
Speaker Independent	0.16666666666666666
Independent ''	1.0
Speaker	0.00016740137269125608
Independent	2.7900228781876013e-05
Speaker Dependent	0.16666666666666666
Dependent ''	1.0
Dependent	2.7900228781876013e-05
recognition applications	0.008264462809917356
include voice	0.037037037037037035
voice user	0.07692307692307693
interfaces such	0.5
as voice	0.003484320557491289
voice dialing	0.07692307692307693
dialing -LRB-	1.0
`` Call	0.005291005291005291
Call home	1.0
home ''	1.0
, call	0.0005614823133071309
call routing	0.3333333333333333
routing -LRB-	0.3333333333333333
`` I	0.005291005291005291
I would	1.0
a collect	0.001226993865030675
collect call	1.0
call ''	0.3333333333333333
, domotic	0.0005614823133071309
domotic appliance	1.0
appliance control	1.0
control ,	0.2
search -LRB-	0.09090909090909091
a podcast	0.001226993865030675
podcast where	1.0
where particular	0.02857142857142857
particular words	0.07692307692307693
were spoken	0.024390243902439025
spoken -RRB-	0.07142857142857142
simple data	0.038461538461538464
entry -LRB-	0.25
, entering	0.0011229646266142617
entering a	0.5
card number	0.25
, preparation	0.0005614823133071309
preparation of	1.0
of structured	0.00089126559714795
structured documents	0.16666666666666666
a radiology	0.001226993865030675
radiology report	1.0
report -RRB-	0.25
, speech-to-text	0.0005614823133071309
speech-to-text processing	0.5
, word	0.0005614823133071309
word processors	0.016666666666666666
processors or	1.0
or emails	0.0045045045045045045
emails -RRB-	0.5
and aircraft	0.001445086705202312
aircraft -LRB-	0.2857142857142857
usually termed	0.03125
termed Direct	0.25
Direct Voice	1.0
Voice Input	0.2
Input -RRB-	0.5
dialing	2.7900228781876013e-05
Call	2.7900228781876013e-05
home	2.7900228781876013e-05
I	2.7900228781876013e-05
collect	2.7900228781876013e-05
domotic	2.7900228781876013e-05
appliance	2.7900228781876013e-05
podcast	2.7900228781876013e-05
entering	5.5800457563752025e-05
preparation	2.7900228781876013e-05
radiology	2.7900228781876013e-05
speech-to-text	5.5800457563752025e-05
processors	2.7900228781876013e-05
aircraft	0.0001953016014731321
Direct	2.7900228781876013e-05
Voice	0.00013950114390938006
term voice	0.05555555555555555
voice recognition	0.07692307692307693
recognition refers	0.008264462809917356
to finding	0.0013280212483399733
`` who	0.005291005291005291
who ''	0.1
is speaking	0.0020325203252032522
than what	0.022222222222222223
what they	0.03125
are saying	0.004149377593360996
saying .	1.0
saying	2.7900228781876013e-05
<s> Recognizing	0.0007686395080707148
Recognizing the	1.0
the speaker	0.001384083044982699
speaker can	0.05555555555555555
can simplify	0.0055248618784530384
simplify the	1.0
of translating	0.00089126559714795
translating speech	0.25
been trained	0.014705882352941176
trained on	0.3333333333333333
on specific	0.0047169811320754715
specific person	0.047619047619047616
's voices	0.0196078431372549
voices or	1.0
or it	0.0045045045045045045
to authenticate	0.0013280212483399733
authenticate or	1.0
or verify	0.0045045045045045045
verify the	1.0
speaker as	0.05555555555555555
a security	0.001226993865030675
security process	1.0
Recognizing	2.7900228781876013e-05
simplify	2.7900228781876013e-05
trained	8.370068634562804e-05
voices	2.7900228781876013e-05
authenticate	2.7900228781876013e-05
verify	2.7900228781876013e-05
security	2.7900228781876013e-05
<s> Front-End	0.0007686395080707148
Front-End speech	1.0
is where	0.0040650406504065045
the provider	0.001384083044982699
provider dictates	1.0
dictates into	1.0
a speech-recognition	0.0036809815950920245
speech-recognition engine	0.6666666666666666
engine ,	0.16666666666666666
the recognized	0.001384083044982699
recognized words	0.16666666666666666
are displayed	0.004149377593360996
displayed as	0.5
are spoken	0.004149377593360996
the dictator	0.0006920415224913495
dictator is	1.0
is responsible	0.0020325203252032522
responsible for	1.0
for editing	0.0036101083032490976
editing and	0.5
and signing	0.001445086705202312
signing off	1.0
off on	0.5
Front-End	2.7900228781876013e-05
provider	5.5800457563752025e-05
dictates	5.5800457563752025e-05
speech-recognition	8.370068634562804e-05
dictator	2.7900228781876013e-05
responsible	2.7900228781876013e-05
signing	2.7900228781876013e-05
<s> Back-End	0.0007686395080707148
Back-End or	1.0
or deferred	0.0045045045045045045
deferred speech	1.0
digital dictation	0.14285714285714285
dictation system	1.0
the voice	0.0006920415224913495
voice is	0.07692307692307693
is routed	0.0040650406504065045
routed through	0.5
speech-recognition machine	0.3333333333333333
machine and	0.012658227848101266
recognized draft	0.16666666666666666
draft document	0.5
document is	0.027777777777777776
routed along	0.5
original voice	0.07692307692307693
voice file	0.07692307692307693
file to	1.0
the editor	0.0006920415224913495
editor ,	1.0
the draft	0.0006920415224913495
draft is	0.5
is edited	0.0020325203252032522
edited and	1.0
and report	0.001445086705202312
report finalized	0.25
finalized .	1.0
Back-End	2.7900228781876013e-05
deferred	2.7900228781876013e-05
dictation	2.7900228781876013e-05
routed	5.5800457563752025e-05
draft	5.5800457563752025e-05
file	2.7900228781876013e-05
editor	2.7900228781876013e-05
edited	2.7900228781876013e-05
finalized	2.7900228781876013e-05
<s> Deferred	0.0007686395080707148
Deferred speech	1.0
the industry	0.0006920415224913495
industry currently	0.3333333333333333
currently .	0.14285714285714285
Deferred	2.7900228781876013e-05
Many Electronic	0.08333333333333333
Electronic Medical	0.5
Medical Records	0.5
Records -LRB-	1.0
-LRB- EMR	0.0027100271002710027
EMR -RRB-	0.3333333333333333
-RRB- applications	0.0027100271002710027
applications can	0.04
more effective	0.010526315789473684
effective and	0.16666666666666666
performed more	0.1
more easily	0.010526315789473684
easily when	0.1111111111111111
when deployed	0.02857142857142857
deployed in	0.5
in conjunction	0.003745318352059925
conjunction with	0.6666666666666666
Electronic	5.5800457563752025e-05
Records	2.7900228781876013e-05
EMR	8.370068634562804e-05
<s> Searches	0.0007686395080707148
Searches ,	1.0
, queries	0.0005614823133071309
queries ,	0.3333333333333333
and form	0.001445086705202312
form filling	0.05
filling may	1.0
may all	0.019230769230769232
all be	0.023255813953488372
be faster	0.004219409282700422
faster to	0.3333333333333333
perform by	0.09090909090909091
by voice	0.011428571428571429
voice than	0.07692307692307693
than by	0.022222222222222223
a keyboard	0.001226993865030675
keyboard .	0.3333333333333333
Searches	2.7900228781876013e-05
filling	2.7900228781876013e-05
faster	8.370068634562804e-05
keyboard	8.370068634562804e-05
major issues	0.08333333333333333
issues relating	0.2
relating to	1.0
recognition in	0.024793388429752067
in healthcare	0.0018726591760299626
healthcare is	1.0
American Recovery	0.2
Recovery and	1.0
and Reinvestment	0.001445086705202312
Reinvestment Act	1.0
Act of	1.0
of 2009	0.00089126559714795
2009 -LRB-	0.3333333333333333
-LRB- ARRA	0.0027100271002710027
ARRA -RRB-	1.0
-RRB- provides	0.0027100271002710027
provides for	0.5
for substantial	0.0036101083032490976
substantial financial	0.2
financial benefits	0.25
benefits to	0.5
to physicians	0.0013280212483399733
physicians who	1.0
who utilize	0.1
utilize an	0.5
an EMR	0.007575757575757576
EMR according	0.3333333333333333
`` Meaningful	0.005291005291005291
Meaningful Use	1.0
Use ''	0.5
'' standards	0.005154639175257732
relating	2.7900228781876013e-05
healthcare	2.7900228781876013e-05
Recovery	2.7900228781876013e-05
Reinvestment	2.7900228781876013e-05
Act	2.7900228781876013e-05
ARRA	2.7900228781876013e-05
provides	5.5800457563752025e-05
physicians	2.7900228781876013e-05
utilize	5.5800457563752025e-05
Meaningful	2.7900228781876013e-05
These standards	0.058823529411764705
standards require	0.2
require that	0.045454545454545456
a substantial	0.001226993865030675
substantial amount	0.2
data be	0.012987012987012988
be maintained	0.004219409282700422
maintained by	0.5
the EMR	0.0006920415224913495
EMR -LRB-	0.3333333333333333
-LRB- now	0.008130081300813009
now more	0.07692307692307693
commonly referred	0.125
an Electronic	0.007575757575757576
Electronic Health	0.5
Health Record	0.5
Record or	1.0
or EHR	0.0045045045045045045
EHR -RRB-	0.3333333333333333
maintained	5.5800457563752025e-05
Record	2.7900228781876013e-05
EHR	8.370068634562804e-05
<s> Unfortunately	0.0007686395080707148
Unfortunately ,	1.0
many instances	0.019230769230769232
instances ,	0.3333333333333333
recognition within	0.008264462809917356
within an	0.05555555555555555
an EHR	0.007575757575757576
EHR will	0.3333333333333333
not lead	0.008928571428571428
data maintained	0.012987012987012988
maintained within	0.5
database ,	0.1
rather to	0.0625
to narrative	0.0013280212483399733
narrative text	1.0
Unfortunately	2.7900228781876013e-05
narrative	2.7900228781876013e-05
this reason	0.02197802197802198
reason ,	0.5
, substantial	0.0005614823133071309
substantial resources	0.2
resources are	0.16666666666666666
being expended	0.05555555555555555
expended to	1.0
allow for	0.2
of front-end	0.00089126559714795
front-end SR	1.0
SR while	0.3333333333333333
while capturing	0.05
capturing data	1.0
data within	0.012987012987012988
the EHR	0.0006920415224913495
EHR .	0.3333333333333333
expended	2.7900228781876013e-05
front-end	2.7900228781876013e-05
capturing	2.7900228781876013e-05
<s> Military	0.0007686395080707148
Military High-performance	1.0
High-performance fighter	1.0
fighter aircraft	0.5
aircraft Substantial	0.14285714285714285
Substantial efforts	0.5
been devoted	0.014705882352941176
devoted in	0.2
last decade	0.4
decade to	0.3333333333333333
test and	0.2
in fighter	0.0056179775280898875
aircraft .	0.14285714285714285
Military	2.7900228781876013e-05
High-performance	2.7900228781876013e-05
fighter	0.00016740137269125608
Substantial	5.5800457563752025e-05
decade	8.370068634562804e-05
<s> Of	0.0007686395080707148
Of particular	1.0
particular note	0.07692307692307693
note is	1.0
U.S. program	0.14285714285714285
program in	0.09090909090909091
in speech	0.013108614232209739
recognition for	0.008264462809917356
the Advanced	0.0006920415224913495
Advanced Fighter	0.2
Fighter Technology	1.0
Technology Integration	0.3333333333333333
Integration -LRB-	1.0
-LRB- AFTI	0.0027100271002710027
AFTI -RRB-	1.0
-RRB- \/	0.0027100271002710027
\/ F-16	0.3333333333333333
F-16 aircraft	0.5
-LRB- F-16	0.0027100271002710027
F-16 VISTA	0.5
VISTA -RRB-	1.0
in France	0.003745318352059925
France installing	0.25
installing speech	1.0
systems on	0.008928571428571428
on Mirage	0.0047169811320754715
Mirage aircraft	1.0
aircraft ,	0.2857142857142857
and also	0.001445086705202312
also programs	0.014492753623188406
programs in	0.09090909090909091
UK dealing	0.25
of aircraft	0.00089126559714795
aircraft platforms	0.14285714285714285
platforms .	1.0
Of	2.7900228781876013e-05
note	2.7900228781876013e-05
Fighter	2.7900228781876013e-05
Technology	8.370068634562804e-05
Integration	2.7900228781876013e-05
AFTI	2.7900228781876013e-05
F-16	5.5800457563752025e-05
VISTA	2.7900228781876013e-05
installing	2.7900228781876013e-05
Mirage	2.7900228781876013e-05
platforms	2.7900228781876013e-05
In these	0.009523809523809525
these programs	0.023809523809523808
speech recognizers	0.006578947368421052
recognizers have	0.5
been operated	0.014705882352941176
operated successfully	0.5
successfully in	0.3333333333333333
with applications	0.00546448087431694
applications including	0.04
: setting	0.00980392156862745
setting radio	0.2
radio frequencies	1.0
frequencies ,	0.5
, commanding	0.0005614823133071309
commanding an	1.0
an autopilot	0.007575757575757576
autopilot system	1.0
, setting	0.0011229646266142617
setting steer-point	0.2
steer-point coordinates	1.0
coordinates and	1.0
and weapons	0.001445086705202312
weapons release	1.0
release parameters	0.3333333333333333
parameters ,	0.25
and controlling	0.001445086705202312
controlling flight	1.0
flight displays	0.5
displays .	1.0
recognizers	5.5800457563752025e-05
radio	2.7900228781876013e-05
commanding	2.7900228781876013e-05
autopilot	2.7900228781876013e-05
steer-point	2.7900228781876013e-05
coordinates	2.7900228781876013e-05
weapons	2.7900228781876013e-05
controlling	2.7900228781876013e-05
displays	2.7900228781876013e-05
<s> Working	0.0007686395080707148
Working with	1.0
with Swedish	0.00546448087431694
Swedish pilots	1.0
pilots flying	0.5
flying in	1.0
the JAS-39	0.0006920415224913495
JAS-39 Gripen	1.0
Gripen cockpit	1.0
cockpit ,	0.5
, Englund	0.0005614823133071309
Englund -LRB-	1.0
-LRB- 2004	0.0027100271002710027
2004 -RRB-	0.3333333333333333
-RRB- found	0.0027100271002710027
found recognition	0.07142857142857142
recognition deteriorated	0.008264462809917356
deteriorated with	1.0
with increasing	0.00546448087431694
increasing G-loads	0.3333333333333333
G-loads .	1.0
Working	2.7900228781876013e-05
Swedish	2.7900228781876013e-05
pilots	5.5800457563752025e-05
flying	2.7900228781876013e-05
JAS-39	2.7900228781876013e-05
Gripen	2.7900228781876013e-05
cockpit	5.5800457563752025e-05
Englund	2.7900228781876013e-05
deteriorated	2.7900228781876013e-05
G-loads	2.7900228781876013e-05
It was	0.05263157894736842
also concluded	0.014492753623188406
that adaptation	0.0035460992907801418
adaptation greatly	0.3333333333333333
greatly improved	0.14285714285714285
improved the	0.25
results in	0.047619047619047616
in all	0.0056179775280898875
all cases	0.023255813953488372
cases and	0.05555555555555555
and introducing	0.001445086705202312
introducing models	1.0
for breathing	0.0036101083032490976
breathing was	1.0
improve recognition	0.15384615384615385
recognition scores	0.008264462809917356
scores significantly	0.2
significantly .	1.0
adaptation	8.370068634562804e-05
introducing	2.7900228781876013e-05
breathing	2.7900228781876013e-05
significantly	2.7900228781876013e-05
what might	0.03125
be expected	0.012658227848101266
expected ,	0.14285714285714285
no effects	0.07692307692307693
effects of	1.0
the broken	0.0006920415224913495
broken English	0.2
English of	0.02702702702702703
the speakers	0.0006920415224913495
speakers were	0.25
found .	0.07142857142857142
effects	2.7900228781876013e-05
broken	0.00013950114390938006
was evident	0.012987012987012988
evident that	0.5
that spontaneous	0.0035460992907801418
spontaneous speech	1.0
speech caused	0.006578947368421052
caused problems	1.0
problems for	0.058823529411764705
the recognizer	0.0006920415224913495
recognizer ,	1.0
as could	0.003484320557491289
expected .	0.14285714285714285
spontaneous	8.370068634562804e-05
caused	2.7900228781876013e-05
recognizer	2.7900228781876013e-05
A restricted	0.02
restricted vocabulary	0.25
vocabulary ,	0.125
and above	0.001445086705202312
above all	0.07692307692307693
a proper	0.001226993865030675
proper syntax	0.14285714285714285
, could	0.0005614823133071309
could thus	0.0625
thus be	0.1
accuracy substantially	0.03225806451612903
substantially .	1.0
substantially	2.7900228781876013e-05
The Eurofighter	0.005208333333333333
Eurofighter Typhoon	1.0
Typhoon currently	1.0
currently in	0.14285714285714285
in service	0.0018726591760299626
service with	0.2
UK RAF	0.25
RAF employs	1.0
employs a	0.5
a speaker-dependent	0.001226993865030675
speaker-dependent system	1.0
i.e. it	0.05263157894736842
requires each	0.0625
each pilot	0.022222222222222223
pilot to	0.4
template .	0.25
Eurofighter	2.7900228781876013e-05
Typhoon	2.7900228781876013e-05
RAF	2.7900228781876013e-05
speaker-dependent	2.7900228781876013e-05
pilot	0.00013950114390938006
for any	0.0036101083032490976
any safety	0.03225806451612903
safety critical	1.0
critical or	0.25
or weapon	0.0045045045045045045
weapon critical	0.5
critical tasks	0.25
as weapon	0.003484320557491289
weapon release	0.5
release or	0.3333333333333333
or lowering	0.0045045045045045045
lowering of	1.0
the undercarriage	0.0006920415224913495
undercarriage ,	1.0
other cockpit	0.014285714285714285
cockpit functions	0.5
functions .	0.5
safety	2.7900228781876013e-05
weapon	5.5800457563752025e-05
lowering	2.7900228781876013e-05
undercarriage	2.7900228781876013e-05
<s> Voice	0.0007686395080707148
Voice commands	0.2
commands are	0.2
are confirmed	0.004149377593360996
confirmed by	1.0
by visual	0.005714285714285714
visual and\/or	0.5
and\/or aural	0.3333333333333333
aural feedback	1.0
feedback .	0.5
confirmed	2.7900228781876013e-05
aural	2.7900228781876013e-05
is seen	0.0020325203252032522
major design	0.08333333333333333
design feature	0.25
feature in	0.07692307692307693
the reduction	0.0006920415224913495
reduction of	0.5
of pilot	0.00089126559714795
pilot workload	0.2
workload ,	1.0
even allows	0.037037037037037035
the pilot	0.0006920415224913495
assign targets	0.2
targets to	1.0
to himself	0.0013280212483399733
himself with	0.5
two simple	0.034482758620689655
simple voice	0.038461538461538464
voice commands	0.07692307692307693
commands or	0.2
his wingmen	0.08333333333333333
wingmen with	1.0
with only	0.00546448087431694
only five	0.02631578947368421
five commands	0.2
commands .	0.4
reduction	5.5800457563752025e-05
workload	2.7900228781876013e-05
targets	2.7900228781876013e-05
wingmen	2.7900228781876013e-05
<s> Speaker	0.0015372790161414297
Speaker independent	0.16666666666666666
independent systems	0.5
also being	0.014492753623188406
being developed	0.05555555555555555
developed and	0.038461538461538464
in testing	0.0018726591760299626
testing for	0.2
the F35	0.0006920415224913495
F35 Lightning	1.0
Lightning II	1.0
II -LRB-	0.5
-LRB- JSF	0.0027100271002710027
JSF -RRB-	1.0
the Alenia	0.0006920415224913495
Alenia Aermacchi	1.0
Aermacchi M-346	1.0
M-346 Master	1.0
Master lead-in	1.0
lead-in fighter	1.0
fighter trainer	0.16666666666666666
trainer .	1.0
independent	5.5800457563752025e-05
F35	2.7900228781876013e-05
Lightning	2.7900228781876013e-05
JSF	2.7900228781876013e-05
Alenia	2.7900228781876013e-05
Aermacchi	2.7900228781876013e-05
M-346	2.7900228781876013e-05
Master	2.7900228781876013e-05
lead-in	2.7900228781876013e-05
trainer	2.7900228781876013e-05
have produced	0.009615384615384616
produced word	0.1111111111111111
word accuracies	0.016666666666666666
accuracies in	1.0
in excess	0.003745318352059925
excess of	1.0
of 98	0.00089126559714795
accuracies	2.7900228781876013e-05
excess	5.5800457563752025e-05
<s> Helicopters	0.0007686395080707148
Helicopters The	1.0
The problems	0.005208333333333333
problems of	0.058823529411764705
achieving high	0.5
high recognition	0.05555555555555555
accuracy under	0.03225806451612903
under stress	0.2
stress and	0.5
and noise	0.001445086705202312
noise pertain	0.125
pertain strongly	1.0
strongly to	0.5
the helicopter	0.0020761245674740486
helicopter environment	0.5
environment as	0.16666666666666666
the jet	0.0006920415224913495
jet fighter	1.0
fighter environment	0.16666666666666666
environment .	0.3333333333333333
Helicopters	2.7900228781876013e-05
stress	5.5800457563752025e-05
pertain	2.7900228781876013e-05
helicopter	0.00011160091512750405
jet	2.7900228781876013e-05
The acoustic	0.005208333333333333
acoustic noise	0.3333333333333333
noise problem	0.125
actually more	0.3333333333333333
more severe	0.010526315789473684
severe in	1.0
environment ,	0.16666666666666666
only because	0.02631578947368421
the high	0.001384083044982699
high noise	0.05555555555555555
noise levels	0.125
levels but	0.045454545454545456
also because	0.014492753623188406
helicopter pilot	0.25
pilot ,	0.2
not wear	0.008928571428571428
wear a	1.0
a facemask	0.001226993865030675
facemask ,	1.0
would reduce	0.018867924528301886
reduce acoustic	1.0
noise in	0.125
the microphone	0.0006920415224913495
microphone .	1.0
acoustic	0.00016740137269125608
severe	2.7900228781876013e-05
wear	2.7900228781876013e-05
facemask	2.7900228781876013e-05
reduce	2.7900228781876013e-05
microphone	2.7900228781876013e-05
<s> Substantial	0.0007686395080707148
Substantial test	0.5
evaluation programs	0.018518518518518517
programs have	0.09090909090909091
been carried	0.014705882352941176
carried out	0.5
the past	0.001384083044982699
past decade	0.3333333333333333
decade in	0.3333333333333333
systems applications	0.008928571428571428
in helicopters	0.003745318352059925
helicopters ,	0.5
, notably	0.0005614823133071309
notably by	0.3333333333333333
U.S. Army	0.14285714285714285
Army Avionics	0.25
Avionics Research	1.0
Research and	0.125
and Development	0.001445086705202312
Development Activity	1.0
Activity -LRB-	1.0
-LRB- AVRADA	0.0027100271002710027
AVRADA -RRB-	0.5
and by	0.001445086705202312
the Royal	0.001384083044982699
Royal Aerospace	0.5
Aerospace Establishment	0.5
Establishment -LRB-	1.0
-LRB- RAE	0.0027100271002710027
RAE -RRB-	1.0
helicopters	5.5800457563752025e-05
Avionics	2.7900228781876013e-05
Development	2.7900228781876013e-05
Activity	2.7900228781876013e-05
AVRADA	5.5800457563752025e-05
Royal	5.5800457563752025e-05
Aerospace	5.5800457563752025e-05
Establishment	2.7900228781876013e-05
RAE	2.7900228781876013e-05
Work in	0.5
France has	0.25
has included	0.011904761904761904
included speech	0.125
the Puma	0.0006920415224913495
Puma helicopter	1.0
helicopter .	0.25
Puma	2.7900228781876013e-05
There has	0.18181818181818182
been much	0.014705882352941176
much useful	0.045454545454545456
useful work	0.07142857142857142
in Canada	0.0018726591760299626
Canada .	0.16666666666666666
<s> Results	0.0007686395080707148
Results have	1.0
been encouraging	0.014705882352941176
encouraging ,	1.0
and voice	0.001445086705202312
voice applications	0.07692307692307693
have included	0.009615384615384616
included :	0.125
: control	0.00980392156862745
control of	0.6
communication radios	0.2
radios ,	1.0
setting of	0.2
of navigation	0.00089126559714795
navigation systems	0.5
an automated	0.007575757575757576
automated target	0.14285714285714285
target handover	0.09090909090909091
handover system	1.0
Results	2.7900228781876013e-05
encouraging	2.7900228781876013e-05
radios	2.7900228781876013e-05
handover	2.7900228781876013e-05
fighter applications	0.16666666666666666
the overriding	0.0006920415224913495
overriding issue	1.0
issue for	0.125
for voice	0.0036101083032490976
voice in	0.07692307692307693
helicopters is	0.5
impact on	0.5
on pilot	0.0047169811320754715
pilot effectiveness	0.2
effectiveness .	0.3333333333333333
overriding	2.7900228781876013e-05
<s> Encouraging	0.0007686395080707148
Encouraging results	1.0
are reported	0.004149377593360996
reported for	0.2
the AVRADA	0.0006920415224913495
AVRADA tests	0.5
tests ,	0.25
although these	0.16666666666666666
these represent	0.023809523809523808
represent only	0.1111111111111111
a feasibility	0.001226993865030675
feasibility demonstration	0.5
demonstration in	0.2
test environment	0.1
Encouraging	2.7900228781876013e-05
feasibility	5.5800457563752025e-05
Much remains	0.3333333333333333
remains to	0.25
done both	0.09090909090909091
both in	0.03225806451612903
in overall	0.0018726591760299626
overall speech	0.16666666666666666
recognition technology	0.008264462809917356
to consistently	0.0013280212483399733
consistently achieve	0.3333333333333333
achieve performance	0.5
performance improvements	0.05555555555555555
improvements in	0.5
in operational	0.0018726591760299626
operational settings	1.0
settings .	1.0
improvements	5.5800457563752025e-05
operational	2.7900228781876013e-05
settings	2.7900228781876013e-05
<s> Battle	0.0007686395080707148
Battle management	0.5
management Question	0.14285714285714285
Question book-new	0.14285714285714285
book-new .	1.0
Battle	5.5800457563752025e-05
book-new	2.7900228781876013e-05
<s> svg	0.0007686395080707148
svg This	1.0
This unreferenced	0.015873015873015872
unreferenced section	1.0
section requires	0.3333333333333333
requires citations	0.0625
to ensure	0.0013280212483399733
ensure verifiability	1.0
verifiability .	1.0
svg	2.7900228781876013e-05
unreferenced	2.7900228781876013e-05
ensure	2.7900228781876013e-05
verifiability	2.7900228781876013e-05
, Battle	0.0005614823133071309
Battle Management	0.5
Management command	1.0
command centres	0.5
centres require	1.0
require rapid	0.045454545454545456
rapid access	1.0
to and	0.0013280212483399733
large ,	0.043478260869565216
, rapidly	0.0005614823133071309
rapidly changing	0.5
changing information	1.0
information databases	0.021739130434782608
Management	2.7900228781876013e-05
centres	2.7900228781876013e-05
rapid	2.7900228781876013e-05
changing	2.7900228781876013e-05
<s> Commanders	0.0007686395080707148
Commanders and	1.0
and system	0.001445086705202312
system operators	0.010752688172043012
operators need	1.0
to query	0.0013280212483399733
query these	0.3333333333333333
these databases	0.023809523809523808
databases as	0.125
as conveniently	0.003484320557491289
conveniently as	1.0
an eyes-busy	0.007575757575757576
eyes-busy environment	1.0
environment where	0.16666666666666666
where much	0.02857142857142857
is presented	0.0040650406504065045
a display	0.001226993865030675
display format	0.5
format .	0.5
Commanders	2.7900228781876013e-05
operators	2.7900228781876013e-05
conveniently	2.7900228781876013e-05
eyes-busy	2.7900228781876013e-05
display	5.5800457563752025e-05
<s> Human-machine	0.0007686395080707148
Human-machine interaction	1.0
interaction by	0.125
voice has	0.07692307692307693
the potential	0.0020761245674740486
potential to	0.2857142857142857
very useful	0.04878048780487805
these environments	0.023809523809523808
environments .	1.0
Human-machine	2.7900228781876013e-05
environments	5.5800457563752025e-05
of efforts	0.00089126559714795
been undertaken	0.014705882352941176
undertaken to	0.5
to interface	0.0013280212483399733
interface commercially	0.25
commercially available	1.0
available isolated-word	0.058823529411764705
isolated-word recognizers	1.0
recognizers into	0.5
into battle	0.01282051282051282
battle management	1.0
management environments	0.14285714285714285
commercially	5.5800457563752025e-05
isolated-word	2.7900228781876013e-05
battle	5.5800457563752025e-05
In one	0.009523809523809525
one feasibility	0.015384615384615385
feasibility study	0.5
study ,	0.25
recognition equipment	0.008264462809917356
equipment was	0.3333333333333333
was tested	0.012987012987012988
tested in	0.5
an integrated	0.007575757575757576
integrated information	0.3333333333333333
information display	0.021739130434782608
display for	0.5
for naval	0.0036101083032490976
naval battle	0.3333333333333333
management applications	0.14285714285714285
naval	8.370068634562804e-05
<s> Users	0.0007686395080707148
Users were	1.0
very optimistic	0.024390243902439025
optimistic about	1.0
although capabilities	0.16666666666666666
capabilities were	0.2
were limited	0.024390243902439025
Users	2.7900228781876013e-05
optimistic	2.7900228781876013e-05
Speech understanding	0.03225806451612903
understanding programs	0.030303030303030304
programs sponsored	0.09090909090909091
sponsored by	0.5
the Defense	0.0006920415224913495
Defense Advanced	1.0
Advanced Research	0.2
Research Projects	0.125
Projects Agency	1.0
Agency -LRB-	0.5
-LRB- DARPA	0.0027100271002710027
DARPA -RRB-	0.25
U.S. has	0.14285714285714285
speech interface	0.006578947368421052
interface .	0.25
sponsored	5.5800457563752025e-05
Defense	2.7900228781876013e-05
Projects	2.7900228781876013e-05
recognition efforts	0.008264462809917356
continuous speech	0.5
-LRB- CSR	0.005420054200542005
CSR -RRB-	0.6666666666666666
, large-vocabulary	0.0005614823133071309
large-vocabulary speech	0.6666666666666666
speech designed	0.006578947368421052
be representative	0.004219409282700422
representative of	1.0
the naval	0.0006920415224913495
naval resource	0.6666666666666666
resource management	0.4
management task	0.14285714285714285
CSR	8.370068634562804e-05
large-vocabulary	8.370068634562804e-05
representative	2.7900228781876013e-05
<s> Significant	0.0007686395080707148
Significant advances	1.0
advances in	1.0
the state-of-the-art	0.0006920415224913495
state-of-the-art in	0.5
in CSR	0.0018726591760299626
CSR have	0.3333333333333333
and current	0.001445086705202312
current efforts	0.14285714285714285
efforts are	0.14285714285714285
are focused	0.004149377593360996
on integrating	0.0047169811320754715
integrating speech	1.0
processing to	0.018518518518518517
allow spoken	0.2
language interaction	0.006756756756756757
interaction with	0.125
a naval	0.001226993865030675
management system	0.14285714285714285
Significant	2.7900228781876013e-05
advances	2.7900228781876013e-05
integrating	2.7900228781876013e-05
<s> Training	0.0007686395080707148
Training air	0.5
air traffic	0.6
traffic controllers	1.0
controllers Training	0.3333333333333333
Training for	0.5
for air	0.0036101083032490976
controllers -LRB-	0.3333333333333333
-LRB- ATC	0.0027100271002710027
ATC -RRB-	0.2
-RRB- represents	0.0027100271002710027
represents an	0.25
an excellent	0.007575757575757576
excellent application	1.0
application for	0.07142857142857142
for speech	0.01444043321299639
Training	5.5800457563752025e-05
air	0.00013950114390938006
traffic	8.370068634562804e-05
controllers	8.370068634562804e-05
ATC	0.00013950114390938006
excellent	2.7900228781876013e-05
Many ATC	0.08333333333333333
ATC training	0.4
training systems	0.03571428571428571
systems currently	0.008928571428571428
currently require	0.14285714285714285
person to	0.10526315789473684
to act	0.0026560424966799467
`` pseudo-pilot	0.005291005291005291
pseudo-pilot ''	0.5
, engaging	0.0005614823133071309
engaging in	1.0
a voice	0.001226993865030675
voice dialog	0.07692307692307693
dialog with	0.5
the trainee	0.0006920415224913495
trainee controller	1.0
controller ,	0.5
which simulates	0.007246376811594203
simulates the	1.0
the dialog	0.0006920415224913495
dialog that	0.5
the controller	0.001384083044982699
controller would	0.25
to conduct	0.0013280212483399733
conduct with	1.0
with pilots	0.00546448087431694
pilots in	0.5
real ATC	0.1111111111111111
ATC situation	0.2
situation .	0.5
pseudo-pilot	5.5800457563752025e-05
engaging	2.7900228781876013e-05
dialog	5.5800457563752025e-05
trainee	2.7900228781876013e-05
controller	0.00011160091512750405
simulates	2.7900228781876013e-05
conduct	2.7900228781876013e-05
and synthesis	0.001445086705202312
synthesis techniques	1.0
techniques offer	0.043478260869565216
offer the	1.0
eliminate the	0.5
as pseudo-pilot	0.003484320557491289
pseudo-pilot ,	0.5
thus reducing	0.1
reducing training	0.5
training and	0.03571428571428571
and support	0.001445086705202312
support personnel	0.25
personnel .	1.0
synthesis	2.7900228781876013e-05
offer	2.7900228781876013e-05
reducing	5.5800457563752025e-05
personnel	2.7900228781876013e-05
, Air	0.0005614823133071309
Air controller	0.3333333333333333
controller tasks	0.25
also characterized	0.014492753623188406
characterized by	0.5
by highly	0.005714285714285714
highly structured	0.1111111111111111
structured speech	0.16666666666666666
speech as	0.013157894736842105
primary output	0.5
, hence	0.0005614823133071309
hence reducing	0.5
reducing the	0.5
the difficulty	0.0006920415224913495
recognition task	0.01652892561983471
task should	0.023809523809523808
In practice	0.009523809523809525
practice ,	0.5
is rarely	0.0020325203252032522
rarely the	0.3333333333333333
The FAA	0.005208333333333333
FAA document	0.5
document 7110.65	0.027777777777777776
7110.65 details	1.0
details the	0.5
the phrases	0.0006920415224913495
phrases that	0.0625
by air	0.011428571428571429
controllers .	0.3333333333333333
FAA	5.5800457563752025e-05
7110.65	2.7900228781876013e-05
While this	0.2
this document	0.01098901098901099
document gives	0.027777777777777776
gives less	0.5
than 150	0.022222222222222223
150 examples	0.5
such phrases	0.008130081300813009
of phrases	0.00089126559714795
phrases supported	0.0625
supported by	1.0
by one	0.005714285714285714
the simulation	0.0006920415224913495
simulation vendors	0.3333333333333333
vendors speech	0.25
of 500,000	0.00089126559714795
500,000 .	1.0
supported	2.7900228781876013e-05
500,000	2.7900228781876013e-05
The USAF	0.005208333333333333
USAF ,	1.0
, USMC	0.0005614823133071309
USMC ,	1.0
, US	0.0011229646266142617
US Army	0.14285714285714285
Army ,	0.25
US Navy	0.14285714285714285
Navy ,	1.0
and FAA	0.001445086705202312
FAA as	0.5
of international	0.00089126559714795
international ATC	0.5
training organizations	0.03571428571428571
organizations such	1.0
Royal Australian	0.5
Australian Air	0.5
Force and	0.5
and Civil	0.001445086705202312
Civil Aviation	1.0
Aviation Authorities	1.0
Authorities in	1.0
in Italy	0.0018726591760299626
, Brazil	0.0005614823133071309
Brazil ,	1.0
and Canada	0.001445086705202312
Canada are	0.16666666666666666
currently using	0.14285714285714285
using ATC	0.01694915254237288
ATC simulators	0.2
simulators with	1.0
with speech	0.01092896174863388
recognition from	0.01652892561983471
different vendors	0.02040816326530612
vendors .	0.25
USAF	2.7900228781876013e-05
USMC	2.7900228781876013e-05
Navy	2.7900228781876013e-05
organizations	2.7900228781876013e-05
Civil	2.7900228781876013e-05
Aviation	2.7900228781876013e-05
Authorities	2.7900228781876013e-05
Brazil	2.7900228781876013e-05
simulators	2.7900228781876013e-05
<s> Telephony	0.0007686395080707148
Telephony and	1.0
other domains	0.014285714285714285
domains ASR	0.125
ASR in	0.5
of telephony	0.00089126559714795
telephony is	0.3333333333333333
now commonplace	0.07692307692307693
commonplace and	1.0
computer gaming	0.022727272727272728
gaming and	1.0
and simulation	0.001445086705202312
simulation is	0.3333333333333333
is becoming	0.0020325203252032522
becoming more	1.0
more widespread	0.010526315789473684
widespread .	1.0
Telephony	2.7900228781876013e-05
telephony	8.370068634562804e-05
commonplace	2.7900228781876013e-05
gaming	2.7900228781876013e-05
becoming	2.7900228781876013e-05
widespread	2.7900228781876013e-05
<s> Despite	0.0007686395080707148
Despite the	1.0
of integration	0.00089126559714795
integration with	1.0
with word	0.01639344262295082
word processing	0.016666666666666666
general personal	0.045454545454545456
personal computing	0.25
computing .	0.5
Despite	2.7900228781876013e-05
integration	2.7900228781876013e-05
computing	5.5800457563752025e-05
, ASR	0.0005614823133071309
of document	0.00089126559714795
document production	0.027777777777777776
production has	0.3333333333333333
not seen	0.008928571428571428
seen the	0.1
expected -LRB-	0.14285714285714285
-LRB- by	0.005420054200542005
by whom	0.005714285714285714
whom ?	0.5
<s> increases	0.0007686395080707148
The improvement	0.005208333333333333
of mobile	0.00089126559714795
mobile processor	0.5
processor speeds	1.0
speeds made	0.5
made feasible	0.0625
feasible the	0.5
the speech-enabled	0.0006920415224913495
speech-enabled Symbian	1.0
Symbian and	1.0
and Windows	0.001445086705202312
Windows Mobile	1.0
Mobile Smartphones	0.3333333333333333
Smartphones .	1.0
mobile	5.5800457563752025e-05
processor	2.7900228781876013e-05
speeds	5.5800457563752025e-05
feasible	5.5800457563752025e-05
speech-enabled	2.7900228781876013e-05
Symbian	2.7900228781876013e-05
Windows	2.7900228781876013e-05
Smartphones	2.7900228781876013e-05
Speech is	0.06451612903225806
used mostly	0.008849557522123894
mostly as	0.5
of User	0.00089126559714795
User Interface	0.5
Interface ,	1.0
for creating	0.0036101083032490976
creating pre-defined	0.14285714285714285
pre-defined or	0.5
or custom	0.0045045045045045045
custom speech	0.5
speech commands	0.006578947368421052
Interface	2.7900228781876013e-05
custom	5.5800457563752025e-05
<s> Leading	0.0007686395080707148
Leading software	1.0
software vendors	0.037037037037037035
vendors in	0.25
field are	0.037037037037037035
: Microsoft	0.00980392156862745
Microsoft Corporation	0.5
-LRB- Microsoft	0.0027100271002710027
Microsoft Voice	0.5
Voice Command	0.2
Command -RRB-	0.5
, Digital	0.0005614823133071309
Digital Syphon	1.0
Syphon -LRB-	1.0
-LRB- Sonic	0.0027100271002710027
Sonic Extractor	1.0
Extractor -RRB-	1.0
, Nuance	0.0005614823133071309
-LRB- Nuance	0.0027100271002710027
Nuance Voice	0.3333333333333333
Voice Control	0.2
Control -RRB-	1.0
Speech Technology	0.03225806451612903
Technology Center	0.3333333333333333
Center ,	1.0
, Vito	0.0005614823133071309
Vito Technology	1.0
Technology -LRB-	0.3333333333333333
-LRB- VITO	0.0027100271002710027
VITO Voice2Go	1.0
Voice2Go -RRB-	1.0
, Speereo	0.0005614823133071309
Speereo Software	0.5
Software -LRB-	0.5
-LRB- Speereo	0.0027100271002710027
Speereo Voice	0.5
Voice Translator	0.2
Translator -RRB-	1.0
, Verbyx	0.0005614823133071309
Verbyx VRX	1.0
VRX and	1.0
and SVOX	0.001445086705202312
SVOX .	1.0
Leading	2.7900228781876013e-05
Microsoft	5.5800457563752025e-05
Command	5.5800457563752025e-05
Digital	2.7900228781876013e-05
Syphon	2.7900228781876013e-05
Sonic	2.7900228781876013e-05
Extractor	2.7900228781876013e-05
Control	2.7900228781876013e-05
Center	2.7900228781876013e-05
Vito	2.7900228781876013e-05
VITO	2.7900228781876013e-05
Voice2Go	2.7900228781876013e-05
Speereo	5.5800457563752025e-05
Translator	2.7900228781876013e-05
Verbyx	2.7900228781876013e-05
VRX	2.7900228781876013e-05
SVOX	2.7900228781876013e-05
Further applications	0.3333333333333333
applications Aerospace	0.04
Aerospace -LRB-	0.5
e.g. space	0.017857142857142856
space exploration	0.2
exploration ,	1.0
, spacecraft	0.0005614823133071309
spacecraft ,	1.0
-RRB- NASA	0.0027100271002710027
NASA 's	1.0
's Mars	0.0196078431372549
Mars Polar	0.5
Polar Lander	1.0
Lander used	0.5
used speech	0.008849557522123894
from technology	0.009615384615384616
technology Sensory	0.045454545454545456
Sensory ,	1.0
Inc. in	0.5
the Mars	0.0006920415224913495
Mars Microphone	0.5
Microphone on	1.0
the Lander	0.0006920415224913495
Lander Automatic	0.5
Automatic translation	0.1111111111111111
translation Automotive	0.013513513513513514
Automotive speech	1.0
, OnStar	0.0005614823133071309
OnStar ,	1.0
, Ford	0.0005614823133071309
Ford Sync	1.0
Sync -RRB-	1.0
-RRB- Court	0.0027100271002710027
Court reporting	1.0
reporting -LRB-	0.3333333333333333
-LRB- Realtime	0.0027100271002710027
Realtime Speech	1.0
Speech Writing	0.03225806451612903
Writing -RRB-	1.0
-RRB- Hands-free	0.0027100271002710027
Hands-free computing	1.0
computing :	0.5
: Speech	0.00980392156862745
computer user	0.022727272727272728
user interface	0.07142857142857142
interface Home	0.25
Home automation	1.0
automation Interactive	1.0
Interactive voice	0.5
voice response	0.07692307692307693
response Mobile	0.5
Mobile telephony	0.3333333333333333
telephony ,	0.6666666666666666
including mobile	0.07142857142857142
mobile email	0.5
email Multimodal	0.5
Multimodal interaction	1.0
interaction Pronunciation	0.125
Pronunciation evaluation	1.0
in computer-aided	0.0018726591760299626
computer-aided language	0.3333333333333333
language learning	0.006756756756756757
learning applications	0.023255813953488372
applications Robotics	0.04
Robotics Speech-to-text	1.0
Speech-to-text reporter	1.0
reporter -LRB-	1.0
-LRB- transcription	0.0027100271002710027
transcription of	0.5
speech into	0.013157894736842105
video captioning	0.2
captioning ,	1.0
, Court	0.0005614823133071309
reporting -RRB-	0.3333333333333333
-RRB- Telematics	0.0027100271002710027
Telematics -LRB-	1.0
, vehicle	0.0005614823133071309
vehicle Navigation	1.0
Navigation Systems	1.0
Systems -RRB-	0.08333333333333333
-RRB- Transcription	0.0027100271002710027
Transcription -LRB-	1.0
-LRB- digital	0.0027100271002710027
digital speech-to-text	0.14285714285714285
speech-to-text -RRB-	0.5
-RRB- Video	0.0027100271002710027
Video games	1.0
games ,	1.0
with Tom	0.00546448087431694
Tom Clancy	1.0
Clancy 's	1.0
's EndWar	0.0196078431372549
EndWar and	1.0
and Lifeline	0.001445086705202312
Lifeline as	1.0
as working	0.003484320557491289
working examples	0.14285714285714285
examples Performance	0.041666666666666664
Performance The	1.0
The performance	0.005208333333333333
usually evaluated	0.03125
evaluated in	0.14285714285714285
of accuracy	0.0017825311942959
accuracy and	0.03225806451612903
and speed	0.002890173410404624
speed .	0.42857142857142855
exploration	2.7900228781876013e-05
spacecraft	2.7900228781876013e-05
NASA	2.7900228781876013e-05
Mars	5.5800457563752025e-05
Polar	2.7900228781876013e-05
Lander	5.5800457563752025e-05
Sensory	2.7900228781876013e-05
Microphone	2.7900228781876013e-05
Automotive	2.7900228781876013e-05
OnStar	2.7900228781876013e-05
Ford	2.7900228781876013e-05
Sync	2.7900228781876013e-05
Court	5.5800457563752025e-05
Realtime	2.7900228781876013e-05
Writing	2.7900228781876013e-05
Hands-free	2.7900228781876013e-05
Home	2.7900228781876013e-05
automation	2.7900228781876013e-05
Multimodal	2.7900228781876013e-05
Pronunciation	2.7900228781876013e-05
Robotics	2.7900228781876013e-05
Speech-to-text	2.7900228781876013e-05
reporter	2.7900228781876013e-05
captioning	2.7900228781876013e-05
Telematics	2.7900228781876013e-05
vehicle	2.7900228781876013e-05
Navigation	2.7900228781876013e-05
Transcription	2.7900228781876013e-05
Video	2.7900228781876013e-05
games	2.7900228781876013e-05
Tom	2.7900228781876013e-05
Clancy	2.7900228781876013e-05
EndWar	2.7900228781876013e-05
Lifeline	2.7900228781876013e-05
Performance	2.7900228781876013e-05
Accuracy is	0.14285714285714285
usually rated	0.03125
rated with	1.0
word error	0.016666666666666666
rate -LRB-	0.09090909090909091
-LRB- WER	0.0027100271002710027
WER -RRB-	1.0
whereas speed	0.3333333333333333
speed is	0.14285714285714285
measured with	0.16666666666666666
real time	0.1111111111111111
time factor	0.030303030303030304
factor .	0.5
rated	2.7900228781876013e-05
WER	2.7900228781876013e-05
Other measures	0.14285714285714285
measures of	0.16666666666666666
accuracy include	0.03225806451612903
include Single	0.037037037037037035
Single Word	1.0
Word Error	0.14285714285714285
Error Rate	0.5
Rate -LRB-	1.0
-LRB- SWER	0.0027100271002710027
SWER -RRB-	1.0
and Command	0.001445086705202312
Command Success	0.5
Success Rate	1.0
Single	2.7900228781876013e-05
Error	5.5800457563752025e-05
Rate	5.5800457563752025e-05
SWER	2.7900228781876013e-05
Success	2.7900228781876013e-05
machine -RRB-	0.012658227848101266
very complex	0.024390243902439025
complex problem	0.041666666666666664
<s> Vocalizations	0.0007686395080707148
Vocalizations vary	1.0
vary in	0.5
of accent	0.00089126559714795
accent ,	1.0
, pronunciation	0.0005614823133071309
pronunciation ,	1.0
, articulation	0.0005614823133071309
articulation ,	1.0
, roughness	0.0005614823133071309
roughness ,	1.0
, nasality	0.0005614823133071309
nasality ,	1.0
, pitch	0.0005614823133071309
pitch ,	1.0
, volume	0.0005614823133071309
volume ,	0.25
Vocalizations	2.7900228781876013e-05
accent	2.7900228781876013e-05
pronunciation	2.7900228781876013e-05
articulation	2.7900228781876013e-05
roughness	2.7900228781876013e-05
nasality	2.7900228781876013e-05
pitch	2.7900228781876013e-05
is distorted	0.0040650406504065045
distorted by	0.5
a background	0.001226993865030675
background noise	0.3333333333333333
noise and	0.125
and echoes	0.001445086705202312
echoes ,	1.0
, electrical	0.0005614823133071309
electrical characteristics	1.0
characteristics .	0.5
distorted	5.5800457563752025e-05
echoes	5.5800457563752025e-05
electrical	2.7900228781876013e-05
recognition vary	0.008264462809917356
vary with	0.16666666666666666
following :	0.13333333333333333
: Vocabulary	0.00980392156862745
Vocabulary size	0.3333333333333333
and confusability	0.001445086705202312
confusability Speaker	1.0
Speaker dependence	0.16666666666666666
dependence vs.	1.0
vs. independence	0.08333333333333333
independence Isolated	1.0
Isolated ,	1.0
, discontinuous	0.0005614823133071309
discontinuous ,	0.3333333333333333
or continuous	0.0045045045045045045
speech Task	0.006578947368421052
Task and	0.6666666666666666
and language	0.004335260115606936
language constraints	0.006756756756756757
constraints Read	0.25
Read vs.	1.0
vs. spontaneous	0.08333333333333333
speech Adverse	0.006578947368421052
Adverse conditions	1.0
conditions Accuracy	0.2
recognition As	0.008264462809917356
earlier in	0.25
article accuracy	0.034482758620689655
speech recogniton	0.006578947368421052
recogniton vary	0.5
in following	0.0018726591760299626
: Error	0.00980392156862745
Error Rates	0.5
Rates Increase	1.0
Increase as	1.0
the Vocabulary	0.0006920415224913495
Vocabulary Size	0.3333333333333333
Size Grows	1.0
Grows :	1.0
: e.g.	0.0196078431372549
e.g. The	0.03571428571428571
The 10	0.005208333333333333
10 digits	0.125
digits ``	1.0
`` zero	0.005291005291005291
zero ''	1.0
`` nine	0.005291005291005291
nine ''	1.0
be recognized	0.008438818565400843
recognized essentially	0.16666666666666666
essentially perfectly	0.125
perfectly ,	1.0
but vocabulary	0.014705882352941176
vocabulary sizes	0.125
of 200	0.00089126559714795
200 ,	0.5
, 5000	0.0005614823133071309
5000 or	1.0
or 100000	0.0045045045045045045
100000 may	1.0
have error	0.009615384615384616
error rates	0.25
of 3	0.00089126559714795
3 %	0.2
, 7	0.0005614823133071309
7 %	0.14285714285714285
% or	0.02564102564102564
or 45	0.0045045045045045045
45 %	1.0
Vocabulary	8.370068634562804e-05
confusability	2.7900228781876013e-05
dependence	2.7900228781876013e-05
independence	2.7900228781876013e-05
Isolated	5.5800457563752025e-05
discontinuous	8.370068634562804e-05
constraints	0.00011160091512750405
Read	5.5800457563752025e-05
Adverse	5.5800457563752025e-05
recogniton	5.5800457563752025e-05
Rates	2.7900228781876013e-05
Increase	2.7900228781876013e-05
Size	2.7900228781876013e-05
Grows	2.7900228781876013e-05
digits	2.7900228781876013e-05
zero	2.7900228781876013e-05
nine	2.7900228781876013e-05
perfectly	2.7900228781876013e-05
5000	2.7900228781876013e-05
100000	2.7900228781876013e-05
45	2.7900228781876013e-05
<s> Vocabulary	0.0007686395080707148
Vocabulary is	0.3333333333333333
is Hard	0.0020325203252032522
Hard to	0.5
to Recognize	0.0013280212483399733
Recognize if	1.0
it Contains	0.008547008547008548
Contains Confusable	1.0
Confusable Words	1.0
Words :	0.25
The 26	0.005208333333333333
26 letters	1.0
alphabet are	0.3333333333333333
are difficult	0.004149377593360996
discriminate because	0.3333333333333333
are confusable	0.004149377593360996
confusable words	1.0
most notoriously	0.017241379310344827
notoriously ,	1.0
the E-set	0.0006920415224913495
E-set :	1.0
`` B	0.005291005291005291
B ,	1.0
, C	0.0005614823133071309
C ,	1.0
, D	0.0005614823133071309
D ,	1.0
, E	0.0005614823133071309
E ,	1.0
, G	0.0005614823133071309
G ,	1.0
, P	0.0005614823133071309
P ,	0.5
, T	0.0005614823133071309
T ,	0.16666666666666666
, V	0.0005614823133071309
V ,	1.0
, Z	0.0005614823133071309
Z ''	1.0
; An	0.02127659574468085
An 8	0.0625
8 %	1.0
% error	0.02564102564102564
rate is	0.18181818181818182
considered good	0.1111111111111111
good for	0.07692307692307693
this vocabulary	0.01098901098901099
vocabulary .	0.25
Hard	5.5800457563752025e-05
Recognize	2.7900228781876013e-05
Contains	2.7900228781876013e-05
Confusable	2.7900228781876013e-05
26	2.7900228781876013e-05
confusable	2.7900228781876013e-05
notoriously	2.7900228781876013e-05
E-set	2.7900228781876013e-05
B	2.7900228781876013e-05
C	2.7900228781876013e-05
D	2.7900228781876013e-05
E	2.7900228781876013e-05
G	2.7900228781876013e-05
V	2.7900228781876013e-05
Z	2.7900228781876013e-05
8	2.7900228781876013e-05
Speaker Dependence	0.16666666666666666
Dependence vs.	1.0
vs. Independence	0.08333333333333333
Independence :	1.0
: A	0.00980392156862745
A speaker	0.04
speaker dependent	0.05555555555555555
dependent system	0.3333333333333333
is intended	0.0040650406504065045
intended for	0.4
for use	0.007220216606498195
use by	0.027777777777777776
single speaker	0.07142857142857142
Dependence	2.7900228781876013e-05
Independence	2.7900228781876013e-05
speaker independent	0.05555555555555555
independent system	0.5
by any	0.005714285714285714
any speaker	0.03225806451612903
speaker ,	0.05555555555555555
<s> Isolated	0.0007686395080707148
, Discontinuous	0.0005614823133071309
Discontinuous or	1.0
or Continuous	0.0045045045045045045
Continuous speech	1.0
speech With	0.006578947368421052
With isolated	0.14285714285714285
isolated speech	0.4
speech single	0.006578947368421052
single words	0.07142857142857142
, therefore	0.0016844469399213925
therefore it	0.6
becomes easier	0.5
easier to	0.25
to recognize	0.00796812749003984
recognize the	0.4444444444444444
Discontinuous	2.7900228781876013e-05
Continuous	2.7900228781876013e-05
With discontinuous	0.14285714285714285
discontinuous speech	0.6666666666666666
speech full	0.006578947368421052
full sentenced	0.2
sentenced separated	1.0
by silence	0.005714285714285714
silence are	1.0
with isolated	0.00546448087431694
sentenced	2.7900228781876013e-05
silence	2.7900228781876013e-05
With continuous	0.14285714285714285
speech naturally	0.006578947368421052
naturally spoken	0.5
spoken sentences	0.07142857142857142
becomes harder	0.25
from both	0.009615384615384616
both isloated	0.03225806451612903
isloated and	1.0
and discontinuous	0.001445086705202312
isloated	2.7900228781876013e-05
<s> Task	0.0007686395080707148
and Language	0.005780346820809248
Language Constraints	0.08333333333333333
Constraints e.g.	0.3333333333333333
e.g. Querying	0.017857142857142856
Querying application	1.0
application may	0.07142857142857142
may dismiss	0.019230769230769232
dismiss the	1.0
the hypothesis	0.0006920415224913495
hypothesis ``	1.0
The apple	0.010416666666666666
apple is	0.6666666666666666
is red	0.0020325203252032522
red .	1.0
Constraints	8.370068634562804e-05
Querying	2.7900228781876013e-05
dismiss	2.7900228781876013e-05
hypothesis	2.7900228781876013e-05
apple	8.370068634562804e-05
red	2.7900228781876013e-05
<s> e.g.	0.0015372790161414297
e.g. Constraints	0.017857142857142856
Constraints may	0.3333333333333333
be semantic	0.004219409282700422
semantic ;	0.047619047619047616
; rejecting	0.0425531914893617
rejecting ``	0.6666666666666666
is angry	0.0020325203252032522
angry .	0.5
e.g. Syntactic	0.017857142857142856
Syntactic ;	1.0
`` Red	0.005291005291005291
Red is	1.0
is apple	0.0020325203252032522
apple the	0.3333333333333333
the .	0.0006920415224913495
Syntactic	2.7900228781876013e-05
Red	2.7900228781876013e-05
<s> Constraints	0.0007686395080707148
Constraints are	0.3333333333333333
often represented	0.022727272727272728
represented by	0.3333333333333333
<s> Read	0.0007686395080707148
vs. Spontaneous	0.08333333333333333
Spontaneous Speech	1.0
Speech When	0.03225806451612903
When a	0.14285714285714285
person reads	0.05263157894736842
reads it	0.5
it 's	0.008547008547008548
's usually	0.0196078431372549
context that	0.030303030303030304
been previously	0.014705882352941176
previously prepared	0.5
prepared ,	1.0
but when	0.014705882352941176
person uses	0.05263157894736842
uses spontaneous	0.07142857142857142
Spontaneous	2.7900228781876013e-05
prepared	2.7900228781876013e-05
<s> because	0.0007686395080707148
the disfluences	0.0006920415224913495
disfluences -LRB-	1.0
-LRB- like	0.0027100271002710027
`` uh	0.005291005291005291
uh ''	1.0
`` um	0.005291005291005291
um ''	1.0
, false	0.0005614823133071309
false starts	0.5
starts ,	0.5
, incomplete	0.0005614823133071309
incomplete sentences	1.0
, stutering	0.0005614823133071309
stutering ,	1.0
, coughing	0.0005614823133071309
coughing ,	1.0
and laughter	0.001445086705202312
laughter -RRB-	1.0
and limited	0.001445086705202312
limited vocabulary	0.1
disfluences	2.7900228781876013e-05
uh	2.7900228781876013e-05
um	2.7900228781876013e-05
starts	5.5800457563752025e-05
incomplete	2.7900228781876013e-05
stutering	2.7900228781876013e-05
coughing	2.7900228781876013e-05
laughter	2.7900228781876013e-05
<s> Adverse	0.0007686395080707148
conditions Environmental	0.2
Environmental noise	1.0
noise -LRB-	0.125
e.g. Noise	0.017857142857142856
Noise in	1.0
a car	0.001226993865030675
car or	1.0
a factory	0.001226993865030675
factory -RRB-	1.0
-RRB- Acoustical	0.0027100271002710027
Acoustical distortions	0.5
distortions -LRB-	1.0
e.g. echoes	0.017857142857142856
, room	0.0005614823133071309
room acoustics	1.0
acoustics -RRB-	1.0
-RRB- Speech	0.0027100271002710027
a multileveled	0.001226993865030675
multileveled pattern	1.0
Environmental	2.7900228781876013e-05
Noise	2.7900228781876013e-05
car	2.7900228781876013e-05
factory	2.7900228781876013e-05
Acoustical	5.5800457563752025e-05
distortions	2.7900228781876013e-05
room	2.7900228781876013e-05
acoustics	2.7900228781876013e-05
multileveled	2.7900228781876013e-05
<s> Acoustical	0.0007686395080707148
Acoustical signals	0.5
signals are	1.0
are structured	0.004149377593360996
structured into	0.16666666666666666
a hierarchy	0.001226993865030675
hierarchy of	1.0
of units	0.00089126559714795
units ;	0.14285714285714285
; e.g.	0.0425531914893617
e.g. Phonemes	0.017857142857142856
Phonemes ,	1.0
, Words	0.0005614823133071309
Words ,	0.25
, Phrases	0.0005614823133071309
Phrases ,	1.0
and Sentences	0.001445086705202312
Sentences ;	1.0
; Each	0.02127659574468085
Each level	0.16666666666666666
level provides	0.05
provides additional	0.5
additional constraints	0.16666666666666666
constraints ;	0.25
e.g. Known	0.017857142857142856
Known word	1.0
word pronunciations	0.016666666666666666
pronunciations or	1.0
or legal	0.0045045045045045045
legal word	0.3333333333333333
word sequences	0.016666666666666666
sequences ,	0.1111111111111111
can compensate	0.0055248618784530384
compensate for	1.0
for errors	0.0036101083032490976
errors or	0.2
or uncertainties	0.0045045045045045045
uncertainties at	1.0
at lower	0.014705882352941176
lower level	0.4
level ;	0.1
; This	0.02127659574468085
This hierarchy	0.015873015873015872
of constraints	0.00089126559714795
constraints are	0.25
are exploited	0.004149377593360996
exploited ;	1.0
; By	0.02127659574468085
By combining	0.3333333333333333
combining decisions	0.25
decisions probabilistically	0.1
probabilistically at	1.0
all lower	0.023255813953488372
lower levels	0.4
levels ,	0.045454545454545456
making more	0.14285714285714285
more deterministic	0.021052631578947368
deterministic decisions	0.25
decisions only	0.1
only at	0.02631578947368421
the highest	0.0006920415224913495
highest level	0.3333333333333333
; Speech	0.02127659574468085
Speech recogniton	0.03225806451612903
recogniton by	0.5
machine is	0.012658227848101266
process broken	0.027777777777777776
broken into	0.6
into several	0.01282051282051282
several phases	0.045454545454545456
phases .	1.0
signals	5.5800457563752025e-05
hierarchy	5.5800457563752025e-05
Phonemes	2.7900228781876013e-05
Phrases	2.7900228781876013e-05
Sentences	2.7900228781876013e-05
Known	2.7900228781876013e-05
pronunciations	2.7900228781876013e-05
compensate	2.7900228781876013e-05
uncertainties	2.7900228781876013e-05
exploited	2.7900228781876013e-05
probabilistically	2.7900228781876013e-05
phases	2.7900228781876013e-05
<s> Computationally	0.0007686395080707148
Computationally ,	1.0
which a	0.014492753623188406
sound pattern	0.05
pattern has	0.16666666666666666
recognized or	0.16666666666666666
or classified	0.0045045045045045045
classified into	1.0
a category	0.001226993865030675
category that	0.5
that represents	0.0035460992907801418
a meaning	0.00245398773006135
meaning to	0.08695652173913043
Computationally	2.7900228781876013e-05
classified	2.7900228781876013e-05
<s> Every	0.0007686395080707148
Every acoustic	1.0
acoustic signal	0.16666666666666666
signal can	0.3333333333333333
be broken	0.004219409282700422
broken in	0.2
in smaller	0.0018726591760299626
smaller more	0.14285714285714285
more basic	0.021052631578947368
basic sub-signals	0.07692307692307693
sub-signals .	1.0
Every	2.7900228781876013e-05
sub-signals	2.7900228781876013e-05
As the	0.05555555555555555
complex sound	0.125
sound signal	0.05
signal is	0.16666666666666666
is broken	0.0020325203252032522
the smaller	0.0006920415224913495
smaller sub-sounds	0.14285714285714285
sub-sounds ,	1.0
different levels	0.02040816326530612
levels are	0.045454545454545456
where at	0.02857142857142857
top level	0.2
level we	0.05
have complex	0.009615384615384616
complex sounds	0.041666666666666664
sounds ,	0.13333333333333333
simpler sounds	0.6666666666666666
sounds on	0.06666666666666667
on lower	0.0047169811320754715
and going	0.001445086705202312
going to	0.25
to lower	0.0013280212483399733
levels even	0.045454545454545456
even more	0.037037037037037035
more ,	0.010526315789473684
create more	0.058823529411764705
basic and	0.07692307692307693
and shorter	0.001445086705202312
shorter and	0.5
and simpler	0.001445086705202312
sounds .	0.06666666666666667
sub-sounds	2.7900228781876013e-05
The lowest	0.005208333333333333
lowest level	1.0
sounds are	0.13333333333333333
most fundamental	0.017241379310344827
fundamental ,	0.5
would check	0.018867924528301886
check for	0.5
for simple	0.0036101083032490976
simple and	0.07692307692307693
more probabilistic	0.010526315789473684
probabilistic rules	0.14285714285714285
what sound	0.03125
sound should	0.1
should represent	0.10526315789473684
represent .	0.2222222222222222
lowest	2.7900228781876013e-05
Once these	0.2
these sounds	0.023809523809523808
are put	0.004149377593360996
put together	0.25
together into	0.125
sound on	0.05
on upper	0.0047169811320754715
upper level	1.0
new set	0.041666666666666664
deterministic rules	0.25
rules should	0.023255813953488372
should predict	0.05263157894736842
predict what	0.16666666666666666
what new	0.03125
new complex	0.041666666666666664
upper	5.5800457563752025e-05
most upper	0.017241379310344827
deterministic rule	0.25
rule should	0.3333333333333333
should figure	0.05263157894736842
figure out	0.5
of complex	0.00089126559714795
complex expressions	0.041666666666666664
figure	5.5800457563752025e-05
to expand	0.0013280212483399733
expand our	1.0
our knowledge	0.2
about speech	0.05
recognition we	0.008264462809917356
a consideration	0.001226993865030675
consideration neural	0.3333333333333333
expand	2.7900228781876013e-05
are four	0.004149377593360996
four steps	0.14285714285714285
steps of	0.5
of neural	0.00089126559714795
network approaches	0.3333333333333333
: Digitize	0.00980392156862745
Digitize the	1.0
speech that	0.006578947368421052
recognize For	0.1111111111111111
For telephone	0.01639344262295082
telephone speech	0.5
speech the	0.006578947368421052
the sampling	0.0006920415224913495
sampling rate	1.0
is 8000	0.0020325203252032522
8000 samples	1.0
samples per	0.5
per second	0.5
second ;	0.1
; Compute	0.02127659574468085
Compute features	1.0
of spectral-domain	0.00089126559714795
spectral-domain of	1.0
with Fourier	0.00546448087431694
Fourier transform	0.6666666666666666
transform -RRB-	0.2
; Computed	0.02127659574468085
Computed every	1.0
every 10msec	0.3333333333333333
10msec ,	0.5
with one	0.00546448087431694
one 10msec	0.015384615384615385
10msec section	0.5
section called	0.16666666666666666
called a	0.05555555555555555
a frame	0.001226993865030675
frame ;	0.5
; Analysis	0.02127659574468085
Analysis of	0.2
of four	0.00089126559714795
four step	0.14285714285714285
step neural	0.06666666666666667
approaches can	0.03571428571428571
be explained	0.004219409282700422
explained by	1.0
by further	0.005714285714285714
further information	0.125
Digitize	2.7900228781876013e-05
telephone	5.5800457563752025e-05
sampling	2.7900228781876013e-05
8000	2.7900228781876013e-05
Compute	2.7900228781876013e-05
spectral-domain	2.7900228781876013e-05
Fourier	8.370068634562804e-05
transform	0.00013950114390938006
Computed	2.7900228781876013e-05
10msec	5.5800457563752025e-05
frame	5.5800457563752025e-05
explained	2.7900228781876013e-05
<s> Sound	0.0015372790161414297
Sound is	0.3333333333333333
is produced	0.0040650406504065045
air -LRB-	0.2
other medium	0.014285714285714285
medium -RRB-	0.3333333333333333
-RRB- vibration	0.0027100271002710027
vibration ,	1.0
which we	0.007246376811594203
we register	0.022222222222222223
register by	1.0
by ears	0.005714285714285714
ears ,	1.0
but machines	0.014705882352941176
machines by	0.25
by receivers	0.005714285714285714
receivers .	1.0
Sound	8.370068634562804e-05
vibration	2.7900228781876013e-05
register	2.7900228781876013e-05
ears	2.7900228781876013e-05
receivers	2.7900228781876013e-05
<s> Basic	0.0007686395080707148
Basic sound	1.0
sound creates	0.05
creates a	0.5
a wave	0.0049079754601227
wave which	0.1111111111111111
has 2	0.011904761904761904
2 descriptions	0.2
descriptions ;	1.0
; Amplitude	0.02127659574468085
Amplitude -LRB-	1.0
how strong	0.034482758620689655
strong is	0.25
is it	0.0020325203252032522
it -RRB-	0.008547008547008548
and frequency	0.001445086705202312
frequency -LRB-	0.5
how often	0.034482758620689655
often it	0.022727272727272728
it vibrates	0.008547008547008548
vibrates per	1.0
second -RRB-	0.1
Basic	2.7900228781876013e-05
creates	5.5800457563752025e-05
wave	0.0002511020590368841
descriptions	2.7900228781876013e-05
Amplitude	2.7900228781876013e-05
vibrates	2.7900228781876013e-05
<s> Digitized	0.0007686395080707148
Digitized Sound	1.0
Sound Graph	0.3333333333333333
Graph This	1.0
the wave	0.0006920415224913495
wave in	0.1111111111111111
the water	0.0006920415224913495
water .	1.0
Digitized	2.7900228781876013e-05
Graph	2.7900228781876013e-05
water	2.7900228781876013e-05
<s> Big	0.0007686395080707148
Big wave	1.0
wave is	0.2222222222222222
is strong	0.0020325203252032522
strong and	0.25
and smaller	0.001445086705202312
smaller ones	0.14285714285714285
ones are	0.1
usually faster	0.03125
faster but	0.3333333333333333
but weaker	0.014705882352941176
weaker .	1.0
Big	2.7900228781876013e-05
weaker	2.7900228781876013e-05
how air	0.034482758620689655
air is	0.2
distorted ,	0.5
but we	0.014705882352941176
we do	0.022222222222222223
n't see	0.25
see it	0.05
it easily	0.008547008547008548
easily ,	0.1111111111111111
order for	0.07142857142857142
for sound	0.0036101083032490976
sound to	0.05
to travel	0.0013280212483399733
travel .	1.0
travel	2.7900228781876013e-05
These waves	0.058823529411764705
waves can	0.14285714285714285
be digitalized	0.004219409282700422
digitalized :	1.0
: Sample	0.00980392156862745
Sample a	1.0
a strength	0.001226993865030675
strength at	0.2
at short	0.014705882352941176
short intervals	0.125
intervals like	1.0
like in	0.03571428571428571
in picture	0.0018726591760299626
picture above	0.25
above to	0.07692307692307693
get bunch	0.14285714285714285
bunch of	1.0
of numbers	0.0017825311942959
numbers that	0.14285714285714285
that approximate	0.0035460992907801418
approximate at	0.5
at each	0.014705882352941176
each time	0.022222222222222223
time step	0.030303030303030304
step the	0.06666666666666667
wave .	0.2222222222222222
waves	0.0001953016014731321
digitalized	2.7900228781876013e-05
Sample	2.7900228781876013e-05
intervals	2.7900228781876013e-05
bunch	5.5800457563752025e-05
<s> Collection	0.0007686395080707148
Collection of	1.0
numbers represent	0.14285714285714285
represent analog	0.1111111111111111
analog wave	0.5
Collection	2.7900228781876013e-05
This new	0.015873015873015872
new wave	0.041666666666666664
is digital	0.0020325203252032522
digital .	0.14285714285714285
Sound waves	0.3333333333333333
waves are	0.14285714285714285
are complicated	0.004149377593360996
complicated because	0.3333333333333333
they superimpose	0.025
superimpose one	1.0
one on	0.015384615384615385
on top	0.0047169811320754715
top of	0.2
other .	0.02857142857142857
superimpose	2.7900228781876013e-05
<s> Like	0.0007686395080707148
Like the	0.5
the waves	0.0006920415224913495
waves would	0.14285714285714285
would .	0.018867924528301886
This way	0.015873015873015872
way they	0.041666666666666664
they create	0.025
create odd	0.058823529411764705
odd looking	1.0
looking waves	0.2
waves .	0.14285714285714285
odd	5.5800457563752025e-05
if there	0.07142857142857142
are two	0.008298755186721992
two waves	0.034482758620689655
waves that	0.14285714285714285
that interact	0.0035460992907801418
interact with	1.0
with each	0.00546448087431694
other we	0.014285714285714285
can add	0.0055248618784530384
add them	1.0
them which	0.05263157894736842
which creates	0.007246376811594203
creates new	0.5
new odd	0.041666666666666664
looking wave	0.2
wave as	0.1111111111111111
is shown	0.0020325203252032522
picture on	0.25
interact	2.7900228781876013e-05
add	2.7900228781876013e-05
<s> Neural	0.0015372790161414297
Neural Network	0.25
Network classifies	1.0
classifies features	1.0
features into	0.038461538461538464
into phonetic-based	0.01282051282051282
phonetic-based categories	1.0
categories ;	0.1111111111111111
; Given	0.02127659574468085
Given basic	0.07142857142857142
basic sound	0.15384615384615385
sound blocks	0.05
blocks ,	0.25
machine digitized	0.012658227848101266
digitized ,	1.0
a bunch	0.001226993865030675
numbers which	0.14285714285714285
which describe	0.007246376811594203
describe a	0.16666666666666666
wave and	0.1111111111111111
and waves	0.001445086705202312
waves describe	0.14285714285714285
describe words	0.16666666666666666
Neural	0.00011160091512750405
Network	2.7900228781876013e-05
classifies	2.7900228781876013e-05
phonetic-based	2.7900228781876013e-05
digitized	2.7900228781876013e-05
Each frame	0.16666666666666666
frame has	0.5
a unit	0.001226993865030675
unit block	0.3333333333333333
block of	1.0
of sound	0.0017825311942959
sound ,	0.1
are broken	0.004149377593360996
into basic	0.01282051282051282
sound waves	0.05
waves and	0.14285714285714285
and represented	0.001445086705202312
by numbers	0.005714285714285714
numbers after	0.14285714285714285
after Fourier	0.08333333333333333
Fourier Transform	0.3333333333333333
Transform ,	1.0
be statistically	0.004219409282700422
statistically evaluated	1.0
evaluated to	0.2857142857142857
set to	0.02564102564102564
which class	0.007246376811594203
of sounds	0.00089126559714795
sounds it	0.06666666666666667
it belongs	0.008547008547008548
belongs to	1.0
block	2.7900228781876013e-05
Transform	2.7900228781876013e-05
statistically	5.5800457563752025e-05
belongs	2.7900228781876013e-05
The nodes	0.005208333333333333
nodes in	0.14285714285714285
the figure	0.0006920415224913495
figure on	0.5
a slide	0.001226993865030675
slide represent	1.0
a feature	0.00245398773006135
sound in	0.05
wave from	0.1111111111111111
from first	0.009615384615384616
first layer	0.030303030303030304
layer of	1.0
of nodes	0.0035650623885918
nodes to	0.14285714285714285
second layer	0.2
nodes based	0.14285714285714285
some statistical	0.012048192771084338
statistical analysis	0.030303030303030304
nodes	0.0001953016014731321
slide	2.7900228781876013e-05
layer	8.370068634562804e-05
This analysis	0.015873015873015872
analysis depends	0.015384615384615385
on programer	0.0047169811320754715
programer 's	1.0
's instructions	0.0196078431372549
instructions .	1.0
programer	2.7900228781876013e-05
instructions	2.7900228781876013e-05
At this	0.3333333333333333
this point	0.01098901098901099
nodes represents	0.14285714285714285
higher level	0.14285714285714285
level features	0.05
sound input	0.05
input which	0.024390243902439025
is again	0.0020325203252032522
again statistically	1.0
see what	0.05
what class	0.03125
class they	0.25
they belong	0.025
belong to	1.0
again	2.7900228781876013e-05
belong	2.7900228781876013e-05
<s> Last	0.0007686395080707148
Last level	1.0
nodes should	0.14285714285714285
be output	0.004219409282700422
output nodes	0.07692307692307693
nodes that	0.14285714285714285
that tell	0.0035460992907801418
tell us	0.3333333333333333
us with	0.5
high probability	0.05555555555555555
probability what	0.14285714285714285
what original	0.03125
original sound	0.07692307692307693
sound really	0.05
really was	1.0
was .	0.012987012987012988
Last	2.7900228781876013e-05
really	2.7900228781876013e-05
Search to	0.5
to match	0.0026560424966799467
the neural-network	0.0006920415224913495
neural-network output	1.0
output scores	0.038461538461538464
scores for	0.2
best word	0.05555555555555555
word ,	0.03333333333333333
was most	0.012987012987012988
likely uttered	0.0625
uttered ;	0.3333333333333333
; A	0.02127659574468085
A machine	0.02
machine speech	0.012658227848101266
recognition using	0.008264462809917356
using neural	0.01694915254237288
network is	0.16666666666666666
still just	0.06666666666666667
a fancy	0.001226993865030675
fancy statistics	1.0
neural-network	2.7900228781876013e-05
uttered	8.370068634562804e-05
fancy	2.7900228781876013e-05
<s> Artificial	0.0007686395080707148
Artificial neural	0.5
network has	0.16666666666666666
has specialized	0.011904761904761904
specialized output	0.5
nodes for	0.14285714285714285
for results	0.0036101083032490976
, unlike	0.0005614823133071309
unlike brain	1.0
brain .	0.3333333333333333
specialized	5.5800457563752025e-05
unlike	2.7900228781876013e-05
brain	8.370068634562804e-05
Our brain	0.6666666666666666
brain recognizes	0.3333333333333333
in fundamentally	0.0018726591760299626
fundamentally different	1.0
different way	0.02040816326530612
way .	0.041666666666666664
fundamentally	2.7900228781876013e-05
brain is	0.3333333333333333
is entirely	0.0020325203252032522
entirely committed	0.5
committed into	1.0
the perception	0.0006920415224913495
perception of	0.5
sound .	0.05
committed	2.7900228781876013e-05
perception	5.5800457563752025e-05
When we	0.14285714285714285
we hear	0.022222222222222223
hear sound	0.5
, our	0.0005614823133071309
our life	0.2
life experience	0.25
experience is	0.5
is brought	0.0020325203252032522
brought together	1.0
together to	0.125
to action	0.0013280212483399733
action of	0.2
of listening	0.00089126559714795
listening to	1.0
sound into	0.05
a appropriate	0.001226993865030675
appropriate perspective	0.25
perspective so	0.25
is meaningful	0.0020325203252032522
meaningful .	0.125
hear	5.5800457563752025e-05
experience	5.5800457563752025e-05
brought	2.7900228781876013e-05
listening	2.7900228781876013e-05
<s> Brain	0.0007686395080707148
Brain has	1.0
a purpose	0.001226993865030675
purpose when	0.2
when it	0.02857142857142857
it listens	0.008547008547008548
listens for	1.0
sound that	0.05
is steered	0.0020325203252032522
steered toward	1.0
toward actions	1.0
Brain	2.7900228781876013e-05
listens	2.7900228781876013e-05
steered	2.7900228781876013e-05
toward	2.7900228781876013e-05
In 1982	0.009523809523809525
1982 ,	0.3333333333333333
Kurzweil Applied	0.14285714285714285
Applied Intelligence	0.5
Intelligence and	0.3333333333333333
and Dragon	0.001445086705202312
Dragon Systems	1.0
Systems released	0.16666666666666666
released speech	0.5
recognition products	0.008264462809917356
products .	0.25
Dragon	5.5800457563752025e-05
released	5.5800457563752025e-05
<s> By	0.0007686395080707148
By 1985	0.3333333333333333
1985 ,	1.0
Kurzweil 's	0.14285714285714285
's software	0.0196078431372549
software had	0.037037037037037035
a vocabulary	0.001226993865030675
vocabulary of	0.125
of 1,000	0.00089126559714795
1,000 words	0.5
words --	0.009174311926605505
if uttered	0.03571428571428571
uttered one	0.3333333333333333
one word	0.03076923076923077
word at	0.016666666666666666
1985	2.7900228781876013e-05
, its	0.0005614823133071309
its lexicon	0.02857142857142857
lexicon reached	0.1111111111111111
reached 20,000	0.5
20,000 words	1.0
entering the	0.5
the realm	0.0006920415224913495
realm of	1.0
human vocabularies	0.021739130434782608
which range	0.007246376811594203
from 10,000	0.009615384615384616
10,000 to	1.0
to 150,000	0.0013280212483399733
150,000 words	1.0
20,000	2.7900228781876013e-05
realm	2.7900228781876013e-05
10,000	2.7900228781876013e-05
150,000	2.7900228781876013e-05
But recognition	0.16666666666666666
accuracy was	0.03225806451612903
was only	0.012987012987012988
only 10	0.02631578947368421
% in	0.02564102564102564
in 1993	0.0018726591760299626
1993 .	0.3333333333333333
1993	8.370068634562804e-05
the error	0.0006920415224913495
rate crossed	0.09090909090909091
crossed below	1.0
below 50	0.2
50 %	0.6666666666666666
crossed	2.7900228781876013e-05
<s> Dragon	0.0007686395080707148
released ``	0.5
`` Naturally	0.005291005291005291
Naturally Speaking	1.0
Speaking ''	1.0
1997 ,	0.5
which recognized	0.007246376811594203
recognized normal	0.16666666666666666
normal human	0.5
human speech	0.021739130434782608
Naturally	2.7900228781876013e-05
Speaking	2.7900228781876013e-05
normal	5.5800457563752025e-05
<s> Progress	0.0007686395080707148
Progress mainly	1.0
mainly came	0.16666666666666666
came from	0.5
from improved	0.009615384615384616
improved computer	0.25
computer performance	0.022727272727272728
performance and	0.1111111111111111
larger source	0.0625
text databases	0.006289308176100629
Progress	2.7900228781876013e-05
major database	0.08333333333333333
database available	0.1
containing several	0.125
several million	0.045454545454545456
million words	0.3333333333333333
In 2006	0.009523809523809525
2006 ,	0.3333333333333333
, Google	0.0005614823133071309
Google published	0.25
published a	0.2857142857142857
a trillion-word	0.001226993865030675
trillion-word corpus	1.0
while Carnegie	0.05
Carnegie Mellon	1.0
Mellon University	1.0
University researchers	0.1111111111111111
researchers found	0.1
found no	0.07142857142857142
no significant	0.07692307692307693
significant increase	0.1111111111111111
trillion-word	2.7900228781876013e-05
Carnegie	5.5800457563752025e-05
Mellon	5.5800457563752025e-05
Algorithms Both	0.5
Both acoustic	0.3333333333333333
acoustic modeling	0.3333333333333333
modeling and	0.14285714285714285
language modeling	0.006756756756756757
modeling are	0.14285714285714285
are important	0.004149377593360996
important parts	0.0625
of modern	0.00089126559714795
modern statistically-based	0.2
statistically-based speech	1.0
recognition algorithms	0.008264462809917356
statistically-based	2.7900228781876013e-05
are widely	0.004149377593360996
many systems	0.019230769230769232
<s> Language	0.0007686395080707148
Language modeling	0.08333333333333333
modeling has	0.14285714285714285
other applications	0.014285714285714285
applications such	0.04
as smart	0.003484320557491289
smart keyboard	1.0
keyboard and	0.3333333333333333
document classification	0.05555555555555555
classification .	0.11764705882352941
smart	2.7900228781876013e-05
models Main	0.038461538461538464
: Hidden	0.00980392156862745
model Modern	0.03333333333333333
Modern general-purpose	0.3333333333333333
general-purpose speech	1.0
on Hidden	0.0047169811320754715
Models .	0.3333333333333333
general-purpose	2.7900228781876013e-05
are statistical	0.004149377593360996
that output	0.0035460992907801418
output a	0.07692307692307693
of symbols	0.00089126559714795
symbols or	0.3333333333333333
or quantities	0.0045045045045045045
quantities .	0.3333333333333333
quantities	8.370068634562804e-05
HMMs are	0.25
recognition because	0.008264462809917356
because a	0.03333333333333333
a speech	0.00245398773006135
speech signal	0.006578947368421052
a piecewise	0.001226993865030675
piecewise stationary	1.0
stationary signal	0.2857142857142857
signal or	0.16666666666666666
a short-time	0.001226993865030675
short-time stationary	0.5
signal .	0.16666666666666666
piecewise	2.7900228781876013e-05
short-time	5.5800457563752025e-05
short time-scales	0.125
time-scales -LRB-	1.0
10 milliseconds	0.25
milliseconds -RRB-	0.5
be approximated	0.004219409282700422
approximated as	1.0
stationary process	0.14285714285714285
time-scales	2.7900228781876013e-05
milliseconds	5.5800457563752025e-05
approximated	2.7900228781876013e-05
Speech can	0.03225806451612903
be thought	0.004219409282700422
a Markov	0.001226993865030675
model for	0.06666666666666667
many stochastic	0.019230769230769232
stochastic purposes	0.125
Another reason	0.07692307692307693
reason why	0.25
why HMMs	0.14285714285714285
are popular	0.004149377593360996
popular is	0.1111111111111111
is because	0.0020325203252032522
be trained	0.004219409282700422
trained automatically	0.3333333333333333
automatically and	0.09523809523809523
are simple	0.004149377593360996
and computationally	0.001445086705202312
computationally feasible	0.5
feasible to	0.5
In speech	0.009523809523809525
the hidden	0.0006920415224913495
would output	0.018867924528301886
of n-dimensional	0.00089126559714795
n-dimensional real-valued	1.0
real-valued vectors	0.3333333333333333
vectors -LRB-	0.3333333333333333
with n	0.00546448087431694
n being	0.5
small integer	0.1111111111111111
integer ,	1.0
as 10	0.003484320557491289
10 -RRB-	0.125
, outputting	0.0005614823133071309
outputting one	0.5
these every	0.023809523809523808
every 10	0.3333333333333333
milliseconds .	0.5
n-dimensional	2.7900228781876013e-05
integer	2.7900228781876013e-05
The vectors	0.005208333333333333
vectors would	0.3333333333333333
would consist	0.018867924528301886
consist of	1.0
of cepstral	0.00089126559714795
cepstral coefficients	0.5
coefficients ,	0.25
by taking	0.005714285714285714
taking a	0.2
a Fourier	0.001226993865030675
transform of	0.2
short time	0.125
time window	0.030303030303030304
and decorrelating	0.001445086705202312
decorrelating the	1.0
the spectrum	0.0006920415224913495
spectrum using	1.0
a cosine	0.001226993865030675
cosine transform	0.3333333333333333
transform ,	0.4
then taking	0.02857142857142857
first -LRB-	0.030303030303030304
most significant	0.017241379310344827
significant -RRB-	0.1111111111111111
-RRB- coefficients	0.0027100271002710027
coefficients .	0.25
consist	2.7900228781876013e-05
cepstral	5.5800457563752025e-05
coefficients	0.00011160091512750405
decorrelating	2.7900228781876013e-05
spectrum	2.7900228781876013e-05
The hidden	0.005208333333333333
model will	0.03333333333333333
will tend	0.02857142857142857
in each	0.0018726591760299626
each state	0.022222222222222223
state a	0.07142857142857142
statistical distribution	0.030303030303030304
a mixture	0.001226993865030675
mixture of	1.0
of diagonal	0.00089126559714795
diagonal covariance	1.0
covariance Gaussians	0.5
Gaussians ,	1.0
will give	0.02857142857142857
give a	0.25
a likelihood	0.001226993865030675
likelihood for	0.3333333333333333
each observed	0.022222222222222223
observed vector	1.0
vector .	0.3333333333333333
mixture	2.7900228781876013e-05
diagonal	2.7900228781876013e-05
covariance	5.5800457563752025e-05
Gaussians	2.7900228781876013e-05
likelihood	8.370068634562804e-05
observed	2.7900228781876013e-05
Each word	0.16666666666666666
or -LRB-	0.0045045045045045045
for more	0.007220216606498195
general speech	0.045454545454545456
systems -RRB-	0.008928571428571428
each phoneme	0.022222222222222223
phoneme ,	0.5
different output	0.02040816326530612
output distribution	0.038461538461538464
distribution ;	0.25
; a	0.02127659574468085
a hidden	0.001226993865030675
or phonemes	0.009009009009009009
phonemes is	0.16666666666666666
made by	0.0625
by concatenating	0.005714285714285714
concatenating the	1.0
individual trained	0.08333333333333333
trained hidden	0.3333333333333333
the separate	0.0006920415224913495
and phonemes	0.001445086705202312
phonemes .	0.16666666666666666
phoneme	5.5800457563752025e-05
phonemes	0.00016740137269125608
concatenating	2.7900228781876013e-05
<s> Described	0.0007686395080707148
Described above	1.0
above are	0.07692307692307693
the core	0.0006920415224913495
core elements	0.5
elements of	0.25
, HMM-based	0.0005614823133071309
HMM-based approach	0.6666666666666666
Described	2.7900228781876013e-05
<s> Modern	0.0007686395080707148
Modern speech	0.3333333333333333
use various	0.013888888888888888
various combinations	0.05555555555555555
combinations of	1.0
of standard	0.00089126559714795
standard techniques	0.07142857142857142
techniques in	0.043478260869565216
improve results	0.07692307692307693
results over	0.047619047619047616
basic approach	0.07692307692307693
approach described	0.02857142857142857
above .	0.07692307692307693
combinations	2.7900228781876013e-05
typical large-vocabulary	0.1111111111111111
large-vocabulary system	0.3333333333333333
would need	0.018867924528301886
need context	0.047619047619047616
context dependency	0.030303030303030304
dependency for	0.2
the phonemes	0.001384083044982699
phonemes -LRB-	0.16666666666666666
so phonemes	0.03333333333333333
phonemes with	0.16666666666666666
with different	0.01092896174863388
different left	0.02040816326530612
right context	0.1
context have	0.030303030303030304
have different	0.019230769230769232
different realizations	0.02040816326530612
realizations as	1.0
as HMM	0.003484320557491289
HMM states	0.3333333333333333
states -RRB-	0.25
; it	0.02127659574468085
would use	0.018867924528301886
use cepstral	0.013888888888888888
cepstral normalization	0.5
normalization to	0.16666666666666666
to normalize	0.0013280212483399733
normalize for	1.0
for different	0.0036101083032490976
different speaker	0.02040816326530612
speaker and	0.05555555555555555
and recording	0.001445086705202312
recording conditions	1.0
conditions ;	0.2
further speaker	0.125
speaker normalization	0.05555555555555555
normalization it	0.16666666666666666
it might	0.008547008547008548
might use	0.07692307692307693
use vocal	0.013888888888888888
vocal tract	1.0
tract length	1.0
length normalization	0.125
normalization -LRB-	0.16666666666666666
-LRB- VTLN	0.0027100271002710027
VTLN -RRB-	1.0
-RRB- for	0.005420054200542005
for male-female	0.0036101083032490976
male-female normalization	1.0
normalization and	0.16666666666666666
and maximum	0.001445086705202312
maximum likelihood	0.3333333333333333
likelihood linear	0.6666666666666666
linear regression	0.14285714285714285
regression -LRB-	1.0
-LRB- MLLR	0.0027100271002710027
MLLR -RRB-	1.0
general speaker	0.045454545454545456
speaker adaptation	0.1111111111111111
adaptation .	0.6666666666666666
realizations	2.7900228781876013e-05
HMM	8.370068634562804e-05
normalize	2.7900228781876013e-05
recording	2.7900228781876013e-05
vocal	2.7900228781876013e-05
tract	2.7900228781876013e-05
VTLN	2.7900228781876013e-05
male-female	2.7900228781876013e-05
regression	2.7900228781876013e-05
MLLR	2.7900228781876013e-05
The features	0.005208333333333333
features would	0.038461538461538464
have so-called	0.009615384615384616
so-called delta	0.3333333333333333
delta and	1.0
and delta-delta	0.002890173410404624
delta-delta coefficients	1.0
coefficients to	0.25
to capture	0.0013280212483399733
capture speech	0.5
speech dynamics	0.006578947368421052
dynamics and	0.5
addition might	0.16666666666666666
use heteroscedastic	0.013888888888888888
heteroscedastic linear	1.0
linear discriminant	0.2857142857142857
discriminant analysis	1.0
-LRB- HLDA	0.0027100271002710027
HLDA -RRB-	1.0
; or	0.02127659574468085
or might	0.0045045045045045045
might skip	0.038461538461538464
skip the	1.0
the delta	0.0006920415224913495
coefficients and	0.25
use splicing	0.013888888888888888
splicing and	1.0
an LDA-based	0.007575757575757576
LDA-based projection	1.0
projection followed	1.0
followed perhaps	0.25
perhaps by	0.16666666666666666
by heteroscedastic	0.005714285714285714
a global	0.001226993865030675
global semitied	0.3333333333333333
semitied covariance	1.0
covariance transform	0.5
transform -LRB-	0.2
as maximum	0.003484320557491289
linear transform	0.14285714285714285
or MLLT	0.0045045045045045045
MLLT -RRB-	1.0
delta	5.5800457563752025e-05
delta-delta	5.5800457563752025e-05
heteroscedastic	5.5800457563752025e-05
discriminant	5.5800457563752025e-05
HLDA	2.7900228781876013e-05
skip	2.7900228781876013e-05
splicing	2.7900228781876013e-05
LDA-based	2.7900228781876013e-05
projection	2.7900228781876013e-05
semitied	2.7900228781876013e-05
MLLT	2.7900228781876013e-05
Many systems	0.08333333333333333
use so-called	0.013888888888888888
so-called discriminative	0.3333333333333333
discriminative training	1.0
training techniques	0.03571428571428571
that dispense	0.0035460992907801418
dispense with	1.0
a purely	0.001226993865030675
purely statistical	1.0
statistical approach	0.030303030303030304
to HMM	0.0013280212483399733
HMM parameter	0.3333333333333333
parameter estimation	1.0
estimation and	1.0
and instead	0.001445086705202312
instead optimize	0.14285714285714285
optimize some	1.0
some classification-related	0.012048192771084338
classification-related measure	1.0
discriminative	5.5800457563752025e-05
dispense	2.7900228781876013e-05
purely	2.7900228781876013e-05
parameter	2.7900228781876013e-05
estimation	2.7900228781876013e-05
optimize	2.7900228781876013e-05
classification-related	2.7900228781876013e-05
are maximum	0.004149377593360996
maximum mutual	0.16666666666666666
mutual information	1.0
information -LRB-	0.021739130434782608
-LRB- MMI	0.0027100271002710027
MMI -RRB-	1.0
, minimum	0.0005614823133071309
minimum classification	0.5
classification error	0.058823529411764705
error -LRB-	0.16666666666666666
-LRB- MCE	0.0027100271002710027
MCE -RRB-	1.0
and minimum	0.001445086705202312
minimum phone	0.5
phone error	0.25
-LRB- MPE	0.0027100271002710027
MPE -RRB-	1.0
mutual	2.7900228781876013e-05
MMI	2.7900228781876013e-05
minimum	5.5800457563752025e-05
MCE	2.7900228781876013e-05
MPE	2.7900228781876013e-05
<s> Decoding	0.0007686395080707148
Decoding of	0.5
what happens	0.03125
happens when	1.0
presented with	0.16666666666666666
new utterance	0.041666666666666664
utterance and	0.3333333333333333
and must	0.001445086705202312
must compute	0.07142857142857142
compute the	0.5
likely source	0.0625
source sentence	0.08333333333333333
would probably	0.018867924528301886
probably use	0.25
use the	0.013888888888888888
best path	0.05555555555555555
path ,	0.5
and here	0.001445086705202312
here there	0.5
a choice	0.001226993865030675
choice between	0.125
between dynamically	0.02564102564102564
dynamically creating	0.5
combination hidden	0.2
includes both	0.14285714285714285
the acoustic	0.0006920415224913495
acoustic and	0.16666666666666666
language model	0.006756756756756757
model information	0.03333333333333333
and combining	0.001445086705202312
combining it	0.25
it statically	0.008547008547008548
statically beforehand	1.0
beforehand -LRB-	1.0
the finite	0.0006920415224913495
state transducer	0.14285714285714285
transducer ,	0.5
or FST	0.0045045045045045045
FST ,	1.0
, approach	0.0005614823133071309
approach -RRB-	0.05714285714285714
happens	2.7900228781876013e-05
statically	2.7900228781876013e-05
beforehand	2.7900228781876013e-05
transducer	5.5800457563752025e-05
FST	2.7900228781876013e-05
A possible	0.02
possible improvement	0.041666666666666664
improvement to	0.25
to decoding	0.0013280212483399733
decoding is	1.0
keep a	0.3333333333333333
of good	0.00089126559714795
candidates instead	0.2
of just	0.00089126559714795
just keeping	0.1111111111111111
keeping the	0.5
best candidate	0.05555555555555555
candidate ,	0.3333333333333333
better scoring	0.1111111111111111
scoring function	0.5
function -LRB-	0.125
-LRB- rescoring	0.0027100271002710027
rescoring -RRB-	1.0
rate these	0.09090909090909091
these good	0.023809523809523808
candidates so	0.2
we may	0.022222222222222223
may pick	0.019230769230769232
pick the	1.0
best one	0.05555555555555555
one according	0.015384615384615385
this refined	0.01098901098901099
refined score	1.0
decoding	2.7900228781876013e-05
rescoring	2.7900228781876013e-05
pick	2.7900228781876013e-05
refined	2.7900228781876013e-05
The set	0.005208333333333333
of candidates	0.00089126559714795
candidates can	0.2
be kept	0.004219409282700422
kept either	1.0
list -LRB-	0.09090909090909091
the N-best	0.0006920415224913495
N-best list	1.0
list approach	0.09090909090909091
the models	0.0006920415224913495
a lattice	0.001226993865030675
lattice -RRB-	1.0
kept	2.7900228781876013e-05
N-best	2.7900228781876013e-05
lattice	2.7900228781876013e-05
<s> Rescoring	0.0007686395080707148
Rescoring is	1.0
by trying	0.005714285714285714
to minimize	0.0013280212483399733
minimize the	1.0
the Bayes	0.0006920415224913495
Bayes risk	0.3333333333333333
risk -LRB-	0.5
approximation thereof	0.16666666666666666
thereof -RRB-	1.0
: Instead	0.00980392156862745
of taking	0.00089126559714795
sentence with	0.020833333333333332
with maximal	0.00546448087431694
maximal probability	1.0
probability ,	0.14285714285714285
we try	0.022222222222222223
take the	0.2
sentence that	0.041666666666666664
that minimizes	0.0070921985815602835
minimizes the	1.0
the expectancy	0.0006920415224913495
expectancy of	1.0
given loss	0.041666666666666664
loss function	1.0
function with	0.125
with regards	0.00546448087431694
regards to	1.0
possible transcriptions	0.08333333333333333
transcriptions -LRB-	0.5
we take	0.022222222222222223
the average	0.0006920415224913495
average distance	0.5
distance to	0.3333333333333333
to other	0.0013280212483399733
other possible	0.014285714285714285
possible sentences	0.041666666666666664
sentences weighted	0.013157894736842105
weighted by	0.3333333333333333
by their	0.005714285714285714
their estimated	0.029411764705882353
estimated probability	1.0
Rescoring	2.7900228781876013e-05
minimize	2.7900228781876013e-05
thereof	2.7900228781876013e-05
maximal	2.7900228781876013e-05
minimizes	5.5800457563752025e-05
expectancy	2.7900228781876013e-05
loss	5.5800457563752025e-05
regards	2.7900228781876013e-05
transcriptions	5.5800457563752025e-05
estimated	2.7900228781876013e-05
The loss	0.005208333333333333
function is	0.125
usually the	0.03125
the Levenshtein	0.0006920415224913495
Levenshtein distance	1.0
be different	0.004219409282700422
different distances	0.02040816326530612
distances for	0.5
for specific	0.0036101083032490976
specific tasks	0.047619047619047616
tasks ;	0.03125
transcriptions is	0.5
course ,	0.3333333333333333
, pruned	0.0005614823133071309
pruned to	1.0
to maintain	0.0013280212483399733
maintain tractability	1.0
tractability .	1.0
Levenshtein	2.7900228781876013e-05
distances	5.5800457563752025e-05
pruned	2.7900228781876013e-05
maintain	2.7900228781876013e-05
tractability	2.7900228781876013e-05
<s> Efficient	0.0007686395080707148
Efficient algorithms	1.0
been devised	0.014705882352941176
devised to	0.5
to rescore	0.0013280212483399733
rescore lattices	1.0
lattices represented	1.0
as weighted	0.003484320557491289
weighted finite	0.3333333333333333
state transducers	0.07142857142857142
transducers with	1.0
with edit	0.00546448087431694
edit distances	1.0
distances represented	0.5
represented themselves	0.16666666666666666
themselves as	0.25
a finite	0.00245398773006135
transducer verifying	0.5
verifying certain	1.0
certain assumptions	0.14285714285714285
assumptions .	0.2
Efficient	2.7900228781876013e-05
rescore	2.7900228781876013e-05
lattices	2.7900228781876013e-05
transducers	2.7900228781876013e-05
edit	2.7900228781876013e-05
verifying	2.7900228781876013e-05
Dynamic time	0.8
time warping	0.12121212121212122
warping -LRB-	0.25
-LRB- DTW	0.0027100271002710027
DTW -RRB-	0.3333333333333333
-RRB- -	0.0027100271002710027
based speech	0.018518518518518517
recognition Main	0.008264462809917356
: Dynamic	0.00980392156862745
warping Dynamic	0.25
warping is	0.5
was historically	0.012987012987012988
historically used	0.5
recognition but	0.008264462809917356
but has	0.014705882352941176
has now	0.011904761904761904
now largely	0.07692307692307693
largely been	0.2
been displaced	0.014705882352941176
displaced by	1.0
successful HMM-based	0.1111111111111111
warping	0.00011160091512750405
DTW	8.370068634562804e-05
historically	5.5800457563752025e-05
displaced	2.7900228781876013e-05
for measuring	0.0036101083032490976
measuring similarity	1.0
between two	0.05128205128205128
two sequences	0.034482758620689655
sequences that	0.1111111111111111
may vary	0.019230769230769232
in time	0.0018726591760299626
time or	0.030303030303030304
or speed	0.0045045045045045045
measuring	2.7900228781876013e-05
, similarities	0.0005614823133071309
similarities in	0.5
in walking	0.0018726591760299626
walking patterns	0.3333333333333333
patterns would	0.2
be detected	0.004219409282700422
detected ,	0.5
if in	0.07142857142857142
one video	0.015384615384615385
video the	0.2
person was	0.05263157894736842
was walking	0.012987012987012988
walking slowly	0.3333333333333333
slowly and	0.5
and if	0.001445086705202312
another he	0.07692307692307693
he or	0.14285714285714285
or she	0.0045045045045045045
she were	1.0
were walking	0.024390243902439025
walking more	0.3333333333333333
more quickly	0.010526315789473684
quickly ,	1.0
were accelerations	0.024390243902439025
accelerations and	1.0
and decelerations	0.001445086705202312
decelerations during	1.0
the course	0.0006920415224913495
course of	0.3333333333333333
one observation	0.015384615384615385
observation .	1.0
walking	8.370068634562804e-05
slowly	5.5800457563752025e-05
she	2.7900228781876013e-05
quickly	2.7900228781876013e-05
accelerations	2.7900228781876013e-05
decelerations	2.7900228781876013e-05
observation	2.7900228781876013e-05
<s> DTW	0.0007686395080707148
DTW has	0.3333333333333333
to video	0.0013280212483399733
video ,	0.2
and graphics	0.001445086705202312
graphics --	1.0
-- indeed	0.04
indeed ,	0.3333333333333333
, any	0.0005614823133071309
any data	0.03225806451612903
be turned	0.004219409282700422
linear representation	0.14285714285714285
representation can	0.05263157894736842
be analyzed	0.004219409282700422
analyzed with	0.2
with DTW	0.00546448087431694
DTW .	0.3333333333333333
graphics	2.7900228781876013e-05
A well-known	0.02
well-known application	1.0
application has	0.07142857142857142
been automatic	0.014705882352941176
to cope	0.0013280212483399733
cope with	1.0
different speaking	0.02040816326530612
speaking speeds	0.125
speeds .	0.5
well-known	2.7900228781876013e-05
cope	2.7900228781876013e-05
method that	0.0625
that allows	0.0035460992907801418
allows a	0.125
an optimal	0.007575757575757576
optimal match	1.0
match between	0.16666666666666666
two given	0.034482758620689655
given sequences	0.041666666666666664
sequences -LRB-	0.1111111111111111
, time	0.0005614823133071309
time series	0.030303030303030304
series -RRB-	0.125
with certain	0.00546448087431694
certain restrictions	0.14285714285714285
restrictions .	1.0
optimal	2.7900228781876013e-05
restrictions	2.7900228781876013e-05
the sequences	0.0006920415224913495
sequences are	0.1111111111111111
are ``	0.004149377593360996
`` warped	0.005291005291005291
warped ''	1.0
'' non-linearly	0.005154639175257732
non-linearly to	1.0
match each	0.16666666666666666
warped	2.7900228781876013e-05
non-linearly	2.7900228781876013e-05
This sequence	0.015873015873015872
sequence alignment	0.125
alignment method	0.5
method is	0.0625
often used	0.022727272727272728
of hidden	0.00089126559714795
models ...	0.038461538461538464
... .	0.5
alignment	5.5800457563752025e-05
Neural networks	0.75
networks Main	0.07142857142857142
: Neural	0.00980392156862745
networks Neural	0.07142857142857142
networks emerged	0.07142857142857142
emerged as	1.0
an attractive	0.007575757575757576
attractive acoustic	0.3333333333333333
modeling approach	0.14285714285714285
approach in	0.02857142857142857
in ASR	0.003745318352059925
1980s .	0.2222222222222222
emerged	2.7900228781876013e-05
Since then	0.2
, neural	0.0022459292532285235
networks have	0.07142857142857142
many aspects	0.019230769230769232
recognition such	0.008264462809917356
as phoneme	0.003484320557491289
phoneme classification	0.5
classification ,	0.058823529411764705
, isolated	0.0005614823133071309
isolated word	0.2
word recognition	0.016666666666666666
and speaker	0.001445086705202312
to HMMs	0.0013280212483399733
HMMs ,	0.125
networks make	0.07142857142857142
make no	0.05
no assumptions	0.07692307692307693
assumptions about	0.2
about feature	0.025
feature statistical	0.07692307692307693
statistical properties	0.030303030303030304
properties and	0.25
and have	0.001445086705202312
have several	0.009615384615384616
several qualities	0.045454545454545456
qualities making	0.5
making them	0.14285714285714285
them attractive	0.05263157894736842
attractive recognition	0.3333333333333333
recognition models	0.008264462809917356
When used	0.14285714285714285
speech feature	0.006578947368421052
feature segment	0.07692307692307693
segment ,	0.2222222222222222
networks allow	0.07142857142857142
allow discriminative	0.2
training in	0.03571428571428571
efficient manner	0.3333333333333333
<s> Few	0.0007686395080707148
Few assumptions	1.0
assumptions on	0.2
the statistics	0.0006920415224913495
statistics of	0.125
input features	0.024390243902439025
made with	0.0625
with neural	0.00546448087431694
Few	2.7900228781876013e-05
in spite	0.0018726591760299626
spite of	1.0
of their	0.0017825311942959
their effectiveness	0.029411764705882353
effectiveness in	0.3333333333333333
in classifying	0.0018726591760299626
classifying short-time	0.2
short-time units	0.5
units such	0.14285714285714285
as individual	0.003484320557491289
individual phones	0.08333333333333333
phones and	0.5
and isolated	0.001445086705202312
isolated words	0.2
networks are	0.07142857142857142
are rarely	0.004149377593360996
rarely successful	0.3333333333333333
successful for	0.1111111111111111
for continuous	0.0036101083032490976
continuous recognition	0.16666666666666666
recognition tasks	0.01652892561983471
, largely	0.0005614823133071309
largely because	0.2
their lack	0.029411764705882353
lack of	1.0
of ability	0.00089126559714795
to model	0.0013280212483399733
model temporal	0.03333333333333333
temporal dependencies	0.5
spite	2.7900228781876013e-05
phones	5.5800457563752025e-05
lack	2.7900228781876013e-05
one alternative	0.015384615384615385
alternative approach	0.3333333333333333
use neural	0.013888888888888888
networks as	0.07142857142857142
a pre-processing	0.001226993865030675
pre-processing e.g.	1.0
e.g. feature	0.017857142857142856
feature transformation	0.07692307692307693
transformation ,	1.0
, dimensionality	0.0005614823133071309
dimensionality reduction	1.0
reduction ,	0.5
the HMM	0.0006920415224913495
HMM based	0.3333333333333333
based recognition	0.018518518518518517
pre-processing	2.7900228781876013e-05
transformation	2.7900228781876013e-05
dimensionality	2.7900228781876013e-05
Further information	0.3333333333333333
information Popular	0.021739130434782608
Popular speech	1.0
recognition conferences	0.008264462809917356
conferences held	1.0
held each	1.0
each year	0.022222222222222223
year or	0.16666666666666666
two include	0.034482758620689655
include SpeechTEK	0.037037037037037035
SpeechTEK and	0.5
and SpeechTEK	0.001445086705202312
SpeechTEK Europe	0.5
, ICASSP	0.0005614823133071309
ICASSP ,	1.0
, Eurospeech\/ICSLP	0.0005614823133071309
Eurospeech\/ICSLP -LRB-	1.0
now named	0.15384615384615385
named Interspeech	0.14285714285714285
Interspeech -RRB-	1.0
the IEEE	0.001384083044982699
IEEE ASRU	0.3333333333333333
ASRU .	1.0
Popular	2.7900228781876013e-05
conferences	2.7900228781876013e-05
held	2.7900228781876013e-05
SpeechTEK	5.5800457563752025e-05
ICASSP	2.7900228781876013e-05
Eurospeech\/ICSLP	2.7900228781876013e-05
Interspeech	2.7900228781876013e-05
IEEE	8.370068634562804e-05
ASRU	2.7900228781876013e-05
<s> Conferences	0.0007686395080707148
Conferences in	0.5
of Natural	0.00089126559714795
as ACL	0.003484320557491289
ACL ,	0.5
, NAACL	0.0005614823133071309
NAACL ,	1.0
, EMNLP	0.0005614823133071309
EMNLP ,	1.0
and HLT	0.001445086705202312
HLT ,	1.0
are beginning	0.004149377593360996
beginning to	0.5
include papers	0.037037037037037035
on speech	0.0047169811320754715
speech processing	0.006578947368421052
NAACL	2.7900228781876013e-05
EMNLP	2.7900228781876013e-05
HLT	2.7900228781876013e-05
<s> Important	0.0007686395080707148
Important journals	1.0
journals include	0.5
IEEE Transactions	0.6666666666666666
Transactions on	1.0
on Speech	0.0047169811320754715
and Audio	0.001445086705202312
Audio Processing	0.5
Processing -LRB-	0.75
named IEEE	0.14285714285714285
on Audio	0.0047169811320754715
Audio ,	0.5
Language Processing	0.25
Processing -RRB-	0.25
, Computer	0.0005614823133071309
Computer Speech	0.3333333333333333
Language ,	0.08333333333333333
and Speech	0.001445086705202312
Speech Communication	0.03225806451612903
Communication .	1.0
Important	2.7900228781876013e-05
Transactions	5.5800457563752025e-05
Audio	5.5800457563752025e-05
Processing	0.00011160091512750405
Communication	2.7900228781876013e-05
<s> Books	0.0007686395080707148
Books like	1.0
`` Fundamentals	0.010582010582010581
Fundamentals of	1.0
of Speech	0.00089126559714795
Recognition ''	0.375
'' by	0.02577319587628866
by Lawrence	0.005714285714285714
Lawrence Rabiner	1.0
Rabiner can	1.0
to acquire	0.0013280212483399733
acquire basic	1.0
basic knowledge	0.07692307692307693
knowledge but	0.037037037037037035
fully up	0.16666666666666666
to date	0.0026560424966799467
-LRB- 1993	0.0027100271002710027
1993 -RRB-	0.3333333333333333
Books	2.7900228781876013e-05
Fundamentals	5.5800457563752025e-05
Lawrence	2.7900228781876013e-05
Rabiner	2.7900228781876013e-05
acquire	2.7900228781876013e-05
A very	0.02
very recent	0.024390243902439025
recent book	0.125
book -LRB-	0.25
-LRB- Dec.	0.0027100271002710027
Dec. 2011	1.0
2011 -RRB-	0.5
of Speaker	0.00089126559714795
Speaker Recognition	0.16666666666666666
by Homayoon	0.005714285714285714
Homayoon Beigi	1.0
Beigi covers	1.0
more recent	0.010526315789473684
recent developments	0.125
some detail	0.012048192771084338
detail .	0.5
Dec.	2.7900228781876013e-05
Homayoon	2.7900228781876013e-05
Beigi	2.7900228781876013e-05
the title	0.0006920415224913495
title concentrates	1.0
concentrates on	1.0
on speaker	0.0047169811320754715
speaker recognition	0.05555555555555555
but a	0.014705882352941176
large portion	0.043478260869565216
book applies	0.125
applies directly	0.14285714285714285
lot of	0.3333333333333333
of valuable	0.00089126559714795
valuable detailed	0.5
detailed background	0.5
background material	0.3333333333333333
material .	0.5
title	2.7900228781876013e-05
concentrates	2.7900228781876013e-05
Another good	0.07692307692307693
good source	0.07692307692307693
source can	0.041666666666666664
be ``	0.004219409282700422
`` Statistical	0.005291005291005291
Statistical Methods	0.1111111111111111
for Speech	0.0036101083032490976
by Frederick	0.005714285714285714
Frederick Jelinek	1.0
Jelinek and	0.5
`` Spoken	0.005291005291005291
Spoken Language	1.0
-LRB- 2001	0.0027100271002710027
2001 -RRB-	0.5
-RRB- ''	0.005420054200542005
by Xuedong	0.005714285714285714
Xuedong Huang	1.0
Huang etc.	1.0
Frederick	2.7900228781876013e-05
Spoken	2.7900228781876013e-05
Xuedong	2.7900228781876013e-05
Huang	2.7900228781876013e-05
More up	0.1111111111111111
date is	0.3333333333333333
`` Computer	0.005291005291005291
Speech ''	0.03225806451612903
by Manfred	0.005714285714285714
Manfred R.	1.0
R. Schroeder	0.16666666666666666
Schroeder ,	1.0
, second	0.0005614823133071309
second edition	0.1
edition published	1.0
published in	0.14285714285714285
in 2004	0.0018726591760299626
2004 .	0.3333333333333333
Manfred	2.7900228781876013e-05
Schroeder	2.7900228781876013e-05
edition	2.7900228781876013e-05
The recently	0.005208333333333333
recently updated	0.3333333333333333
updated textbook	1.0
textbook of	0.5
`` Speech	0.005291005291005291
-LRB- 2008	0.0027100271002710027
2008 -RRB-	1.0
by Jurafsky	0.005714285714285714
Jurafsky and	1.0
and Martin	0.001445086705202312
Martin presents	0.5
presents the	1.0
the basics	0.0006920415224913495
basics and	1.0
art for	0.5
for ASR	0.0036101083032490976
ASR .	0.16666666666666666
updated	2.7900228781876013e-05
2008	2.7900228781876013e-05
Jurafsky	2.7900228781876013e-05
presents	2.7900228781876013e-05
basics	2.7900228781876013e-05
A good	0.02
good insight	0.07692307692307693
insight into	1.0
the techniques	0.0006920415224913495
techniques used	0.043478260869565216
best modern	0.05555555555555555
modern systems	0.2
be gained	0.004219409282700422
gained by	0.5
by paying	0.005714285714285714
paying attention	1.0
attention to	0.5
to government	0.0013280212483399733
government sponsored	0.3333333333333333
sponsored evaluations	0.5
evaluations such	0.16666666666666666
those organised	0.045454545454545456
organised by	1.0
by DARPA	0.005714285714285714
DARPA -LRB-	0.25
the largest	0.0006920415224913495
largest speech	1.0
speech recognition-related	0.006578947368421052
recognition-related project	1.0
project ongoing	0.07692307692307693
ongoing as	0.5
2007 is	0.2
the GALE	0.001384083044982699
GALE project	1.0
which involves	0.007246376811594203
involves both	0.1
both speech	0.03225806451612903
translation components	0.013513513513513514
components -RRB-	0.2
insight	2.7900228781876013e-05
paying	2.7900228781876013e-05
organised	2.7900228781876013e-05
largest	2.7900228781876013e-05
recognition-related	2.7900228781876013e-05
GALE	5.5800457563752025e-05
In terms	0.009523809523809525
of freely	0.00089126559714795
freely available	1.0
available resources	0.058823529411764705
resources ,	0.3333333333333333
, Carnegie	0.0005614823133071309
University 's	0.1111111111111111
's SPHINX	0.0196078431372549
SPHINX toolkit	1.0
toolkit is	0.5
one place	0.015384615384615385
place to	0.25
to start	0.0026560424966799467
start to	0.14285714285714285
both learn	0.03225806451612903
learn about	0.07692307692307693
start experimenting	0.14285714285714285
experimenting .	1.0
freely	2.7900228781876013e-05
SPHINX	2.7900228781876013e-05
toolkit	5.5800457563752025e-05
experimenting	2.7900228781876013e-05
Another resource	0.07692307692307693
resource -LRB-	0.2
-LRB- free	0.0027100271002710027
free as	0.25
in free	0.003745318352059925
free beer	0.25
beer ,	1.0
not as	0.008928571428571428
free speech	0.25
the HTK	0.0006920415224913495
HTK book	0.5
the accompanying	0.0006920415224913495
accompanying HTK	1.0
HTK toolkit	0.5
toolkit -RRB-	0.5
beer	2.7900228781876013e-05
HTK	5.5800457563752025e-05
accompanying	2.7900228781876013e-05
The AT&T	0.005208333333333333
AT&T libraries	1.0
libraries GRM	0.5
GRM library	1.0
library ,	0.5
and DCD	0.001445086705202312
DCD library	1.0
library are	0.5
also general	0.014492753623188406
general software	0.045454545454545456
software libraries	0.037037037037037035
libraries for	0.5
for large-vocabulary	0.0036101083032490976
AT&T	2.7900228781876013e-05
libraries	5.5800457563752025e-05
GRM	2.7900228781876013e-05
library	5.5800457563752025e-05
DCD	2.7900228781876013e-05
more software	0.010526315789473684
software resources	0.037037037037037035
see List	0.05
software .	0.037037037037037035
A useful	0.02
useful review	0.07142857142857142
review of	0.3333333333333333
of robustness	0.00089126559714795
robustness in	0.25
ASR is	0.16666666666666666
is provided	0.0020325203252032522
by Junqua	0.005714285714285714
Junqua and	1.0
and Haton	0.001445086705202312
Haton -LRB-	1.0
-LRB- 1995	0.0027100271002710027
1995 -RRB-	1.0
robustness	0.00011160091512750405
Junqua	2.7900228781876013e-05
Haton	2.7900228781876013e-05
1995	2.7900228781876013e-05
<s> People	0.0007686395080707148
People with	1.0
with disabilities	0.01092896174863388
disabilities People	0.25
disabilities can	0.25
can benefit	0.011049723756906077
from speech	0.009615384615384616
recognition programs	0.008264462809917356
People	5.5800457563752025e-05
disabilities	0.00011160091512750405
For individuals	0.01639344262295082
individuals that	1.0
are Deaf	0.004149377593360996
Deaf or	1.0
or Hard	0.0045045045045045045
Hard of	0.5
of Hearing	0.00089126559714795
Hearing ,	1.0
software is	0.07407407407407407
automatically generate	0.047619047619047616
a closed-captioning	0.001226993865030675
closed-captioning of	1.0
of conversations	0.00089126559714795
conversations such	0.3333333333333333
as discussions	0.003484320557491289
discussions in	0.3333333333333333
in conference	0.0018726591760299626
conference rooms	0.5
rooms ,	1.0
, classroom	0.0005614823133071309
classroom lectures	1.0
lectures ,	1.0
, and\/or	0.0005614823133071309
and\/or religious	0.3333333333333333
religious services	1.0
individuals	2.7900228781876013e-05
Deaf	2.7900228781876013e-05
Hearing	2.7900228781876013e-05
closed-captioning	2.7900228781876013e-05
rooms	2.7900228781876013e-05
classroom	2.7900228781876013e-05
lectures	2.7900228781876013e-05
religious	2.7900228781876013e-05
people who	0.125
who have	0.2
have difficulty	0.009615384615384616
difficulty using	0.14285714285714285
using their	0.01694915254237288
their hands	0.029411764705882353
hands ,	1.0
from mild	0.009615384615384616
mild repetitive	1.0
repetitive stress	0.5
stress injuries	0.5
injuries to	1.0
to involved	0.0013280212483399733
involved disabilities	0.16666666666666666
disabilities that	0.25
that preclude	0.0035460992907801418
preclude using	1.0
using conventional	0.01694915254237288
conventional computer	1.0
computer input	0.022727272727272728
hands	2.7900228781876013e-05
mild	2.7900228781876013e-05
injuries	2.7900228781876013e-05
preclude	2.7900228781876013e-05
conventional	2.7900228781876013e-05
, people	0.0005614823133071309
who used	0.1
used the	0.008849557522123894
the keyboard	0.0006920415224913495
keyboard a	0.3333333333333333
lot and	0.3333333333333333
developed RSI	0.038461538461538464
RSI became	1.0
became an	0.2
an urgent	0.007575757575757576
urgent early	1.0
early market	0.1
market for	0.3333333333333333
RSI	2.7900228781876013e-05
urgent	2.7900228781876013e-05
in deaf	0.0018726591760299626
deaf telephony	1.0
as voicemail	0.003484320557491289
voicemail to	1.0
, relay	0.0005614823133071309
relay services	1.0
services ,	0.3333333333333333
and captioned	0.001445086705202312
captioned telephone	1.0
telephone .	0.5
deaf	2.7900228781876013e-05
voicemail	2.7900228781876013e-05
relay	2.7900228781876013e-05
captioned	2.7900228781876013e-05
<s> Individuals	0.0007686395080707148
Individuals with	1.0
with learning	0.00546448087431694
learning disabilities	0.023255813953488372
disabilities who	0.25
have problems	0.009615384615384616
problems with	0.058823529411764705
with thought-to-paper	0.00546448087431694
thought-to-paper communication	1.0
-LRB- essentially	0.0027100271002710027
essentially they	0.125
they think	0.025
think of	0.3333333333333333
an idea	0.007575757575757576
idea but	0.14285714285714285
is processed	0.0020325203252032522
processed incorrectly	0.16666666666666666
incorrectly causing	1.0
causing it	1.0
up differently	0.045454545454545456
differently on	1.0
on paper	0.0047169811320754715
paper -RRB-	0.09090909090909091
software -LRB-	0.037037037037037035
Individuals	2.7900228781876013e-05
thought-to-paper	2.7900228781876013e-05
incorrectly	2.7900228781876013e-05
causing	2.7900228781876013e-05
differently	2.7900228781876013e-05
-LRB- icon	0.0027100271002710027
icon -RRB-	1.0
-RRB- This	0.0027100271002710027
requires expansion	0.0625
expansion .	0.3333333333333333
icon	2.7900228781876013e-05
Current research	0.2
and funding	0.001445086705202312
funding Measuring	0.125
Measuring progress	1.0
progress in	0.2857142857142857
recognition performance	0.03305785123966942
performance is	0.1111111111111111
difficult and	0.03571428571428571
and controversial	0.001445086705202312
controversial .	1.0
Measuring	2.7900228781876013e-05
controversial	2.7900228781876013e-05
Some speech	0.047619047619047616
Word error	0.14285714285714285
rates on	0.125
some tasks	0.012048192771084338
are less	0.004149377593360996
than 1	0.022222222222222223
On others	0.16666666666666666
others they	0.08333333333333333
as high	0.003484320557491289
high as	0.05555555555555555
as 50	0.003484320557491289
<s> Sometimes	0.0007686395080707148
Sometimes it	1.0
it even	0.008547008547008548
even appears	0.037037037037037035
appears that	0.2
that performance	0.010638297872340425
is going	0.0020325203252032522
going backward	0.25
backward ,	1.0
as researchers	0.003484320557491289
researchers undertake	0.1
undertake harder	1.0
harder tasks	0.14285714285714285
tasks that	0.03125
have higher	0.009615384615384616
higher error	0.14285714285714285
rates .	0.125
Sometimes	2.7900228781876013e-05
backward	2.7900228781876013e-05
undertake	2.7900228781876013e-05
Because progress	0.5
progress is	0.14285714285714285
is slow	0.0020325203252032522
slow and	0.5
measure ,	0.09090909090909091
is some	0.0020325203252032522
some perception	0.012048192771084338
perception that	0.5
performance has	0.05555555555555555
has plateaued	0.011904761904761904
plateaued and	1.0
that funding	0.0035460992907801418
funding has	0.125
has dried	0.011904761904761904
dried up	1.0
up or	0.045454545454545456
or shifted	0.0045045045045045045
shifted priorities	1.0
priorities .	1.0
slow	5.5800457563752025e-05
plateaued	5.5800457563752025e-05
dried	2.7900228781876013e-05
shifted	2.7900228781876013e-05
priorities	2.7900228781876013e-05
Such perceptions	0.125
perceptions are	1.0
not new	0.008928571428571428
new .	0.041666666666666664
perceptions	2.7900228781876013e-05
1969 ,	0.5
John Pierce	0.125
Pierce wrote	1.0
open letter	0.25
letter that	0.16666666666666666
did cause	0.2
cause much	0.5
much funding	0.045454545454545456
funding to	0.125
to dry	0.0013280212483399733
dry up	1.0
Pierce	2.7900228781876013e-05
dry	2.7900228781876013e-05
In 1993	0.009523809523809525
1993 there	0.3333333333333333
strong feeling	0.25
feeling that	1.0
performance had	0.05555555555555555
had plateaued	0.07142857142857142
were workshops	0.024390243902439025
workshops dedicated	0.5
feeling	2.7900228781876013e-05
1990s ,	0.3333333333333333
funding continued	0.125
continued more	0.1111111111111111
less uninterrupted	0.08333333333333333
uninterrupted and	1.0
and performance	0.001445086705202312
performance continued	0.05555555555555555
continued ,	0.1111111111111111
, slowly	0.0005614823133071309
slowly but	0.5
but steadily	0.014705882352941176
steadily ,	1.0
improve .	0.07692307692307693
uninterrupted	2.7900228781876013e-05
steadily	2.7900228781876013e-05
For the	0.01639344262295082
past thirty	0.3333333333333333
thirty years	1.0
recognition research	0.008264462809917356
been characterized	0.014705882352941176
steady accumulation	0.5
accumulation of	1.0
of small	0.00089126559714795
small incremental	0.1111111111111111
incremental improvements	1.0
improvements .	0.5
thirty	2.7900228781876013e-05
accumulation	2.7900228781876013e-05
incremental	2.7900228781876013e-05
a trend	0.001226993865030675
to change	0.0013280212483399733
change focus	1.0
focus to	0.14285714285714285
to more	0.0026560424966799467
difficult tasks	0.07142857142857142
tasks due	0.03125
to progress	0.0013280212483399733
the availability	0.0006920415224913495
availability of	1.0
of faster	0.00089126559714795
faster computers	0.3333333333333333
change	2.7900228781876013e-05
availability	2.7900228781876013e-05
this shifting	0.01098901098901099
shifting to	1.0
tasks has	0.03125
has characterized	0.011904761904761904
characterized DARPA	0.25
DARPA funding	0.25
funding of	0.125
recognition since	0.008264462809917356
since the	0.1
shifting	2.7900228781876013e-05
decade ,	0.3333333333333333
has continued	0.011904761904761904
continued with	0.1111111111111111
the EARS	0.0006920415224913495
EARS project	1.0
which undertook	0.007246376811594203
undertook recognition	1.0
of Mandarin	0.00089126559714795
Mandarin and	1.0
and Arabic	0.002890173410404624
Arabic in	0.25
to English	0.0013280212483399733
which focused	0.007246376811594203
focused solely	0.09090909090909091
solely on	1.0
on Mandarin	0.0047169811320754715
Arabic and	0.25
and required	0.001445086705202312
required translation	0.14285714285714285
translation simultaneously	0.013513513513513514
simultaneously with	0.5
EARS	2.7900228781876013e-05
undertook	2.7900228781876013e-05
Mandarin	5.5800457563752025e-05
solely	2.7900228781876013e-05
Commercial research	0.5
other academic	0.014285714285714285
academic research	1.0
research also	0.023809523809523808
also continue	0.014492753623188406
continue to	1.0
to focus	0.0013280212483399733
on increasingly	0.0047169811320754715
increasingly difficult	0.3333333333333333
academic	2.7900228781876013e-05
continue	2.7900228781876013e-05
One key	0.07692307692307693
key area	0.3333333333333333
improve robustness	0.07692307692307693
robustness of	0.25
not just	0.008928571428571428
just robustness	0.1111111111111111
robustness against	0.5
against noise	0.2
noise but	0.125
but robustness	0.014705882352941176
against any	0.2
any condition	0.03225806451612903
condition that	1.0
that causes	0.0035460992907801418
causes a	1.0
major degradation	0.08333333333333333
degradation in	1.0
in performance	0.0018726591760299626
condition	2.7900228781876013e-05
causes	2.7900228781876013e-05
degradation	2.7900228781876013e-05
Another key	0.07692307692307693
research is	0.047619047619047616
is focused	0.0020325203252032522
an opportunity	0.007575757575757576
opportunity rather	0.5
This research	0.015873015873015872
applications there	0.04
large quantity	0.043478260869565216
quantity of	0.3333333333333333
speech data	0.006578947368421052
, up	0.0005614823133071309
to millions	0.0013280212483399733
of hours	0.00089126559714795
hours .	0.5
is too	0.0020325203252032522
expensive to	0.14285714285714285
have humans	0.009615384615384616
humans transcribe	0.08333333333333333
transcribe such	1.0
such large	0.008130081300813009
large quantities	0.08695652173913043
quantities of	0.6666666666666666
research focus	0.023809523809523808
focus is	0.14285714285714285
on developing	0.0047169811320754715
developing new	0.25
new methods	0.041666666666666664
learning that	0.023255813953488372
can effectively	0.0055248618784530384
effectively utilize	0.3333333333333333
utilize large	0.5
of unlabeled	0.00089126559714795
unlabeled data	1.0
transcribe	2.7900228781876013e-05
unlabeled	2.7900228781876013e-05
Another area	0.07692307692307693
is better	0.0020325203252032522
better understanding	0.1111111111111111
human capabilities	0.021739130434782608
capabilities and	0.2
this understanding	0.01098901098901099
improve machine	0.07692307692307693
machine recognition	0.012658227848101266
of identifying	0.00089126559714795
boundaries between	0.18181818181818182
between words	0.05128205128205128
, syllables	0.0005614823133071309
syllables ,	0.5
phonemes in	0.16666666666666666
spoken natural	0.07142857142857142
syllables	5.5800457563752025e-05
term applies	0.1111111111111111
applies both	0.2857142857142857
the mental	0.0006920415224913495
mental processes	0.6666666666666666
processes used	0.4
by humans	0.011428571428571429
to artificial	0.0026560424966799467
artificial processes	0.18181818181818182
processes of	0.2
important subproblem	0.0625
subproblem of	1.0
be adequately	0.004219409282700422
adequately solved	1.0
solved in	0.2
in isolation	0.0018726591760299626
isolation .	0.5
subproblem	2.7900228781876013e-05
adequately	2.7900228781876013e-05
processing problems	0.018518518518518517
one must	0.015384615384615385
must take	0.07142857142857142
account context	0.3333333333333333
, grammar	0.0005614823133071309
even so	0.037037037037037035
often a	0.022727272727272728
a probabilistic	0.001226993865030675
probabilistic division	0.14285714285714285
division rather	0.5
a categorical	0.001226993865030675
categorical .	1.0
categorical	2.7900228781876013e-05
A comprehensive	0.02
comprehensive survey	0.2
survey of	1.0
segmentation problems	0.06060606060606061
and techniques	0.001445086705202312
techniques can	0.043478260869565216
seen in	0.1
in .	0.0018726591760299626
survey	2.7900228781876013e-05
Some writing	0.047619047619047616
writing systems	0.2222222222222222
systems indicate	0.008928571428571428
indicate speech	0.3333333333333333
segmentation between	0.030303030303030304
words by	0.009174311926605505
word divider	0.016666666666666666
divider ,	1.0
the space	0.0020761245674740486
space .	0.2
divider	2.7900228781876013e-05
is compounded	0.0020325203252032522
compounded by	1.0
of co-articulation	0.00089126559714795
co-articulation of	1.0
speech sounds	0.006578947368421052
where one	0.02857142857142857
one may	0.015384615384615385
be modified	0.004219409282700422
modified in	1.0
ways by	0.125
the adjacent	0.0006920415224913495
adjacent sounds	0.16666666666666666
sounds :	0.06666666666666667
: it	0.00980392156862745
may blend	0.019230769230769232
blend smoothly	0.6666666666666666
smoothly with	0.5
, fuse	0.0005614823133071309
fuse with	1.0
, split	0.0005614823133071309
split ,	0.25
even disappear	0.037037037037037035
disappear .	1.0
compounded	2.7900228781876013e-05
co-articulation	2.7900228781876013e-05
modified	2.7900228781876013e-05
smoothly	5.5800457563752025e-05
fuse	5.5800457563752025e-05
disappear	2.7900228781876013e-05
phenomenon may	0.2
may happen	0.019230769230769232
happen between	1.0
between adjacent	0.05128205128205128
adjacent words	0.3333333333333333
words just	0.009174311926605505
easily as	0.1111111111111111
as within	0.003484320557491289
single word	0.07142857142857142
happen	2.7900228781876013e-05
notion that	0.25
that speech	0.0035460992907801418
speech is	0.006578947368421052
produced like	0.1111111111111111
like writing	0.03571428571428571
of distinct	0.00089126559714795
distinct vowels	0.14285714285714285
vowels and	0.3333333333333333
and consonants	0.001445086705202312
consonants ,	0.3333333333333333
a relic	0.001226993865030675
relic of	1.0
of our	0.00089126559714795
our alphabetic	0.2
alphabetic heritage	1.0
heritage -LRB-	1.0
vowels	8.370068634562804e-05
consonants	8.370068634562804e-05
relic	2.7900228781876013e-05
alphabetic	2.7900228781876013e-05
heritage	2.7900228781876013e-05
way we	0.08333333333333333
we produce	0.044444444444444446
produce vowels	0.045454545454545456
vowels depends	0.3333333333333333
the surrounding	0.001384083044982699
surrounding consonants	0.2
consonants and	0.3333333333333333
produce consonants	0.045454545454545456
consonants depends	0.3333333333333333
surrounding vowels	0.2
vowels .	0.3333333333333333
when we	0.05714285714285714
we say	0.044444444444444446
say `	0.2857142857142857
` kit	0.125
kit '	1.0
the -LRB-	0.0006920415224913495
-LRB- k	0.0027100271002710027
k -RRB-	1.0
is farther	0.0020325203252032522
farther forward	1.0
forward than	1.0
than when	0.022222222222222223
` caught	0.0625
caught '	1.0
' .	0.10526315789473684
kit	5.5800457563752025e-05
k	2.7900228781876013e-05
farther	2.7900228781876013e-05
forward	2.7900228781876013e-05
caught	2.7900228781876013e-05
But also	0.16666666666666666
the vowel	0.001384083044982699
vowel in	1.0
in `	0.003745318352059925
` kick	0.0625
kick '	1.0
' is	0.05263157894736842
is phonetically	0.0020325203252032522
phonetically different	1.0
though we	0.1
we normally	0.022222222222222223
normally do	0.5
not hear	0.008928571428571428
hear this	0.5
this .	0.01098901098901099
vowel	5.5800457563752025e-05
kick	2.7900228781876013e-05
phonetically	2.7900228781876013e-05
normally	5.5800457563752025e-05
are language-specific	0.004149377593360996
language-specific changes	1.0
changes which	1.0
which occur	0.007246376811594203
occur on	0.2
on casual	0.0047169811320754715
casual speech	1.0
speech which	0.006578947368421052
it quite	0.008547008547008548
from spelling	0.009615384615384616
spelling .	1.0
language-specific	2.7900228781876013e-05
changes	2.7900228781876013e-05
casual	2.7900228781876013e-05
spelling	2.7900228781876013e-05
phrase `	0.1
` hit	0.0625
hit you	1.0
you '	0.07692307692307693
' could	0.05263157894736842
could often	0.0625
often be	0.022727272727272728
more appropriately	0.010526315789473684
appropriately spelled	0.5
spelled `	1.0
` hitcha	0.0625
hitcha '	1.0
hit	2.7900228781876013e-05
spelled	2.7900228781876013e-05
hitcha	2.7900228781876013e-05
even with	0.037037037037037035
best algorithms	0.05555555555555555
of phonetic	0.00089126559714795
phonetic segmentation	0.5
segmentation will	0.030303030303030304
will usually	0.02857142857142857
usually be	0.03125
very distant	0.024390243902439025
distant from	1.0
standard written	0.07142857142857142
written language	0.11538461538461539
phonetic	5.5800457563752025e-05
distant	2.7900228781876013e-05
the lexical	0.0006920415224913495
syntactic parsing	0.07692307692307693
spoken text	0.07142857142857142
text normally	0.006289308176100629
normally requires	0.5
requires specialized	0.0625
specialized algorithms	0.5
, distinct	0.0005614823133071309
for parsing	0.0036101083032490976
parsing written	0.03571428571428571
Statistical models	0.1111111111111111
models can	0.038461538461538464
to segment	0.00398406374501992
segment and	0.1111111111111111
and align	0.001445086705202312
align recorded	1.0
recorded speech	0.5
to words	0.0013280212483399733
or phones	0.0045045045045045045
phones .	0.5
align	2.7900228781876013e-05
Applications include	0.5
include automatic	0.037037037037037035
automatic lip-synch	0.043478260869565216
lip-synch timing	1.0
timing for	1.0
for cartoon	0.0036101083032490976
cartoon animation	1.0
animation ,	1.0
, follow-the-bouncing-ball	0.0005614823133071309
follow-the-bouncing-ball video	1.0
video sub-titling	0.2
sub-titling ,	1.0
and linguistic	0.001445086705202312
linguistic research	0.0625
lip-synch	2.7900228781876013e-05
timing	2.7900228781876013e-05
cartoon	2.7900228781876013e-05
animation	2.7900228781876013e-05
follow-the-bouncing-ball	2.7900228781876013e-05
sub-titling	2.7900228781876013e-05
Automatic segmentation	0.3333333333333333
and alignment	0.001445086705202312
alignment software	0.5
is commercially	0.0020325203252032522
Lexical segmentation	0.5
segmentation In	0.030303030303030304
In all	0.009523809523809525
all natural	0.023255813953488372
complex spoken	0.041666666666666664
spoken sentence	0.07142857142857142
sentence -LRB-	0.020833333333333332
which often	0.007246376811594203
been heard	0.014705882352941176
heard or	1.0
or uttered	0.0045045045045045045
uttered before	0.3333333333333333
be understood	0.004219409282700422
understood only	1.0
by decomposing	0.005714285714285714
decomposing it	1.0
into smaller	0.01282051282051282
smaller lexical	0.14285714285714285
lexical segments	0.07692307692307693
segments -LRB-	0.2
-LRB- roughly	0.005420054200542005
roughly ,	0.6666666666666666
language -RRB-	0.013513513513513514
, associating	0.0005614823133071309
associating a	1.0
each segment	0.044444444444444446
then combining	0.02857142857142857
combining those	0.25
those meanings	0.045454545454545456
meanings according	0.25
heard	2.7900228781876013e-05
understood	2.7900228781876013e-05
decomposing	2.7900228781876013e-05
associating	2.7900228781876013e-05
The recognition	0.005208333333333333
each lexical	0.022222222222222223
lexical segment	0.07692307692307693
segment in	0.1111111111111111
turn requires	0.16666666666666666
requires its	0.0625
its decomposition	0.02857142857142857
decomposition into	1.0
of discrete	0.00089126559714795
discrete phonetic	0.3333333333333333
phonetic segments	0.5
segments and	0.2
and mapping	0.001445086705202312
mapping each	0.5
segment to	0.1111111111111111
one element	0.015384615384615385
element of	1.0
finite set	0.2
of elementary	0.00089126559714795
elementary sounds	1.0
phonemes of	0.16666666666666666
meaning then	0.043478260869565216
then can	0.02857142857142857
found by	0.07142857142857142
by standard	0.005714285714285714
standard table	0.07142857142857142
table lookup	0.14285714285714285
lookup algorithms	1.0
decomposition	2.7900228781876013e-05
element	2.7900228781876013e-05
elementary	2.7900228781876013e-05
lookup	2.7900228781876013e-05
For most	0.01639344262295082
lexical units	0.07692307692307693
are surprisingly	0.004149377593360996
surprisingly difficult	0.3333333333333333
identify .	0.08333333333333333
One might	0.07692307692307693
might expect	0.038461538461538464
expect that	0.3333333333333333
the inter-word	0.0006920415224913495
inter-word spaces	1.0
spaces used	0.2
by many	0.005714285714285714
many written	0.019230769230769232
English or	0.02702702702702703
or Spanish	0.0045045045045045045
Spanish ,	0.5
would correspond	0.018867924528301886
to pauses	0.0013280212483399733
pauses in	0.25
their spoken	0.029411764705882353
spoken version	0.07142857142857142
version ;	0.3333333333333333
is true	0.0020325203252032522
true only	0.5
very slow	0.024390243902439025
slow speech	0.5
speaker deliberately	0.05555555555555555
deliberately inserts	1.0
inserts those	1.0
those pauses	0.045454545454545456
pauses .	0.25
inter-word	5.5800457563752025e-05
deliberately	2.7900228781876013e-05
inserts	2.7900228781876013e-05
In normal	0.009523809523809525
normal speech	0.5
one typically	0.015384615384615385
typically finds	0.05555555555555555
finds many	1.0
many consecutive	0.019230769230769232
consecutive words	0.5
words being	0.009174311926605505
being said	0.05555555555555555
said with	1.0
no pauses	0.07692307692307693
final sounds	0.1111111111111111
sounds of	0.13333333333333333
word blend	0.016666666666666666
smoothly or	0.5
or fuse	0.0045045045045045045
the initial	0.0006920415224913495
initial sounds	0.3333333333333333
finds	2.7900228781876013e-05
said	2.7900228781876013e-05
utterance can	0.3333333333333333
different meanings	0.02040816326530612
meanings depending	0.25
A popular	0.02
popular example	0.1111111111111111
often quoted	0.022727272727272728
quoted in	1.0
field ,	0.037037037037037035
phrase How	0.1
How to	0.2857142857142857
to wreck	0.0013280212483399733
wreck a	1.0
nice beach	0.25
beach ,	1.0
which sounds	0.007246376811594203
sounds very	0.06666666666666667
to How	0.0013280212483399733
recognize speech	0.1111111111111111
quoted	2.7900228781876013e-05
wreck	2.7900228781876013e-05
beach	2.7900228781876013e-05
As this	0.05555555555555555
this example	0.01098901098901099
example shows	0.012345679012345678
shows ,	1.0
, proper	0.0005614823133071309
proper lexical	0.14285714285714285
lexical segmentation	0.07692307692307693
segmentation depends	0.030303030303030304
on context	0.0047169811320754715
which draws	0.007246376811594203
draws on	1.0
the whole	0.0006920415224913495
whole of	0.1111111111111111
human knowledge	0.021739130434782608
and experience	0.001445086705202312
experience ,	0.5
and would	0.001445086705202312
would thus	0.018867924528301886
thus require	0.1
require advanced	0.045454545454545456
advanced pattern	0.2
and artificial	0.001445086705202312
intelligence technologies	0.125
technologies to	0.25
implemented on	0.2
shows	2.7900228781876013e-05
draws	2.7900228781876013e-05
problem overlaps	0.022727272727272728
overlaps to	0.5
some extent	0.012048192771084338
extent with	0.25
segmentation that	0.030303030303030304
that occurs	0.0035460992907801418
languages which	0.02
traditionally written	0.5
written without	0.038461538461538464
without inter-word	0.07692307692307693
spaces ,	0.2
Chinese and	0.14285714285714285
and Japanese	0.001445086705202312
Japanese .	0.125
even for	0.037037037037037035
often much	0.022727272727272728
much easier	0.045454545454545456
than speech	0.022222222222222223
segmentation ,	0.09090909090909091
the written	0.0006920415224913495
language usually	0.006756756756756757
usually has	0.03125
has little	0.011904761904761904
little interference	0.3333333333333333
interference between	1.0
often contains	0.022727272727272728
contains additional	0.1
additional clues	0.16666666666666666
clues not	0.3333333333333333
of Chinese	0.00089126559714795
Chinese characters	0.14285714285714285
characters for	0.0625
for word	0.0036101083032490976
word stems	0.016666666666666666
stems in	0.5
in Japanese	0.0018726591760299626
Japanese -RRB-	0.125
interference	2.7900228781876013e-05
Text segmentation	0.16666666666666666
of dividing	0.00267379679144385
dividing written	0.3333333333333333
meaningful units	0.125
units ,	0.14285714285714285
as words	0.003484320557491289
or topics	0.0045045045045045045
topics .	0.14285714285714285
dividing	8.370068634562804e-05
to mental	0.0013280212483399733
humans when	0.08333333333333333
when reading	0.02857142857142857
reading text	0.125
processes implemented	0.2
implemented in	0.2
in computers	0.0018726591760299626
is non-trivial	0.0020325203252032522
non-trivial ,	0.5
because while	0.03333333333333333
while some	0.05
have explicit	0.009615384615384616
explicit word	0.2
word boundary	0.016666666666666666
boundary markers	0.16666666666666666
markers ,	0.3333333333333333
word spaces	0.016666666666666666
spaces of	0.2
written English	0.038461538461538464
English and	0.08108108108108109
the distinctive	0.0006920415224913495
distinctive initial	0.5
initial ,	0.3333333333333333
, medial	0.0005614823133071309
medial and	1.0
and final	0.001445086705202312
final letter	0.1111111111111111
of Arabic	0.00089126559714795
Arabic ,	0.25
such signals	0.008130081300813009
are sometimes	0.004149377593360996
sometimes ambiguous	0.07692307692307693
all written	0.06976744186046512
non-trivial	5.5800457563752025e-05
medial	2.7900228781876013e-05
<s> Compare	0.0007686395080707148
Compare speech	1.0
dividing speech	0.3333333333333333
into linguistically	0.01282051282051282
linguistically meaningful	1.0
meaningful portions	0.125
portions .	1.0
Compare	2.7900228781876013e-05
linguistically	2.7900228781876013e-05
portions	2.7900228781876013e-05
In English	0.01904761904761905
and many	0.001445086705202312
languages using	0.02
the Latin	0.0006920415224913495
Latin alphabet	0.25
space is	0.2
good approximation	0.07692307692307693
approximation of	0.16666666666666666
word delimiter	0.016666666666666666
delimiter .	1.0
delimiter	2.7900228781876013e-05
-LRB- Some	0.0027100271002710027
Some examples	0.047619047619047616
examples where	0.041666666666666664
space character	0.2
character alone	0.045454545454545456
alone may	0.25
be sufficient	0.004219409282700422
sufficient include	0.2
include contractions	0.037037037037037035
contractions like	0.5
like ca	0.03571428571428571
ca n't	1.0
n't for	0.25
for can	0.0036101083032490976
ca	2.7900228781876013e-05
However the	0.02702702702702703
the equivalent	0.0006920415224913495
equivalent to	0.2
this character	0.01098901098901099
character is	0.09090909090909091
not found	0.008928571428571428
written scripts	0.038461538461538464
scripts ,	0.3333333333333333
without it	0.07692307692307693
it word	0.008547008547008548
word segmentation	0.05
a difficult	0.001226993865030675
difficult problem	0.03571428571428571
Languages which	0.3333333333333333
which do	0.007246376811594203
a trivial	0.001226993865030675
trivial word	0.25
segmentation process	0.030303030303030304
process include	0.027777777777777776
include Chinese	0.037037037037037035
Japanese ,	0.125
sentences but	0.02631578947368421
not words	0.026785714285714284
are delimited	0.012448132780082987
delimited ,	0.5
, Thai	0.0005614823133071309
Thai and	0.5
and Lao	0.001445086705202312
Lao ,	1.0
where phrases	0.02857142857142857
and Vietnamese	0.001445086705202312
Vietnamese ,	1.0
where syllables	0.02857142857142857
syllables but	0.5
delimited .	0.25
delimited	0.00011160091512750405
Lao	2.7900228781876013e-05
Vietnamese	2.7900228781876013e-05
some writing	0.012048192771084338
systems however	0.008928571428571428
the Ge'ez	0.0006920415224913495
Ge'ez script	1.0
script used	0.25
for Amharic	0.0036101083032490976
Amharic and	1.0
and Tigrinya	0.001445086705202312
Tigrinya among	1.0
are explicitly	0.004149377593360996
explicitly delimited	0.25
delimited -LRB-	0.25
-LRB- at	0.0027100271002710027
least historically	0.2
historically -RRB-	0.5
a non-whitespace	0.001226993865030675
non-whitespace character	1.0
character .	0.045454545454545456
Ge'ez	2.7900228781876013e-05
Amharic	2.7900228781876013e-05
Tigrinya	2.7900228781876013e-05
non-whitespace	2.7900228781876013e-05
The Unicode	0.005208333333333333
Unicode Consortium	1.0
Consortium has	1.0
has published	0.011904761904761904
a Standard	0.001226993865030675
Standard Annex	0.5
Annex on	1.0
on Text	0.0047169811320754715
Text Segmentation	0.16666666666666666
Segmentation ,	1.0
, exploring	0.0005614823133071309
exploring the	1.0
the issues	0.0006920415224913495
issues of	0.2
of segmentation	0.00089126559714795
segmentation in	0.030303030303030304
in multiscript	0.0018726591760299626
multiscript texts	1.0
Unicode	2.7900228781876013e-05
Consortium	2.7900228781876013e-05
Annex	2.7900228781876013e-05
Segmentation	2.7900228781876013e-05
exploring	2.7900228781876013e-05
multiscript	2.7900228781876013e-05
Word splitting	0.2857142857142857
splitting is	0.5
parsing concatenated	0.03571428571428571
concatenated text	1.0
i.e. text	0.05263157894736842
contains no	0.1
no spaces	0.07692307692307693
spaces or	0.2
other word	0.014285714285714285
word separators	0.016666666666666666
separators -RRB-	1.0
to infer	0.0013280212483399733
infer where	1.0
where word	0.02857142857142857
word breaks	0.016666666666666666
breaks exist	0.5
exist .	1.0
splitting	5.5800457563752025e-05
concatenated	2.7900228781876013e-05
separators	2.7900228781876013e-05
infer	2.7900228781876013e-05
exist	2.7900228781876013e-05
splitting may	0.5
may also	0.019230769230769232
also refer	0.014492753623188406
of hyphenation	0.00089126559714795
hyphenation .	1.0
hyphenation	2.7900228781876013e-05
Sentence segmentation	0.4
segmentation Sentence	0.030303030303030304
dividing a	0.3333333333333333
language into	0.006756756756756757
into its	0.01282051282051282
its component	0.02857142857142857
component sentences	0.2
using punctuation	0.01694915254237288
particularly the	0.2
full stop	0.4
stop character	1.0
reasonable approximation	0.5
approximation .	0.16666666666666666
stop	5.5800457563752025e-05
However even	0.02702702702702703
English this	0.02702702702702703
not trivial	0.008928571428571428
trivial due	0.25
character for	0.045454545454545456
for abbreviations	0.0036101083032490976
which may	0.007246376811594203
may or	0.019230769230769232
not also	0.008928571428571428
also terminate	0.014492753623188406
terminate a	1.0
terminate	2.7900228781876013e-05
example Mr.	0.012345679012345678
Mr. is	0.5
not its	0.008928571428571428
own sentence	0.16666666666666666
`` Mr.	0.005291005291005291
Mr. Smith	0.5
Smith went	1.0
the shops	0.0006920415224913495
shops in	1.0
in Jones	0.0018726591760299626
Jones Street	1.0
Street .	0.3333333333333333
Mr.	5.5800457563752025e-05
Smith	2.7900228781876013e-05
shops	2.7900228781876013e-05
Jones	2.7900228781876013e-05
When processing	0.14285714285714285
processing plain	0.018518518518518517
plain text	1.0
, tables	0.0005614823133071309
tables of	0.3333333333333333
abbreviations that	0.2
contain periods	0.08333333333333333
periods can	0.3333333333333333
can help	0.0055248618784530384
help prevent	0.1111111111111111
prevent incorrect	1.0
incorrect assignment	0.3333333333333333
assignment of	0.5
of sentence	0.00089126559714795
plain	2.7900228781876013e-05
prevent	2.7900228781876013e-05
As with	0.05555555555555555
languages contain	0.02
contain punctuation	0.08333333333333333
punctuation characters	0.14285714285714285
are useful	0.004149377593360996
for approximating	0.0036101083032490976
approximating sentence	1.0
approximating	2.7900228781876013e-05
Other segmentation	0.14285714285714285
problems Processes	0.058823529411764705
Processes may	1.0
be required	0.004219409282700422
required to	0.14285714285714285
segment text	0.2222222222222222
segments besides	0.2
besides words	1.0
including morphemes	0.07142857142857142
morphemes -LRB-	0.3333333333333333
task usually	0.023809523809523808
usually called	0.03125
called morphological	0.05555555555555555
morphological analysis	0.3333333333333333
, paragraphs	0.0005614823133071309
paragraphs ,	0.25
, topics	0.0005614823133071309
topics or	0.14285714285714285
discourse turns	0.027777777777777776
turns .	0.3333333333333333
Processes	2.7900228781876013e-05
besides	2.7900228781876013e-05
A document	0.02
contain multiple	0.08333333333333333
multiple topics	0.07692307692307693
topics ,	0.14285714285714285
computerized text	0.5
segmentation may	0.030303030303030304
to discover	0.0013280212483399733
discover these	1.0
these topics	0.023809523809523808
topics automatically	0.14285714285714285
and segment	0.001445086705202312
segment the	0.1111111111111111
text accordingly	0.006289308176100629
accordingly .	1.0
discover	2.7900228781876013e-05
accordingly	2.7900228781876013e-05
The topic	0.005208333333333333
topic boundaries	0.125
boundaries may	0.09090909090909091
be apparent	0.004219409282700422
apparent from	1.0
from section	0.009615384615384616
section titles	0.16666666666666666
titles and	0.5
and paragraphs	0.001445086705202312
paragraphs .	0.25
apparent	2.7900228781876013e-05
cases one	0.05555555555555555
one needs	0.015384615384615385
use techniques	0.013888888888888888
techniques similar	0.043478260869565216
different approaches	0.02040816326530612
tried .	0.3333333333333333
segmentation approaches	0.030303030303030304
approaches Automatic	0.03571428571428571
of implementing	0.00089126559714795
implementing a	1.0
computer process	0.022727272727272728
implementing	2.7900228781876013e-05
When punctuation	0.14285714285714285
and similar	0.001445086705202312
similar clues	0.037037037037037035
clues are	0.3333333333333333
consistently available	0.3333333333333333
the segmentation	0.0006920415224913495
segmentation task	0.030303030303030304
task often	0.023809523809523808
often requires	0.022727272727272728
requires fairly	0.0625
fairly non-trivial	0.25
non-trivial techniques	0.5
as statistical	0.003484320557491289
statistical decision-making	0.030303030303030304
decision-making ,	1.0
, large	0.0005614823133071309
large dictionaries	0.043478260869565216
dictionaries ,	1.0
as consideration	0.003484320557491289
consideration of	0.3333333333333333
semantic constraints	0.047619047619047616
constraints .	0.25
decision-making	2.7900228781876013e-05
dictionaries	2.7900228781876013e-05
<s> Effective	0.0007686395080707148
Effective natural	1.0
systems and	0.008928571428571428
segmentation tools	0.06060606060606061
tools usually	0.16666666666666666
usually operate	0.03125
operate on	1.0
on text	0.0047169811320754715
specific domains	0.047619047619047616
and sources	0.001445086705202312
Effective	2.7900228781876013e-05
operate	2.7900228781876013e-05
, processing	0.0005614823133071309
processing text	0.018518518518518517
text used	0.006289308176100629
in medical	0.0018726591760299626
records is	0.25
different problem	0.02040816326530612
problem than	0.022727272727272728
than processing	0.022222222222222223
processing news	0.018518518518518517
or real	0.0045045045045045045
real estate	0.1111111111111111
estate advertisements	1.0
estate	2.7900228781876013e-05
of developing	0.00089126559714795
developing text	0.25
tools starts	0.16666666666666666
starts with	0.5
with collecting	0.00546448087431694
collecting a	1.0
large corpus	0.043478260869565216
application domain	0.07142857142857142
collecting	2.7900228781876013e-05
two general	0.034482758620689655
general approaches	0.045454545454545456
: Manual	0.00980392156862745
Manual analysis	0.3333333333333333
and writing	0.001445086705202312
writing custom	0.1111111111111111
custom software	0.5
software Annotate	0.037037037037037035
Annotate the	1.0
the sample	0.0006920415224913495
sample corpus	0.3333333333333333
corpus with	0.03225806451612903
with boundary	0.00546448087431694
boundary information	0.16666666666666666
information and	0.021739130434782608
use Machine	0.013888888888888888
Machine Learning	0.1111111111111111
Learning Some	1.0
Some text	0.047619047619047616
segmentation systems	0.030303030303030304
systems take	0.008928571428571428
any markup	0.03225806451612903
markup like	1.0
like HTML	0.03571428571428571
HTML and	1.0
and know	0.001445086705202312
know document	0.5
document formats	0.027777777777777776
formats like	1.0
like PDF	0.03571428571428571
PDF to	1.0
provide additional	0.16666666666666666
additional evidence	0.16666666666666666
evidence for	0.5
for sentence	0.0036101083032490976
sentence and	0.020833333333333332
and paragraph	0.001445086705202312
paragraph boundaries	0.3333333333333333
Annotate	2.7900228781876013e-05
Learning	2.7900228781876013e-05
markup	2.7900228781876013e-05
HTML	2.7900228781876013e-05
formats	2.7900228781876013e-05
PDF	2.7900228781876013e-05
