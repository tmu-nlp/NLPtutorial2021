{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "0f8c0e69-6066-423b-b4ad-fb08329e85d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import math \n",
    "\n",
    "def beam_search(words,possible_tags,P_T,P_E):\n",
    "    B=3\n",
    "    l=len(words)\n",
    "    best_score={\"0 <s>\":0}\n",
    "    best_edge={\"0 <s>\":None}\n",
    "    active_tags=defaultdict(lambda:0)\n",
    "    active_tags[0]=[\"<s>\"]\n",
    "    lam=0.05\n",
    "    N=10**5\n",
    "    for i in range(l):\n",
    "        my_best={}\n",
    "        for prev in active_tags[i]:\n",
    "            for next_ in possible_tags:\n",
    "                if f\"{i} {prev}\" in best_score and f\"T {prev} {next_}\" in P_T:\n",
    "                    score=best_score[f\"{i} {prev}\"]-math.log(P_T[f\"T {prev} {next_}\"],2)-math.log(lam*P_E[f\"E {next_} {words[i]}\"]+(1-lam)/N,2)\n",
    "                    if f\"{i+1} {next_}\" not in best_score or best_score[f\"{i+1} {next_}\"]>score:\n",
    "                        best_score[f\"{i+1} {next_}\"]=score\n",
    "                        best_edge[f\"{i+1} {next_}\"]=f\"{i} {prev}\"\n",
    "                        my_best[next_]=score\n",
    "        sort_tags=[k for k in sorted(my_best, key=my_best.get)]\n",
    "        active_tags[i+1]=sort_tags[:B]\n",
    "       \n",
    "    for tag in possible_tags:\n",
    "        if f\"T {tag} <\\s>\" in P_T and f\"{l} {tag}\" in best_score:\n",
    "            score=best_score[f\"{l} {tag}\"]-math.log(P_T[f\"T {tag} <\\s>\"])\n",
    "            if f\"{l+1} <\\s>\" not in best_score or best_score[f\"{l+1} <\\s>\"]>score:\n",
    "                best_score[f\"{l+1} <\\s>\"]=score\n",
    "                best_edge[f\"{l+1} <\\s>\"]=f\"{l} {tag}\"\n",
    "            \n",
    "    tag_path=[]\n",
    "    next_edge=best_edge[f\"{l+1} <\\s>\"]\n",
    "    while next_edge!=\"0 <s>\":\n",
    "        no,tag=next_edge.split()\n",
    "        tag_path.append(tag)\n",
    "        next_edge=best_edge[next_edge]\n",
    "    tag_path.reverse()\n",
    "    return tag_path\n",
    "\n",
    "\n",
    "with open(\"wiki-en-train.norm_pos.txt\",\"r\",encoding=\"utf-8\")as f:\n",
    "    emit=defaultdict(int)\n",
    "    transition=defaultdict(int)\n",
    "    context=defaultdict(int)\n",
    "    for line in f:\n",
    "        previous=\"<s>\"\n",
    "        context[previous]+=1\n",
    "        wordtags=line.strip().split()\n",
    "        for wordtag in wordtags:\n",
    "            word,tag=wordtag.split(\"_\")\n",
    "            transition[f\"{previous} {tag}\"]+=1\n",
    "            context[f\"{tag}\"]+=1\n",
    "            emit[f\"{tag} {word}\"]+=1\n",
    "            previous=tag\n",
    "        transition[f\"{previous} <\\s>\"]+=1\n",
    "    P_T=defaultdict(float)\n",
    "    P_E=defaultdict(float)\n",
    "    possible_tags=defaultdict(int)\n",
    "    for key,value in transition.items():\n",
    "        tag1,tag2=key.split()\n",
    "        possible_tags[tag1]+=1\n",
    "    \n",
    "    for key,value in transition.items():\n",
    "        previous,word=key.split(\" \")\n",
    "        prob=value/context[previous]\n",
    "        P_T[f\"T {key}\"]=prob\n",
    "\n",
    "    for key,value in emit.items():\n",
    "        previous,word=key.split(\" \")\n",
    "        prob=value/context[previous]\n",
    "        P_E[f\"E {key}\"]=prob\n",
    "    \n",
    "        \n",
    "        \n",
    " \n",
    "    with open(\"wiki-en-test.norm.txt\",\"r\",encoding=\"utf-8\") as f1:\n",
    "        for line in f1:\n",
    "            X=line.strip().split()\n",
    "            tag_path=beam_search(X,possible_tags,P_T,P_E)\n",
    "            with open(\"answer.txt\",\"a\",encoding=\"utf-8\") as ans:\n",
    "                ans.write(\" \".join(tag_path)+\"\\n\")\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "2f79207f-0c35-4735-bda5-5b5fc2c90bed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.873767258382643\n"
     ]
    }
   ],
   "source": [
    "with open(\"answer.txt\",\"r\",encoding=\"utf-8\") as ans:\n",
    "    Y_test=[]\n",
    "    for line in ans:\n",
    "        tags=line.strip().split()\n",
    "        Y_test.append(tags)\n",
    "\n",
    "with open(\"wiki-en-test.norm_pos.txt\",\"r\",encoding=\"utf-8\") as f2:\n",
    "    Y_ans=[]\n",
    "    for line in f2:\n",
    "        word_pos=line.strip().split()\n",
    "        Y=[]\n",
    "        for w_p in word_pos:\n",
    "            x,y=w_p.split(\"_\")\n",
    "            Y.append(y)\n",
    "        Y_ans.append(Y)\n",
    "    \n",
    "    count=0\n",
    "    correct=0\n",
    "    for test,ans in zip(Y_test,Y_ans):\n",
    "        for i,j in zip(test,ans):\n",
    "            count+=1\n",
    "            if(i==j):\n",
    "                correct+=1\n",
    "    print(str(correct/count))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
